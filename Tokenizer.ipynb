{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will develop a custom tokenizer, train it and store it.\n",
    "\n",
    "\n",
    "In order to do this, this notebook consists of the following sections:\n",
    "- Data preparation: loading all required data in the proper form\n",
    "- EDA: exploration of the data [of dit niet meer?]\n",
    "- Creating a dictionary with the morphological segmentations of Dutch words\n",
    "- Creating the tokenizer using this dictionary\n",
    "- Evaluating the tokenizer and comparing it to other tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two main sources of data:\n",
    "- OSCAR: a corpus with a lot of Dutch text data\n",
    "- CELEX: a database with information about Dutch words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSCAR \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of ways to work with the OSCAR corpus. The main choice we have to make is whether we want to download the corpus to our personal computer first, or download the dataset (in segments, as the dataset is too large to lead into memory at once) from the Hugging Face library when we want to use it for a certain task. \n",
    "\n",
    "Downloading the corpus manually is done in 45 segments. This means we could load one of these segments into memory at once, but it is easier to make a generator that behaves in the same way as the one that is necessary for streaming the dataset directly from Hugging Face, so that our functions can handle both. \n",
    "\n",
    "We will also create a small dataset in that can be used for testing some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset, DatasetDict\n",
    "# import os\n",
    "\n",
    "\n",
    "# # function that returns a dictionary with a generator for every existing OSCAR file in this computer\n",
    "# def create_local_oscar_generators(data_path, i=0, j=0):\n",
    "\n",
    "#     out = {}\n",
    "    \n",
    "#     if j > i:\n",
    "#         n = j - i\n",
    "\n",
    "#         for x in range(i, j+1):\n",
    "#             full_path = os.path.join(data_path, 'OSCAR', f'nl_part_{x}.txt')\n",
    "#             if os.path.isfile(full_path):\n",
    "#                 out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "        \n",
    "#         if len(out) != n + 1:\n",
    "#             print('Not all parts requested are on this computer')\n",
    "    \n",
    "#     else:\n",
    "\n",
    "#         for i in range(1, 50):\n",
    "#             full_path = os.path.join(data_path, 'OSCAR', f'nl_part_{i}.txt')\n",
    "#             if os.path.isfile(full_path):\n",
    "#                 out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# # function that creates one generator out of multiple generators\n",
    "# def create_super_generator(generator_dict, list_input=False):\n",
    "\n",
    "#     if list_input:\n",
    "#         for generator in generator_dict:\n",
    "#             yield from generator\n",
    "#     else:\n",
    "#         for generator in generator_dict.values():\n",
    "#             yield from generator\n",
    "\n",
    "\n",
    "# # one function to create OSCAR generator by combining n parts of the dataset, from part i to part j\n",
    "# def create_super_local_oscar_generator(data_path, i=0, j=0):\n",
    "    \n",
    "#     if j > i:\n",
    "#         generators = create_local_oscar_generators(data_path, i=i, j=j)\n",
    "#     else:\n",
    "#         generators = create_local_oscar_generators(data_path)\n",
    "\n",
    "#     return create_super_generator(generators)\n",
    "\n",
    "\n",
    "# # function to create a dataset with text \n",
    "# def create_test_set(dataset_generator, start, end):\n",
    "#     it = iter(dataset_generator)\n",
    "#     for _ in range(start):\n",
    "#         next(it)\n",
    "#     for _ in range(end - start + 1):\n",
    "#         yield next(it)\n",
    "\n",
    "\n",
    "# # function to turn a generator that returns a dictionary with 'text' as key into a generator of the values\n",
    "# def create_text_generator(gen):\n",
    "#     for i in gen:\n",
    "#         yield i['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set path to datasets\n",
    "# data_path = '/Users/jan/Documents/Master/Thesis/Code/Datasets'\n",
    "\n",
    "# # download from huggingface\n",
    "# dataset_from_hub = load_dataset('oscar', 'unshuffled_deduplicated_nl', split='train', streaming=True, trust_remote_code=True)\n",
    "\n",
    "# # create from local files\n",
    "# oscar1 = os.path.join(data_path, 'OSCAR', 'nl_part_1.txt')\n",
    "# data_files = {\"train\": oscar1}\n",
    "# oscar_it_dict = load_dataset('text', data_files=data_files, split='train', streaming=True)\n",
    "\n",
    "# # create dictionary with a generator for every part\n",
    "# gen_dict = create_local_oscar_generators(data_path)\n",
    "\n",
    "# # create from local files\n",
    "# oscar_gen_1 = gen_dict['oscar1']\n",
    "# oscar_gen_2 = gen_dict['oscar2']\n",
    "\n",
    "# # create super generator from all OSCAR files on computer\n",
    "# oscar_gen_super = create_super_local_oscar_generator(data_path)\n",
    "\n",
    "# # create small dataset (uneven number of lines)\n",
    "# oscar_gen_small = create_test_set(oscar_gen_1, 0, 100007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CELEX database consists of more than 10 datasets, all focused on different features of language. For out purpuses, we use two of these datasets:\n",
    "- one with morphological segmentations\n",
    "- one with information that we can use to create groups of related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to datasets\n",
    "data_path = '/Users/jan/Documents/Master/Thesis/Code/Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex = os.path.join(data_path, 'CELEX-2-NL', 'DUTCH', 'DML', 'DML.CD')\n",
    "celex2 = os.path.join(data_path, 'CELEX-2-NL', 'DUTCH', 'DFW', 'DFW.CD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simlex(simlex999, scores=False):\n",
    "    # create list with a tuple for every word pair in the form of (word_1, word_2, similarity score, POS-tag)\n",
    "    word_pairs = []\n",
    "\n",
    "    # create a set with all words\n",
    "    words_set = set([])\n",
    "\n",
    "    with open(simlex999) as simlex:\n",
    "        \n",
    "        next(simlex) # skip first line\n",
    "        \n",
    "        for line in simlex:\n",
    "    \n",
    "            split = line.strip().split('\\t')\n",
    "            word_pairs.append(tuple(split))\n",
    "            words_set.add(split[0])\n",
    "            words_set.add(split[1])\n",
    "\n",
    "    # create a list of unique words\n",
    "    simlex_words = list(words_set)\n",
    "\n",
    "    if scores:\n",
    "        return word_pairs\n",
    "    else:\n",
    "        return simlex_words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_path = os.path.join(data_path, 'SimLex-999', 'SimLex-999-Dutch-final.txt')\n",
    "simlex_words = load_simlex(simlex_path)\n",
    "simlex_pairs = load_simlex(simlex_path, scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morfessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an existing module that is based on several (statistical) methods to morphilogically segment a word. A model is trained with a list of words. We will first do this for English and then for Dutch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import words\n",
    "\n",
    "\n",
    "# # using nltk word corpus as training data\n",
    "# words = words.words()\n",
    "# outfile = open(\"words\", \"w\")\n",
    "# for word in words:\n",
    "#     outfile.write(word+\"\\n\")\n",
    "\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n"
     ]
    }
   ],
   "source": [
    "# import math\n",
    "# import morfessor\n",
    "\n",
    "# # function for adjusting the counts of each compound\n",
    "# def log_func(x):\n",
    "#     return int(round(math.log(x + 1, 2)))\n",
    "\n",
    "# infile = \"words\"\n",
    "# io = morfessor.MorfessorIO()\n",
    "# train_data = list(io.read_corpus_file(infile))\n",
    "# model = morfessor.BaselineModel()\n",
    "# model.load_data(train_data, count_modifier=log_func)\n",
    "# model.train_batch()\n",
    "# io.write_binary_model_file(\"model.bin\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un', 'test', 'ably']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model_file = \"model.bin\"\n",
    "# io = morfessor.MorfessorIO()\n",
    "# model = io.read_binary_model_file(model_file)\n",
    "\n",
    "# word = 'untestably'\n",
    "# # for segmenting new words we use the viterbi_segment(compound) method\n",
    "# print(model.viterbi_segment(word)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dutch version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a Dutch model now. For this we only need a list of Dutch words. I have used this one: https://github.com/OpenTaal/opentaal-wordlist\n",
    "\n",
    "\n",
    "It contains over 400.000 Dutch words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n"
     ]
    }
   ],
   "source": [
    "# def log_func(x):\n",
    "#     return int(round(math.log(x + 1, 2)))\n",
    "\n",
    "# infile = \"wordlist.txt\"\n",
    "# io = morfessor.MorfessorIO()\n",
    "# train_data = list(io.read_corpus_file(infile))\n",
    "# model_nl = morfessor.BaselineModel()\n",
    "# model_nl.load_data(train_data, count_modifier=log_func)\n",
    "# model_nl.train_batch()\n",
    "# io.write_binary_model_file(\"model_nl.bin\", model_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['huis', 'arrest']\n"
     ]
    }
   ],
   "source": [
    "# model_file = \"model_nl.bin\"\n",
    "# io = morfessor.MorfessorIO()\n",
    "# model_nl = io.read_binary_model_file(model_file)\n",
    "\n",
    "# word = 'huisarrest'\n",
    "# # for segmenting new words we use the viterbi_segment(compound) method\n",
    "# print(model_nl.viterbi_segment(word)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to use this model in our tokenization algorithm. Let's first see how long it takes to tokenize all 400.000 words with this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_nl = []\n",
    "\n",
    "# with open('wordlist.txt') as file:\n",
    "#     for i, line in enumerate(file):\n",
    "#         words_nl.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmented_words = {}\n",
    "# for word in words_nl:\n",
    "#     segmented_words[word] = model_nl.viterbi_segment(word)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily this is pretty fast, which means no problems will arise when we use it in our tokenization algorithm.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomTokenizerMorfessor:\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.vocab = {'UNK': 0}\n",
    "#         self.n = 0\n",
    "#         self.max_vocab_size = 50000\n",
    "#         self.model = morfessor.MorfessorIO().read_binary_model_file(\"model_nl.bin\") # this could of course be done differently, for instance by passing the model as argument, but it's fine for now\n",
    "    \n",
    "#     def get_vocab(self):\n",
    "#         return self.vocab # note: we should probably use a getter here, but for now this is ok\n",
    "    \n",
    "#     def normalize(self, seq):\n",
    "#         return seq.lower() \n",
    "    \n",
    "#     def pre_tokenize(self, seq):\n",
    "#         return seq.split()\n",
    "    \n",
    "#     def create_vocab(self, tokens):\n",
    "#         for token in tokens:\n",
    "#             if token not in self.vocab and len(self.get_vocab()) < self.max_vocab_size:\n",
    "#                 self.n += 1\n",
    "#                 self.vocab[token] = self.n\n",
    "    \n",
    "#     def encode(self, seq):\n",
    "#         seq = self.pre_tokenize(self.normalize(seq))\n",
    "#         seq = [self.model.viterbi_segment(word)[0] for word in seq]\n",
    "#         seq = [item for sublist in seq for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "#         return [self.vocab[token] if token in self.vocab else self.vocab['UNK'] for token in seq]\n",
    "    \n",
    "#     def decode(self, ids: list[int]):\n",
    "#         assert type(ids) == list\n",
    "#         assert type(ids[0]) == int   # dit kan wel netter, volgens mij kan het al met alleen type hints\n",
    "#         inverted_vocab = {value: key for key, value in self.vocab.items()}  # met een getter zou je dit niet elke keer opnieuw hoeven doen. Maar let altijd op of als je de een update je de ander ook update\n",
    "#         out = ''\n",
    "#         for idx in ids:\n",
    "#             out += inverted_vocab[idx] + ' '\n",
    "#         return out\n",
    "    \n",
    "#     def tokenize(self, seq):\n",
    "#         inverted_vocab = {value: key for key, value in self.vocab.items()}  # met een getter zou je dit niet elke keer opnieuw hoeven doen. Maar let altijd op of als je de een update je de ander ook update\n",
    "#         return [inverted_vocab[idx] if idx in inverted_vocab else inverted_vocab[0] for idx in self.encode(seq)]\n",
    "\n",
    "#     def __call__(self, seq):\n",
    "#         ids = self.encode(seq)\n",
    "#         types = [0 for token in ids]\n",
    "#         attention = [1 for token in ids]\n",
    "#         return {'input_ids': ids, 'token_type_ids': types, 'attention_mask': attention}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to use this morphological segmentation model in our tokenizer. Let's first see in how many unique parts the 400.000 words are split up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parts = set([])\n",
    "\n",
    "# for i in segmented_words.values():\n",
    "#     for j in i:\n",
    "#         parts.add(j)\n",
    "\n",
    "# parts = list(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 413937 words in the database are split up into 46463 unique units\n"
     ]
    }
   ],
   "source": [
    "# print(f'The {len(segmented_words)} words in the database are split up into {len(parts)} unique units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the more than 400.000 words can be represented by less than 47.000 tokens. This is actually a fairly common vocabulary size, so the first thing we can do is build a tokenizer with these 47.000 tokens as the vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA (CELEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find some more things about our dataset. In the 9th column we have the morphemes of a word. There are four options here:\n",
    "1. the entry is empty (because the word cannot be segmented and the word itself is not a morpheme)\n",
    "2. the entry has one morpheme that is identical with the word\n",
    "3. the entry has one morpheme that is not identical with the word\n",
    "4. the entry contains multiple morphemes, that when concatenated are identical to the word\n",
    "5. the entry contains multiple morphemes, that when concatenated are not identical to the word\n",
    "\n",
    "Let's see how often these things occur. We will first do this for the initial segmentations, so without an extra segmentation of parts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def initial_stats_celex(celex, print_info=True):\n",
    "\n",
    "#     n1 = {}\n",
    "#     n2 = {}\n",
    "#     n3 = {}\n",
    "#     n4 = {}\n",
    "#     n5 = {}\n",
    "#     doubles = {}\n",
    "\n",
    "\n",
    "#     with open(celex) as cd:\n",
    "#         for i, line in enumerate(cd):\n",
    "            \n",
    "#             line = line.strip().split('\\\\')\n",
    "            \n",
    "#             word = line[1]\n",
    "#             seg = line[8]\n",
    "#             morph = line[12]\n",
    "            \n",
    "#             if word in n1 or word in n2 or word in n3 or word in n4 or word in n5:\n",
    "#                 doubles[word] = i+1\n",
    "\n",
    "#             if len(seg) == 0:\n",
    "#                 n1[word] = i+1\n",
    "            \n",
    "#             else:\n",
    "#                 if not '+' in seg:\n",
    "#                     if word == seg:\n",
    "#                         n2[word] = i+1\n",
    "#                     else:\n",
    "#                         n3[word] = (i+1, seg)\n",
    "            \n",
    "#                 else:\n",
    "#                     split = seg.split('+')\n",
    "#                     concat = ''.join(split)\n",
    "\n",
    "#                     if concat == word:\n",
    "#                         n4[word] = i+1\n",
    "#                     else:\n",
    "#                         n5[word] = (i+1, seg)\n",
    "\n",
    "#     j = len(n1) + len(n2) + len(n3) + len(n4) + len(n5)\n",
    "\n",
    "#     print('---- Numbers for initial segmentation ----')\n",
    "#     print(f'Option 1 occurs {len(n1)} times ({round(100*len(n1)/j, 1)}%)')\n",
    "#     print(f'Option 2 occurs {len(n2)} times ({round(100*len(n2)/j, 1)}%)')\n",
    "#     print(f'Option 3 occurs {len(n3)} times ({round(100*len(n3)/j, 1)}%)')\n",
    "#     print(f'Option 4 occurs {len(n4)} times ({round(100*len(n4)/j, 1)}%)')\n",
    "#     print(f'Option 5 occurs {len(n5)} times ({round(100*len(n5)/j, 1)}%)')\n",
    "\n",
    "\n",
    "\n",
    "#     # do the same after an extra loop\n",
    "    \n",
    "# def stats_after_loop(segmentations):\n",
    "\n",
    "#     n1 = {}\n",
    "#     n2 = {}\n",
    "#     n3 = {}\n",
    "#     n4 = {}\n",
    "#     n5 = {}\n",
    "\n",
    "#     for word, seg in segmentations.items():\n",
    "#         if len(seg) == 0:\n",
    "#             n1[word] = seg\n",
    "#         if len(seg) == 1:\n",
    "#             if word == seg[0]:\n",
    "#                 n2[word] = seg\n",
    "#             else:\n",
    "#                 n3[word] = seg\n",
    "#         if len(seg) > 1:\n",
    "#             if word == ''.join(seg):\n",
    "#                 n4[word] = seg\n",
    "#             else:\n",
    "#                 n5[word] = seg \n",
    "\n",
    "\n",
    "#     j = len(n1) + len(n2) + len(n3) + len(n4) + len(n5)\n",
    "\n",
    "#     print('---- Numbers after extra segmentation step ----')\n",
    "#     print(f'Option 1 occurs {len(n1)} times ({round(100*len(n1)/j, 1)}%)')\n",
    "#     print(f'Option 2 occurs {len(n2)} times ({round(100*len(n2)/j, 1)}%)')\n",
    "#     print(f'Option 3 occurs {len(n3)} times ({round(100*len(n3)/j, 1)}%)')\n",
    "#     print(f'Option 4 occurs {len(n4)} times ({round(100*len(n4)/j, 1)}%)')\n",
    "#     print(f'Option 5 occurs {len(n5)} times ({round(100*len(n5)/j, 1)}%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that there are words that occur more than once in the dataset. Let's see how many times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates occur 539 times (0.0043%)\n"
     ]
    }
   ],
   "source": [
    "# def count_duplicates(celex):\n",
    "\n",
    "#     dub = {}\n",
    "#     duplicates = {}\n",
    "\n",
    "#     with open(celex) as cd:\n",
    "#         for i, line in enumerate(cd):\n",
    "            \n",
    "#             line = line.strip().split('\\\\')\n",
    "            \n",
    "#             word = line[1]\n",
    "#             seg = line[8]\n",
    "#             morph = line[12]\n",
    "\n",
    "#             if not word in dub:\n",
    "#                 dub[word] = seg\n",
    "            \n",
    "#             else:\n",
    "#                 if not dub[word] == seg:\n",
    "#                     duplicates[word] = (i, dub[word], seg)\n",
    "\n",
    "\n",
    "#     print(f'Duplicates occur {len(duplicates)} times ({round(len(duplicates)/i, 4)}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a segmentation dictionary from CELEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to create dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import json\n",
    "\n",
    "def load_json(path):\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        my_dict = json.load(f)\n",
    "    return my_dict\n",
    "\n",
    "def store_json(path, object):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(object, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_substrings(input_string):\n",
    "    \n",
    "    # Regular expression to match sequences of letters\n",
    "    pattern = re.compile(r'([a-zA-Z]+)')\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = pattern.findall(input_string)\n",
    "    \n",
    "    return [part for part in matches if not part in ['N', 'V', 'P', 'A', 'PA', 'PV']]\n",
    "\n",
    "\n",
    "\n",
    "def create_initial_dataframe(celex):\n",
    "    \n",
    "    new_dict2 = {}\n",
    "\n",
    "    with open(celex) as cd:\n",
    "        for line in cd:\n",
    "\n",
    "            \n",
    "            line = line.strip().split('\\\\')\n",
    "\n",
    "            \n",
    "            if line[12] == '':\n",
    "                cat = line[-1]\n",
    "            else:\n",
    "                cat = line[12][-2]\n",
    "\n",
    "            word = line[1]\n",
    "            seg = line[8]\n",
    "            morph = line[12]\n",
    "            parts = extract_substrings(morph)\n",
    "\n",
    "            new_dict2[word] = {'cat': cat, 'segments1': seg, 'segments2': parts, 'info': morph}\n",
    "\n",
    "    return new_dict2\n",
    "\n",
    "\n",
    "def create_segmentations_from_base(base, only_same_spelling=False):\n",
    "\n",
    "    new_dict_updated2 = {}\n",
    "\n",
    "    for word, dic in base.items():\n",
    "        \n",
    "        seg = dic['segments1']\n",
    "        split1 = seg.split('+')\n",
    "        split2 = dic['segments2']\n",
    "\n",
    "        concat1 = ''.join(split1)\n",
    "        concat2 = ''.join(split2)\n",
    "\n",
    "        if only_same_spelling:\n",
    "            if word == concat2:\n",
    "                new_dict_updated2[word] = split2\n",
    "            else:\n",
    "                if word == concat1:\n",
    "                        new_dict_updated2[word] = split1\n",
    "                else:\n",
    "                    if len(base[word]['segments1']) == 0 and len(base[word]['segments2']) == 0:\n",
    "                        new_dict_updated2[word] = []\n",
    "        else:\n",
    "            if word == concat2:\n",
    "                new_dict_updated2[word] = split2\n",
    "            else:\n",
    "                if word == concat1:\n",
    "                        new_dict_updated2[word] = split1\n",
    "                else:\n",
    "                    if len(base[word]['segments1']) == 0 and len(base[word]['segments2']) == 0:\n",
    "                        new_dict_updated2[word] = []\n",
    "                    else:\n",
    "                        if len(split1) > len(split2):\n",
    "                            new_dict_updated2[word] = split1\n",
    "                        else:\n",
    "                            new_dict_updated2[word] = split2\n",
    "        \n",
    "    return new_dict_updated2\n",
    "\n",
    "\n",
    "def add_basic_verbs(df, base):\n",
    "\n",
    "    new_dict_updated2 = copy.deepcopy(df)\n",
    "\n",
    "    for word, dic in base.items():\n",
    "        \n",
    "        seg = dic['segments1']\n",
    "        split1 = seg.split('+')\n",
    "        split2 = dic['segments2']\n",
    "\n",
    "        concat1 = ''.join(split1)\n",
    "        concat2 = ''.join(split2)\n",
    "\n",
    "        if dic['cat'] == 'V' and concat2 + 'en' == word:\n",
    "            split2.append('en')\n",
    "            new_dict_updated2[word] = split2\n",
    "\n",
    "        else:\n",
    "            if dic['cat'] == 'V' and concat1 + 'en' == word:\n",
    "                split1.append('en')\n",
    "                new_dict_updated2[word] = split1\n",
    "  \n",
    "    \n",
    "    return new_dict_updated2\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentations_extra_loop(df):\n",
    "    \n",
    "    segmentations_new = {}\n",
    "\n",
    "    n1 = 0\n",
    "\n",
    "    for word, segments in df.items():\n",
    "        seg = []\n",
    "        for unit in segments:\n",
    "            if not unit in df:\n",
    "                seg.append(unit)\n",
    "            else:\n",
    "                if len(df[unit]) == 0:\n",
    "                    seg.append(unit)\n",
    "                elif len(df[unit]) == 1:   # note: we must choose whether we want to replace words that have a single morpheme that is not identical with the word\n",
    "                    #seg.append(unit)      # we do this in another function now, so I don't do it here\n",
    "                    seg.append(df[unit][0])\n",
    "                else:\n",
    "                    seg += df[unit] \n",
    "    \n",
    "        segmentations_new[word] = seg\n",
    "    \n",
    "    return segmentations_new\n",
    "\n",
    "\n",
    "# this function adds all the morphemes in a dictionary to the dictionary with the morpheme as key and as value\n",
    "def add_morphemes_to_dict(d):\n",
    "\n",
    "    dic = d\n",
    "    n = 0\n",
    "\n",
    "    morfs = set([])\n",
    "\n",
    "    for word, segs in dic.items():\n",
    "        for seg in segs:\n",
    "            morfs.add(seg)\n",
    "\n",
    "    for morf in morfs:\n",
    "        if not morf in dic or len(dic[morf]) == 0:\n",
    "            n += 1\n",
    "            dic[morf] = [morf]\n",
    "\n",
    "    return dic\n",
    "\n",
    "\n",
    "\n",
    "# this function adds the word as segmentation of itself for all words that have an empty list as segmentation\n",
    "def add_empty_segmentations(df):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for word, seg in df.items():\n",
    "        if len(seg) == 0:\n",
    "            out[word] = [word]\n",
    "        else:\n",
    "            out[word] = seg\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# this function replaces the single morphemes that are not identical with the word with the word\n",
    "def replace_non_identical_morphs(df):\n",
    "     \n",
    "\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for word, seg in df.items():\n",
    "        if len(seg) == 1 and not word == seg[0]:\n",
    "            out[word] = [word]\n",
    "        else:\n",
    "            out[word] = seg\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create dictionary with related words for every word\n",
    "def create_word_fams(celex2):\n",
    "\n",
    "    word_fams = {}\n",
    "\n",
    "    with open(celex2) as cd:\n",
    "        for line in cd:\n",
    "            line = line.strip().split('\\\\')\n",
    "            word = line[1]\n",
    "            fam = line[2]\n",
    "            word_fams[word] = fam\n",
    "    \n",
    "    return word_fams\n",
    "\n",
    "\n",
    "# function to make 'inverse' dict by value\n",
    "def group_keys_by_value(input_dict):\n",
    "\n",
    "    value_to_keys = {}\n",
    "    for key, value in input_dict.items():\n",
    "        if value not in value_to_keys:\n",
    "            value_to_keys[value] = []\n",
    "        value_to_keys[value].append(key)\n",
    "  \n",
    "    output_dict = {key: [k for k in value_to_keys[input_dict[key]] if k != key] for key in input_dict}\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "\n",
    "# function to create extra segmentation dataframe for a suffix\n",
    "def create_extra_dataframe(df, word_fams, suffix):\n",
    "\n",
    "    word_groups = group_keys_by_value(word_fams)\n",
    "    \n",
    "    related_words = {word: rels for word, rels in word_groups.items() if word in initial_dataframe}\n",
    "\n",
    "    plus = {}\n",
    "    segmentations_extra = {}\n",
    "\n",
    "    for word in segmentations:\n",
    "        for rel in related_words[word]:\n",
    "            if not rel in segmentations and word + suffix == rel:\n",
    "                plus[word] = rel\n",
    "\n",
    "    for word, mult in plus.items():\n",
    "        segmentations_extra[mult] = segmentations[word] + [suffix]\n",
    "    \n",
    "    return segmentations_extra\n",
    "\n",
    "\n",
    "\n",
    "def remove_ortho_changes(df):\n",
    "\n",
    "\n",
    "    return {word: seg for word, seg in df.items() if ''.join(seg) == word}\n",
    "\n",
    "\n",
    "# function to add conjugations of verbs\n",
    "# the non_words parameter is for the greedy / non-greedy approach\n",
    "def create_verb_segmentations(base, groups, non_words=False):\n",
    "\n",
    "    extra_segmentations = {}\n",
    "\n",
    "    if non_words:\n",
    "\n",
    "        for word, dic in base.items():\n",
    "            \n",
    "            seg = dic['segments1']\n",
    "            split1 = seg.split('+')\n",
    "            split2 = dic['segments2']\n",
    "\n",
    "            concat1 = ''.join(split1)\n",
    "            concat2 = ''.join(split2)\n",
    "\n",
    "\n",
    "            if dic['cat'] == 'V' and concat2 + 'en' == word:  # waarom gebeurt dit nooit?\n",
    "\n",
    "\n",
    "                extra_segmentations[concat2 + 'de'] = split2 + ['de']\n",
    "                extra_segmentations[concat2 + 'den'] = split2 + ['den']\n",
    "                extra_segmentations[concat2 + 'end'] = split2 + ['end']\n",
    "                extra_segmentations[concat2 + 'ende'] = split2 + ['end', 'e']\n",
    "                extra_segmentations[concat2 + 't'] = split2 + ['t']\n",
    "                extra_segmentations['ge' + concat2 + 'd'] = ['ge'] + split2 + ['d']\n",
    "                extra_segmentations['ge' + concat2 + 't'] = ['ge'] + split2 + ['t']\n",
    "\n",
    "                extra_segmentations[concat2 + 'er'] = split2 + ['er']\n",
    "                extra_segmentations[concat2 + 'eur'] = split2 + ['eur']\n",
    "                extra_segmentations[concat2 + 'ster'] = split2 + ['ster']\n",
    "                extra_segmentations[concat2 + 'euse'] = split2 + ['euse']\n",
    "\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if dic['cat'] == 'V' and concat1 + 'en' == word:\n",
    "\n",
    "\n",
    "                    extra_segmentations[concat1 + 'de'] = split1 + ['de']\n",
    "                    extra_segmentations[concat1 + 'den'] = split1 + ['den']\n",
    "                    extra_segmentations[concat1 + 'end'] = split1 + ['end']\n",
    "                    extra_segmentations[concat1 + 'ende'] = split1 + ['end', 'e']\n",
    "                    extra_segmentations[concat1 + 't'] = split1 + ['t']\n",
    "                    extra_segmentations['ge' + concat1 + 'd'] = ['ge'] + split1 + ['d']\n",
    "                    extra_segmentations['ge' + concat1 + 't'] = ['ge'] + split1 + ['t']\n",
    "\n",
    "                    extra_segmentations[concat1 + 'er'] = split2 + ['er']\n",
    "                    extra_segmentations[concat1 + 'eur'] = split2 + ['eur']\n",
    "                    extra_segmentations[concat1 + 'ster'] = split2 + ['ster']\n",
    "                    extra_segmentations[concat1 + 'euse'] = split2 + ['euse']\n",
    "\n",
    "                    # nog toevoegen: werkwoorden als wegfietsen -> weg-ge-fiets-t\n",
    "                    # hoe herken je deze? niet-greedy is het wel te doen denk ik\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        for word, dic in base.items():\n",
    "            \n",
    "            seg = dic['segments1']\n",
    "            split1 = seg.split('+')\n",
    "            split2 = dic['segments2']\n",
    "\n",
    "            concat1 = ''.join(split1)\n",
    "            concat2 = ''.join(split2)\n",
    "\n",
    "\n",
    "            if dic['cat'] == 'V' and concat2 + 'en' == word:  # waarom gebeurt dit nooit?\n",
    "\n",
    "                if concat2 + 'de' in groups[word] :\n",
    "                    extra_segmentations[concat2 + 'de'] = split2 + ['de']\n",
    "                if concat2 + 'den' in groups[word] :\n",
    "                    extra_segmentations[concat2 + 'den'] = split2 + ['den']\n",
    "                if concat2 + 'end' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'end'] = split2 + ['end']\n",
    "                if concat2 + 'ende' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'ende'] = split2 + ['end', 'e']\n",
    "                if concat2 + 't' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 't'] = split2 + ['t']\n",
    "                if 'ge' + concat2 + 'd' in groups[word]:\n",
    "                    extra_segmentations['ge' + concat2 + 'd'] = ['ge'] + split2 + ['d']\n",
    "                if 'ge' + concat2 + 't' in groups[word]:\n",
    "                    extra_segmentations['ge' + concat2 + 't'] = ['ge'] + split2 + ['t']\n",
    "                if  concat2 + 'er' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'er'] = split2 + ['er']\n",
    "                if  concat2 + 'eur' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'eur'] = split2 + ['eur']\n",
    "                if  concat2 + 'ster' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'ster'] = split2 + ['ster']\n",
    "                if  concat2 + 'euse' in groups[word]:\n",
    "                        extra_segmentations[concat2 + 'euse'] = split2 + ['euse']\n",
    "\n",
    "\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if dic['cat'] == 'V' and concat1 + 'en' == word:\n",
    "\n",
    "                    if concat1 + 'de' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'de'] = split1 + ['de']\n",
    "                    if concat1 + 'den' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'den'] = split1 + ['den']\n",
    "                    if concat1 + 'end' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'end'] = split1 + ['end']\n",
    "                    if concat1 + 'ende' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'ende'] = split1 + ['end', 'e']\n",
    "                    if concat1 + 't' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 't'] = split1 + ['t']\n",
    "                    if 'ge' + concat1 + 'd' in groups[word]:\n",
    "                        extra_segmentations['ge' + concat1 + 'd'] = ['ge'] + split1 + ['d']\n",
    "                    if 'ge' + concat1 + 't' in groups[word]:\n",
    "                        extra_segmentations['ge' + concat1 + 't'] = ['ge'] + split1 + ['t']\n",
    "                    if  concat2 + 'er' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'er'] = split2 + ['er']\n",
    "                    if  concat2 + 'eur' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'eur'] = split2 + ['eur']\n",
    "                    if  concat2 + 'ster' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'ster'] = split2 + ['ster']\n",
    "                    if  concat2 + 'euse' in groups[word]:\n",
    "                            extra_segmentations[concat1 + 'euse'] = split2 + ['euse']\n",
    "        \n",
    "    return extra_segmentations\n",
    "\n",
    "\n",
    "def add_plurals_(dic):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    morphemes = set([])\n",
    "    for word, segs in dic.items():\n",
    "        for seg in segs:\n",
    "            morphemes.add(seg)\n",
    "    \n",
    "    for word, segs in dic.items():\n",
    "        out[word] = segs\n",
    "    \n",
    "    for word, segs in dic.items():\n",
    "        concat = ''.join(segs)\n",
    "        if word == concat + 'en':\n",
    "            out[word] = segs + ['en']\n",
    "        if word == concat + 's':\n",
    "            out[word] = segs + ['s']\n",
    "        if word == concat + 'je':\n",
    "            out[word] = segs + ['je']\n",
    "        if word == concat + 'jes':\n",
    "            out[word] = segs + ['je', 's']\n",
    "        if word == concat + 'tje':\n",
    "            out[word] = segs + ['tje']\n",
    "        if word == concat + 'tjes':\n",
    "            out[word] = segs + ['tje', 's']\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def create_n_segmentations(df, n):\n",
    "\n",
    "    return {word: segments for word, segments in df.items() if len(segments) >= n}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_noun_segmentations(df, groups, word_freqs, non_words=False, n_min=2):\n",
    "\n",
    "\n",
    "    prefixes = ['be', 'ge', 'her', 'on', 'ont', 'tegen', 'ver', 'aarts', 'opper', 'super', 'hyper', 'ultra', 'wan', 'vice', 'vice-', 'sub', 'anti', 'pro', 'ex', 'ex-', \n",
    "                'oud-', 'oud', 'niet-', 'niet', 'non-', 'non', 'her', 'weder', 're-', 'oer', 'pre', 'pre-', 'post', 'post-' 'inter', 'auto', 'neo', 'neo-', 'pan', 'pseudo', \n",
    "                'pan-', 'pseudo-', 'pseudo', 'anti-']\n",
    "    suffixes = ['aar', 'eur', 'achtig', 'es', 'aard', 'erd', 'heid', 'ig', 'erig', 'ij', 'in', 'ing', 'je', 'tje', 'lijk', 'schap', 'sel', 'te', 'teit',\n",
    "               'tie', 'tor', 'trix', 'ette', 'trice', 's', 'e', 'schap', 'en']\n",
    "    \n",
    "\n",
    "    if non_words:\n",
    "\n",
    "        segmentations_extra = {}\n",
    "\n",
    "        for word in df:\n",
    "            for suffix in suffixes:\n",
    "                segmentations_extra[word + suffix] = df[word] + [suffix]\n",
    "        \n",
    "        for word in df:\n",
    "            for prefix in prefixes:\n",
    "                segmentations_extra[prefix + word] = [prefix] + df[word] \n",
    "    \n",
    "    else:\n",
    "\n",
    "        segmentations_extra = {}\n",
    "\n",
    "        for word in df:\n",
    "            for suffix in suffixes:\n",
    "                if word + suffix in word_freqs:\n",
    "                    segmentations_extra[word + suffix] = df[word] + [suffix]\n",
    "\n",
    "        for word in df:\n",
    "            for prefix in prefixes:\n",
    "                if prefix + word in word_freqs:\n",
    "                    segmentations_extra[prefix + word] = [prefix] + df[word] \n",
    "\n",
    "        \n",
    "        for word in df:\n",
    "            for suffix in suffix:\n",
    "                for prefix in prefix:\n",
    "                    if prefix + word + suffix in word_freqs:\n",
    "                        segmentations_extra[prefix + word + suffix] = [prefix] + df[word] + [suffix]\n",
    "        \n",
    "        for word in df:\n",
    "            for suffix in suffixes:\n",
    "                for suffix2 in suffixes:\n",
    "                    if word + suffix + suffix2 in word_freqs:\n",
    "                        segmentations_extra[word + suffix + suffix2] = df[word] + [suffix] + [suffix2]\n",
    "        \n",
    "\n",
    "        for word in df:\n",
    "            for prefix in prefixes:\n",
    "                for prefix2 in suffixes:\n",
    "                    if prefix + prefix2 + word in word_freqs:\n",
    "                        segmentations_extra[prefix + prefix2 +word] = [prefix] + [prefix2] + df[word]\n",
    "\n",
    "        # for word in df:\n",
    "        #     for suffix in suffixes:\n",
    "        #         for suffix2 in suffixes:\n",
    "        #             for prefix in prefixes:\n",
    "        #                 if prefix + word + suffix + suffix2 in word_freqs:\n",
    "        #                     segmentations_extra[prefix + word + suffix + suffix2] = [prefix] + df[word] + [suffix] + [suffix2]\n",
    "\n",
    "        # for word in df:\n",
    "        #     for prefix in prefixes:\n",
    "        #         for prefix2 in suffixes:\n",
    "        #             for suffix in suffixes:\n",
    "        #                 if prefix + prefix2 + word + suffix in word_freqs:\n",
    "        #                     segmentations_extra[prefix + prefix2 + word + suffix] = [prefix] + [prefix2] + df[word] + [suffix]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # else:\n",
    "\n",
    "    #     related_words = {word: rels for word, rels in groups.items() if word in df}\n",
    "\n",
    "    #     segmentations_extra = {}\n",
    "\n",
    "    #     for word in df:\n",
    "    #         if word in related_words:\n",
    "    #             for rel in related_words[word]:\n",
    "    #                 for suffix in suffixes:\n",
    "    #                     if rel in df:\n",
    "    #                         if len(df[rel]) < n_min and word + suffix == rel:  # OR if word + suffix == rel:\n",
    "    #                             segmentations_extra[word + suffix] = df[word] + [suffix]\n",
    "    #                     else:\n",
    "    #                         segmentations_extra[word + suffix] = df[word] + [suffix]\n",
    "\n",
    "        \n",
    "    #     for word in df:\n",
    "    #         if word in related_words:\n",
    "    #             for rel in related_words[word]:\n",
    "    #                 for prefix in prefixes:\n",
    "    #                     if rel in df:\n",
    "    #                         if len(df[rel]) < n_min and word + prefix == rel: # OR if word + suffix == rel:\n",
    "    #                             segmentations_extra[prefix + word] = [prefix] + df[word] \n",
    "    #                     else:\n",
    "    #                         segmentations_extra[prefix + word] = [prefix] + df[word] \n",
    "  \n",
    "    \n",
    "    return segmentations_extra\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_compounds_(df, word_freqs, replace=False):\n",
    "\n",
    "\n",
    "    extra = {}\n",
    "\n",
    "\n",
    "\n",
    "    for word in df:\n",
    "        for word2 in df:\n",
    "            if word + word2 in word_freqs:\n",
    "                extra[word + word2] = df[word] + df[word2]\n",
    "    \n",
    "    if replace:\n",
    "        return df | extra\n",
    "\n",
    "    else: \n",
    "        return extra | df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_dictionaries_verb(dic1, dic2, replace=True, n_min=2):\n",
    "    \n",
    "    out = {word: segs for word, segs in dic1.items()}\n",
    "    words_not_to_be_replaced = ['beurt', 'buit', 'dorst', 'geit', 'luid', 'geluid', 'pracht', 'rijt', 'ruit', 'geruit', 'sliert', 'spijt', 'spuit', 'tuit', 'vlijt', 'vorst']\n",
    "    \n",
    "    if replace:\n",
    "        for word, segs in dic2.items():\n",
    "            if not word in words_not_to_be_replaced:\n",
    "                out[word] = segs\n",
    "    else:\n",
    "        for word, segs in dic2.items():\n",
    "            if word in out:\n",
    "                pass\n",
    "            else:\n",
    "                out[word] = segs\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_dictionaries_nouns(dic1, dic2, replace=True, n_min=2):\n",
    "    \n",
    "    out = {word: segs for word, segs in dic1.items()}\n",
    "    \n",
    "    if replace:\n",
    "        for word, segs in dic2.items():\n",
    "                out[word] = segs\n",
    "    else:\n",
    "        for word, segs in dic2.items():\n",
    "            if word in out:\n",
    "                if len(segs) >= 2 and segs[0] == 'on' and segs[1] == 'ge':\n",
    "                    out[word] = segs\n",
    "            else:\n",
    "                out[word] = segs\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def count_morphemes(df):\n",
    "\n",
    "    total = set([])\n",
    "    out = set([])\n",
    "    for word, segs in df.items():\n",
    "        out.add(segs[0])\n",
    "        for seg in segs:\n",
    "            total.add(seg)\n",
    "    print(f'There are {len(total)} morphemes, out of these {len(out)} appear at the begining of a word')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_words_not_in_corpus(df, word_freqs, treshold=0):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    if treshold > 0:\n",
    "        for word, segs in df.items():\n",
    "            if word in word_freqs:\n",
    "                if word_freqs[word] > treshold:\n",
    "                    out[word] = segs\n",
    "\n",
    "    else:\n",
    "\n",
    "        for word, segs in df.items():\n",
    "            if word in word_freqs:\n",
    "                out[word] = segs\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "###  Complete function to create a dictionary from the database  ###\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "def create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs, extra_loop=True, add_morphemes=True, \n",
    "                                   add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=False,\n",
    "                                   add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "                                   add_compounds=True, replace_compounds=False, remove_ortho=True, remove_not_in_corpus=False, meta_data=False, print_info=True):\n",
    "    \n",
    "    # create base dictionary of dictionaries for every word in the dataset\n",
    "    base = create_initial_dataframe(segmentation_data)\n",
    "    stats = {}\n",
    "\n",
    "    # create initial segmentation dictionary\n",
    "    dic = create_segmentations_from_base(base)\n",
    "\n",
    "    # add basic verbs\n",
    "    dic = add_basic_verbs(dic, base)\n",
    "\n",
    "    # print stats\n",
    "    n0 = len([word for word, segs in dic.items() if len(segs) == 0])\n",
    "    n1 = len([word for word, segs in dic.items() if len(segs) == 1])\n",
    "    n2 = len([word for word, segs in dic.items() if len(segs) > 1])\n",
    "    stats['size_0'] = n0\n",
    "    stats['size_1'] = n1\n",
    "    stats['size_2+'] = n2\n",
    "    if print_info:\n",
    "        print(f'''There are {len(dic)} entries in the database. Out of these:\n",
    "          - {n0} words have no segmentations\n",
    "          - {n1} words have a single morpheme as segmentation \n",
    "          - {n2} words are split up into multiple morphemes\\n''')\n",
    "\n",
    "\n",
    "    # add possible further segmentations of segments\n",
    "    d = copy.deepcopy(dic)\n",
    "    if extra_loop:\n",
    "        dic = create_segmentations_extra_loop(dic)\n",
    "    \n",
    "        # print stats\n",
    "        loop_changes = [word for word in dic if not dic[word] == d[word] or not word in d]\n",
    "        n3 = len(loop_changes)\n",
    "        stats['loop changes'] = loop_changes\n",
    "        stats['number of loop changes'] = n3\n",
    "        if print_info:\n",
    "            print(f'- Including the extra loop has increased the number of morphemes for {n3} words [total size = {len(dic)}]')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # add every morpheme in the segmentations as entry to the dictionary\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_morphemes:\n",
    "        dic = add_morphemes_to_dict(dic)\n",
    "\n",
    "        # print stats\n",
    "        morphs_added = set(dic) - set(d)\n",
    "        n4 = len(morphs_added)\n",
    "        stats['morphemes added'] = morphs_added\n",
    "        stats['number of morphs added'] = n4\n",
    "        if print_info:\n",
    "            print(f'- {n4} Morphemes were added as entry to the dictionary [total size = {len(dic)}]')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # add every word with no segmentation to the dictionary with itself as value\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_empty:\n",
    "        dic = add_empty_segmentations(dic)\n",
    "        \n",
    "        # print stats\n",
    "        added_words = set([word for word, seg in d.items() if len(seg) == 0]) - set([word for word, seg in dic.items() if len(seg) == 0])\n",
    "        n5 = len(added_words)\n",
    "        stats['identical words added'] = list(added_words)\n",
    "        stats['number of idenitical words added'] = n5\n",
    "        if print_info:\n",
    "            print(f'- By choosing to add the words with no segmentation to the dictionary, {n5} segmentations were added [total size = {len(dic)}]')\n",
    "    \n",
    "\n",
    "    # add plurals\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_plurals:\n",
    "        dic = add_plurals_(dic)\n",
    "\n",
    "    \n",
    "    # replace the single morphemes that are not identical with the word with the word\n",
    "    d = copy.deepcopy(dic)\n",
    "    stats['non identical words'] = [word for word, seg in d.items() if len(seg) == 1 and not word == seg[0]]\n",
    "    if replace_non_identical:\n",
    "        dic = replace_non_identical_morphs(dic)\n",
    "        words_replaced = set([word for word, seg in d.items() if len(seg) == 1 and not word == seg[0]]) - set([word for word, seg in dic.items() if len(seg) == 1 and not word == seg[0]])\n",
    "        n6 = len(words_replaced)\n",
    "        stats['number of non identical words replaced'] = n6\n",
    "        \n",
    "        # print stats\n",
    "        if print_info:\n",
    "            print(f'- {n6} Non-identical single morph words were replaced with the identical word [total size = {len(dic)}]')\n",
    "    \n",
    "\n",
    "    # load data with word families\n",
    "    word_fams = create_word_fams(word_family_data)\n",
    "    word_groups = group_keys_by_value(word_fams)\n",
    "\n",
    "\n",
    "    # add verb conjugation\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_verbs:\n",
    "        if greedy_verb:\n",
    "            extra = create_verb_segmentations(base, word_groups, True)\n",
    "            if replace_verbs:\n",
    "                dic = merge_dictionaries_verb(dic, extra, replace=True, n_min=2)\n",
    "                # if remove_not_in_corpus:\n",
    "                #     dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "            else:\n",
    "                dic = merge_dictionaries_verb(dic, extra, replace=False)\n",
    "                # if remove_not_in_corpus:\n",
    "                #     dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            extra = create_verb_segmentations(base, word_groups, False)\n",
    "            if replace_verbs:\n",
    "                dic = merge_dictionaries_verb(dic, extra, replace=True, n_min=2)\n",
    "                # if remove_not_in_corpus:\n",
    "                #     dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "            else:\n",
    "                dic = merge_dictionaries_verb(dic, extra, replace=False)\n",
    "                # if remove_not_in_corpus:\n",
    "                #     dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "            \n",
    "        \n",
    "        # print stats\n",
    "        verb_additions = set(dic) - set(d)\n",
    "        n7 = len(verb_additions)\n",
    "        stats['verb conjugates added'] = verb_additions\n",
    "        stats['number of verb conjugates added'] = n7\n",
    "        if print_info:\n",
    "            if greedy_verb:\n",
    "                print(f'- By choosing to add verbs with a greedy approach, {n7} verb conjugates were added to the dictionary [total size = {len(dic)}]')\n",
    "            else:\n",
    "                print(f'- By choosing to add verbs with a non-greedy approach, {n7} verb conjugates were added to the dictionary [total size = {len(dic)}]')\n",
    "\n",
    "    \n",
    "    # add noun conjugation\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_nouns:\n",
    "        if greedy_noun:\n",
    "            extra = create_noun_segmentations(dic, word_groups, word_freqs, True)\n",
    "            if replace_nouns:\n",
    "                dic = merge_dictionaries_nouns(dic, extra, replace=True, n_min=2)\n",
    "            else:\n",
    "                dic = merge_dictionaries_nouns(dic, extra, replace=False)\n",
    "        else:\n",
    "            extra = create_noun_segmentations(dic, word_groups, word_freqs, False)\n",
    "            if replace_nouns:\n",
    "                dic = merge_dictionaries_nouns(dic, extra, replace=True, n_min=2)\n",
    "            else:\n",
    "                dic = merge_dictionaries_nouns(dic, extra, replace=False)\n",
    "        \n",
    "        # print stats\n",
    "        noun_additions = set(dic) - set(d)\n",
    "        n8 = len(noun_additions)\n",
    "        stats['noun conjugates added'] = noun_additions\n",
    "        stats['number of noun conjugates added'] = n8\n",
    "        if print_info:\n",
    "            if greedy_noun:\n",
    "                print(f'- By choosing to add nouns with a greedy approach, {n8} noun conjugates were added to the dictionary [total size = {len(dic)}]')\n",
    "            else:\n",
    "                print(f'- By choosing to add nouns with a non-greedy approach, {n8} noun conjugates were added to the dictionary [total size = {len(dic)}]')\n",
    "    \n",
    "\n",
    "\n",
    "    # remove the enties that have less than n morphemes (standard: delete empty segmentations)\n",
    "    d = copy.deepcopy(dic)\n",
    "    dic = {word: segs for word, segs in dic.items() if len(segs) >= min_n_segments}\n",
    "    words_deleted = set(d) - set(dic)\n",
    "    n9 = len(words_deleted)\n",
    "    stats['empty words deleted'] = words_deleted\n",
    "    stats['number of empty words deleted'] = n9\n",
    "    if print_info:\n",
    "        print(f'- By choosing to remove the words with less than {min_n_segments} morpheme(s), {n9} words were deleted [total size = {len(dic)}]')\n",
    "\n",
    "\n",
    "    # remove words with orthograpic changes in the segmentation\n",
    "    if remove_ortho:\n",
    "        d = copy.deepcopy(dic)\n",
    "        dic = remove_ortho_changes(dic)\n",
    "        \n",
    "        # print stats \n",
    "        removed = set(d) - set(dic)\n",
    "        n10 = len(removed)\n",
    "        stats['ortho words deleted'] = removed\n",
    "        stats['number of ortho words deleted'] = n10\n",
    "        if print_info:\n",
    "            print(f'- By choosing to remove the words where a change in spelling in the segmentations occurs, {n10} words were removed [total size = {len(dic)}]')\n",
    "    \n",
    "\n",
    "\n",
    "    # remove words that do not occur in a corpus\n",
    "    if remove_not_in_corpus:\n",
    "        dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "\n",
    "    # add compounds\n",
    "    if add_compounds:\n",
    "        if replace_compounds:\n",
    "            dic = add_compounds_(dic, word_freqs, True)\n",
    "        else:\n",
    "            dic = add_compounds_(dic, word_freqs, False)\n",
    "\n",
    "\n",
    "    # return just the dictonary, or add meta-data\n",
    "    if meta_data:\n",
    "        return dic, stats\n",
    "    else:\n",
    "        return dic\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10, 2: 30, 3: 40}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1: 10, 2: 20}\n",
    "b = {2: 30, 3: 40}\n",
    "\n",
    "a | b\n",
    "\n",
    "#b | a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to compare dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the tokenizers, we need the following elements:\n",
    "- the simlex words\n",
    "- a corpus in the form of a generator\n",
    "- a corpus in the form of a frequency dictionary\n",
    "\n",
    "We will create various different versions of these three elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_basic(seq):\n",
    "    return [s.strip(string.punctuation) for s in seq.strip().split()]\n",
    "\n",
    "def preprocess_lower(seq):\n",
    "    return [s.strip(string.punctuation) for s in seq.strip().lower().split()]\n",
    "\n",
    "def preprocess_bpe(seq, tokenizer):\n",
    "    return [word.replace('', '') for word in [word for word, offset in tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)]]\n",
    "\n",
    "\n",
    "# this function counts the number of times words in a dataframe occur in a corpus, taking the corpus as generator\n",
    "def count_frequency_from_generator(words, corpus_generator):\n",
    "\n",
    "    words_in = 0\n",
    "    words_out = 0\n",
    "\n",
    "    for i in corpus_generator:\n",
    "        text = preprocess_lower(i) # andere preproces mogelijk\n",
    "        for word in text:\n",
    "            if word in words:\n",
    "                words_in += 1\n",
    "            else:\n",
    "                words_out += 1\n",
    "    \n",
    "    print(f'{round(100 * words_in / (words_in + words_out), 1)}% of words in the corpus are in the celex database')\n",
    "    print(f'{round(100 * words_out / (words_in + words_out), 1)}% of words are not')\n",
    "\n",
    "    return (words_in, words_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function creates a word frequency dictionary for a corpus, so that we can count faster later on\n",
    "def create_word_freqs_from_corpus(corpus_generator, sorted=False):\n",
    "    \n",
    "    word_freqs = {}\n",
    "\n",
    "    for i in corpus_generator:     \n",
    "        text = preprocess_basic(i)\n",
    "        for word in text:\n",
    "            if word in word_freqs:\n",
    "                word_freqs[word] += 1\n",
    "            else:\n",
    "                word_freqs[word] = 1\n",
    "    \n",
    "    if sorted:\n",
    "        word_freqs = dict(sorted(word_freqs.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "\n",
    "# this function creates a word frequency dictionary for a corpus, so that we can count faster later on\n",
    "# a progress bar was added\n",
    "def create_word_freqs_from_local_corpus(corpus_generator, sort=False, progress=True, path=0, prep_lower=False):\n",
    "    \n",
    "    if progress:\n",
    "        print(f'Estimating the size of the dataset ...\\n')\n",
    "        if path == 0:\n",
    "            assert path == 1, 'Enter path to get progress bar, or set progress=False to perform the function without one'\n",
    "        else:\n",
    "            size = get_size_for_local(path)\n",
    "    \n",
    "        word_freqs = {}\n",
    "        \n",
    "        for i in range(1):\n",
    "            if i == 0:\n",
    "                print(f'Data size: {format_with_dots(size)} lines of text! Generating the frequency dictionary ...')\n",
    "\n",
    "        if prep_lower:\n",
    "\n",
    "            for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "                text = preprocess_lower(i)\n",
    "                for word in text:\n",
    "                    if word in word_freqs:\n",
    "                        word_freqs[word] += 1\n",
    "                    else:\n",
    "                        word_freqs[word] = 1\n",
    "        \n",
    "        else:\n",
    "\n",
    "            for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "                text = preprocess_basic(i)\n",
    "                print(text)\n",
    "                for word in text:\n",
    "                    if word in word_freqs:\n",
    "                        word_freqs[word] += 1\n",
    "                    else:\n",
    "                        word_freqs[word] = 1\n",
    "    \n",
    "    else:\n",
    "\n",
    "        print('Performing task without progress bar')\n",
    "\n",
    "        word_freqs = {}\n",
    "\n",
    "        for i in corpus_generator:     \n",
    "            text = preprocess_basic(i)\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "        \n",
    "    if sort:\n",
    "        word_freqs = dict(sorted(word_freqs.items(), key=lambda item: item[1], reverse=True)) \n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "# this function creates a frequency dictionary for a corpus loaded with a generator, especially usefull for streaming from huggingface server\n",
    "def create_word_freqs_from_online_corpus(corpus_generator, sorted=False, progress=True, avg_size=6750000, n_files=45):\n",
    "\n",
    "    size = n_files * avg_size\n",
    "    \n",
    "    if progress:\n",
    "        print(f'The estimated size of the entire corpus is around {format_with_dots(size)} lines of text!')\n",
    "        \n",
    "        word_freqs = {}\n",
    "\n",
    "        for i in range(1):\n",
    "            if i == 0:\n",
    "                print(f'Generating the frequency dictionary ...\\n')\n",
    "\n",
    "        for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "            text = preprocess_basic(i['text'])\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "\n",
    "def get_size_for_local(path):\n",
    "    with open(path) as osc:\n",
    "        n = 0\n",
    "        for line in osc:\n",
    "            n+= 1\n",
    "        return n \n",
    "\n",
    "def format_with_dots(number):\n",
    "    return f\"{number:,}\".replace(\",\", \".\")\n",
    "\n",
    "\n",
    "# this function counts how many of the words in a dataframe occur at least once in the corpus, which is printed\n",
    "# it returns two lists, one with the words in the corpus, one with the words not in the corpus\n",
    "# update: now also returns frequencies\n",
    "def dataset_in_corpus(df, word_freqs, lower=False, print_info=True):\n",
    "\n",
    "    words_in = {}\n",
    "    words_out = []\n",
    "\n",
    "    if lower:\n",
    "\n",
    "        word_freqs_lower = {key.lower(): value for key, value in word_freqs.items()}\n",
    "\n",
    "        for word in df:\n",
    "            if word in word_freqs or word in word_freqs_lower:\n",
    "                if word in words_in:\n",
    "                    if word in word_freqs:\n",
    "                        words_in[word] += word_freqs[word]\n",
    "                    else:\n",
    "                        words_in[word] += word_freqs_lower[word]\n",
    "                else:\n",
    "                    if word in word_freqs:\n",
    "                        words_in[word] = word_freqs[word]\n",
    "                    else:\n",
    "                        words_in[word] = word_freqs_lower[word]\n",
    "\n",
    "            else:\n",
    "                words_out.append(word)\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        for word in df:\n",
    "            if word in word_freqs:\n",
    "                if word in words_in:\n",
    "                    words_in[word] += word_freqs[word]\n",
    "                else:\n",
    "                    words_in[word] = word_freqs[word]\n",
    "            \n",
    "            else:\n",
    "                words_out.append(word)\n",
    "\n",
    "    \n",
    "    n_in = len(words_in)\n",
    "    n_out = len(words_out)\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'{round(100 * n_in / (n_in + n_out), 1)}% of words in the dataset are in the corpus')\n",
    "        print(f'{round(100 * n_out / (n_in + n_out), 1)}% of words are not\\n')\n",
    "\n",
    "    return words_in, words_out\n",
    "\n",
    "\n",
    "# this function calculates the number of words in the corpus that are in a dataframe. \n",
    "# two prints are made: one for every word in the corpus that is in the dataframe, one for every unique word in the corpus that is in the dataframe\n",
    "# the function returns four dictionaries (in/not in dataframe - all/unique)\n",
    "def corpus_in_dataset(df, word_freqs, lower=False, print_info=True):\n",
    "\n",
    "    n_in = 0\n",
    "    n_out = 0\n",
    "\n",
    "    n_in_abs = 0\n",
    "    n_out_abs = 0\n",
    "\n",
    "    words_in = []\n",
    "    words_out = []\n",
    "\n",
    "    if lower:\n",
    "\n",
    "        for word in word_freqs:\n",
    "            if word in df or word.lower() in df:\n",
    "                n_in += word_freqs[word]\n",
    "                n_in_abs += 1\n",
    "                words_in.append(word)\n",
    "            else:\n",
    "                n_out += word_freqs[word]\n",
    "                n_out_abs += 1\n",
    "                words_out.append(word)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for word in word_freqs:\n",
    "            if word in df:\n",
    "                n_in += word_freqs[word]\n",
    "                n_in_abs += 1\n",
    "                words_in.append(word)\n",
    "            else:\n",
    "                n_out += word_freqs[word]\n",
    "                n_out_abs += 1\n",
    "                words_out.append(word)\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'{round(100 * n_in / (n_in + n_out), 1)}% of words in the corpus are in the dataset')\n",
    "        print(f'{round(100 * n_out / (n_in + n_out), 1)}% of words are not\\n')\n",
    "\n",
    "        print(f'{round(100 * n_in_abs / (n_in_abs + n_out_abs), 1)}% of unique words in the corpus are in the dataset')\n",
    "        print(f'{round(100 * n_out_abs / (n_in_abs + n_out_abs), 1)}% of unique words are not\\n')\n",
    "\n",
    "    return words_in, words_out, n_in, n_out, n_in_abs, n_out_abs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function uses the previous two functions to give a 'complete' picture of the relationship between a dataframe and the corpus\n",
    "def compare_dataset_and_corpus(df, word_freqs, lower_=False, print_info_=True):\n",
    "\n",
    "    n_corpus = sum(word_freqs.values())\n",
    "    n_dataset = len(df)\n",
    "\n",
    "    if print_info_:\n",
    "        print(f'There are {n_corpus} words in the corpus')\n",
    "        print(f'There are {n_dataset} words in the dataset\\n')\n",
    "\n",
    "    a, b, c, d, e, f = corpus_in_dataset(df, word_freqs, lower=lower_, print_info=print_info_)\n",
    "    g, h = dataset_in_corpus(df, word_freqs, lower=lower_, print_info=print_info_)\n",
    "    \n",
    "    #return g, b, f\n",
    "    return {'in both': g, 'not in dataset': b, 'not in corpus': h, 'n in both': c, 'n not in dataset': d, 'n in corpus': len(g), 'n not in corpus': len(h)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function is not finished yet\n",
    "# def compare_segmentations_and_corpus(df, word_freqs, lower=False):\n",
    "\n",
    "#     a = {word for word, segments in df.items() if len(segments) == 0}\n",
    "#     b = {seg for segments in df.values() for seg in segments if len(segments) == 1}\n",
    "#     c = {seg for segments in df.values() for seg in segments if len(segments) > 1}\n",
    "\n",
    "#     tokens_max = a | b | c\n",
    "#     tokens_min = c\n",
    "#     tokens_x = b | c\n",
    "\n",
    "\n",
    "\n",
    "# this function calculates the percentage of words that have no orthographic changes in the segmentation that have at least two moprhemes\n",
    "# it does this in relation to a corpus,  so based on the number of times it occurs in the corpus\n",
    "def count_ortho(df, word_freqs, lower=False):\n",
    "\n",
    "    segmentations = {word: segments for word, segments in df.items() if len(segments) >= 2}\n",
    "\n",
    "    seg = {word for word, segments in segmentations.items() if ''.join(segments) == word}\n",
    "    no_seg = {word for word, segments in segmentations.items() if ''.join(segments) != word}\n",
    "\n",
    "    n_in = 0\n",
    "    n_out = 0\n",
    "\n",
    "    n_total = sum(word_freqs.values())\n",
    "\n",
    "    if lower:\n",
    "\n",
    "        for word in word_freqs:\n",
    "            if word in seg or word.lower() in seg:\n",
    "                n_in += word_freqs[word]\n",
    "            elif word in no_seg or word.lower() in no_seg:\n",
    "                n_out += word_freqs[word]\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for word in word_freqs:\n",
    "            if word in seg:\n",
    "                n_in += word_freqs[word]\n",
    "            elif word in no_seg:\n",
    "                n_out += word_freqs[word]\n",
    "\n",
    "\n",
    "    print(f'{round(100 * n_in / (n_in + n_out), 1)}% of segmentable words in the corpus are segmented via the dict')\n",
    "    print(f'This is equal to {round(100 * n_in / n_total, 1)}% of words in the corpus \\n')\n",
    "\n",
    "\n",
    "\n",
    "def sort_dictionary(df, descending=True):\n",
    "\n",
    "    if descending:\n",
    "         sorted_dict = dict(sorted(df.items(), key=lambda item: item[1], reverse=True))\n",
    "    else:\n",
    "        sorted_dict = dict(sorted(df.items(), key=lambda item: item[1]))\n",
    "    \n",
    "    return sorted_dict\n",
    "\n",
    "\n",
    "\n",
    "def combine_dictionaries(*dictionaries):\n",
    "    out = {}\n",
    "    for dictionary in dictionaries:\n",
    "        for word, freq in dictionary.items():\n",
    "            if word in out:\n",
    "                out[word] += freq\n",
    "            else:\n",
    "                out[word] = freq\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_multiple_dicts_and_copora(frequency_dictionaries, datasets):\n",
    "    \n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    for i, freq in enumerate(frequency_dictionaries):\n",
    "        x = f'Corpus {i+1}'\n",
    "        results1[x] = {}\n",
    "        results2[x] = {}\n",
    "\n",
    "\n",
    "        for j, data in enumerate(datasets):\n",
    "\n",
    "\n",
    "            y = f'Segmentations {j+1}'\n",
    "    \n",
    "\n",
    "            result = compare_dataset_and_corpus(data, freq, print_info_=False)\n",
    "            in_both = result['in both']\n",
    "            not_in_data = result['not in dataset']\n",
    "            not_in_corpus = result['not in corpus']\n",
    "            n_in_both = result['n in both']\n",
    "            n_not_in_data = result['n not in dataset']\n",
    "            n_in_corpus = result['n in corpus']\n",
    "            n_not_in_corpus = result['n not in corpus']\n",
    "\n",
    "\n",
    "            a = round(100 * n_in_both / (n_in_both + n_not_in_data), 1)\n",
    "            b = round(100 * n_in_corpus / (n_in_corpus + n_not_in_corpus), 1)\n",
    "\n",
    "            results1[x][y] = a\n",
    "            results2[x][y] = b\n",
    "    \n",
    "    df1 = pd.DataFrame(results1) #.T\n",
    "    df2 = pd.DataFrame(results2) #.T\n",
    "            \n",
    "\n",
    "    print(df1)\n",
    "    print('\\n')\n",
    "    print(df2)\n",
    "\n",
    "\n",
    "def compare_multiple_corpora(frequency_dictionaries, dataset):\n",
    "    \n",
    "    results1 = {}\n",
    "\n",
    "    \n",
    "    for i, freq in enumerate(frequency_dictionaries):\n",
    "        x = f'Corpus {i+1}'\n",
    "        results1[x] = {}\n",
    "\n",
    "        result = compare_dataset_and_corpus(dataset, freq, print_info_=False)\n",
    "        in_both = result['in both']\n",
    "        not_in_data = result['not in dataset']\n",
    "        not_in_corpus = result['not in corpus']\n",
    "        n_in_both = result['n in both']\n",
    "        n_not_in_data = result['n not in dataset']\n",
    "        n_in_corpus = result['n in corpus']\n",
    "        n_not_in_corpus = result['n not in corpus']\n",
    "\n",
    "\n",
    "        a = round(100 * n_in_both / (n_in_both + n_not_in_data), 1)\n",
    "        b = round(100 * n_in_corpus / (n_in_corpus + n_not_in_corpus), 1)\n",
    "\n",
    "        results1[x]['A'] = a\n",
    "        results1[x]['B'] = b\n",
    "\n",
    "    \n",
    "    df1 = pd.DataFrame(results1) #.T  \n",
    "\n",
    "    return df1\n",
    "\n",
    "\n",
    "\n",
    "def compare_multiple_dicts(frequency_dictionary, datasets):\n",
    "    \n",
    "    results1 = {}\n",
    "\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        x = f'Segmentations dictionary {i+1}'\n",
    "        results1[x] = {}\n",
    "\n",
    "        result = compare_dataset_and_corpus(dataset, frequency_dictionary, print_info_=False)\n",
    "        in_both = result['in both']\n",
    "        not_in_data = result['not in dataset']\n",
    "        not_in_corpus = result['not in corpus']\n",
    "        n_in_both = result['n in both']\n",
    "        n_not_in_data = result['n not in dataset']\n",
    "        n_in_corpus = result['n in corpus']\n",
    "        n_not_in_corpus = result['n not in corpus']\n",
    "\n",
    "\n",
    "        a = round(100 * n_in_both / (n_in_both + n_not_in_data), 1)\n",
    "        b = round(100 * n_in_corpus / (n_in_corpus + n_not_in_corpus), 1)\n",
    "\n",
    "        results1[x]['Corpus words in segmentations dict (%)'] = a\n",
    "        results1[x]['Segmentations dict words in corpus (%)'] = b\n",
    "\n",
    "    \n",
    "    df1 = pd.DataFrame(results1).T  \n",
    "\n",
    "    return df1\n",
    "\n",
    "\n",
    "def compare_only_dictionaries(dict1, dict2, return_dict=False):\n",
    "\n",
    "    diff = []\n",
    "    not_in_2 = []\n",
    "    not_in_1 = []\n",
    "    \n",
    "    for word, segs in dict1.items():\n",
    "        if word in dict2:\n",
    "            if not segs == dict2[word]:\n",
    "                diff.append(word)\n",
    "        else:\n",
    "            not_in_2.append(word)\n",
    "    \n",
    "    for word, segs in dict2.items():\n",
    "        if word in dict1:\n",
    "            if not segs == dict1[word]:\n",
    "                diff.append(word)\n",
    "        else:\n",
    "            not_in_1.append(word)\n",
    "\n",
    "    dic = {word: (dict1[word], dict2[word]) for word in diff}\n",
    "\n",
    "    if return_dict:\n",
    "        return dic, not_in_2, not_in_1\n",
    "    else:\n",
    "        return diff, not_in_2, not_in_1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_sets(a, b, print_info=True):\n",
    "\n",
    "    incl = []\n",
    "    excl = []\n",
    "\n",
    "    for word in a:\n",
    "        if word in b:\n",
    "            incl.append(word)\n",
    "        else:\n",
    "            excl.append(word)\n",
    "\n",
    "    p_in = 100 * len(incl) / len(a)\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'{round(p_in, 2)}% of words in set a are in set b')\n",
    "    \n",
    "    return incl, excl\n",
    "\n",
    "\n",
    "def compare_dict_simlex(sim, dic, print_info=True):\n",
    "\n",
    "    incl = []\n",
    "    excl = []\n",
    "    mult = 0\n",
    "\n",
    "    for word in sim:\n",
    "        if word in dic:\n",
    "            incl.append(word)\n",
    "            if len(dic[word]) > 1:\n",
    "                mult += 1\n",
    "        else:\n",
    "            excl.append(word)\n",
    "\n",
    "    p_in = 100 * len(incl) / len(sim)\n",
    "    p_mult = 100 * mult / len(sim)\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'{round(p_in, 2)}% of words in simlex are in the dictionary')\n",
    "        print(f'{round(p_mult, 2)}% of words in simlex are in the dictionary and have more than one segment')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_number_of_morphemes(dic):\n",
    "    out = set([])\n",
    "    for word, segs in dic.items():\n",
    "        for seg in segs:\n",
    "            out.add(seg)\n",
    "    return len(out)\n",
    "\n",
    "\n",
    "def count_morphemes_extra(df, print_info=True):\n",
    "\n",
    "    total = set([])\n",
    "    begin = set([])\n",
    "    mid = set([])\n",
    "\n",
    "    for word, segs in df.items():\n",
    "        begin.add(segs[0])\n",
    "        if len(segs) > 1:\n",
    "           for item in segs[1:]:\n",
    "               mid.add(item)\n",
    "        for seg in segs:\n",
    "            total.add(seg)\n",
    "\n",
    "    not_at_begin = mid - begin\n",
    "\n",
    "    size = len(total) + len(begin) - len(not_at_begin)\n",
    "\n",
    "    if print_info:\n",
    "    \n",
    "        print(f'There are {len(total)} morphemes, out of these {len(begin)} appear at the begining of a word')\n",
    "        print(f'{len(not_at_begin)} morphemes do not appear at the beginning. This means that the vocabulary has a size of {size} tokens (only lowercase).')\n",
    "    \n",
    "    else:\n",
    "        return size\n",
    "\n",
    "\n",
    "\n",
    "def return_morphemes(df, form='list'):\n",
    "\n",
    "    out = set([])\n",
    "    for word, segs in df.items():\n",
    "        for seg in segs:\n",
    "            out.add(seg)\n",
    "    \n",
    "    if form == 'list':\n",
    "        return list(out)\n",
    "    else:\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating word frequency dictionaries for the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for first 4 parts of OSCAR\n",
    "word_freqs_4 = load_json('word_freqs_all_lower.json')\n",
    "\n",
    "# dictionary for first 20 parts of OSCAR\n",
    "word_freqs_20 = load_json('/Users/jan/Documents/Master/Thesis/Code/Snellius/Outputs/frequencies20.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of different dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create some different versions of the segmentation dictionory. We can do this with one functions, which has a lot of boolean parameters to specify our choices. \n",
    "\n",
    "\n",
    "\n",
    "The possible choices we have are:\n",
    "- extra_loop: chech whether a morpheme of a word is in the dictionary with a segmentation itself. If so, replace with this extra segmentation.\n",
    "- add_morphemes: add the morphemes that are not in the dictionary as key to the dictionary, with as segmentation the identical morpheme\n",
    "- add_empty: for the words with no segmentation, add the identical word as the segmentation of the word. \n",
    "- replace_non_identical: for words that have a single morpheme as segmentation that is not identical to the word, replace the morpheme with the identical word\n",
    "- add_verbs: add the conjugation of every verb\n",
    "- greedy_verb: do this in a way that also non-existent words will enter the dictionary\n",
    "- add_nouns: add the conjugation of every noun\n",
    "- greedy_noun: do this in a way that also non-existent words will enter the dictionary\n",
    "- replace_conjugates: creating these inflections of words can lead to words that are already in the dictionary. Choose whether we want to replace them in this case. \n",
    "- min_n_segments: return only the words with at least n morphemes as segmentation. Automatically set to n = 1.\n",
    "- remove_ortho: remove all words for which the concatenated morphemes are not identical to the word\n",
    "- meta_data: return an additional dictionary with meta data about the dictionary\n",
    "- print_info: print information related to (the creation of) the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_data = celex\n",
    "word_family_data = celex2\n",
    "\n",
    "word_fams = create_word_fams(word_family_data)\n",
    "word_groups = group_keys_by_value(word_fams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of extra loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of adding morphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of adding words with emppty segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of replacing words with one mopheme that is not identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of adding verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of adding nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# no_nouns = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=False, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)\n",
    "\n",
    "# with_nouns = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87854"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'with_nouns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6t/7jzn66s57nvb6j7rsh2w2dmr0000gn/T/ipykernel_2648/3856953988.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_nouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'with_nouns' is not defined"
     ]
    }
   ],
   "source": [
    "len(with_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of replacing words with these newly formed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_replace = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=True, min_n_segments=1, \n",
    "#                                    remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)\n",
    "\n",
    "\n",
    "# no_replace = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = compare_only_dictionaries(no_replace, with_replace, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of replacing compunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m comps_no_replace  \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_segmentation_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_family_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_freqs_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_morphemes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43madd_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_plurals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_non_identical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_verbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy_verb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43madd_nouns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy_noun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_verbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_nouns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_n_segments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43madd_compounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_compounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_ortho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_not_in_corpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 830\u001b[0m, in \u001b[0;36mcreate_segmentation_dictionary\u001b[0;34m(segmentation_data, word_family_data, word_freqs, extra_loop, add_morphemes, add_empty, add_plurals, replace_non_identical, add_verbs, greedy_verb, add_nouns, greedy_noun, replace_verbs, replace_nouns, min_n_segments, add_compounds, replace_compounds, remove_ortho, remove_not_in_corpus, meta_data, print_info)\u001b[0m\n\u001b[1;32m    828\u001b[0m         dic \u001b[38;5;241m=\u001b[39m add_compounds_(dic, word_freqs, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 830\u001b[0m         dic \u001b[38;5;241m=\u001b[39m \u001b[43madd_compounds_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_freqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# return just the dictonary, or add meta-data\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta_data:\n",
      "Cell \u001b[0;32mIn[46], line 539\u001b[0m, in \u001b[0;36madd_compounds_\u001b[0;34m(df, word_freqs, replace)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word2 \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[0;32m--> 539\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mword2\u001b[49m \u001b[38;5;129;01min\u001b[39;00m word_freqs:\n\u001b[1;32m    540\u001b[0m             extra[word \u001b[38;5;241m+\u001b[39m word2] \u001b[38;5;241m=\u001b[39m df[word] \u001b[38;5;241m+\u001b[39m df[word2]\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# comps_no_replace  = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    add_compounds=True, replace_compounds=False, remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comps_replace = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    add_compounds=True, replace_compounds=True, remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: the optimal dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final dictionary will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_dictionary = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "                                   add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "                                   add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "                                   add_compounds=False, replace_compounds=False, remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m segmentation_dictionary2 \u001b[38;5;241m=\u001b[39m \u001b[43madd_compounds_\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation_dictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_freqs_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 539\u001b[0m, in \u001b[0;36madd_compounds_\u001b[0;34m(df, word_freqs, replace)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word2 \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[0;32m--> 539\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mword2\u001b[49m \u001b[38;5;129;01min\u001b[39;00m word_freqs:\n\u001b[1;32m    540\u001b[0m             extra[word \u001b[38;5;241m+\u001b[39m word2] \u001b[38;5;241m=\u001b[39m df[word] \u001b[38;5;241m+\u001b[39m df[word2]\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segmentation_dictionary2 = add_compounds_(segmentation_dictionary, word_freqs_20, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_json('/Users/jan/Documents/Master/Thesis/Code/seg_dict_with_compounds.json', segmentation_dictionary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dictionary in a json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_json('/Users/jan/Documents/Master/Thesis/Code/seg_dict.json', segmentation_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if there are words for which the segmentations do not add up to the the identical word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = segmentation_dictionary\n",
    "\n",
    "for word in d:\n",
    "    concat = ''.join(d[word])\n",
    "    if word != concat:\n",
    "        print(word, d[word])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons with the words in Dutch SimLex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.65% of words in simlex are in the dictionary\n",
      "19.71% of words in simlex are in the dictionary and have more than one segment\n"
     ]
    }
   ],
   "source": [
    "compare_dict_simlex(simlex_words, segmentation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.65% of words in simlex are in the dictionary\n",
      "19.71% of words in simlex are in the dictionary and have more than one segment\n"
     ]
    }
   ],
   "source": [
    "compare_dict_simlex(simlex_words, sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with the text corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.6% of words in the corpus are in the dataset\n",
      "27.4% of words are not\n",
      "\n",
      "1.3% of unique words in the corpus are in the dataset\n",
      "98.7% of unique words are not\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = corpus_in_dataset(segmentation_dictionary, word_freqs_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.6% of words in the corpus are in the dataset\n",
      "27.4% of words are not\n",
      "\n",
      "1.3% of unique words in the corpus are in the dataset\n",
      "98.7% of unique words are not\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = corpus_in_dataset(sd, word_freqs_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of tokens our vocabulary will have from this segmentation dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13602 morphemes, out of these 13299 appear at the begining of a word\n",
      "303 morphemes do not appear at the beginning. This means that the vocabulary has a size of 26598 tokens (only lowercase).\n"
     ]
    }
   ],
   "source": [
    "count_morphemes_extra(segmentation_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three parts:\n",
    "- creating the vocabulary\n",
    "- tokenizing text\n",
    "- detokenizing tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The vocabulary is formed from two sources:\n",
    "- dataset with morphemes\n",
    "- BPE\n",
    "\n",
    "(In reality we there is not one vocabulary created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphemes\n",
    "\n",
    "We first create the set of morphemes, which we take from the segmentation dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13609 in the dictionary. Due to a difference between the start and not-start of a word, this means 26626 tokens in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "seg_dict = segmentation_dictionary\n",
    "\n",
    "# OR load from disk:\n",
    "# seg_dict = \n",
    "\n",
    "morphemes = return_morphemes(seg_dict)\n",
    "\n",
    "print(f'There are {len(morphemes)} in the dictionary. Due to a difference between the start and not-start of a word, this means {count_morphemes_extra(seg_dict, print_info=False)} tokens in the vocabulary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the number of morphemes and the desired size of the vocabulary, we can train a BPE algorithm to tokenize the words that are not in our dictionary.\n",
    "\n",
    "In order to do this we must preprocess the data in a way that takes the words out, and that converts it lowercase. \n",
    "\n",
    "The best way in our case is to create new text files, so we define a function that returens the converted text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer_x = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "segmentation_dictionary = segmentation_dictionary\n",
    "\n",
    "def lowercase_text(item):\n",
    "    return item.lower()\n",
    "\n",
    "def remove_words(item):\n",
    "    text = tokenizer_x._tokenizer.pre_tokenizer.pre_tokenize_str(item)\n",
    "    words_a = [word for word, offset in text]\n",
    "    words_b = [word.replace('', '') for word in words_a]\n",
    "    out = []\n",
    "    for i, word in enumerate(words_b):\n",
    "        if not word in segmentation_dictionary:\n",
    "            out.append(words_a[i])\n",
    "    return tokenizer_x.convert_tokens_to_string(out)\n",
    "\n",
    "def convert_text(input):\n",
    "    with open(input) as inp:\n",
    "        with open(input[:-4] + '_converted.txt', 'w') as outp:\n",
    "            for line in inp:\n",
    "                line = lowercase_text(line)\n",
    "                line = remove_words(line)\n",
    "                outp.write(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this function to one file here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_text('/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the text files to train BPE with, we can do this for a desired vocabulary size. \n",
    "\n",
    "This is the code to do it locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import datasets\n",
    "\n",
    "paths = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short_converted.txt'\n",
    "\n",
    "# set size\n",
    "desired_vocab_size = 35000\n",
    "n_extra_tokens = desired_vocab_size - count_morphemes_extra(segmentation_dictionary, print_info=False)\n",
    "\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer_30 = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer_30.train(files=paths, vocab_size=n_extra_tokens, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])\n",
    "\n",
    "\n",
    "# save\n",
    "tokenizer_30.save_model('/home/scur2141/tokenizer_test/t30')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paths = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short_converted.txt'\n",
    "\n",
    "# set size\n",
    "desired_vocab_size = 35000\n",
    "n_extra_tokens = desired_vocab_size - count_morphemes_extra(segmentation_dictionary, print_info=False)\n",
    "\n",
    "\n",
    "def create_text_generator(gen):\n",
    "    for i in gen:\n",
    "        yield i['text']\n",
    "\n",
    "\n",
    "path = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt'\n",
    "oscar_short = load_dataset('text', data_files={\"train\": path}, split='train')\n",
    "oscar_short_it = load_dataset('text', data_files={\"train\": path}, split='train', streaming=True)\n",
    "\n",
    "dataset = create_text_generator(oscar_short_it)\n",
    "\n",
    "\n",
    "# load an existing BPE tokenizer\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "new_tokenizer = old_tokenizer.train_new_from_iterator(dataset, n_extra_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we have done this on the Snellus computer. So we will load them here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "t30 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/tokenizeXX/t30\", max_len=512)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now that we have the two components for our tokenizer, we can combine them to form a single tokenizer. \n",
    "\n",
    "We will do this in a tokenizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nog toevoegen:\n",
    "#    - return_tensors method, die ervoor zorgt dat de input ids enzo als een tensor worden gegeven (of dit al standaard doen) \n",
    "# [deze zit in de call method zie voorbeeld: inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# overigens heb je die andere methods ook nodig (padding & truncation)\n",
    "\n",
    "\n",
    "## DEZE NIET AANPASSEN ##\n",
    "\n",
    "\n",
    "\n",
    "# class CustomTokenizerMP:\n",
    "\n",
    "#     def __init__(self, segmentation_dictionary, bpe_tokenizer):\n",
    "        \n",
    "#         self.bpe_tokenizer = bpe_tokenizer\n",
    "#         self.bpe_vocab = self.bpe_tokenizer.get_vocab()\n",
    "\n",
    "\n",
    "#         self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "#         self.seg_dict = {}\n",
    "#         for word, segs in self.segmentations.items():\n",
    "#             out = []\n",
    "#             for i, seg in enumerate(segs):\n",
    "#                 if i == 0:\n",
    "#                     out.append('' + seg)\n",
    "#                 else:\n",
    "#                     out.append(seg)\n",
    "#             self.seg_dict[word] = out\n",
    "        \n",
    "#         self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "#         self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "#         self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "#         self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "#         self.seg_dict = {}\n",
    "#         for word, segs in self.segmentations.items():\n",
    "#             out = []\n",
    "#             for i, seg in enumerate(segs):\n",
    "#                 if i == 0:\n",
    "#                     out.append('' + seg)\n",
    "#                 else:\n",
    "#                     out.append(seg)\n",
    "#             self.seg_dict[word] = out\n",
    "        \n",
    "#         self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "#         self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "#         self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "#         self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "\n",
    "#     def get_vocab(self):\n",
    "#         return self.vocab # note: we should probably use a getter here, but for now this is ok\n",
    "\n",
    "\n",
    "#     def encode(self, seq):\n",
    "#         text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "#         return text\n",
    "#         # words_a = [word for word in [word for word, offset in text]]\n",
    "#         # words_b = [word.replace('', '') for word in [word for word, offset in text]]\n",
    "#         # #print(f'words_a: {words_a}')\n",
    "#         # #print(f'words_b: {words_b}')\n",
    "#         # out = []\n",
    "#         # for i, word_b in enumerate(words_b):\n",
    "#         #     if word_b in self.seg_dict:\n",
    "#         #         out += [self.vocab[seg] for seg in self.seg_dict[word_b]]\n",
    "#         #     else:\n",
    "#         #         if words_a[i][0] == '':\n",
    "#         #             out += self.bpe_tokenizer.encode(' ' + word_b)\n",
    "#         #         else: \n",
    "#         #             out += self.bpe_tokenizer.encode(word_b)\n",
    "#         # #print(f'tokenization: {[self.inverted_vocab[id] for id in out]}')\n",
    "#         # #print(f'out = {out}')\n",
    "#         # return out\n",
    "\n",
    "\n",
    "#     def decode(self, ids: list[int]):\n",
    "#         assert type(ids) == list\n",
    "#        # assert type(ids[0]) == int   # dit kan wel netter, volgens mij kan het al met alleen type hints, en dit gaat mis is de list leeg is\n",
    "#         out = ''\n",
    "#         for id in ids:\n",
    "#             word = self.inverted_vocab[id]\n",
    "#             if word[0] == '':\n",
    "#                 out += word.replace('', ' ')\n",
    "#             else:\n",
    "#                 out += word\n",
    "#         return out\n",
    "    \n",
    "    \n",
    "#     def tokenize(self, seq):\n",
    "#         return [self.inverted_vocab[id] for id in self.encode(seq)] \n",
    "   \n",
    "\n",
    "#     def __call__(self, seq):\n",
    "#         ids = self.encode(seq)\n",
    "#         #types = [0 for token in ids]\n",
    "#         attention = [1 for token in ids]\n",
    "#         #return {'input_ids': ids, 'token_type_ids': types, 'attention_mask': attention}\n",
    "#         #return {'input_ids': ids}\n",
    "#         return {'input_ids': ids, 'attention_mask': attention}\n",
    "\n",
    "\n",
    "\n",
    "## DEZE NIET AANPASSEN ##\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomTokenizer:\n",
    "\n",
    "    def __init__(self, segmentation_dictionary, bpe_tokenizer, max_length=512, pad_to_multiple_of=None):\n",
    "        \n",
    "        self.bpe_tokenizer = bpe_tokenizer\n",
    "        self.bpe_vocab = self.bpe_tokenizer.get_vocab()\n",
    "\n",
    "        self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "        self.seg_dict = {}\n",
    "        for word, segs in self.segmentations.items():\n",
    "            out = []\n",
    "            for i, seg in enumerate(segs):\n",
    "                if i == 0:\n",
    "                    out.append('' + seg)\n",
    "                else:\n",
    "                    out.append(seg)\n",
    "            self.seg_dict[word] = out\n",
    "        \n",
    "        self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "        # self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "        # self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "\n",
    "        self.vocab = self.bpe_vocab.copy()\n",
    "        \n",
    "        for element in self.segments:\n",
    "            if element not in self.vocab:\n",
    "                self.vocab[element] = len(self.vocab) + 1\n",
    "\n",
    "        self.mask_token = \"<mask>\"\n",
    "        self.mask_token_id = self.vocab['<mask>']\n",
    "        self.vocab[self.mask_token_id] = self.vocab['<mask>']\n",
    "        \n",
    "        self.cls_token = \"<s>\"\n",
    "        self.cls_token_id = self.vocab['<s>']\n",
    "        self.vocab[self.cls_token] = self.vocab['<s>']\n",
    "        \n",
    "        self.sep_token = \"</s>\"\n",
    "        self.sep_token_id = self.vocab['</s>']\n",
    "        self.vocab[self.sep_token] = self.vocab['</s>']\n",
    "        \n",
    "        self.pad_token = '<pad>'\n",
    "        self.pad_token_id = self.vocab['<pad>']\n",
    "        self.vocab[self.pad_token] = self.vocab['<pad>']\n",
    "        \n",
    "\n",
    "\n",
    "        # self.unk_token = '<|endoftext|>'\n",
    "        # self.unk_token_id = self.vocab['<|endoftext|>']\n",
    "        # self.vocab[self.unk_token] = self.vocab['<|endoftext|>']\n",
    "        \n",
    "        self.vocab['<unk>'] = len(self.vocab) + 1 \n",
    "        self.unk_token = '<unk>'\n",
    "        self.unk_token_id = self.vocab['<unk>']\n",
    "        self.vocab[self.unk_token] = self.vocab['<unk>']\n",
    "        \n",
    "        # self.bos_token = '<|endoftext|>'\n",
    "        # self.bos_token_id = self.vocab['<|endoftext|>']\n",
    "        # self.vocab[self.bos_token] = self.vocab['<|endoftext|>']\n",
    "\n",
    "        self.bos_token = '<s>'\n",
    "        self.bos_token_id = self.vocab['<s>']\n",
    "        self.vocab[self.bos_token] = self.vocab['<s>']\n",
    "        \n",
    "        self.eos_token = \"</s>\"\n",
    "        self.eos_token_id = self.vocab[\"</s>\"]\n",
    "        self.vocab[self.eos_token] = self.vocab[\"</s>\"]\n",
    "        \n",
    "        self.special_tokens = [self.vocab['<mask>'], self.vocab['<s>'], self.vocab['</s>'], self.vocab['<pad>'], self.vocab['<unk>']]\n",
    "   \n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "    def tokenize(self, seq):\n",
    "\n",
    "        # Implement your token to ID conversion logic here\n",
    "        text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "        words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "        words_b = [word.replace('', '') for word in [word for word, offset in text]]\n",
    "        tokens = []\n",
    "        for i, word_b in enumerate(words_b):\n",
    "            if word_b in self.seg_dict:\n",
    "                tokens += self.seg_dict[word_b]\n",
    "            else:\n",
    "                if words_a[i][0] == '':\n",
    "                    tokens += self.bpe_tokenizer.tokenize(' ' + word_b)\n",
    "                else: \n",
    "                    tokens += self.bpe_tokenizer.tokenize(word_b)    \n",
    "        return tokens\n",
    "        \n",
    "        \n",
    "    def encode(self, seq):\n",
    "\n",
    "\n",
    "        return [self.bos_token_id] + self.convert_tokens_to_ids(self.tokenize(seq)) + [self.eos_token_id]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        if token in self.vocab:\n",
    "            return self.vocab[token]\n",
    "        else:\n",
    "            return self.unk_token_id\n",
    "\n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        if isinstance(tokens, list):\n",
    "            return [self._convert_token_to_id(token) for token in tokens]\n",
    "        return self._convert_token_to_id(tokens)\n",
    "\n",
    "\n",
    "    def _tokenize(self, seq):\n",
    "        text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "        words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "        words_b = [word.replace('', '') for word in [word for word, offset in text]]\n",
    "        tokens = []\n",
    "        for i, word_b in enumerate(words_b):\n",
    "            if word_b in self.seg_dict:\n",
    "                tokens += self.seg_dict[word_b]\n",
    "            else:\n",
    "                if words_a[i][0] == '':\n",
    "                    tokens += self.bpe_tokenizer.tokenize(' ' + word_b)\n",
    "                else: \n",
    "                    tokens += self.bpe_tokenizer.tokenize(word_b)    \n",
    "        return tokens\n",
    "\n",
    "\n",
    "    def __call__(self, text, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "        if isinstance(text, list):\n",
    "            self.batch_encode_plus(text, truncation=truncation, return_tensors=return_tensors, padding=padding, max_length=max_length, add_special_tokens=add_special_tokens)\n",
    "        else:\n",
    "\n",
    "            token_ids = self.encode(text) \n",
    "\n",
    "            if truncation and max_length:\n",
    "                token_ids = [self.bos_token_id] + token_ids[:max_length - 2] + [self.eos_token_id]\n",
    "            if padding and max_length is not None:\n",
    "                token_ids = token_ids + [self.pad_token_id] * (max_length - len(token_ids))\n",
    "            if return_tensors == \"pt\":\n",
    "                return {\"input_ids\": torch.tensor(token_ids, dtype=torch.long)}\n",
    "            return {\"input_ids\": token_ids}\n",
    "\n",
    "\n",
    "    def _convert_id_to_token(self, id):\n",
    "        # Implement your ID to token conversion logic here\n",
    "        return self.inverted_vocab[id]\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        # Convert IDs back to tokens\n",
    "        if isinstance(ids, list):\n",
    "            return [self._convert_id_to_token(id) for id in ids]\n",
    "        return self._convert_id_to_token(ids)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        out = ''\n",
    "        for id in ids:\n",
    "            word = self._convert_id_to_token(id)\n",
    "            if word[0] == '':\n",
    "                out += word.replace('', ' ')\n",
    "            else:\n",
    "                out += word\n",
    "        return out\n",
    "        \n",
    "\n",
    "    def get_special_tokens_mask(self, token_ids, already_has_special_tokens=False):\n",
    "        # Create a mask for special tokens\n",
    "        return [1 if self._is_special_token(token_id) else 0 for token_id in token_ids]\n",
    "\n",
    "\n",
    "    def _is_special_token(self, token_id):\n",
    "        # Implement your logic to check if a token is a special token\n",
    "        if token_id in self.special_tokens:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def batch_encode_plus(self, texts, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "        batch_token_ids = [self.__call__(text, truncation=truncation, max_length=max_length, add_special_tokens=add_special_tokens)[\"input_ids\"] for text in texts]\n",
    "        \n",
    "        if padding:\n",
    "            if max_length is None:\n",
    "                max_length = max(len(ids) for ids in batch_token_ids)\n",
    "            batch_token_ids = [ids + [self.pad_token_id] * (max_length - len(ids)) for ids in batch_token_ids]\n",
    "        \n",
    "        if return_tensors == \"pt\":\n",
    "            return {\"input_ids\": torch.tensor(batch_token_ids, dtype=torch.long)}\n",
    "        return {\"input_ids\": batch_token_ids}\n",
    "\n",
    "\n",
    "    def pad(self, batch, return_tensors=\"pt\", pad_to_multiple_of=None):\n",
    "        if pad_to_multiple_of is None:\n",
    "            pad_to_multiple_of = self.pad_to_multiple_of\n",
    "\n",
    "\n",
    "        input_ids_list = []\n",
    "        for dictionary in batch:\n",
    "            for key, value in dictionary.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    input_ids_list.append(value.tolist())\n",
    "\n",
    "\n",
    "        max_length = self.max_length or max(len(x) for x in input_ids_list)\n",
    "        \n",
    "        if pad_to_multiple_of is not None:\n",
    "            max_length = (max_length + pad_to_multiple_of - 1) // pad_to_multiple_of * pad_to_multiple_of\n",
    "        \n",
    "        padded_batch = []\n",
    "        for seq in input_ids_list:\n",
    "            if len(seq) < max_length:\n",
    "                seq.extend([self.pad_token_id] * (max_length - len(seq)))\n",
    "            padded_batch.append(seq)\n",
    "        \n",
    "        attention_list = []\n",
    "        for inner_list in padded_batch:\n",
    "            p_list = [1 if value < self.vocab_size else 0 for value in inner_list]\n",
    "            attention_list.append(p_list)\n",
    "        \n",
    "        if return_tensors == \"pt\":\n",
    "            return {'input_ids': torch.tensor(padded_batch, dtype=torch.long), 'attention_mask': torch.tensor(attention_list, dtype=torch.long)}\n",
    "        \n",
    "        return {'input_ids': padded_batch, 'attention_mask': attention_list}\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizerWP:\n",
    "\n",
    "    def __init__(self, segmentation_dictionary, wp_tokenizer, max_length=512, pad_to_multiple_of=None):\n",
    "        \n",
    "        self.wp_tokenizer = wp_tokenizer\n",
    "        self.wp_vocab = self.wp_tokenizer.get_vocab()\n",
    "\n",
    "        self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "        self.seg_dict = {}\n",
    "        for word, segs in self.segmentations.items():\n",
    "            out = []\n",
    "            for i, seg in enumerate(segs):\n",
    "                if i == 0:\n",
    "                    out.append(seg)\n",
    "                else:\n",
    "                    out.append('##' + seg)\n",
    "            self.seg_dict[word] = out\n",
    "        \n",
    "        self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "        # self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "        # self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "\n",
    "        self.vocab = self.wp_vocab.copy()\n",
    "        \n",
    "        for element in self.segments:\n",
    "            if element not in self.vocab:\n",
    "                self.vocab[element] = len(self.vocab) + 1\n",
    "        \n",
    "\n",
    "        self.l = len(self.vocab)\n",
    "\n",
    "        self.vocab['<unk>'] = self.l + 1 \n",
    "        self.unk_token = '<unk>'\n",
    "        self.unk_token_id = self.vocab['<unk>']\n",
    "        self.vocab[self.unk_token] = self.vocab['<unk>']\n",
    "\n",
    "        self.vocab['<mask>'] = self.l + 2 \n",
    "        self.mask_token = \"<mask>\"\n",
    "        self.mask_token_id = self.vocab['<mask>']\n",
    "        self.vocab[self.mask_token_id] = self.vocab['<mask>']\n",
    "        \n",
    "        self.vocab['<s>'] = self.l + 3\n",
    "        self.cls_token = \"<s>\"\n",
    "        self.cls_token_id = self.vocab['<s>']\n",
    "        self.vocab[self.cls_token] = self.vocab['<s>']\n",
    "        \n",
    "        self.vocab['</s>'] = self.l + 4\n",
    "        self.sep_token = \"</s>\"\n",
    "        self.sep_token_id = self.vocab['</s>']\n",
    "        self.vocab[self.sep_token] = self.vocab['</s>']\n",
    "        \n",
    "        self.vocab['<pad>'] = self.l + 5\n",
    "        self.pad_token = '<pad>'\n",
    "        self.pad_token_id = self.vocab['<pad>']\n",
    "        self.vocab[self.pad_token] = self.vocab['<pad>']\n",
    "        \n",
    "        self.vocab['<s>'] = self.l + 6\n",
    "        self.bos_token = '<s>'\n",
    "        self.bos_token_id = self.vocab['<s>']\n",
    "        self.vocab[self.bos_token] = self.vocab['<s>']\n",
    "        \n",
    "        self.vocab['</s>'] = self.l + 7 \n",
    "        self.eos_token = \"</s>\"\n",
    "        self.eos_token_id = self.vocab[\"</s>\"]\n",
    "        self.vocab[self.eos_token] = self.vocab[\"</s>\"]\n",
    "        \n",
    "        self.special_tokens = [self.vocab['<mask>'], self.vocab['<s>'], self.vocab['</s>'], self.vocab['<pad>'], self.vocab['<unk>']]\n",
    "   \n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "    def tokenize(self, seq):\n",
    "\n",
    "\n",
    "        text = self.wp_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "        words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "        words_b = [word.replace('##', '') for word in [word for word, offset in text]]\n",
    "        tokens = []\n",
    "        for i, word_b in enumerate(words_b):\n",
    "            if word_b in self.seg_dict:\n",
    "                tokens += self.seg_dict[word_b]\n",
    "            else:\n",
    "                if words_a[i][0] == '##':\n",
    "                    tokens += self.wp_tokenizer.tokenize(word_b)\n",
    "                else: \n",
    "                    tokens += self.wp_tokenizer.tokenize(' ' + word_b)    \n",
    "        return tokens\n",
    "        \n",
    "        \n",
    "    def encode(self, seq):\n",
    "\n",
    "\n",
    "        return [self.bos_token_id] + self.convert_tokens_to_ids(self.tokenize(seq)) + [self.eos_token_id]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        if token in self.vocab:\n",
    "            return self.vocab[token]\n",
    "        else:\n",
    "            return self.unk_token_id\n",
    "\n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        if isinstance(tokens, list):\n",
    "            return [self._convert_token_to_id(token) for token in tokens]\n",
    "        return self._convert_token_to_id(tokens)\n",
    "\n",
    "\n",
    "    def _tokenize(self, seq):\n",
    "\n",
    "        text = self.wp_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "        words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "        words_b = [word.replace('##', '') for word in [word for word, offset in text]]\n",
    "        tokens = []\n",
    "        for i, word_b in enumerate(words_b):\n",
    "            if word_b in self.seg_dict:\n",
    "                tokens += self.seg_dict[word_b]\n",
    "            else:\n",
    "                if words_a[i][0] == '##':\n",
    "                    tokens += self.wp_tokenizer.tokenize(word_b)\n",
    "                else: \n",
    "                    tokens += self.wp_tokenizer.tokenize(' ' + word_b)    \n",
    "        return tokens\n",
    "\n",
    "\n",
    "    def __call__(self, text, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "        if isinstance(text, list):\n",
    "            self.batch_encode_plus(text, truncation=truncation, return_tensors=return_tensors, padding=padding, max_length=max_length, add_special_tokens=add_special_tokens)\n",
    "        else:\n",
    "\n",
    "            token_ids = self.encode(text) \n",
    "\n",
    "            if truncation and max_length:\n",
    "                token_ids = [self.bos_token_id] + token_ids[:max_length - 2] + [self.eos_token_id]\n",
    "            if padding and max_length is not None:\n",
    "                token_ids = token_ids + [self.pad_token_id] * (max_length - len(token_ids))\n",
    "            if return_tensors == \"pt\":\n",
    "                return {\"input_ids\": torch.tensor(token_ids, dtype=torch.long)}\n",
    "            return {\"input_ids\": token_ids}\n",
    "\n",
    "\n",
    "    def _convert_id_to_token(self, id):\n",
    "        # Implement your ID to token conversion logic here\n",
    "        return self.inverted_vocab[id]\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        # Convert IDs back to tokens\n",
    "        if isinstance(ids, list):\n",
    "            return [self._convert_id_to_token(id) for id in ids]\n",
    "        return self._convert_id_to_token(ids)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        out = ''\n",
    "        for id in ids:\n",
    "            word = self._convert_id_to_token(id)\n",
    "            if word[:2] == '##':\n",
    "                out += word.replace('##', '')\n",
    "            else:\n",
    "                out += ' ' + word\n",
    "        return out\n",
    "        \n",
    "\n",
    "    def get_special_tokens_mask(self, token_ids, already_has_special_tokens=False):\n",
    "        # Create a mask for special tokens\n",
    "        return [1 if self._is_special_token(token_id) else 0 for token_id in token_ids]\n",
    "\n",
    "\n",
    "    def _is_special_token(self, token_id):\n",
    "        # Implement your logic to check if a token is a special token\n",
    "        if token_id in self.special_tokens:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def batch_encode_plus(self, texts, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "        batch_token_ids = [self.__call__(text, truncation=truncation, max_length=max_length, add_special_tokens=add_special_tokens)[\"input_ids\"] for text in texts]\n",
    "        \n",
    "        if padding:\n",
    "            if max_length is None:\n",
    "                max_length = max(len(ids) for ids in batch_token_ids)\n",
    "            batch_token_ids = [ids + [self.pad_token_id] * (max_length - len(ids)) for ids in batch_token_ids]\n",
    "        \n",
    "        if return_tensors == \"pt\":\n",
    "            return {\"input_ids\": torch.tensor(batch_token_ids, dtype=torch.long)}\n",
    "        return {\"input_ids\": batch_token_ids}\n",
    "\n",
    "\n",
    "    def pad(self, batch, return_tensors=\"pt\", pad_to_multiple_of=None):\n",
    "        if pad_to_multiple_of is None:\n",
    "            pad_to_multiple_of = self.pad_to_multiple_of\n",
    "\n",
    "\n",
    "        input_ids_list = []\n",
    "        for dictionary in batch:\n",
    "            for key, value in dictionary.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    input_ids_list.append(value.tolist())\n",
    "\n",
    "\n",
    "        max_length = self.max_length or max(len(x) for x in input_ids_list)\n",
    "        \n",
    "        if pad_to_multiple_of is not None:\n",
    "            max_length = (max_length + pad_to_multiple_of - 1) // pad_to_multiple_of * pad_to_multiple_of\n",
    "        \n",
    "        padded_batch = []\n",
    "        for seq in input_ids_list:\n",
    "            if len(seq) < max_length:\n",
    "                seq.extend([self.pad_token_id] * (max_length - len(seq)))\n",
    "            padded_batch.append(seq)\n",
    "        \n",
    "        attention_list = []\n",
    "        for inner_list in padded_batch:\n",
    "            p_list = [1 if value < self.vocab_size else 0 for value in inner_list]\n",
    "            attention_list.append(p_list)\n",
    "        \n",
    "        if return_tensors == \"pt\":\n",
    "            return {'input_ids': torch.tensor(padded_batch, dtype=torch.long), 'attention_mask': torch.tensor(attention_list, dtype=torch.long)}\n",
    "        \n",
    "        return {'input_ids': padded_batch, 'attention_mask': attention_list}\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "\n",
    "# class CustomTokenizer:\n",
    "\n",
    "#     def __init__(self, segmentation_dictionary, bpe_tokenizer):\n",
    "        \n",
    "#         self.bpe_tokenizer = bpe_tokenizer\n",
    "#         self.bpe_vocab = self.bpe_tokenizer.get_vocab()\n",
    "\n",
    "#         self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "#         self.seg_dict = {}\n",
    "#         for word, segs in self.segmentations.items():\n",
    "#             out = []\n",
    "#             for i, seg in enumerate(segs):\n",
    "#                 if i == 0:\n",
    "#                     out.append('' + seg)\n",
    "#                 else:\n",
    "#                     out.append(seg)\n",
    "#             self.seg_dict[word] = out\n",
    "        \n",
    "#         self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "#         self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "#         self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "    \n",
    "#         self.vs = len(self.vocab)\n",
    "#         self.mask_token = \"<mask>\"\n",
    "#         self.mask_token_id = self.vs + 1\n",
    "#         self.vocab[self.mask_token_id] = self.vs + 1\n",
    "#         self.cls_token = \"<s>\"\n",
    "#         self.cls_token_id = self.vs + 2\n",
    "#         self.vocab[self.cls_token] = self.vs + 2\n",
    "#         self.sep_token = \"</s>\"\n",
    "#         self.sep_token_id = self.vs + 3\n",
    "#         self.vocab[self.sep_token] = self.vs + 3\n",
    "#         self.pad_token = '<pad>'\n",
    "#         self.pad_token_id = self.vs + 4\n",
    "#         self.vocab[self.pad_token] = self.vs + 4\n",
    "#         #self.unk_token = '<unk>'\n",
    "#         self.unk_token = '<|endoftext|>'\n",
    "#         self.unk_token_id = self.vs + 5\n",
    "#         self.vocab[self.unk_token] = self.vs + 5\n",
    "#         #self.bos_token = '<s>'\n",
    "#         self.bos_token = '<|endoftext|>'\n",
    "#         self.bos_token_id = self.vs + 6\n",
    "#         self.vocab[self.bos_token] = self.vs + 6\n",
    "#         #self.eos_token = '</s>'\n",
    "#         self.eos_token = '<|endoftext|>'\n",
    "#         self.eos_token_id = self.vs + 7\n",
    "#         self.vocab[self.eos_token] = self.vs + 7\n",
    "        \n",
    "#         self.vocab_size = len(self.vocab)\n",
    "\n",
    "#         self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "\n",
    "\n",
    "#     def get_vocab(self):\n",
    "#         return self.vocab\n",
    "\n",
    "    \n",
    "#     def tokenize(self, seq):\n",
    "\n",
    "#         # Implement your token to ID conversion logic here\n",
    "#         text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "#         words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "#         words_b = [word.replace('', '') for word in [word for word, offset in text]]\n",
    "#         tokens = []\n",
    "#         for i, word_b in enumerate(words_b):\n",
    "#             if word_b in self.seg_dict:\n",
    "#                 tokens += self.seg_dict[word_b]\n",
    "#             else:\n",
    "#                 if words_a[i][0] == '':\n",
    "#                     tokens += self.bpe_tokenizer.tokenize(' ' + word_b)\n",
    "#                 else: \n",
    "#                     tokens += self.bpe_tokenizer.tokenize(word_b)    \n",
    "#         return tokens\n",
    "        \n",
    "#     def encode(self, seq):\n",
    "#         return self.convert_tokens_to_ids(self.tokenize(seq))\n",
    "\n",
    "\n",
    "#     def _convert_token_to_id(self, token):\n",
    "#         if token in self.vocab:\n",
    "#             return self.vocab[token]\n",
    "#         else:\n",
    "#             return self.unk_token_id\n",
    "\n",
    "    \n",
    "#     def convert_tokens_to_ids(self, tokens):\n",
    "#         if isinstance(tokens, list):\n",
    "#             return [self._convert_token_to_id(token) for token in tokens]\n",
    "#         return self._convert_token_to_id(tokens)\n",
    "\n",
    "\n",
    "#     def _tokenize(self, seq):\n",
    "#         text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "#         words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "#         words_b = [word.replace('', '') for word in [word for word, offset in text]]\n",
    "#         tokens = []\n",
    "#         for i, word_b in enumerate(words_b):\n",
    "#             if word_b in self.seg_dict:\n",
    "#                 tokens += self.seg_dict[word_b]\n",
    "#             else:\n",
    "#                 if words_a[i][0] == '':\n",
    "#                     tokens += self.bpe_tokenizer.tokenize(' ' + word_b)\n",
    "#                 else: \n",
    "#                     tokens += self.bpe_tokenizer.tokenize(word_b)    \n",
    "#         return tokens\n",
    "\n",
    "\n",
    "\n",
    "#     def __call__(self, text, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "#         if isinstance(text, list):\n",
    "#             self.batch_encode_plus(text, truncation=truncation, return_tensors=return_tensors, padding=padding, max_length=max_length, add_special_tokens=add_special_tokens)\n",
    "#         else:\n",
    "\n",
    "#             token_ids = self.encode(text)  \n",
    "#             if add_special_tokens:\n",
    "#                 token_ids = [self.bos_token_id] + token_ids + [self.eos_token_id]\n",
    "#             if truncation and max_length is not None:\n",
    "#                 token_ids = token_ids[:max_length]\n",
    "#             if padding and max_length is not None:\n",
    "#                 token_ids = token_ids + [self.pad_token_id] * (max_length - len(token_ids))\n",
    "#             if return_tensors == \"pt\":\n",
    "#                 return {\"input_ids\": torch.tensor(token_ids, dtype=torch.long)}\n",
    "#             return {\"input_ids\": token_ids}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     def _convert_id_to_token(self, id):\n",
    "#         # Implement your ID to token conversion logic here\n",
    "#         return self.inverted_vocab[id]\n",
    "\n",
    "#     def convert_ids_to_tokens(self, ids):\n",
    "#         # Convert IDs back to tokens\n",
    "#         if isinstance(ids, list):\n",
    "#             return [self._convert_id_to_token(id) for id in ids]\n",
    "#         return self._convert_id_to_token(ids)\n",
    "    \n",
    "#     def decode(self, ids):\n",
    "#         out = ''\n",
    "#         for id in ids:\n",
    "#             word = self._convert_id_to_token(id)\n",
    "#             if word[0] == '':\n",
    "#                 out += word.replace('', ' ')\n",
    "#             else:\n",
    "#                 out += word\n",
    "#         return out\n",
    "        \n",
    "\n",
    "#     def get_special_tokens_mask(self, token_ids, already_has_special_tokens=False):\n",
    "#         # Create a mask for special tokens\n",
    "#         return [1 if self._is_special_token(token_id) else 0 for token_id in token_ids]\n",
    "\n",
    "\n",
    "#     def _is_special_token(self, token_id):\n",
    "#         # Implement your logic to check if a token is a special token\n",
    "#         if token_id in self.special_tokens:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "\n",
    "\n",
    "\n",
    "#     def batch_encode_plus(self, texts, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=True):\n",
    "#         batch_token_ids = [self.__call__(text, truncation=truncation, max_length=max_length, add_special_tokens=add_special_tokens)[\"input_ids\"] for text in texts]\n",
    "        \n",
    "#         if padding:\n",
    "#             if max_length is None:\n",
    "#                 max_length = max(len(ids) for ids in batch_token_ids)\n",
    "#             batch_token_ids = [ids + [self.pad_token_id] * (max_length - len(ids)) for ids in batch_token_ids]\n",
    "        \n",
    "#         if return_tensors == \"pt\":\n",
    "#             return {\"input_ids\": torch.tensor(batch_token_ids, dtype=torch.long)}\n",
    "#         return {\"input_ids\": batch_token_ids}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 29.3 ms, total: 1.21 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# import os\n",
    "# import torch\n",
    "# from datasets import Dataset\n",
    "\n",
    "\n",
    "# # pick tokenizer\n",
    "# tokenizer = ff\n",
    "\n",
    "# # pick txt file to transform\n",
    "# text_file_path = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_shorter.txt'\n",
    "\n",
    "# def tokenize_line(line):\n",
    "#     # Specify the max_length parameter to ensure consistent padding\n",
    "#     return {'input_ids': tokenizer(line.strip())['input_ids']}\n",
    "#     #return tokenizer(line, truncation=False, max_length=512, return_tensors='pt', add_special_tokens=False)\n",
    "\n",
    "# # Read the text file and tokenize each line\n",
    "# with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "#     lines = file.readlines()\n",
    "\n",
    "# # Create a list of dictionaries with tokenized lines\n",
    "# tokenized_lines = [tokenize_line(line) for line in lines]\n",
    "\n",
    "# # Create a Hugging Face dataset from the list of dictionaries\n",
    "# dataset = Dataset.from_list(tokenized_lines).with_format(\"torch\")\n",
    "\n",
    "# # save\n",
    "# #dataset.save_to_disk('tokenized_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=ff, mlm=True, mlm_probability=0.15\n",
    "# )\n",
    "\n",
    "# # klein model om te testen\n",
    "# config = RobertaConfig(\n",
    "#     vocab_size=len(tokenizer.get_vocab()),\n",
    "#     max_position_embeddings=514,\n",
    "#     num_attention_heads=6,\n",
    "#     num_hidden_layers=3,\n",
    "#     type_vocab_size=1,\n",
    "# )\n",
    "\n",
    "\n",
    "# model = RobertaForMaskedLM(config=config)\n",
    "\n",
    "# print(f'number of parameters model: {model.num_parameters()}')\n",
    "\n",
    "# from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"/Users/jan/Documents/Master/Thesis/Code/Models/model2\", # note, this is not where the model is saved, just info about training\n",
    "#     overwrite_output_dir=True,\n",
    "#     num_train_epochs=1,\n",
    "#     per_device_train_batch_size=64,\n",
    "#     save_steps=10_000,\n",
    "#     save_total_limit=1000,\n",
    "#     prediction_loss_only=True,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=dataset,\n",
    "# )\n",
    "\n",
    "# %%time\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must now find a way to convert the toke ids to text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_b: ['fietsen']\n",
      "out = [15022]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15022]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laten we fietsen nemen\n",
    "\n",
    "x = CustomTokenizerMorphPiece(segmentations, tokenizer)\n",
    "\n",
    "x.encode('fietsen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fiets'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.decode([15022])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of own tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to evaluate how specific words are tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simlex(simlex999, scores=False):\n",
    "    # create list with a tuple for every word pair in the form of (word_1, word_2, similarity score, POS-tag)\n",
    "    word_pairs = []\n",
    "\n",
    "    # create a set with all words\n",
    "    words_set = set([])\n",
    "\n",
    "    with open(simlex999) as simlex:\n",
    "        \n",
    "        next(simlex) # skip first line\n",
    "        \n",
    "        for line in simlex:\n",
    "    \n",
    "            split = line.strip().split('\\t')\n",
    "            word_pairs.append(tuple(split))\n",
    "            words_set.add(split[0])\n",
    "            words_set.add(split[1])\n",
    "\n",
    "    # create a list of unique words\n",
    "    simlex_words = list(words_set)\n",
    "\n",
    "    if scores:\n",
    "        return word_pairs\n",
    "    else:\n",
    "        return simlex_words\n",
    "\n",
    "def simlex_celex(df, n, simlex_words, exclusive=False, with_segments=False):\n",
    "\n",
    "    d = create_n_segmentations(df, 0)\n",
    "    dic = {}\n",
    "\n",
    "    for i in range(n + 2):\n",
    "        data = create_n_segmentations(df, i)\n",
    "        dic[i] = []\n",
    "        for word in simlex_words:\n",
    "            if word in data:\n",
    "                dic[i].append(word)\n",
    "\n",
    "    if exclusive:\n",
    "        out = list(set(dic[n]) - set(dic[n + 1]))\n",
    "    else:\n",
    "        out = dic[n]\n",
    "    \n",
    "    if with_segments:\n",
    "        out = {word: d[word] for word in out}\n",
    "    \n",
    "    print(f'There are {len(simlex_words)} unique words in the simlex dataset')\n",
    "    \n",
    "    if n != 1:\n",
    "        if exclusive:\n",
    "            print(f'There are {len(out)} words in simlex that have exactly {n} segments in CELEX')\n",
    "        else:\n",
    "            print(f'There are {len(out)} words in simlex that have at least {n} segments in CELEX')\n",
    "    else:\n",
    "        if exclusive:\n",
    "            print(f'There are {len(out)} words in simlex that have exactly {n} segment in CELEX')\n",
    "        else:\n",
    "            print(f'There are {len(out)} words in simlex that have at least {n} segment in CELEX') \n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def tokenizer_segmentations(words, tokenizer, only_splits=False):\n",
    "    \n",
    "    segs = {}\n",
    "\n",
    "    for word in words:\n",
    "        tokenization = tokenizer.tokenize(word)\n",
    "        tokenization = [word.replace('', '') for word in tokenization]\n",
    "        tokenization = [word.replace('##', '') for word in tokenization]\n",
    "        segs[word] = tokenization\n",
    "    \n",
    "    if only_splits:\n",
    "        return {word: seg for word, seg in segs.items() if len(seg) > 1}\n",
    "    else:\n",
    "        return segs\n",
    "\n",
    "\n",
    "def compare_tokenizer_segmentations(words, *tokenizers):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for tokenizer in tokenizers:\n",
    "        results[tokenizer] = tokenizer_segmentations(words, tokenizer)\n",
    "    \n",
    "    words_same = []\n",
    "    words_diff = []\n",
    "\n",
    "    for word in words:\n",
    "        comp = {}\n",
    "        for tokenizer in results:\n",
    "            comp[tokenizer] = results[tokenizer][word]\n",
    "        iterator = iter(comp.values())\n",
    "        first_value = next(iterator)\n",
    "        if all(value == first_value for value in iterator):\n",
    "            words_same.append(word)\n",
    "        else:\n",
    "            words_diff.append(word)\n",
    "    \n",
    "    diff = {}\n",
    "    for word in words_diff:\n",
    "        c = {}\n",
    "        for i, tokenizer in enumerate(tokenizers):\n",
    "            c[i+1] = results[tokenizer][word]\n",
    "        diff[word] = c\n",
    "\n",
    "    \n",
    "    if len(tokenizers) == 2:\n",
    "        print(f'{len(words_same)} words out of the {len(words)} are tokenized in the same way by both tokenizers')\n",
    "    else:\n",
    "        print(f'{len(words_same)} words out of the {len(words)} are tokenized in the same way by all {len(tokenizers)} tokenizers')\n",
    "\n",
    "    return words_same, words_diff, diff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_tokenizer_with_celex(df, tokenizer):\n",
    "\n",
    "    words = [word for word in df]\n",
    "    segs = tokenizer_segmentations(words, tokenizer)\n",
    "\n",
    "    words_same = []\n",
    "    words_diff = []\n",
    "    diff = {}\n",
    "\n",
    "    for word in df:\n",
    "        if df[word] == segs[word]:\n",
    "            words_same.append(word)\n",
    "        else:\n",
    "            words_diff.append(word)\n",
    "    \n",
    "    diff = {}\n",
    "    for word in words_diff:\n",
    "        if len(segs[word]) >= 2:\n",
    "            c = {}\n",
    "            c['CELEX'] = df[word]\n",
    "            c['tokenizer'] = segs[word]\n",
    "            diff[word] = c\n",
    "    \n",
    "    return words_same, words_diff, diff\n",
    "\n",
    "def return_words_not_in_dict(df, words):\n",
    "    out = []\n",
    "    for word in words:\n",
    "        if word not in df:\n",
    "            out.append(word)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to evaluate speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# function to create a dataset with text \n",
    "def create_test_set(dataset_generator, start, end):\n",
    "    it = iter(dataset_generator)\n",
    "    for _ in range(start):\n",
    "        next(it)\n",
    "    for _ in range(end - start + 1):\n",
    "        yield next(it)\n",
    "\n",
    "\n",
    "# function to measure time a function takes\n",
    "def measure_execution_time(function, *args, **kwargs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    function(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# function to measure how much time it takes for a function to process data\n",
    "# the function here should not take a generator as input\n",
    "# the data is supplied by a generator\n",
    "def measure_time_normal_function_x(data_generator, start, end, function, *args, **kwargs):\n",
    "\n",
    "    gen = create_test_set(data_generator, start, end)\n",
    "    t=0\n",
    "\n",
    "    for i in gen:\n",
    "        text = i['text']\n",
    "        t += measure_execution_time(function, text, *args, **kwargs)\n",
    "    \n",
    "    return t\n",
    "\n",
    "# this function takes a generator and function as input, and measures the time it takes to execute the function for every item in the generator\n",
    "def measure_time_normal_function(data_generator, start, end, function, *args, **kwargs):\n",
    "\n",
    "    gen = create_test_set(data_generator, start, end)\n",
    "    t=0\n",
    "\n",
    "    for i in gen:\n",
    "        t += measure_execution_time(function, i, *args, **kwargs)\n",
    "    \n",
    "    return t\n",
    "\n",
    "\n",
    "# function to measure how much time it takes a function to execute for every item in the generator\n",
    "# same as the function above, but this one is for functions that take a generator as argument\n",
    "def measure_time_generator_function(data_generator, start, end, function, *args, **kwargs):\n",
    "    \n",
    "    gen = create_test_set(data_generator, start, end)\n",
    "    return measure_execution_time(function, gen, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# function to use for the generators that yield dictionaries with 'text' as key\n",
    "# this is for the iterable dictionary provided by hugging face\n",
    "# (We now use a wrapper generator, so probably don't need this anymore)\n",
    "def measure_time_iterable_text_dict(data_generator, start, end, function, *args, **kwargs):\n",
    "    \n",
    "    data_generator = create_text_generator(data_generator)\n",
    "    gen = create_test_set(data_generator, start, end)\n",
    "    return measure_execution_time(function, gen, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# function to turn a generator that returns a dictionary with 'text' as key into a generator of the values\n",
    "def create_text_generator(gen):\n",
    "    for i in gen:\n",
    "        yield i['text']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual evaluation and comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the tokenizers, we need the following elements:\n",
    "- the simlex words\n",
    "- a corpus in the form of a generator\n",
    "- a corpus in the form of a frequency dictionary\n",
    "\n",
    "We will create various different versions of these three elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the tokenizers we have trained externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import RobertaTokenizerFast\n",
    "# maakt het uit of we autotokenizer of tokenizerfast gebruiken?\n",
    "\n",
    "\n",
    "t1 = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "t2 = AutoTokenizer.from_pretrained(\"DTAI-KULeuven/robbert-2023-dutch-large\")\n",
    "\n",
    "\n",
    "# WordPiece tokenizers\n",
    "wp_30 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeWP/t30\", max_len=512)\n",
    "wp_40 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeWP/t40\", max_len=512)\n",
    "wp_50 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeWP/t50\", max_len=512)\n",
    "\n",
    "# BPE tokenizer\n",
    "bpe_30 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeBPE/t30\", max_len=512)\n",
    "bpe_40 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeBPE/t40\", max_len=512)\n",
    "bpe_50 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeBPE/t50\", max_len=512)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "t30 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t30\", max_len=512)\n",
    "t32 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t32\", max_len=512)\n",
    "t35 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t35\", max_len=512)\n",
    "t40 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t40\", max_len=512)\n",
    "t45 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t45\", max_len=512)\n",
    "t50 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t50\", max_len=512)\n",
    "\n",
    "# own custom tokenizers\n",
    "own_30 = CustomTokenizer(segmentation_dictionary, t30)\n",
    "own_32 = CustomTokenizer(segmentation_dictionary, t32)\n",
    "own_35 = CustomTokenizer(segmentation_dictionary, t35)\n",
    "own_40 = CustomTokenizer(segmentation_dictionary, t40)\n",
    "own_45 = CustomTokenizer(segmentation_dictionary, t45)\n",
    "own_50 = CustomTokenizer(segmentation_dictionary, t50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41752"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(own_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ik', 'ga', 'lopen']\n",
      "['ik', 'ga', 'lopen']\n",
      "['ik', 'ga', 'l', 'open']\n"
     ]
    }
   ],
   "source": [
    "print(wp_50.tokenize('ik ga lopen'))\n",
    "print(bpe_50.tokenize('ik ga lopen'))\n",
    "print(own_50.tokenize('ik ga lopen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677 words out of the 1045 are tokenized in the same way by both tokenizers\n"
     ]
    }
   ],
   "source": [
    "a, b, c = compare_tokenizer_segmentations(simlex_words, wp_50, bpe_50)\n",
    "\n",
    "#c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_splits(words, tokenizer):\n",
    "\n",
    "    toks = tokenizer_segmentations(words, tokenizer)\n",
    "\n",
    "    split = {}\n",
    "    no_split = []\n",
    "    for word, segs in toks.items():\n",
    "        if len(segs) > 1:\n",
    "            split[word] = segs\n",
    "        else:\n",
    "            no_split.append(word)\n",
    "    \n",
    "    print(f'Number of words split up: {len(split)}')\n",
    "    print(f'Number of words not split up: {len(no_split)}')\n",
    "\n",
    "    return split, no_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words split up: 161\n",
      "Number of words not split up: 884\n"
     ]
    }
   ],
   "source": [
    "r, t = count_splits(simlex_words, wp_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words split up: 441\n",
      "Number of words not split up: 604\n"
     ]
    }
   ],
   "source": [
    "r, t = count_splits(simlex_words, bpe_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words split up: 390\n",
      "Number of words not split up: 655\n"
     ]
    }
   ],
   "source": [
    "r, t = count_splits(simlex_words, own_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46398"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(own_50.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prachtig ['pracht', 'ig']\n",
      "rekenkunde ['reken', 'kunde']\n",
      "doel ['doel']\n",
      "gangpad ['gang', 'pad']\n",
      "scheikunde ['sche', 'ik', 'unde']\n",
      "tabak ['tabak']\n",
      "situatie ['situatie']\n",
      "winnen ['w', 'innen']\n",
      "blik ['blik']\n",
      "boom ['boom']\n",
      "baksteen ['bak', 'steen']\n",
      "agressie ['agressie']\n",
      "lezen ['lezen']\n",
      "kapitein ['kapitein']\n",
      "vers ['vers']\n",
      "regio ['regio']\n",
      "ballade ['ballade']\n",
      "uitbeelden ['uit', 'beeld', 'en']\n",
      "kraampje ['kra', 'amp', 'je']\n",
      "telefoon ['telefoon']\n",
      "melodie ['mel', 'od', 'ie']\n",
      "prins ['prins']\n",
      "koor ['koor']\n",
      "discussie ['discussie']\n",
      "monster ['monster']\n",
      "wortel ['wortel']\n",
      "zelf ['zelf']\n",
      "schildwacht ['schild', 'wacht']\n",
      "macht ['macht']\n",
      "vrolijk ['vrolijk']\n",
      "motor ['motor']\n",
      "diamant ['diamant']\n",
      "theorie ['theorie']\n",
      "misdaad ['mis', 'daad']\n",
      "emotie ['emotie']\n",
      "zeker ['zeker']\n",
      "mantel ['mantel']\n",
      "aanzien ['aanzien']\n",
      "psychologie ['psych', 'ologie']\n",
      "bijwonen ['bij', 'wonen']\n",
      "doos ['doos']\n",
      "insect ['inse', 'ct']\n",
      "doen alsof ['doen', 'alsof']\n",
      "toevoegen ['toe', 'voeg', 'en']\n",
      "ongeduldig ['on', 'geduld', 'ig']\n",
      "pijpleiding ['pijp', 'leid', 'ing']\n",
      "goedkoop ['goed', 'koop']\n",
      "acteur ['acteur']\n",
      "dragen ['dragen']\n",
      "verdedigen ['verde', 'digen']\n",
      "vergeten ['vergeten']\n",
      "arts ['arts']\n",
      "jaar ['jaar']\n",
      "erkennen ['er', 'kennen']\n",
      "vermoeden ['vermoeden']\n",
      "wang ['wang']\n",
      "straalvliegtuig ['straal', 'vlieg', 'tuig']\n",
      "dom ['dom']\n",
      "komen ['kom', 'en']\n",
      "verstikken ['ver', 'st', 'ikken']\n",
      "beeld ['beeld']\n",
      "gevoel ['ge', 'voel']\n",
      "kostuum ['kostuum']\n",
      "gehoorzamen ['geh', 'oor', 'z', 'amen']\n",
      "chocolade ['chocolade']\n",
      "tevredenstellen ['tevreden', 'stellen']\n",
      "bol ['bol']\n",
      "bestelling ['be', 'stelling']\n",
      "infectie ['infect', 'ie']\n",
      "dieet ['dieet']\n",
      "fles ['fles']\n",
      "achterlaten ['achter', 'laten']\n",
      "onderbuik ['onder', 'buik']\n",
      "klif ['klif']\n",
      "zin ['zin']\n",
      "analyseren ['anal', 'ys', 'eren']\n",
      "stof ['stof']\n",
      "bank ['bank']\n",
      "lus ['lus']\n",
      "bankier ['bank', 'ier']\n",
      "kanon ['kanon']\n",
      "bewustzijn ['bewust', 'zijn']\n",
      "jenever ['jenever']\n",
      "stoer ['stoer']\n",
      "prooi ['prooi']\n",
      "administratie ['administratie']\n",
      "bidden ['bid', 'den']\n",
      "gelukkigheid ['gelukkig', 'heid']\n",
      "keel ['keel']\n",
      "persoon ['persoon']\n",
      "mes ['mes']\n",
      "advocaat ['advocaat']\n",
      "neus ['neus']\n",
      "straal ['straal']\n",
      "handschoen ['hand', 'schoen']\n",
      "cel ['cel']\n",
      "artikel ['artikel']\n",
      "onderzoeken ['onder', 'zoek', 'en']\n",
      "massa ['massa']\n",
      "sigaar ['sigaar']\n",
      "kanker ['kanker']\n",
      "marihuana ['mar', 'i', 'hu', 'ana']\n",
      "stroom ['stroom']\n",
      "dame ['dame']\n",
      "stemmen op ['stemmen', 'op']\n",
      "aartsbisschop ['aarts', 'bisschop']\n",
      "been ['been']\n",
      "afbeelding ['af', 'beeld', 'ing']\n",
      "poort ['poort']\n",
      "filmrol ['film', 'rol']\n",
      "illusie ['illusie']\n",
      "stom ['stom']\n",
      "monnik ['monnik']\n",
      "prinses ['prins', 'es']\n",
      "riem ['riem']\n",
      "communiceren ['commun', 'iceren']\n",
      "pagina ['pagina']\n",
      "onderneming ['onderneming']\n",
      "darm ['darm']\n",
      "salaris ['salaris']\n",
      "hersenen ['hersen', 'en']\n",
      "echtgenoot ['echt', 'genoot']\n",
      "pistool ['pistool']\n",
      "doelwit ['doel', 'wit']\n",
      "zijkant ['zij', 'kant']\n",
      "excursie ['excursie']\n",
      "regelen ['regel', 'en']\n",
      "viool ['viool']\n",
      "dienstmeisje ['dien', 'st', 'meisje']\n",
      "duidelijk ['duid', 'elijk']\n",
      "graan ['graan']\n",
      "verkennen ['ver', 'kennen']\n",
      "raket ['raket']\n",
      "onwetendheid ['on', 'wetend', 'heid']\n",
      "slang ['slang']\n",
      "diefstal ['diefstal']\n",
      "week ['week']\n",
      "anatomie ['an', 'at', 'omie']\n",
      "frustratie ['f', 'ru', 'stratie']\n",
      "voogd ['voogd']\n",
      "slecht ['slecht']\n",
      "elleboog ['elleboog']\n",
      "heerlijk ['heer', 'lijk']\n",
      "uithoudingsvermogen ['uithouding', 's', 'vermogen']\n",
      "tijdschrift ['tijd', 'schrift']\n",
      "camera ['camera']\n",
      "kiezen ['k', 'iezen']\n",
      "wijsheid ['wijs', 'heid']\n",
      "kopen ['kopen']\n",
      "soldaat ['soldaat']\n",
      "beschaamd ['beschaamd']\n",
      "havik ['havik']\n",
      "arm ['arm']\n",
      "juist ['juist']\n",
      "hoofd ['hoofd']\n",
      "dokter ['dokter']\n",
      "lever ['lever']\n",
      "zon ['zon']\n",
      "lied ['lied']\n",
      "richel ['richel']\n",
      "vriend ['vriend']\n",
      "voorstellen ['voorstellen']\n",
      "actie ['actie']\n",
      "zelfvertrouwen ['zelf', 'vertrouwen']\n",
      "zonsopgang ['zon', 's', 'op', 'gang']\n",
      "verschijnen ['versch', 'ijnen']\n",
      "stro ['stro']\n",
      "zone ['zone']\n",
      "sap ['sap']\n",
      "sneeuw ['sneeuw']\n",
      "tijdperk ['tijd', 'perk']\n",
      "long ['long']\n",
      "inspanning ['in', 'spanning']\n",
      "rif ['rif']\n",
      "honing ['honing']\n",
      "arbeider ['arbeid', 'er']\n",
      "veulen ['veulen']\n",
      "orthodontist ['ort', 'hod', 'ont', 'ist']\n",
      "conditie ['conditie']\n",
      "teen ['teen']\n",
      "drank ['drank']\n",
      "toren ['toren']\n",
      "communicatie ['communicatie']\n",
      "machine ['machine']\n",
      "beschermen ['be', 'scherm', 'en']\n",
      "deelnemen ['deel', 'nemen']\n",
      "verdrag ['verdrag']\n",
      "oom ['oom']\n",
      "realiseren ['re', 'aliseren']\n",
      "bewijs ['bewijs']\n",
      "bed ['bed']\n",
      "begrafenis ['be', 'gra', 'fen', 'is']\n",
      "heldin ['held', 'in']\n",
      "koesteren ['koester', 'en']\n",
      "zetten ['zetten']\n",
      "argument ['argument']\n",
      "universum ['univers', 'um']\n",
      "snel ['snel']\n",
      "zenuw ['zenuw']\n",
      "taal ['taal']\n",
      "boter ['boter']\n",
      "opslagplaats ['opslag', 'plaats']\n",
      "zege ['zege']\n",
      "organiseren ['organis', 'eren']\n",
      "hond ['hond']\n",
      "bal ['bal']\n",
      "vereisen ['ver', 'eis', 'en']\n",
      "gek ['gek']\n",
      "keuze ['keuze']\n",
      "boek ['boek']\n",
      "paar ['paar']\n",
      "eerlijk ['eer', 'lijk']\n",
      "maat ['maat']\n",
      "chaos ['chaos']\n",
      "partij ['partij']\n",
      "medium ['medium']\n",
      "streven ['streven']\n",
      "kast ['kast']\n",
      "tragedie ['tragedie']\n",
      "activiteit ['activiteit']\n",
      "plezier ['plezier']\n",
      "verdwijnen ['verd', 'wijnen']\n",
      "rijtuig ['rij', 'tuig']\n",
      "orkest ['orkest']\n",
      "opnemen ['op', 'nemen']\n",
      "intrekken ['in', 'trekken']\n",
      "verschrikkelijk ['versch', 'rik', 'kelijk']\n",
      "afwezigheid ['afwezig', 'heid']\n",
      "leider ['leid', 'er']\n",
      "voorbijgaan ['voor', 'bij', 'gaan']\n",
      "lade ['lade']\n",
      "bijbel ['bijbel']\n",
      "verpleegster ['verpleeg', 'ster']\n",
      "vernietigen ['ver', 'nietig', 'en']\n",
      "broederschap ['broeder', 'schap']\n",
      "badkamer ['bad', 'kamer']\n",
      "vermijden ['ver', 'mijd', 'en']\n",
      "ontstaan ['ont', 'staan']\n",
      "koningin ['koning', 'in']\n",
      "onderontwikkeld ['onder', 'ontwikkeld']\n",
      "vermenigvuldigen ['ver', 'menigvuldig', 'en']\n",
      "geluk ['ge', 'luk']\n",
      "onderwerp ['onderwerp']\n",
      "volwassen ['volwassen']\n",
      "minnaar ['min', 'naar']\n",
      "politieagent ['pol', 'itie', 'agent']\n",
      "voetbal ['voet', 'bal']\n",
      "nieuws ['nieuws']\n",
      "lijden ['lijden']\n",
      "biografie ['bi', 'ografie']\n",
      "verwerven ['ver', 'wer', 'ven']\n",
      "zomer ['zomer']\n",
      "kooi ['kooi']\n",
      "molecuul ['mo', 'le', 'cu', 'ul']\n",
      "ziekenhuis ['ziekenhuis']\n",
      "bevolking ['be', 'volk', 'ing']\n",
      "kabel ['kabel']\n",
      "sluw ['sluw']\n",
      "sla ['sla']\n",
      "ploeg ['ploeg']\n",
      "controleren ['control', 'eren']\n",
      "oceaan ['oceaan']\n",
      "bus ['bus']\n",
      "toeter ['toeter']\n",
      "rechtvaardigen ['recht', 'vaar', 'digen']\n",
      "smal ['smal']\n",
      "huisdier ['huis', 'dier']\n",
      "koffie ['koffie']\n",
      "ijzer ['ijzer']\n",
      "bewijzen ['bewijzen']\n",
      "verschillen ['verschillen']\n",
      "kip ['kip']\n",
      "illegaal ['il', 'legaal']\n",
      "oud ['oud']\n",
      "waarde ['waarde']\n",
      "neiging ['neig', 'ing']\n",
      "smeken ['s', 'me', 'ken']\n",
      "besteden ['be', 'steden']\n",
      "orgaan ['orgaan']\n",
      "beladen ['bel', 'aden']\n",
      "lunch ['lunch']\n",
      "kerel ['kerel']\n",
      "herstellen ['her', 'stellen']\n",
      "esdoorn ['esdoorn']\n",
      "hal ['hal']\n",
      "parade ['par', 'ade']\n",
      "aluminium ['aluminium']\n",
      "avond ['avond']\n",
      "steeg ['steeg']\n",
      "bouwen ['bouw', 'en']\n",
      "cabine ['cabine']\n",
      "flexibel ['flexibel']\n",
      "piloot ['piloot']\n",
      "snoep ['snoep']\n",
      "cocktail ['cocktail']\n",
      "leeftijd ['leef', 'tijd']\n",
      "angstig ['angst', 'ig']\n",
      "helper ['help', 'er']\n",
      "redden ['red', 'den']\n",
      "muis ['muis']\n",
      "industrie ['industrie']\n",
      "vriendelijk ['vriend', 'elijk']\n",
      "bizar ['bizar']\n",
      "kracht ['kracht']\n",
      "huishoudelijk apparaat ['huis', 'houd', 'elijk', 'apparaat']\n",
      "schrijver ['schrijver']\n",
      "fraude ['fraude']\n",
      "botten ['bot', 'ten']\n",
      "stellig ['stell', 'ig']\n",
      "koning ['koning']\n",
      "achterblijven ['achter', 'blijven']\n",
      "gitaar ['gitaar']\n",
      "zelden ['zelden']\n",
      "priester ['priester']\n",
      "rationaliseren ['r', 'ation', 'aliseren']\n",
      "water ['water']\n",
      "gevangenis ['gevangenis']\n",
      "pot ['pot']\n",
      "herberg ['herberg']\n",
      "uitbundigheid ['uitbundig', 'heid']\n",
      "spier ['spier']\n",
      "tandarts ['tand', 'arts']\n",
      "vooroordeel ['voor', 'oor', 'deel']\n",
      "leren ['leren']\n",
      "informatie ['informatie']\n",
      "schemering ['schemer', 'ing']\n",
      "klagen ['k', 'lagen']\n",
      "leraar ['leraar']\n",
      "kapel ['kapel']\n",
      "lokaliseren ['lok', 'aliseren']\n",
      "hogeschool ['hoge', 'school']\n",
      "strand ['strand']\n",
      "kat ['kat']\n",
      "werkelijkheid ['werkelijk', 'heid']\n",
      "knie ['knie']\n",
      "overeenkomst ['overeenkom', 'st']\n",
      "griep ['griep']\n",
      "politicus ['politicus']\n",
      "saai ['saai']\n",
      "blij ['blij']\n",
      "ingang ['ingang']\n",
      "nier ['nier']\n",
      "begrijpen ['be', 'grijp', 'en']\n",
      "herinneren ['her', 'inn', 'eren']\n",
      "schaamte ['schaam', 'te']\n",
      "struik ['struik']\n",
      "onlangs ['onlangs']\n",
      "decennium ['decennium']\n",
      "planeet ['planeet']\n",
      "nacht ['nacht']\n",
      "lichaam ['lichaam']\n",
      "olie ['olie']\n",
      "hotel ['hotel']\n",
      "verkondigen ['verk', 'ond', 'igen']\n",
      "doen ['doen']\n",
      "hysterie ['hy', 'ster', 'ie']\n",
      "schoonheid ['schoon', 'heid']\n",
      "grootmoedig ['groot', 'moed', 'ig']\n",
      "mode ['mode']\n",
      "taak ['taak']\n",
      "benoemen ['be', 'noem', 'en']\n",
      "zonsondergang ['zon', 's', 'onder', 'gang']\n",
      "taart ['taart']\n",
      "verbeelding ['ver', 'beeld', 'ing']\n",
      "zonneschijn ['zonne', 'schijn']\n",
      "toestaan ['toestaan']\n",
      "aankomen ['aan', 'kom', 'en']\n",
      "mier ['mier']\n",
      "heuvel ['heuvel']\n",
      "manager ['manager']\n",
      "verminderen ['ver', 'minder', 'en']\n",
      "voorspellen ['voor', 'spellen']\n",
      "stam ['stam']\n",
      "kritiek ['krit', 'iek']\n",
      "concluderen ['con', 'cl', 'uderen']\n",
      "ballon ['ballon']\n",
      "vernietiging ['ver', 'nietig', 'ing']\n",
      "normaal ['normaal']\n",
      "hengst ['hengst']\n",
      "konijn ['konijn']\n",
      "overnadenken ['over', 'na', 'denken']\n",
      "bloem ['bloem']\n",
      "willen ['w', 'illen']\n",
      "bisschop ['bisschop']\n",
      "ruggengraat ['rug', 'gen', 'gra', 'at']\n",
      "paragraaf ['paragraaf']\n",
      "reis ['reis']\n",
      "sigaret ['sigaret']\n",
      "president ['president']\n",
      "tas ['tas']\n",
      "zich gedragen ['zich', 'gedragen']\n",
      "datum ['datum']\n",
      "aanwezigheid ['aanwezig', 'heid']\n",
      "examineren ['ex', 'amin', 'eren']\n",
      "bepalen ['bep', 'alen']\n",
      "duim ['duim']\n",
      "mannen ['mannen']\n",
      "beker ['beker']\n",
      "visie ['visie']\n",
      "jachthond ['jacht', 'hond']\n",
      "wurgen ['wurg', 'en']\n",
      "kust ['kust']\n",
      "zuid ['zuid']\n",
      "woord ['woord']\n",
      "dek ['dek']\n",
      "trui ['trui']\n",
      "tong ['tong']\n",
      "vuil ['vuil']\n",
      "temperament ['temperament']\n",
      "nodig hebben ['nodig', 'heb', 'ben']\n",
      "appel ['appel']\n",
      "toestand ['toestand']\n",
      "trommel ['trommel']\n",
      "glas ['glas']\n",
      "paard ['paard']\n",
      "weten ['weten']\n",
      "beginnen ['beg', 'innen']\n",
      "dageraad ['dag', 'er', 'aad']\n",
      "kathedraal ['kathedraal']\n",
      "domineren ['dom', 'ineren']\n",
      "opslaan ['op', 'slaan']\n",
      "tekst ['tekst']\n",
      "lip ['lip']\n",
      "menu ['menu']\n",
      "appartement ['appartement']\n",
      "basketbal ['basket', 'bal']\n",
      "volbrengen ['vol', 'breng', 'en']\n",
      "vermogen ['vermogen']\n",
      "tarwe ['tarwe']\n",
      "klaslokaal ['klas', 'lokaal']\n",
      "wetenschap ['weten', 'schap']\n",
      "gewelddadig ['geweld', 'dad', 'ig']\n",
      "portemonnee ['portemonnee']\n",
      "hout ['hout']\n",
      "bij ['bij']\n",
      "uitgang ['uit', 'gang']\n",
      "exotisch ['ex', 'otisch']\n",
      "thema ['thema']\n",
      "plafond ['plafond']\n",
      "binnenkomen ['binnen', 'kom', 'en']\n",
      "azijn ['azijn']\n",
      "ader ['ader']\n",
      "symbool ['symbool']\n",
      "behouden ['be', 'houden']\n",
      "breekbaar ['breek', 'baar']\n",
      "beleefd ['beleefd']\n",
      "vinger ['vinger']\n",
      "katoen ['katoen']\n",
      "koppig ['kopp', 'ig']\n",
      "verloven ['ver', 'loven']\n",
      "uitbreiden ['uit', 'bre', 'iden']\n",
      "lijken ['lijk', 'en']\n",
      "scherp ['scherp']\n",
      "koel ['koel']\n",
      "krant ['krant']\n",
      "film ['film']\n",
      "beest ['beest']\n",
      "vergelijking ['ver', 'gelijk', 'ing']\n",
      "ontkenning ['ont', 'kenning']\n",
      "noodgeval ['nood', 'geval']\n",
      "huisje ['huisje']\n",
      "seconde ['seconde']\n",
      "kaart ['kaart']\n",
      "mosterd ['mosterd']\n",
      "vergoeding ['ver', 'goed', 'ing']\n",
      "baby ['baby']\n",
      "immoreel ['im', 'moreel']\n",
      "bord ['bord']\n",
      "sterk ['sterk']\n",
      "pijp ['pijp']\n",
      "cijfer ['cijfer']\n",
      "partner ['partner']\n",
      "groeien ['groei', 'en']\n",
      "overwinnen ['over', 'w', 'innen']\n",
      "stelen ['st', 'elen']\n",
      "lift ['lift']\n",
      "rijst ['rijst']\n",
      "overtreding ['over', 'treding']\n",
      "anarchie ['anarchie']\n",
      "definitie ['definitie']\n",
      "klas ['klas']\n",
      "brandewijn ['brand', 'e', 'wijn']\n",
      "koppel ['koppel']\n",
      "kristal ['kristal']\n",
      "slim ['slim']\n",
      "bedreiging ['be', 'dreig', 'ing']\n",
      "hut ['hut']\n",
      "marine ['marine']\n",
      "stijl ['stijl']\n",
      "nemen ['nemen']\n",
      "trouwen ['trouw', 'en']\n",
      "rabbijn ['rabbijn']\n",
      "maatschappij ['maatschappij']\n",
      "verwarring ['ver', 'war', 'ring']\n",
      "hemel ['hemel']\n",
      "delen ['delen']\n",
      "avondeten ['avond', 'eten']\n",
      "competentie ['compet', 'entie']\n",
      "heup ['heup']\n",
      "belichamen ['bel', 'ich', 'amen']\n",
      "kennelijk ['kennelijk']\n",
      "deur ['deur']\n",
      "bovenkant ['boven', 'kant']\n",
      "alcohol ['alcohol']\n",
      "comfort ['comfort']\n",
      "geloof ['geloof']\n",
      "kool ['kool']\n",
      "juridische procedures ['jur', 'id', 'ische', 'procedure', 's']\n",
      "werkgever ['werk', 'gever']\n",
      "raam ['raam']\n",
      "lucht ['lucht']\n",
      "grappig ['grappig']\n",
      "truc ['truc']\n",
      "verliezen ['verl', 'iezen']\n",
      "ontmoedigen ['ont', 'moed', 'ig', 'en']\n",
      "indruk ['in', 'druk']\n",
      "gebeuren ['gebeuren']\n",
      "hard ['hard']\n",
      "essay ['essay']\n",
      "voorkomen ['voor', 'komen']\n",
      "hoek ['hoek']\n",
      "west ['west']\n",
      "bedelen ['bedel', 'en']\n",
      "decimeter ['dec', 'imeter']\n",
      "vragen ['vragen']\n",
      "verkrijgen ['ver', 'krijg', 'en']\n",
      "literatuur ['literatuur']\n",
      "gevaar ['gevaar']\n",
      "meter ['meter']\n",
      "rivaal ['rivaal']\n",
      "belasting ['be', 'last', 'ing']\n",
      "karton ['karton']\n",
      "krijgen ['krijg', 'en']\n",
      "jong ['jong']\n",
      "lenen ['lenen']\n",
      "belangrijk ['belang', 'rijk']\n",
      "moeilijk ['moei', 'lijk']\n",
      "kalender ['kalender']\n",
      "intutie ['int', 'u', '', '', '', '', 'tie']\n",
      "verovering ['verover', 'ing']\n",
      "recht ['recht']\n",
      "interesse ['interesse']\n",
      "sturen ['sturen']\n",
      "stoppen ['st', 'oppen']\n",
      "zeggen ['zeggen']\n",
      "vloer ['vloer']\n",
      "bier ['bier']\n",
      "wijn ['wijn']\n",
      "metaal ['metaal']\n",
      "rails ['rail', 's']\n",
      "bel ['bel']\n",
      "aanbevelen ['aan', 'bev', 'elen']\n",
      "meer ['meer']\n",
      "ochtend ['ochtend']\n",
      "moeras ['moeras']\n",
      "lang ['lang']\n",
      "taille ['taille']\n",
      "ritme ['ritme']\n",
      "rand ['rand']\n",
      "ramp ['ramp']\n",
      "wetenschapper ['wetenschapp', 'er']\n",
      "meubels ['meubel', 's']\n",
      "hart ['hart']\n",
      "verhaal ['verhaal']\n",
      "luisteren ['luister', 'en']\n",
      "eeuw ['eeuw']\n",
      "creren ['cre', '', '', '', 'ren']\n",
      "fabriek ['fabriek']\n",
      "inkomen ['inkomen']\n",
      "ontdekken ['ont', 'dekken']\n",
      "lam ['lam']\n",
      "cruciaal ['cru', 'ciaal']\n",
      "held ['held']\n",
      "bocht ['bocht']\n",
      "nerveus ['nerveus']\n",
      "strijd ['strijd']\n",
      "zanger ['zanger']\n",
      "hoed ['hoed']\n",
      "nagel ['nagel']\n",
      "fantastisch ['fant', 'astisch']\n",
      "aandacht ['aandacht']\n",
      "zondaar ['zondaar']\n",
      "geit ['geit']\n",
      "tegenstander ['tegen', 'stand', 'er']\n",
      "voldoen ['vol', 'doen']\n",
      "opvallend ['opvallend']\n",
      "leeuw ['leeuw']\n",
      "vlees ['vlees']\n",
      "wet ['wet']\n",
      "groeten ['groet', 'en']\n",
      "herzien ['her', 'zien']\n",
      "man ['man']\n",
      "meedoen ['mee', 'doen']\n",
      "kogel ['kogel']\n",
      "maker ['maker']\n",
      "steak ['steak']\n",
      "hoorn ['hoorn']\n",
      "bloed ['bloed']\n",
      "inspecteren ['inspe', 'cteren']\n",
      "kalf ['kalf']\n",
      "wolk ['wolk']\n",
      "ongeval ['on', 'geval']\n",
      "voet ['voet']\n",
      "seizoen ['seizoen']\n",
      "lawaai ['lawaai']\n",
      "mand ['mand']\n",
      "straat ['straat']\n",
      "vogel ['vogel']\n",
      "kamer ['kamer']\n",
      "schuilplaats ['schuil', 'plaats']\n",
      "opdracht ['opdracht']\n",
      "slaapkamer ['slaap', 'kamer']\n",
      "chauffeur ['chauffeur']\n",
      "vrouw ['vrouw']\n",
      "salade ['salade']\n",
      "deuropening ['deur', 'open', 'ing']\n",
      "stier ['stier']\n",
      "winter ['winter']\n",
      "staaf ['staaf']\n",
      "gordijn ['gordijn']\n",
      "ruw ['ruw']\n",
      "vlug ['vlug']\n",
      "vergeven ['ver', 'geven']\n",
      "enorm ['enorm']\n",
      "ongeluk ['on', 'ge', 'luk']\n",
      "aandrijving ['aand', 'rijving']\n",
      "dwalen ['dw', 'alen']\n",
      "zoon ['zoon']\n",
      "brug ['brug']\n",
      "groot ['groot']\n",
      "auto ['auto']\n",
      "onderkant ['onder', 'kant']\n",
      "motregen ['mot', 'regen']\n",
      "koe ['koe']\n",
      "deken ['deken']\n",
      "borst ['borst']\n",
      "burgemeester ['burg', 'e', 'meester']\n",
      "saus ['saus']\n",
      "gat ['gat']\n",
      "besluiten ['be', 'sluit', 'en']\n",
      "slagen ['slagen']\n",
      "roddel ['roddel']\n",
      "operatie ['operatie']\n",
      "bescheiden ['bescheiden']\n",
      "rechtvaardigheid ['rechtvaardig', 'heid']\n",
      "formule ['formule']\n",
      "omstandigheid ['omstandig', 'heid']\n",
      "vliegtuig ['vlieg', 'tuig']\n",
      "wafel ['wafel']\n",
      "papier ['papier']\n",
      "meneer ['men', 'eer']\n",
      "drumstel ['drum', 'stel']\n",
      "verjaardag ['ver', 'jaar', 'dag']\n",
      "melk ['melk']\n",
      "volkslied ['volk', 's', 'lied']\n",
      "kerk ['kerk']\n",
      "diepte ['diep', 'te']\n",
      "merg ['merg']\n",
      "voertuig ['voer', 'tuig']\n",
      "boot ['boot']\n",
      "onderhouden ['onder', 'houden']\n",
      "evalueren ['e', 'valu', 'eren']\n",
      "wereldbol ['wereld', 'bol']\n",
      "whisky ['whisky']\n",
      "geest ['geest']\n",
      "logica ['logica']\n",
      "ledemaat ['lede', 'maat']\n",
      "overwinning ['over', 'winning']\n",
      "dicht ['dicht']\n",
      "elastisch ['elastisch']\n",
      "vrede ['vrede']\n",
      "terugtrekken ['terug', 'trekken']\n",
      "traan ['traan']\n",
      "melden ['meld', 'en']\n",
      "bang ['bang']\n",
      "centimeter ['cent', 'imeter']\n",
      "eenvoudig ['eenvoud', 'ig']\n",
      "rivier ['rivier']\n",
      "verdrietig ['verdriet', 'ig']\n",
      "vreugde ['vreugde']\n",
      "brengen ['breng', 'en']\n",
      "horen ['horen']\n",
      "verzamelen ['ver', 'zamel', 'en']\n",
      "binnentreden ['binnen', 'treden']\n",
      "anders ['anders']\n",
      "hek ['hek']\n",
      "gast ['gast']\n",
      "klein ['klein']\n",
      "aansluiten bij ['aan', 'sluit', 'en', 'bij']\n",
      "orkaan ['orkaan']\n",
      "gang ['gang']\n",
      "oog ['oog']\n",
      "luchthaven ['lucht', 'haven']\n",
      "spek ['spek']\n",
      "passie ['passie']\n",
      "gemakkelijk ['gemak', 'kelijk']\n",
      "weigeren ['weiger', 'en']\n",
      "enkel ['enkel']\n",
      "strijder ['strijd', 'er']\n",
      "tante ['tante']\n",
      "auteur ['auteur']\n",
      "management ['management']\n",
      "meisje ['meisje']\n",
      "broer ['broer']\n",
      "bubbel ['b', 'ub', 'bel']\n",
      "simpel ['simpel']\n",
      "discussiren ['disc', 'uss', 'i', '', '', '', 'ren']\n",
      "weekend ['week', 'end']\n",
      "ontmoeten ['ont', 'moeten']\n",
      "vrijgevig ['vrij', 'gev', 'ig']\n",
      "geven ['geven']\n",
      "bende ['bende']\n",
      "referentie ['referentie']\n",
      "zee ['zee']\n",
      "bezorgen ['be', 'zorg', 'en']\n",
      "falen ['falen']\n",
      "ontvangen ['ont', 'vangen']\n",
      "boon ['boon']\n",
      "perceptie ['perceptie']\n",
      "worden ['word', 'en']\n",
      "reflectie ['reflectie']\n",
      "soep ['soep']\n",
      "hals ['hals']\n",
      "verdelen ['ver', 'delen']\n",
      "muziek ['muziek']\n",
      "jas ['jas']\n",
      "bruid ['bruid']\n",
      "buik ['buik']\n",
      "mensen ['men', 's', 'en']\n",
      "wenkbrauw ['wenkbrauw']\n",
      "kil ['kil']\n",
      "instrument ['instrument']\n",
      "mening ['men', 'ing']\n",
      "oordeel ['oor', 'deel']\n",
      "uitleggen ['uit', 'leggen']\n",
      "voorwaarde ['voorwaarde']\n",
      "blijven ['blijven']\n",
      "ziek ['ziek']\n",
      "negeren ['neger', 'en']\n",
      "rijkdom ['rijk', 'dom']\n",
      "besmetting ['bes', 'met', 'ting']\n",
      "berg ['berg']\n",
      "krimpen ['krimp', 'en']\n",
      "atoom ['atoom']\n",
      "vader ['vader']\n",
      "formeel ['formeel']\n",
      "grens ['grens']\n",
      "raar ['raar']\n",
      "maaltijd ['maal', 'tijd']\n",
      "dier ['dier']\n",
      "likeur ['likeur']\n",
      "beheer ['beheer']\n",
      "samenvoegen ['samen', 'voeg', 'en']\n",
      "kerktoren ['kerk', 'toren']\n",
      "textiel ['textiel']\n",
      "brood ['brood']\n",
      "afwijken ['af', 'wijk', 'en']\n",
      "doden ['do', 'den']\n",
      "aankondigen ['aan', 'kond', 'ig', 'en']\n",
      "dood ['dood']\n",
      "mos ['mos']\n",
      "spel ['spel']\n",
      "pleiten ['pleit', 'en']\n",
      "woede ['woede']\n",
      "taxi's ['taxi', \"'\", 's']\n",
      "muur ['muur']\n",
      "jongen ['jongen']\n",
      "vreselijk ['vreselijk']\n",
      "leger ['leger']\n",
      "ouder ['ouder']\n",
      "menigte ['menigte']\n",
      "actrice ['actrice']\n",
      "feit ['feit']\n",
      "accepteren ['accepteren']\n",
      "volharding ['vol', 'hard', 'ing']\n",
      "zout ['zout']\n",
      "kaak ['kaak']\n",
      "wagen ['wagen']\n",
      "kort ['kort']\n",
      "eiland ['eiland']\n",
      "modern ['modern']\n",
      "school ['school']\n",
      "samenwerken ['samen', 'werk', 'en']\n",
      "os ['os']\n",
      "afspraak ['afspraak']\n",
      "rietje ['riet', 'je']\n",
      "bekentenis ['bekentenis']\n",
      "kinderachtig ['kinder', 'achtig']\n",
      "betaling ['betaling']\n",
      "neef ['neef']\n",
      "kelder ['kelder']\n",
      "bruidegom ['bru', 'idegom']\n",
      "tapijt ['tapijt']\n",
      "brutaal ['bru', 'taal']\n",
      "rundvlees ['rund', 'vlees']\n",
      "plan ['plan']\n",
      "wreed ['wreed']\n",
      "code ['code']\n",
      "maan ['maan']\n",
      "instructeur ['instructeur']\n",
      "secretaresse ['secret', 'aresse']\n",
      "trots ['trots']\n",
      "pijn ['pijn']\n",
      "nevel ['nevel']\n",
      "manier ['manier']\n",
      "breed ['breed']\n",
      "container ['container']\n",
      "najagen ['na', 'jagen']\n",
      "adviseren ['advis', 'eren']\n",
      "vijandigheid ['vijand', 'ig', 'heid']\n",
      "uitlenen ['uit', 'lenen']\n",
      "intelligent ['intelligent']\n",
      "hoofdstuk ['hoofd', 'stuk']\n",
      "nek ['nek']\n",
      "dochter ['dochter']\n",
      "kwaad ['kwaad']\n",
      "kruid ['kruid']\n",
      "atmosfeer ['atmosfeer']\n",
      "gaan ['gaan']\n",
      "leveren ['lever', 'en']\n",
      "leerling ['leer', 'ling']\n",
      "decoratie ['decoratie']\n",
      "anker ['anker']\n",
      "verkopen ['verkopen']\n",
      "gras ['gras']\n",
      "gelukkig ['gelukkig']\n",
      "kalkoen ['kalkoen']\n",
      "begrip ['begrip']\n",
      "ontbijt ['ontbijt']\n",
      "desorganiseren ['des', 'organis', 'eren']\n",
      "zelfverzekerd ['zelf', 'verzekerd']\n",
      "viooltjes ['viool', 'tje', 's']\n",
      "bekendheid ['bekend', 'heid']\n",
      "sleutel ['sleutel']\n",
      "kinderbed ['kinder', 'bed']\n",
      "parel ['parel']\n",
      "betaalbaar ['betaal', 'baar']\n",
      "beschermer ['be', 'scherm', 'er']\n",
      "volwassene ['volwassene']\n",
      "brief ['brief']\n",
      "rondzwerven ['rond', 'z', 'wer', 'ven']\n",
      "zaad ['zaad']\n",
      "pols ['pols']\n",
      "spreken ['spreken']\n",
      "vaardigheid ['vaardig', 'heid']\n",
      "thee ['thee']\n",
      "dak ['dak']\n",
      "geloven ['gel', 'oven']\n",
      "bekendmaken ['bekend', 'maken']\n",
      "bereiken ['be', 'reik', 'en']\n",
      "noodzakelijk ['nood', 'zakelijk']\n",
      "kom ['kom']\n",
      "ontkennen ['ont', 'kennen']\n",
      "zoektocht ['z', 'oekt', 'ocht']\n",
      "verdriet ['verdriet']\n",
      "logaritme ['logaritme']\n",
      "noord ['noord']\n",
      "cliff ['cli', 'ff']\n",
      "imiteren ['im', 'iteren']\n",
      "vitamine ['vitamine']\n",
      "tand ['tand']\n",
      "aanmoedigen ['aan', 'moed', 'ig', 'en']\n",
      "balk ['balk']\n",
      "kaas ['kaas']\n",
      "afwijzen ['af', 'wijzen']\n",
      "somber ['somber']\n",
      "ongelukkig ['on', 'gelukkig']\n",
      "kind ['kind']\n",
      "regen ['regen']\n",
      "bont ['bont']\n",
      "legioen ['legioen']\n",
      "biologie ['bi', 'ologie']\n",
      "schouder ['schouder']\n",
      "ziekte ['ziek', 'te']\n",
      "gevangeniscel ['gevangenis', 'cel']\n",
      "bijvoegen ['bij', 'voeg', 'en']\n",
      "kleding ['kleding']\n",
      "meel ['meel']\n",
      "koorts ['koorts']\n",
      "ravijn ['ravijn']\n",
      "denken ['denk', 'en']\n",
      "vlucht ['vlucht']\n",
      "cd ['cd']\n",
      "tuin ['tuin']\n",
      "houding ['houding']\n",
      "heilige ['heilige']\n",
      "stoel ['stoel']\n",
      "kolonel ['kolonel']\n",
      "verklaren ['verkl', 'aren']\n",
      "nieuw ['nieuw']\n",
      "mooi ['mooi']\n",
      "onnodig ['on', 'nodig']\n",
      "huishulp ['huis', 'hulp']\n",
      "broodje ['broodje']\n",
      "vertrekken ['ver', 'trekken']\n",
      "overtuigen ['over', 'tuigen']\n",
      "gerammel ['ge', 'rammel']\n",
      "krankzinnig ['k', 'rank', 'zinnig']\n",
      "vergelijken ['ver', 'gelijk', 'en']\n",
      "minuut ['minuut']\n",
      "moeilijkheid ['moei', 'lijk', 'heid']\n",
      "maand ['maand']\n",
      "officier van justitie ['officier', 'van', 'justitie']\n",
      "schuur ['schuur']\n",
      "boos ['boos']\n",
      "werknemer ['werk', 'nemer']\n",
      "vos ['vos']\n",
      "maken ['maken']\n",
      "aardappel ['aard', 'appel']\n",
      "akkoord gaan ['akkoord', 'g', 'aan']\n",
      "demon ['demon']\n",
      "waas ['waas']\n",
      "computer ['computer']\n",
      "opbouwen ['op', 'bouw', 'en']\n",
      "diner ['diner']\n",
      "suiker ['suiker']\n",
      "geweldig ['geweldig']\n",
      "vereniging ['verenig', 'ing']\n",
      "huis ['huis']\n",
      "lens ['lens']\n",
      "uitgebreid ['uitgebreid']\n",
      "citroen ['citroen']\n",
      "duivel ['duivel']\n",
      "argumenteren ['arg', 'ument', 'eren']\n",
      "weg ['weg']\n",
      "fictie ['fictie']\n",
      "vervuiling ['ver', 'vuil', 'ing']\n",
      "beslissen ['besl', 'issen']\n",
      "mond ['mond']\n",
      "plaatsen ['plaats', 'en']\n",
      "dollar ['dollar']\n",
      "veiligheid ['veilig', 'heid']\n",
      "motel ['motel']\n",
      "wieg ['wieg']\n",
      "matroos ['matroos']\n",
      "gepast ['gepast']\n",
      "wanhoop ['wan', 'hoop']\n",
      "gesprek ['gesprek']\n",
      "onrustig ['on', 'rust', 'ig']\n",
      "kampioen ['kampioen']\n",
      "gebied ['gebied']\n",
      "ijs ['ijs']\n",
      "informeren ['inform', 'eren']\n",
      "zwerven ['z', 'wer', 'ven']\n",
      "geestelijke ['geestelijke']\n",
      "zeldzaam ['zeldzaam']\n",
      "professor ['professor']\n",
      "augustus ['augustus']\n",
      "constructie ['constructie']\n",
      "keuken ['keuken']\n",
      "vervangen ['ver', 'vangen']\n",
      "kandidaat ['kandid', 'aat']\n",
      "leuk ['leuk']\n",
      "lezer ['lezer']\n",
      "staart ['staart']\n",
      "vermaken ['ver', 'maken']\n",
      "genieten ['genieten']\n",
      "snelweg ['snel', 'weg']\n",
      "woordenboek ['woord', 'en', 'boek']\n",
      "merrie ['merrie']\n",
      "producent ['producent']\n",
      "verdienen ['verdien', 'en']\n",
      "vinden ['vind', 'en']\n",
      "weer ['weer']\n",
      "champagne ['champagne']\n",
      "vallei ['vallei']\n",
      "houtskool ['hout', 's', 'kool']\n",
      "ophangen ['op', 'hang', 'en']\n",
      "muziekgroep ['muziek', 'groep']\n",
      "vreemd ['vreemd']\n",
      "vat ['vat']\n",
      "verifiren ['ver', 'ifi', '', '', '', 'ren']\n",
      "rat ['rat']\n",
      "eigenaardig ['eigen', 'aard', 'ig']\n",
      "echtgenote ['e', 'cht', 'genote']\n",
      "aardig ['aardig']\n",
      "schaap ['schaap']\n",
      "essentieel ['ess', 'ent', 'ieel']\n",
      "omvang ['omvang']\n",
      "ziel ['ziel']\n",
      "houden ['houd', 'en']\n",
      "ademen ['adem', 'en']\n",
      "hand ['hand']\n",
      "sheriff ['sheriff']\n",
      "idee ['idee']\n",
      "bezitten ['be', 'zitten']\n",
      "knoop ['knoop']\n",
      "modder ['modder']\n",
      "oever ['oever']\n",
      "fiets ['fiets']\n",
      "taxi ['taxi']\n",
      "dwaas ['dwaas']\n",
      "beweging ['beweging']\n",
      "cursus ['cursus']\n",
      "sprakeloos ['spra', 'kel', 'oos']\n",
      "boosheid ['boos', 'heid']\n",
      "intelligentie ['intelligent', 'ie']\n",
      "pijl ['pijl']\n",
      "bad ['bad']\n",
      "student ['student']\n",
      "ceremonie ['ceremonie']\n",
      "bedrijf ['bedrijf']\n",
      "luchtvaart ['lucht', 'vaart']\n",
      "honkbal ['honk', 'bal']\n",
      "monteur ['monteur']\n",
      "wereld ['wereld']\n",
      "moeder ['moeder']\n",
      "god ['god']\n",
      "verschuldigd zijn ['verschuldigd', 'zijn']\n",
      "overvloed ['over', 'vloed']\n",
      "inzicht ['in', 'zicht']\n",
      "psalm ['psalm']\n",
      "vee ['vee']\n",
      "handpalm ['hand', 'palm']\n",
      "humeur ['humeur']\n",
      "storm ['storm']\n",
      "zwaar ['zwaar']\n",
      "geld ['geld']\n",
      "beroep ['beroep']\n",
      "cent ['cent']\n",
      "schuim ['schuim']\n",
      "makkelijk ['makkelijk']\n",
      "televisie ['televisie']\n",
      "boomstam ['boom', 'stam']\n",
      "tanden ['tand', 'en']\n",
      "helium ['helium']\n",
      "mist ['mist']\n",
      "stemming ['stemming']\n",
      "dag ['dag']\n",
      "razendsnel ['razend', 'snel']\n",
      "armoede ['armoede']\n",
      "winnaar ['winnaar']\n",
      "plaatsvinden ['plaats', 'vind', 'en']\n",
      "schade ['schade']\n",
      "feest ['feest']\n",
      "linnen ['linnen']\n",
      "proberen ['pro', 'beren']\n",
      "eikenboom ['e', 'iken', 'boom']\n",
      "nerts ['nerts']\n",
      "componist ['componist']\n",
      "elegantie ['elegant', 'ie']\n",
      "lepel ['lepel']\n",
      "schuldig ['schuld', 'ig']\n",
      "polyester ['poly', 'ester']\n",
      "koolstof ['kool', 'stof']\n"
     ]
    }
   ],
   "source": [
    "for word in simlex_words:\n",
    "    print(word, own_50.tokenize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dingen opslaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('word_freqs_all.json', 'w') as f:\n",
    "    json.dump(word_freqs_all, f)\n",
    "\n",
    "with open('word_freqs_all_lower.json', 'w') as f:\n",
    "    json.dump(word_freqs_lower_all, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kladblok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689"
      ]
     },
     "execution_count": 1890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3803 + 10 + 11 + 13 + 32 + 30 + 25 - 2500 + 15 + 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def slow_function(n):\n",
    "    result = 0\n",
    "    for i in tqdm(range(n), desc=\"Processing\", unit=\" iterations\", leave=True):\n",
    "        time.sleep(0.1)  # Simulating a time-consuming task\n",
    "        result += i\n",
    "    return result\n",
    "\n",
    "\n",
    "def test_fun(x):\n",
    "    z = 0\n",
    "    v = 0\n",
    "    for c, i in enumerate(tqdm(range(x*999999), desc=f\"Executing function. Progress\", unit=\" iterations\", leave=True)):\n",
    "        z += i\n",
    "        v += c\n",
    "        if c == 0:\n",
    "            print('bijna')\n",
    "\n",
    "    return z, v\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing function. Progress:   8%|         | 751612/9999990 [00:00<00:02, 3833703.04 iterations/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bijna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing function. Progress: 100%|| 9999990/9999990 [00:02<00:00, 4439866.14 iterations/s]\n"
     ]
    }
   ],
   "source": [
    "a, b = test_fun(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1807,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def number_generator():\n",
    "    for i in range(10000000):\n",
    "        yield i\n",
    "\n",
    "def fun(x):\n",
    "    s = 0\n",
    "    # Example usage with tqdm for progress bar\n",
    "    for number in tqdm(x, total=100000000, desc=\"Generating numbers\", unit=\" number\"):\n",
    "        s += number*number - number\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1808,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating numbers:  10%|         | 10000000/100000000 [00:02<00:21, 4175792.71 number/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333333233333340000000"
      ]
     },
     "execution_count": 1808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = number_generator()\n",
    "fun(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|| 100/100 [00:10<00:00,  9.49 iterations/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 1714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_function(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing function. Progress: 100%|| 99999900/99999900 [00:16<00:00, 5971319.45 iterations/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4999989950005050"
      ]
     },
     "execution_count": 1732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fun(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progressss: 100%|| 99999900/99999900 [00:20<00:00, 4828428.92 iterations/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "989999010000"
      ]
     },
     "execution_count": 1726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fun(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {'cat': 'N', 'segments': ['be', 'houd']}\n",
    "\n",
    "'a' in b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 'N', 'segments': ['be', 'houd']}"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words['behoud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2283, 3586, 940, 6589, 2207, 8304, 1512, 5563, 363, 809, 2578]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode('dit is een test met ongberuikelijkbare woorden')\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10, 2: 20, 3: 40, 4: 50}"
      ]
     },
     "execution_count": 1389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {1: 10, 2: 20, 3: 30}\n",
    "y = {3: 40, 4: 50}\n",
    "\n",
    "x | y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 30, 4: 50, 1: 10, 2: 20}"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {1: 10, 2: 20, 3: 30}\n",
    "y = {3: 40, 4: 50}\n",
    "\n",
    "y | x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def ddd(a, b,\n",
    "                  c):\n",
    "    print(a)\n",
    "\n",
    "ddd(3, 4, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 entries in the database. Out of these:\n",
      "- 5 words have no segmentations\n",
      "        - 6 words have a single morpheme as segmentation \n",
      "        - 7 words are split up into multiple morphemes\n"
     ]
    }
   ],
   "source": [
    "print(f'''There are 3 entries in the database. Out of these:\n",
    "- 5 words have no segmentations\n",
    "        - 6 words have a single morpheme as segmentation \n",
    "        - 7 words are split up into multiple morphemes''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# this function adds the word as segmentation of itself for all words that have an empty list as segmentation\n",
    "def add_empty_segmentations(df):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for word, seg in df.items():\n",
    "        if len(seg) == 0:\n",
    "            out[word] = [word]\n",
    "        else:\n",
    "            out[word] = seg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['a'], 'b': ['r']}"
      ]
     },
     "execution_count": 1601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a': [], 'b': ['r']}\n",
    "\n",
    "b = add_empty_segmentations(a)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [], 'b': ['r'], 4: 5}"
      ]
     },
     "execution_count": 1596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a': [], 'b': ['r']}\n",
    "\n",
    "a[4] = 5\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6702288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(oscar1) as osc:\n",
    "    n = 0\n",
    "    for line in osc:\n",
    "        n+= 1\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6803845\n"
     ]
    }
   ],
   "source": [
    "oscar2 = os.path.join(data_path, 'OSCAR', 'nl_part_2.txt')\n",
    "\n",
    "\n",
    "\n",
    "with open(oscar2) as osc:\n",
    "    n = 0\n",
    "    for line in osc:\n",
    "        n+= 1\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1793,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_freqs_from_online_corpus(corpus_generator, sorted=False, progress=True, avg_size=6750000, n_files=45):\n",
    "\n",
    "    size = n_files * avg_size\n",
    "    \n",
    "    if progress:\n",
    "        print(f'The estimated size of the entire corpus is around {format_with_dots(size)} lines of text!')\n",
    "        \n",
    "        word_freqs = {}\n",
    "\n",
    "        for i in range(1):\n",
    "            if i == 0:\n",
    "                print(f'Generating the frequency dictionary ...\\n')\n",
    "\n",
    "        for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "            text = preprocess_basic(i['text'])\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    \n",
    "    return word_freqs\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function creates a word frequency dictionary for a corpus, so that we can count faster later on\n",
    "def create_word_freqs_from_local_corpus(corpus_generator, sorted=False, progress=True, path=0):\n",
    "    \n",
    "    if progress:\n",
    "        print(f'Calculating the size of the dataset ...\\n')\n",
    "        if path == 0:\n",
    "            assert path == 1, 'Enter path to get progress bar, or set progress=False to perform the function without one'\n",
    "        else:\n",
    "            size = get_size_for_local(path)\n",
    "    \n",
    "        word_freqs = {}\n",
    "        \n",
    "\n",
    "        for i in range(1):\n",
    "            if i == 0:\n",
    "                print(f'Data size: {format_with_dots(size)} lines of text! Generating the frequency dictionary ...\\n')\n",
    "\n",
    "        for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "            text = preprocess_basic(i['text'])\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    \n",
    "    else:\n",
    "\n",
    "        print('Performing task without progress bar')\n",
    "\n",
    "        word_freqs = {}\n",
    "\n",
    "        for i in corpus_generator:     \n",
    "            text = preprocess_basic(i['text'])\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "        \n",
    "    \n",
    "    if sorted:\n",
    "        return dict(sorted(word_freqs.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "\n",
    "def get_size_for_local(path):\n",
    "    with open(path) as osc:\n",
    "        n = 0\n",
    "        for line in osc:\n",
    "            n+= 1\n",
    "        return n \n",
    "\n",
    "def format_with_dots(number):\n",
    "    return f\"{number:,}\".replace(\",\", \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1789,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_from_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wienfoiwef', 'weff', 'vervfe', 'verv', 'pp']"
      ]
     },
     "execution_count": 2164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = 'wienfoiwef weff vervfe verv PP'\n",
    "\n",
    "seq.strip().lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maak frequency dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stap 1: maak data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import os\n",
    "\n",
    "\n",
    "# function that returns a dictionary with a generator for every existing OSCAR file in this computer\n",
    "def create_local_oscar_generators(data_path, i=0, j=0):\n",
    "\n",
    "    out = {}\n",
    "    \n",
    "    if j > i:\n",
    "        n = j - i\n",
    "\n",
    "        for x in range(i, j+1):\n",
    "            full_path = os.path.join(data_path, 'OSCAR', f'nl_part_{x}.txt')\n",
    "            if os.path.isfile(full_path):\n",
    "                out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "        \n",
    "        if len(out) != n + 1:\n",
    "            print('Not all parts requested are on this computer')\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for i in range(1, 50):\n",
    "            full_path = os.path.join(data_path, 'OSCAR', f'nl_part_{i}.txt')\n",
    "            if os.path.isfile(full_path):\n",
    "                out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# function that creates one generator out of multiple generators\n",
    "def create_super_generator(generator_dict, list_input=False):\n",
    "\n",
    "    if list_input:\n",
    "        for generator in generator_dict:\n",
    "            yield from generator\n",
    "    else:\n",
    "        for generator in generator_dict.values():\n",
    "            yield from generator\n",
    "\n",
    "\n",
    "# one function to create OSCAR generator by combining n parts of the dataset, from part i to part j\n",
    "def create_super_local_oscar_generator(data_path, i=0, j=0):\n",
    "    \n",
    "    if j > i:\n",
    "        generators = create_local_oscar_generators(data_path, i=i, j=j)\n",
    "    else:\n",
    "        generators = create_local_oscar_generators(data_path)\n",
    "\n",
    "    return create_super_generator(generators)\n",
    "\n",
    "\n",
    "# function to create a dataset with text \n",
    "def create_test_set(dataset_generator, start, end):\n",
    "    it = iter(dataset_generator)\n",
    "    for _ in range(start):\n",
    "        next(it)\n",
    "    for _ in range(end - start + 1):\n",
    "        yield next(it)\n",
    "\n",
    "\n",
    "# function to turn a generator that returns a dictionary with 'text' as key into a generator of the values\n",
    "def create_text_generator(gen):\n",
    "    for i in gen:\n",
    "        yield i['text']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # set path to datasets\n",
    "# data_path = '/Users/jan/Documents/Master Information Studies/Thesis/Code/Datasets'\n",
    "\n",
    "# # create super generator from all OSCAR files on computer\n",
    "# oscar_gen_super = create_super_local_oscar_generator(data_path)\n",
    "\n",
    "# # create small dataset (uneven number of lines)\n",
    "# oscar_gen_small = create_test_set(oscar_gen_1, 0, 100007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "\n",
    "import os\n",
    "\n",
    "def get_all_file_paths(folder_path):\n",
    "    file_paths = []\n",
    "    for root, directories, files in os.walk(folder_path):\n",
    "        # Filter out directories that start with a dot\n",
    "        directories[:] = [d for d in directories if not d.startswith('.')]\n",
    "        for file in files:\n",
    "            # Filter out files that start with a dot\n",
    "            if not file.startswith('.'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                if os.path.isfile(file_path):  # Check if the path is a file\n",
    "                    file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "paths = get_all_file_paths(data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "p = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt'\n",
    "d = load_dataset('text', data_files={\"train\": p}, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freqs_multiple_paths(paths):\n",
    "    word_freqs = {}\n",
    "    for path in paths:\n",
    "        dataset = load_dataset('text', data_files={\"train\": path}, split='train')\n",
    "        for i in dataset:\n",
    "            for word in preprocess_lower(i['text']):\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    return word_freqs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mword_freqs_multiple_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[120], line 8\u001b[0m, in \u001b[0;36mword_freqs_multiple_paths\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m preprocess_lower(i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_freqs:\n\u001b[0;32m----> 8\u001b[0m         word_freqs[word] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m         word_freqs[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_freqs_multiple_paths(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deze code is gebruikt in freqs1.job (freqs1.py)\n",
    "\n",
    "\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "path = '/home/scur2141/datasets'\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_lower(seq):\n",
    "    return [s.strip(string.punctuation) for s in seq.strip().lower().split()]\n",
    "\n",
    "\n",
    "def create_data_gen(path):\n",
    "\n",
    "    iterators = []\n",
    "\n",
    "    for i in range(1, 50):\n",
    "        full_path = os.path.join(path, f'nl_part_{i}.txt')\n",
    "        if os.path.isfile(full_path):\n",
    "            print('ja')\n",
    "            iterators.append(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "    \n",
    "    for it in iterators:\n",
    "        yield from it\n",
    "        \n",
    "    \n",
    "def create_word_freqs_from_corpus(corpus_generator, sort=False):\n",
    "    \n",
    "    word_freqs = {}\n",
    "\n",
    "    for i in corpus_generator:     \n",
    "        text = preprocess_lower(i['text'])\n",
    "        for word in text:\n",
    "            if word in word_freqs:\n",
    "                word_freqs[word] += 1\n",
    "            else:\n",
    "                word_freqs[word] = 1\n",
    "    \n",
    "    if sort:\n",
    "        word_freqs = dict(sorted(word_freqs.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "data_it = create_data_gen(path)\n",
    "freqs = create_word_freqs_from_corpus(data_it, sort=True)\n",
    "\n",
    "\n",
    "with open('frequencies.json', 'w') as f:\n",
    "    json.dump(freqs, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {3:4, 5: 6}\n",
    "\n",
    "with open('test_dict.json', 'w') as f:\n",
    "    json.dump(x_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2239,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_dict.json', 'r') as f:\n",
    "    my_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3': 4, '5': 6}"
      ]
     },
     "execution_count": 2240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import os\n",
    "\n",
    "\n",
    "# function that returns a dictionary with a generator for every existing OSCAR file in this computer\n",
    "def create_local_oscar_generators(path, i=0, j=0):\n",
    "\n",
    "    out = {}\n",
    "    \n",
    "    if j > i:\n",
    "        n = j - i\n",
    "\n",
    "        for x in range(i, j+1):\n",
    "            full_path = os.path.join(path, f'nl_part_{x}.txt')\n",
    "            if os.path.isfile(full_path):\n",
    "                out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "        \n",
    "        if len(out) != n + 1:\n",
    "            print('Not all parts requested are on this computer')\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for i in range(1, 50):\n",
    "            full_path = os.path.join(path, f'nl_part_{i}.txt')\n",
    "            print(full_path)\n",
    "            if os.path.isfile(full_path):\n",
    "                print('ja')\n",
    "                out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# function that creates one generator out of multiple generators\n",
    "def create_super_generator(generator_dict, list_input=False):\n",
    "\n",
    "    if list_input:\n",
    "        for generator in generator_dict:\n",
    "            yield from generator\n",
    "    else:\n",
    "        for generator in generator_dict.values():\n",
    "            yield from generator\n",
    "\n",
    "\n",
    "# one function to create OSCAR generator by combining n parts of the dataset, from part i to part j\n",
    "def create_super_local_oscar_generator(data_path, i=0, j=0):\n",
    "    \n",
    "    if j > i:\n",
    "        generators = create_local_oscar_generators(data_path, i=i, j=j)\n",
    "    else:\n",
    "        generators = create_local_oscar_generators(data_path)\n",
    "\n",
    "    return create_super_generator(generators)\n",
    "\n",
    "\n",
    "# function to create a dataset with text \n",
    "def create_test_set(dataset_generator, start, end):\n",
    "    it = iter(dataset_generator)\n",
    "    for _ in range(start):\n",
    "        next(it)\n",
    "    for _ in range(end - start + 1):\n",
    "        yield next(it)\n",
    "\n",
    "\n",
    "# function to turn a generator that returns a dictionary with 'text' as key into a generator of the values\n",
    "def create_text_generator(gen):\n",
    "    for i in gen:\n",
    "        yield i['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2242,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "\n",
    "x = create_super_generator(create_local_oscar_generators(path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2243,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(x):\n",
    "    if i < 6:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_2.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_3.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_4.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_5.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_6.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_7.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_8.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_9.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_10.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_11.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_12.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_13.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_14.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_15.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_16.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_17.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_18.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_19.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_20.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_21.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_22.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_23.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_24.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_25.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_26.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_27.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_28.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_29.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_30.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_31.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_32.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_33.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_34.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_35.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_36.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_37.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_38.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_39.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_40.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_41.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_42.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_43.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_44.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_45.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_46.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_47.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_48.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_49.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "x = create_local_oscar_generators(path)\n",
    "\n",
    "os.path.isfile('Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 2254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2269,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "y = create_data_gen(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2270,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2270], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "\n",
    "paths = []\n",
    "for x in range(25):\n",
    "    full_path = os.path.join(path, f'nl_part_{x}.txt')\n",
    "    if os.path.isfile(full_path):\n",
    "        paths.append(full_path)\n",
    "        # out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt']\n",
      "freqs dict is gemaakt\n"
     ]
    }
   ],
   "source": [
    "# preprocess function\n",
    "def preprocess_lower(seq):\n",
    "    return [s.strip(string.punctuation) for s in seq.strip().lower().split()]\n",
    "\n",
    "# find paths\n",
    "def get_all_file_paths(folder_path):\n",
    "    file_paths = []\n",
    "    for root, directories, files in os.walk(folder_path):\n",
    "        # Filter out directories that start with a dot\n",
    "        directories[:] = [d for d in directories if not d.startswith('.')]\n",
    "        for file in files:\n",
    "            # Filter out files that start with a dot\n",
    "            if not file.startswith('.'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                if os.path.isfile(file_path):  # Check if the path is a file\n",
    "                    file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "paths = get_all_file_paths('/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short')\n",
    "\n",
    "print(paths)\n",
    "\n",
    "\n",
    "# make dict\n",
    "def word_freqs_multiple_paths(paths):\n",
    "    word_freqs = {}\n",
    "    for path in paths:\n",
    "        dataset = load_dataset('text', data_files={\"train\": path}, split='train')\n",
    "        for i in dataset:\n",
    "            for word in preprocess_lower(i['text']):\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    return word_freqs\n",
    "\n",
    "word_freqs = word_freqs_multiple_paths(paths)\n",
    "\n",
    "\n",
    "print('freqs dict is gemaakt')\n",
    "\n",
    "\n",
    "# store\n",
    "with open('frequencies20.json', 'w') as f:\n",
    "    json.dump(word_freqs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('frequencies20.json', 'r') as f:\n",
    "    a = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vul': 377,\n",
       " 'het': 108245,\n",
       " 'e-mailadres': 542,\n",
       " 'in': 83947,\n",
       " 'dat': 35537,\n",
       " 'bij': 22024,\n",
       " 'uw': 11450,\n",
       " 'account': 606,\n",
       " 'hoort': 420,\n",
       " 'er': 19831,\n",
       " 'zal': 4341,\n",
       " 'een': 110514,\n",
       " 'verificatiecode': 10,\n",
       " 'naar': 16759,\n",
       " 'worden': 14045,\n",
       " 'verzonden': 252,\n",
       " 'wanneer': 2625,\n",
       " 'u': 23911,\n",
       " 'de': 219750,\n",
       " 'heeft': 12072,\n",
       " 'ontvangen': 1031,\n",
       " 'kunt': 6300,\n",
       " 'nieuw': 1513,\n",
       " 'wachtwoord': 355,\n",
       " 'kiezen': 1121,\n",
       " 'voor': 50721,\n",
       " 'gebruikersnaam': 104,\n",
       " 'dit': 15729,\n",
       " 'wijkagent': 9,\n",
       " 'michel': 52,\n",
       " 'van': 129018,\n",
       " 'kempen': 33,\n",
       " 'micheal': 1,\n",
       " 'is': 56843,\n",
       " 'nijmegen': 221,\n",
       " 'centrum': 937,\n",
       " 'geworden': 632,\n",
       " 'zijn': 34003,\n",
       " 'vorige': 542,\n",
       " 'wijken': 88,\n",
       " 'voorlopig': 129,\n",
       " 'onderverdeeld': 28,\n",
       " 'koen': 40,\n",
       " 'en': 126294,\n",
       " 'yvonne': 25,\n",
       " 'zodra': 456,\n",
       " 'nieuwe': 5391,\n",
       " 'zullen': 1714,\n",
       " 'wij': 9959,\n",
       " 'hier': 5854,\n",
       " 'kenbaar': 58,\n",
       " 'maken': 6738,\n",
       " 'wensen': 521,\n",
       " 'heel': 3699,\n",
       " 'veel': 6445,\n",
       " 'succes': 478,\n",
       " 'plezier': 518,\n",
       " 'wijk': 263,\n",
       " 'om': 29232,\n",
       " 'best': 1063,\n",
       " 'mogelijke': 457,\n",
       " 'website': 7120,\n",
       " 'toegang': 580,\n",
       " 'te': 53814,\n",
       " 'bieden': 1567,\n",
       " 'maakt': 2976,\n",
       " 'deze': 22814,\n",
       " 'site': 2424,\n",
       " 'gebruik': 5820,\n",
       " 'cookies': 6437,\n",
       " 'delete': 8,\n",
       " 'alles': 2713,\n",
       " 'begint': 766,\n",
       " 'goede': 2414,\n",
       " 'communicatie': 368,\n",
       " 'altijd': 3536,\n",
       " 'al': 8382,\n",
       " 'zo': 8230,\n",
       " 'geweest': 903,\n",
       " 'helaas': 702,\n",
       " 'wordt': 11763,\n",
       " 'rondom': 303,\n",
       " 'beveiliging': 191,\n",
       " 'vaak': 1961,\n",
       " 'niet': 25338,\n",
       " 'goed': 5979,\n",
       " 'gecommuniceerd': 11,\n",
       " 'leidt': 236,\n",
       " 'tot': 11418,\n",
       " 'frustraties': 12,\n",
       " 'onwil': 5,\n",
       " 'communicatieplan': 3,\n",
       " 'gereed': 40,\n",
       " 'dan': 17250,\n",
       " 'kunnen': 9313,\n",
       " 'we': 15232,\n",
       " 'starten': 287,\n",
       " 'met': 51676,\n",
       " 'bewustwording': 29,\n",
       " 'of': 25590,\n",
       " 'awareness': 8,\n",
       " 'middels': 167,\n",
       " 'gerichte': 88,\n",
       " 'uitingen': 30,\n",
       " 'aes': 5,\n",
       " 'verschillende': 2905,\n",
       " 'sectoren': 65,\n",
       " 'relatief': 167,\n",
       " 'portfolio': 56,\n",
       " 'maar': 16759,\n",
       " 'spectaculaire': 72,\n",
       " 'resultaten': 519,\n",
       " 'naast': 1370,\n",
       " 'bewustwordingscampagnes': 1,\n",
       " 'voeren': 447,\n",
       " 'ook': 22106,\n",
       " 'regelmatig': 684,\n",
       " 'mystery': 12,\n",
       " 'visits': 1,\n",
       " 'op': 58230,\n",
       " 'allerlei': 500,\n",
       " 'alle': 6831,\n",
       " 'organisaties': 388,\n",
       " 'kennen': 470,\n",
       " 'incidenten': 43,\n",
       " 'slechts': 1008,\n",
       " 'weinigen': 14,\n",
       " 'beheersen': 57,\n",
       " 'kunst': 551,\n",
       " 'leren': 861,\n",
       " 'ongewenste': 52,\n",
       " 'gebeurtenissen': 164,\n",
       " 'onze': 11785,\n",
       " 'applicatie': 139,\n",
       " 'bent': 2604,\n",
       " 'staat': 4148,\n",
       " 'die': 27837,\n",
       " 'periodiek': 38,\n",
       " 'informeren': 235,\n",
       " 'management': 309,\n",
       " 'over': 13160,\n",
       " 'imago': 85,\n",
       " 'afdeling': 348,\n",
       " 'professionele': 441,\n",
       " 'managementinformatie': 4,\n",
       " 'kan': 11881,\n",
       " 'men': 1227,\n",
       " 'gestructureerd': 15,\n",
       " 'kaart': 569,\n",
       " 'brengen': 1062,\n",
       " \"risico's\": 39,\n",
       " 'levert': 408,\n",
       " 'als': 22613,\n",
       " 'voordeel': 392,\n",
       " 'maatregelen': 293,\n",
       " 'synergie': 7,\n",
       " 'ontstaat': 273,\n",
       " 'veilige': 226,\n",
       " 'omgeving': 966,\n",
       " 'kostenefficint': 5,\n",
       " 'beveiliginsdiensten': 1,\n",
       " 'gekenmerkt': 53,\n",
       " 'door': 18490,\n",
       " 'medewerkers': 799,\n",
       " 'passief': 22,\n",
       " 'reageren': 303,\n",
       " 'gewonnen': 167,\n",
       " 'meer': 12213,\n",
       " 'kwalitatief': 111,\n",
       " 'hoogstaand': 12,\n",
       " 'uniform': 23,\n",
       " 'werken': 2414,\n",
       " 'noodzakelijk': 366,\n",
       " 'up-to-date': 55,\n",
       " 'handboek': 66,\n",
       " 'instructies': 218,\n",
       " 'werkprocessen': 14,\n",
       " 'hebben': 9889,\n",
       " 'zeker': 1999,\n",
       " 'schade': 443,\n",
       " 'beperkt': 336,\n",
       " 'grootschalig': 18,\n",
       " 'incident': 31,\n",
       " 'belang': 699,\n",
       " 'iedereen': 1650,\n",
       " 'weet': 1655,\n",
       " 'wat': 11279,\n",
       " 'hij': 8710,\n",
       " 'moet': 5219,\n",
       " 'doen': 3868,\n",
       " 'stressvolle': 10,\n",
       " 'situatie': 480,\n",
       " 'garanderen': 161,\n",
       " 'berekenen': 78,\n",
       " 'sluitplan': 2,\n",
       " 'complexe': 95,\n",
       " 'organisatie': 942,\n",
       " 'eenvoudig': 959,\n",
       " 'sleutels': 55,\n",
       " 'nadelen': 51,\n",
       " 'simpel': 168,\n",
       " 'richten': 199,\n",
       " 'standaardisatie': 1,\n",
       " 'beheer': 328,\n",
       " 'onderhoud': 500,\n",
       " 'moeten': 2349,\n",
       " 'voorzieningen': 181,\n",
       " 'afgestemd': 107,\n",
       " 'aanwezig': 620,\n",
       " \"camera's\": 26,\n",
       " 'echter': 1338,\n",
       " 'aangekocht': 15,\n",
       " 'zonder': 2967,\n",
       " 'nagedacht': 43,\n",
       " 'haalbare': 16,\n",
       " 'camera-strategie': 1,\n",
       " 'instellingen': 529,\n",
       " 'visie': 254,\n",
       " 'documenten': 230,\n",
       " 'toegangspassen': 1,\n",
       " 'bestaan': 627,\n",
       " 'technologien': 74,\n",
       " 'belangrijk': 1154,\n",
       " 'juiste': 1394,\n",
       " 'selecteren': 219,\n",
       " 'helder': 220,\n",
       " 'welke': 2229,\n",
       " 'toepassingen': 127,\n",
       " 'aan': 26227,\n",
       " 'pas': 824,\n",
       " 'verbonden': 310,\n",
       " 'toegangsbeheer': 3,\n",
       " 'toegangsbeheerssystemen': 1,\n",
       " 'elk': 1111,\n",
       " 'hun': 5761,\n",
       " 'afhankelijk': 510,\n",
       " 'gewenste': 288,\n",
       " 'functies': 387,\n",
       " 'autorisatiestructuur': 1,\n",
       " 'past': 628,\n",
       " 'ene': 424,\n",
       " 'systeem': 710,\n",
       " 'beter': 1617,\n",
       " 'andere': 6544,\n",
       " 'verwarren': 12,\n",
       " 'security': 90,\n",
       " 'meldkamermanagement': 1,\n",
       " 'zorgt': 1098,\n",
       " 'ervoor': 1066,\n",
       " 'aanweizge': 1,\n",
       " 'beveiligingssystemen': 4,\n",
       " 'slimmer': 26,\n",
       " 'eenvoudiger': 88,\n",
       " 'gebruikt': 2774,\n",
       " 'uitermate': 118,\n",
       " 'gat': 73,\n",
       " 'vegetatie': 8,\n",
       " 'zit': 1533,\n",
       " 'ze': 12158,\n",
       " 'zitten': 1233,\n",
       " 'graag': 2271,\n",
       " 'langer': 667,\n",
       " 'gras': 106,\n",
       " 'waar': 5391,\n",
       " 'vooral': 1618,\n",
       " 'regenwormen': 2,\n",
       " 'emelten': 1,\n",
       " 'zoeken': 833,\n",
       " 'eten': 886,\n",
       " 'watersnip': 4,\n",
       " 'bedreigt': 7,\n",
       " 'vliegt': 73,\n",
       " 'laatste': 1864,\n",
       " 'moment': 1421,\n",
       " 'vliegen': 177,\n",
       " 'zigzaggend': 1,\n",
       " 'snel': 2578,\n",
       " 'omhoog': 213,\n",
       " 'trekvogels': 6,\n",
       " 'november': 1548,\n",
       " 'via': 4335,\n",
       " 'frankrijk': 577,\n",
       " 'spanje': 287,\n",
       " 'eerst': 1544,\n",
       " 'marokko': 76,\n",
       " 'daar': 3466,\n",
       " 'rusten': 65,\n",
       " 'voordat': 536,\n",
       " 'sahara': 21,\n",
       " 'oversteken': 39,\n",
       " 'wel': 7713,\n",
       " 'langs': 1048,\n",
       " 'kust': 208,\n",
       " 'gaan': 5213,\n",
       " 'itali': 340,\n",
       " 'afrika': 118,\n",
       " 'momenteel': 424,\n",
       " 'nog': 10680,\n",
       " 'ongeveer': 811,\n",
       " '46.000': 1,\n",
       " 'gruttoparen': 1,\n",
       " 'nederland': 3004,\n",
       " 'komen': 3158,\n",
       " 'broeden': 28,\n",
       " 'staan': 2400,\n",
       " 'ter': 1463,\n",
       " 'bescherming': 316,\n",
       " 'rode': 413,\n",
       " 'lijst': 640,\n",
       " 'scholeksters': 3,\n",
       " 'vind': 2225,\n",
       " 'je': 50769,\n",
       " 'weidegebieden': 2,\n",
       " 'mosselen': 18,\n",
       " 'kokkels': 1,\n",
       " 'kreeftachtigen': 1,\n",
       " 'voornamelijk': 266,\n",
       " 'wormen': 9,\n",
       " 'insecten(larven': 1,\n",
       " 'tegenwoordig': 374,\n",
       " 'maslanden': 1,\n",
       " 'voorbeelden': 251,\n",
       " 'bekend': 1034,\n",
       " 'platte': 74,\n",
       " 'daken': 50,\n",
       " 'huizen': 188,\n",
       " 'wachtend': 5,\n",
       " 'mannetje': 49,\n",
       " 'sloot': 97,\n",
       " 'wijst': 129,\n",
       " 'broedend': 1,\n",
       " 'vrouwtje': 45,\n",
       " 'waarschuwt': 19,\n",
       " 'haar': 6969,\n",
       " 'raspend-ratelend': 1,\n",
       " 'geluid': 317,\n",
       " 'zoek': 1882,\n",
       " 'geen': 7794,\n",
       " 'nest': 50,\n",
       " 'vast': 884,\n",
       " 'broedt': 5,\n",
       " 'want': 2094,\n",
       " 'gestoord': 16,\n",
       " 'laat': 2344,\n",
       " 'steek': 107,\n",
       " 'aparte': 177,\n",
       " 'baltsvlucht': 1,\n",
       " 'waarbij': 1206,\n",
       " 'gespreide': 5,\n",
       " 'staartveren': 2,\n",
       " 'duikvlucht': 4,\n",
       " 'recht': 1182,\n",
       " 'beneden': 237,\n",
       " 'omdat': 2580,\n",
       " 'trillen': 8,\n",
       " 'veroorzaakt': 162,\n",
       " 'blatende': 1,\n",
       " 'geit': 6,\n",
       " 'slobeenden': 2,\n",
       " 'liefst': 479,\n",
       " 'tussen': 3196,\n",
       " 'dichte': 23,\n",
       " 'begroeiing': 9,\n",
       " 'oevers': 12,\n",
       " 'kleine': 1708,\n",
       " 'holte': 3,\n",
       " 'bekleed': 31,\n",
       " 'roestbruin': 3,\n",
       " 'dons': 12,\n",
       " 'donkerbruine': 9,\n",
       " 'veertjes': 11,\n",
       " 'leggen': 497,\n",
       " 'april': 1039,\n",
       " 'juni': 1152,\n",
       " '6': 1732,\n",
       " '10': 1942,\n",
       " 'vaalgele': 1,\n",
       " 'eieren': 100,\n",
       " 'soms': 1144,\n",
       " '14': 792,\n",
       " 'na': 5673,\n",
       " '23': 395,\n",
       " '26': 340,\n",
       " 'dagen': 1914,\n",
       " 'uit': 13353,\n",
       " 'rondvliegend': 2,\n",
       " 'alarmerend': 1,\n",
       " 'wakend': 2,\n",
       " 'duidt': 23,\n",
       " 'ga': 2109,\n",
       " 'slobeend': 4,\n",
       " 'verstoord': 27,\n",
       " 'verlaten': 168,\n",
       " 'tweede': 1222,\n",
       " 'keer': 1982,\n",
       " 'bevuild': 2,\n",
       " 'uitwerpselen': 8,\n",
       " 'ongeer': 1,\n",
       " '8000': 9,\n",
       " '9000': 12,\n",
       " 'paren': 27,\n",
       " 'vochtige': 31,\n",
       " 'weilanden': 16,\n",
       " 'plassen': 53,\n",
       " 'meren': 30,\n",
       " 'rivierarmen': 1,\n",
       " 'sloten': 59,\n",
       " 'klein': 935,\n",
       " 'aantal': 2418,\n",
       " 'blijft': 1256,\n",
       " 'meesten': 56,\n",
       " 'trekken': 392,\n",
       " 'winter': 343,\n",
       " 'zuiden': 143,\n",
       " 'west': 165,\n",
       " 'europa': 529,\n",
       " 'middelandse': 1,\n",
       " 'zee': 466,\n",
       " '44': 117,\n",
       " '52': 83,\n",
       " 'cm': 1013,\n",
       " 'lang': 1370,\n",
       " 'gemakkelijk': 772,\n",
       " 'herkennen': 152,\n",
       " 'brede': 277,\n",
       " 'lepelvormige': 1,\n",
       " 'snavel': 5,\n",
       " 'daarin': 340,\n",
       " 'reeks': 210,\n",
       " 'filters': 119,\n",
       " 'waarmee': 719,\n",
       " 'oppervlakte': 86,\n",
       " 'water': 1141,\n",
       " 'drijvende': 36,\n",
       " 'voedsel': 188,\n",
       " 'kroos': 1,\n",
       " 'zaadjes': 17,\n",
       " 'waterdiertjes': 1,\n",
       " 'zeven': 227,\n",
       " 'opvallend': 208,\n",
       " 'gekleurd': 54,\n",
       " 'kop': 225,\n",
       " 'glanzend': 31,\n",
       " 'groen': 496,\n",
       " 'borst': 52,\n",
       " 'wit': 475,\n",
       " 'flanken': 4,\n",
       " 'onderkant': 87,\n",
       " 'kastanjebruin': 3,\n",
       " 'onopvallend': 16,\n",
       " 'bruin': 110,\n",
       " 'achter': 1185,\n",
       " 'zomer': 453,\n",
       " 'gaat': 4685,\n",
       " 'rui': 8,\n",
       " 'lijkt': 1076,\n",
       " 'even': 2201,\n",
       " 'sterk': 518,\n",
       " 'zomertaling': 1,\n",
       " 'soort': 828,\n",
       " 'eend': 10,\n",
       " 'eind': 542,\n",
       " 'legt': 212,\n",
       " 'bruinachtig-witte': 1,\n",
       " 'verstopt': 67,\n",
       " 'ondiep': 7,\n",
       " 'kuiltje': 3,\n",
       " 'vochtig': 30,\n",
       " 'grasland': 8,\n",
       " 'dichtbegroeide': 3,\n",
       " 'oever': 32,\n",
       " 'gevoerd': 128,\n",
       " 'donkerbruin': 20,\n",
       " 'witgespikkeld': 1,\n",
       " 'witte': 474,\n",
       " 'toppen': 13,\n",
       " 'erin': 181,\n",
       " 'o.a': 475,\n",
       " 'muggen': 11,\n",
       " 'larven': 5,\n",
       " 'waterslakken': 1,\n",
       " 'kevers': 4,\n",
       " 'bijvoorbeeld': 2060,\n",
       " 'eetbare': 21,\n",
       " 'delen': 1100,\n",
       " 'waterlelie': 2,\n",
       " 'profiteert': 45,\n",
       " 'kievit': 3,\n",
       " 'geeft': 1847,\n",
       " 'tegen': 3156,\n",
       " 'predatoren': 1,\n",
       " 'dieren': 365,\n",
       " 'eieren/kuikens': 1,\n",
       " \"zo'n\": 458,\n",
       " '25': 826,\n",
       " '27': 416,\n",
       " '3': 3715,\n",
       " '4': 2727,\n",
       " 'sporen': 85,\n",
       " '39': 74,\n",
       " 'rond': 1425,\n",
       " '100.000': 37,\n",
       " 'broedparen': 3,\n",
       " 'gedeeltelijk': 110,\n",
       " 'blijven': 1423,\n",
       " 'doortrekken': 9,\n",
       " 'verborgen': 109,\n",
       " 'fijn': 425,\n",
       " 'plantenmateriaal': 1,\n",
       " 'grashalmen': 1,\n",
       " 'gebogen': 43,\n",
       " 'zodat': 1884,\n",
       " 'tentje': 17,\n",
       " 'ligt': 1362,\n",
       " 'veldleeuwerik': 3,\n",
       " 'opvallende': 114,\n",
       " 'kleuren': 877,\n",
       " 'grijsbruin': 1,\n",
       " 'gevlekt': 2,\n",
       " 'makkelijk': 655,\n",
       " 'luide': 7,\n",
       " 'heldere': 115,\n",
       " 'jubelende': 3,\n",
       " 'zang': 43,\n",
       " 'manier': 1801,\n",
       " 'zingend': 7,\n",
       " 'grote': 3542,\n",
       " 'hoogte': 1083,\n",
       " 'cirkelen': 4,\n",
       " 'weer': 4907,\n",
       " 'sluit': 343,\n",
       " 'meters': 49,\n",
       " 'vleugels': 31,\n",
       " 'vallend': 4,\n",
       " 'komt': 2868,\n",
       " 'tijdens': 2896,\n",
       " 'geregeld': 227,\n",
       " 'zie': 1484,\n",
       " 'mooi': 1525,\n",
       " 'achterrand': 1,\n",
       " 'streep': 42,\n",
       " 'boven': 908,\n",
       " 'oog': 440,\n",
       " 'doorloopt': 17,\n",
       " 'nek': 94,\n",
       " 'verder': 3266,\n",
       " 'donkere': 131,\n",
       " 'tekening': 58,\n",
       " 'bruin(gevlekt': 1,\n",
       " 'strepen': 35,\n",
       " 'hoofd': 564,\n",
       " 'lichtbruine': 6,\n",
       " 'wenkbrauwstreep': 1,\n",
       " 'daaronder': 90,\n",
       " 'oogstreep': 2,\n",
       " 'lichte': 308,\n",
       " 'kuikens': 5,\n",
       " 'ondersnavel': 1,\n",
       " 'loopt': 512,\n",
       " 'let': 544,\n",
       " 'dus': 4876,\n",
       " 'voerende': 2,\n",
       " 'ouderparen': 3,\n",
       " 'slordige': 6,\n",
       " 'ondiepe': 11,\n",
       " 'kom': 1101,\n",
       " 'open': 1311,\n",
       " 'gebieden': 177,\n",
       " 'bouwland': 2,\n",
       " 'heidevelden': 3,\n",
       " 'kwelders': 1,\n",
       " 'duinen': 68,\n",
       " 'vroeger': 313,\n",
       " 'was': 8948,\n",
       " 'meest': 1414,\n",
       " 'algemeen': 910,\n",
       " 'voorkomende': 147,\n",
       " 'broedvogels': 2,\n",
       " 'ons': 8191,\n",
       " 'land': 1124,\n",
       " 'jaren': 1810,\n",
       " 'neemt': 794,\n",
       " 'af': 2782,\n",
       " '50.000': 53,\n",
       " 'maart': 1101,\n",
       " 'twee': 3204,\n",
       " 'drie': 1462,\n",
       " 'per': 3562,\n",
       " 'jaar': 7469,\n",
       " '12-14': 3,\n",
       " 'duurt': 245,\n",
       " 'jongen': 249,\n",
       " '10-14': 2,\n",
       " 'vertrekken': 124,\n",
       " 'meeste': 881,\n",
       " 'veldleeuweriken': 1,\n",
       " 'engeland': 157,\n",
       " 'rest': 415,\n",
       " 'overwinterd': 1,\n",
       " \"grutto's\": 3,\n",
       " 'n': 2630,\n",
       " 'vanaf': 2439,\n",
       " 'meestal': 681,\n",
       " 'waarop': 813,\n",
       " '24': 717,\n",
       " 'rietland': 1,\n",
       " 'pol': 21,\n",
       " 'begroeing': 2,\n",
       " 'vlak': 419,\n",
       " 'droge': 123,\n",
       " 'grassprietjes': 2,\n",
       " 'bladeren': 78,\n",
       " 'broed': 2,\n",
       " 'juli': 1008,\n",
       " '19': 485,\n",
       " '21': 510,\n",
       " 'hele': 1691,\n",
       " 'tegenkomen': 55,\n",
       " 'kans': 854,\n",
       " 'heb': 5451,\n",
       " 'trek': 141,\n",
       " 'name': 388,\n",
       " 'najaarstrek': 1,\n",
       " 'overwinteren': 8,\n",
       " 'zuid-engeland': 1,\n",
       " 'zuidwest-europa': 1,\n",
       " 'heten': 59,\n",
       " 'deltasafe': 3,\n",
       " 'groep': 1148,\n",
       " 'harte': 196,\n",
       " 'welkom': 707,\n",
       " 'sponsor': 36,\n",
       " 'akc': 1,\n",
       " 'blauw-wit': 2,\n",
       " 'hopen': 199,\n",
       " 'duurzame': 409,\n",
       " 'samenwerking': 678,\n",
       " 'biedt': 1384,\n",
       " 'veiligheid': 534,\n",
       " 'bestaat': 1092,\n",
       " 'ruime': 370,\n",
       " 'ervaring': 1284,\n",
       " 'expertise': 126,\n",
       " 'facetten': 27,\n",
       " 'zowel': 1468,\n",
       " 'bedrijven': 1076,\n",
       " 'particulieren': 156,\n",
       " 'nu': 5754,\n",
       " 'beveiligings': 3,\n",
       " 'opleidings': 5,\n",
       " 'brand': 236,\n",
       " 'recherchewerkzaamheden': 3,\n",
       " 'adviseurs': 69,\n",
       " 'oplossing': 652,\n",
       " 'eerste': 3640,\n",
       " 'toespraak': 40,\n",
       " 'paus': 27,\n",
       " 'johannes': 59,\n",
       " 'paulus': 33,\n",
       " 'i': 753,\n",
       " 'balkon': 114,\n",
       " 'st.-pietersbasiliek': 1,\n",
       " 'augustus': 921,\n",
       " '1978': 59,\n",
       " 'lightsheer': 1,\n",
       " 'duet': 6,\n",
       " 'gouden': 212,\n",
       " 'standaard': 691,\n",
       " 'gebied': 1240,\n",
       " 'aangaande': 64,\n",
       " 'laser': 44,\n",
       " 'ontharen': 12,\n",
       " 'soprano': 1,\n",
       " 'accord': 2,\n",
       " 'bezit': 333,\n",
       " 'bijkomend': 31,\n",
       " 'getinte': 23,\n",
       " 'huidtype': 8,\n",
       " '': 28764,\n",
       " 'zongebruinde': 1,\n",
       " 'huid': 495,\n",
       " 'eerder': 761,\n",
       " 'effectiever': 29,\n",
       " 'mogen': 819,\n",
       " 'veven.regelrecht': 1,\n",
       " 'flits': 9,\n",
       " 'voelt': 364,\n",
       " 'niks': 475,\n",
       " 'verdere': 220,\n",
       " 'behandeling': 514,\n",
       " 'schaamstreek': 1,\n",
       " 'mag': 1796,\n",
       " 'hetgeen': 152,\n",
       " 'pijn': 254,\n",
       " 'geraken': 45,\n",
       " 'meemaken': 58,\n",
       " 'dorien.nl': 1,\n",
       " 'anti-ageing': 1,\n",
       " 'center': 120,\n",
       " 'beschikt': 360,\n",
       " 'anbos': 1,\n",
       " 'keurmerk': 103,\n",
       " 'wegens': 224,\n",
       " 'professionaliteit': 31,\n",
       " 'kwaliteit': 1439,\n",
       " 'vakkennis': 16,\n",
       " 'permanente': 207,\n",
       " 'ontharing': 2,\n",
       " 'hoogstaande': 21,\n",
       " 'apparatuur': 173,\n",
       " 'beschermt': 84,\n",
       " 'pigmentvlekken': 5,\n",
       " 'mogelijkheid': 617,\n",
       " 'bijwerkingen': 40,\n",
       " 'nihil': 6,\n",
       " 'specialisten': 142,\n",
       " 'iedere': 894,\n",
       " 'zorg': 1198,\n",
       " 'professionalit': 1,\n",
       " 'permanent': 49,\n",
       " 'nauwelijks': 212,\n",
       " 'last': 428,\n",
       " 'hebt': 2519,\n",
       " 'huidirritaties': 2,\n",
       " 'harsen': 12,\n",
       " 'ofwel': 179,\n",
       " 'scheren': 46,\n",
       " 'ingegroeide': 6,\n",
       " 'haartjes': 26,\n",
       " 'gerriteerde': 14,\n",
       " 'stoppels': 2,\n",
       " 'pijnlijk': 43,\n",
       " 'lelijk': 28,\n",
       " 'laserontharing': 1,\n",
       " 'wegnemen': 21,\n",
       " 'denkt': 343,\n",
       " 'weleens': 66,\n",
       " 'feit': 440,\n",
       " 'nimmer': 41,\n",
       " 'hoeft': 672,\n",
       " 'e': 488,\n",
       " 'indien': 1501,\n",
       " 'kiest': 366,\n",
       " 'indicaties': 8,\n",
       " 'huidkliniek': 1,\n",
       " 'vliet': 13,\n",
       " 'ingeval': 45,\n",
       " 'verzekerd': 172,\n",
       " 'raakt': 148,\n",
       " 'vergoeding': 190,\n",
       " 'zorgverzekeraar': 55,\n",
       " 'bezoek': 1045,\n",
       " 'plaats': 2272,\n",
       " 'opties.indien': 1,\n",
       " 'hars': 22,\n",
       " 'afgekoeld': 5,\n",
       " 'zich': 5867,\n",
       " 'smeren': 39,\n",
       " 'bijzonder': 571,\n",
       " 'moeilijk': 442,\n",
       " 'ongemak': 41,\n",
       " 'wilt': 2392,\n",
       " 'vervolgens': 876,\n",
       " 'betreffende': 494,\n",
       " 'elos': 11,\n",
       " 'werkwijze': 93,\n",
       " 'echt': 2276,\n",
       " 'ervaart': 54,\n",
       " 'voordelen': 322,\n",
       " 'gladde': 49,\n",
       " 'hete': 204,\n",
       " 'waxen': 7,\n",
       " 'harsen.om': 1,\n",
       " 'reactie': 546,\n",
       " 'plaatsen': 1852,\n",
       " 'vragen': 2177,\n",
       " 'jouw': 3080,\n",
       " 'loggen': 154,\n",
       " 'registreren': 230,\n",
       " 'klik': 1484,\n",
       " 'verstuur': 25,\n",
       " 'k': 181,\n",
       " 'tracklist': 1,\n",
       " '01': 87,\n",
       " 'stallion': 1,\n",
       " '02': 51,\n",
       " 'make': 46,\n",
       " 'a': 1578,\n",
       " 'wish': 12,\n",
       " '03': 30,\n",
       " 'shameless': 2,\n",
       " 'shadow': 8,\n",
       " 'koningin': 76,\n",
       " 'elisabethwedstrijd': 1,\n",
       " 'internationale': 425,\n",
       " 'muziekwedstrijd': 1,\n",
       " 'belgi235': 3,\n",
       " 'opgericht': 269,\n",
       " '1937': 7,\n",
       " 'elisabeth': 29,\n",
       " 'heette': 34,\n",
       " 'wedstrijd': 393,\n",
       " 'eug232;ne': 2,\n",
       " 'ysa255;ewestrijd': 1,\n",
       " 'eerbetoon': 20,\n",
       " '1931': 11,\n",
       " 'overleden': 134,\n",
       " 'ysa255;e': 1,\n",
       " 'hoofdstuk': 305,\n",
       " '1': 5704,\n",
       " 'rivers': 5,\n",
       " 'casino': 224,\n",
       " 'nightclub': 1,\n",
       " 'krijgt': 1580,\n",
       " 'melkveehouder': 6,\n",
       " 'perrier': 1,\n",
       " 'lapadite': 1,\n",
       " 'onverwachts': 13,\n",
       " 'nno': 1,\n",
       " 'hans': 181,\n",
       " 'landa': 1,\n",
       " 'ss-standartenf252;hrer': 1,\n",
       " 'verdenking': 14,\n",
       " 'verbergen': 88,\n",
       " '': 717,\n",
       " 'avoid': 1,\n",
       " 'coded': 1,\n",
       " 'cosmetics': 3,\n",
       " 'crush': 7,\n",
       " 'with': 466,\n",
       " 'this': 452,\n",
       " 'deluxe': 21,\n",
       " 'wood': 10,\n",
       " 'makeup': 4,\n",
       " 'box': 107,\n",
       " 'built-in': 1,\n",
       " 'mirror': 10,\n",
       " 'bezoeken': 448,\n",
       " 'akkoord': 1411,\n",
       " 'cookie': 928,\n",
       " 'beleid': 420,\n",
       " 'volg': 243,\n",
       " 'twitter': 356,\n",
       " 'copyright': 237,\n",
       " '': 248,\n",
       " '2013': 1068,\n",
       " '2015': 1369,\n",
       " 'betekenis-voornaam.nl': 18,\n",
       " 'sitemap': 50,\n",
       " 'disclaimer': 122,\n",
       " 'script': 44,\n",
       " 'webmasters': 24,\n",
       " 'partners': 544,\n",
       " 'contact': 2152,\n",
       " 'gehele': 310,\n",
       " 'voorwerp': 39,\n",
       " 'plak': 55,\n",
       " 'html': 42,\n",
       " 'pagina': 1121,\n",
       " 'koppelen': 128,\n",
       " 'koppelingin': 2,\n",
       " 'email': 380,\n",
       " 'im': 25,\n",
       " 'document': 189,\n",
       " 'wil': 4238,\n",
       " 'design': 574,\n",
       " 'responsive': 27,\n",
       " 'refereert': 12,\n",
       " 'dikwijls': 45,\n",
       " '3e': 97,\n",
       " 'party': 76,\n",
       " 'code': 391,\n",
       " 'zoals': 4203,\n",
       " 'facebook': 643,\n",
       " 'plug-ins': 19,\n",
       " 'nogal': 218,\n",
       " 'lastig': 242,\n",
       " 'externe': 288,\n",
       " 'stu': 8,\n",
       " 'doordat': 485,\n",
       " 'steeds': 2574,\n",
       " 'projecten': 376,\n",
       " 'mijn': 7633,\n",
       " 'pad': 170,\n",
       " 'kwamen': 405,\n",
       " 'schrijven': 561,\n",
       " 'blog': 827,\n",
       " 'geleidelijk': 84,\n",
       " 'verminderd': 50,\n",
       " 'ik': 24082,\n",
       " 'ben': 4166,\n",
       " 'bijna': 1113,\n",
       " '2': 4753,\n",
       " 'geleden': 1112,\n",
       " 'boek': 1208,\n",
       " 'uitgekomen': 31,\n",
       " 'waarin': 1326,\n",
       " 'yggdrasil': 5,\n",
       " 'volgen': 785,\n",
       " 'doeken': 21,\n",
       " 'gedaan': 879,\n",
       " 'hand': 1171,\n",
       " 'verhaal': 858,\n",
       " 'koffers': 123,\n",
       " 'leg': 199,\n",
       " 'stappen': 374,\n",
       " 'zetten': 1025,\n",
       " 'succesvolle': 155,\n",
       " 'natuurlijke': 440,\n",
       " 'moestuin': 21,\n",
       " 'respons': 10,\n",
       " 'groot': 1677,\n",
       " 'verkoop': 392,\n",
       " 'sindsdien': 93,\n",
       " 'mensen': 3661,\n",
       " 'bijkomende': 87,\n",
       " 'combineren': 299,\n",
       " 'beschikbare': 194,\n",
       " 'uitgebreide': 346,\n",
       " 'uitleg': 305,\n",
       " 'vernieuwende': 39,\n",
       " 'simpele': 122,\n",
       " 'stond': 608,\n",
       " 'inleiding': 446,\n",
       " '': 58,\n",
       " '2012': 867,\n",
       " 'begonnen': 344,\n",
       " 'periode': 646,\n",
       " 'ouders': 860,\n",
       " 'bedrijf': 1433,\n",
       " 'gestapt': 11,\n",
       " 'had': 3043,\n",
       " 'toen': 1750,\n",
       " 'duidelijk': 896,\n",
       " 'beeld': 803,\n",
       " 'toe': 2126,\n",
       " 'wou': 109,\n",
       " 'project': 757,\n",
       " 'wist': 430,\n",
       " 'iets': 2649,\n",
       " 'doe': 936,\n",
       " 'mee': 3598,\n",
       " 'bereiken': 413,\n",
       " 'beroeren': 2,\n",
       " 'waanzinnig': 13,\n",
       " 'geschreven': 366,\n",
       " 'nieuwsbrief': 681,\n",
       " 'papieren': 90,\n",
       " 'online': 2456,\n",
       " 'tijdschriften': 81,\n",
       " 'zou': 3203,\n",
       " 'natuurlijk': 1945,\n",
       " 'tuinieren': 17,\n",
       " 'helemaal': 1499,\n",
       " 'klaar': 1017,\n",
       " 'oorspronkelijk': 104,\n",
       " 'mulchen': 5,\n",
       " 'gedachten': 191,\n",
       " 'opvolger': 85,\n",
       " 'hierover': 233,\n",
       " 'krijg': 638,\n",
       " 'onderwerp': 580,\n",
       " 'informatie': 4216,\n",
       " 'vinden': 2600,\n",
       " 'vindt': 1677,\n",
       " 'tegenstrijdig': 8,\n",
       " 'onvolledig': 27,\n",
       " 'aandacht': 839,\n",
       " 'viel': 232,\n",
       " 'afgelopen': 1044,\n",
       " 'niets': 1115,\n",
       " 'vergelijking': 143,\n",
       " 'interesse': 291,\n",
       " 'filed': 1,\n",
       " 'under': 9,\n",
       " 'permacultuur': 6,\n",
       " 'tagged': 9,\n",
       " 'schijnbare': 14,\n",
       " 'chaos': 31,\n",
       " 'beslissing': 161,\n",
       " 'koelkast': 170,\n",
       " 'steken': 164,\n",
       " 'uitgebreid': 474,\n",
       " 'lichten': 55,\n",
       " 'valt': 636,\n",
       " 'vertellen': 396,\n",
       " 'roept': 103,\n",
       " 'direct': 1664,\n",
       " 'schijnbare': 1,\n",
       " 'chaos': 1,\n",
       " 'uitlegt': 12,\n",
       " 'vraagt': 389,\n",
       " 'denken': 810,\n",
       " 'kijken': 1269,\n",
       " 'tuin': 658,\n",
       " 'evident': 14,\n",
       " 'achtergrond': 227,\n",
       " 'duiding': 7,\n",
       " 'stap': 560,\n",
       " 'sneller': 344,\n",
       " ...}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt',\n",
       " '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_2.txt',\n",
       " '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_file_paths('/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_all_file_paths('/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt',\n",
       " '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_2.txt',\n",
       " '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bewaren voor de zekerheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_morpheme_set(treshold):\n",
    "    morpheme_set = set([])\n",
    "    for word, freq in word_freqs.items():\n",
    "        if freq >= treshold:\n",
    "            for morpheme in segmentations_lowercase[word]:\n",
    "                morpheme_set.add(morpheme)\n",
    "    return len(morpheme_set)\n",
    "\n",
    "results = {}\n",
    "for i in range(30):\n",
    "    results[i] = count_morpheme_set(i)\n",
    "\n",
    "# plot\n",
    "keys = list(results.keys())\n",
    "values = list(results.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(keys, values, marker='o', linestyle='-', color='b')\n",
    "plt.title('Morphemes vs Treshold')\n",
    "plt.xlabel('Treshold')\n",
    "plt.ylabel('Number of morphemes')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vocabulary size\n",
    "vocab_size = 20000\n",
    "\n",
    "# select dataset to train with\n",
    "train_set = bpe_generator(data, vocab, tokenizer)\n",
    "\n",
    "# load an existing BPE tokenizer\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# retrain the tokenizer\n",
    "tokenizer = old_tokenizer.train_new_from_iterator(train_set, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_robbert = RobertaTokenizerFast.from_pretrained(\"DTAI-KULeuven/robbert-2022-dutch-base\")\n",
    "\n",
    "t_robbert = AutoTokenizer.from_pretrained(\"DTAI-KULeuven/robbert-2022-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 204, 544, 2149, 733, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_robbert('Ik ga morgen lopen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 204, 544, 2149, 733, 4, 1903, 544, 29, 87, 733, 4, 13932, 88, 29, 9, 1083, 2203, 4, 112, 12, 9, 12960, 1049, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_robbert('Ik ga morgen lopen. Daarna ga ik weer lopen. Gisteren heb ik een fiets gekocht. Dit is een input tekst.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = t_robbert.get_vocab()\n",
    "g = {value: key for key, value in v.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gisteren'"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[13932]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Met ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dik = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "                                   add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=False,\n",
    "                                   add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "                                   add_compounds=True, replace_compounds=False, remove_ortho=True, remove_not_in_corpus=False, meta_data=False, print_info=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = create_initial_dataframe(segmentation_data)\n",
    "\n",
    "\n",
    "# create initial segmentation dictionary\n",
    "dik = create_segmentations_from_base(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dik2 = {}\n",
    "for word, segs in dik.items():\n",
    "    if len(segs) > 0 and ''.join(segs) != word:\n",
    "        dik2[word] = segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aaien': ['aai'],\n",
       " 'aalbessengelei': ['aal', 'bes', 'en', 'gelei'],\n",
       " 'aalbessenjam': ['aal', 'bes', 'en', 'jam'],\n",
       " 'aalbessenjenever': ['aal', 'bes', 'en', 'jenever'],\n",
       " 'aalbessesap': ['aal', 'bes', 'e', 'sap'],\n",
       " 'aalbessestruik': ['aal', 'bes', 'e', 'struik'],\n",
       " 'aalmoezenier': ['aalmoes', 'enier'],\n",
       " 'aalsteker': ['aal', 'steek', 'er', 'NV'],\n",
       " 'aambeeldsbeentje': ['aambeeld', 's', 'been'],\n",
       " 'aanaarden': ['aan', 'aarde'],\n",
       " 'aanbakken': ['aan', 'bak'],\n",
       " 'aanbeeldsbeentje': ['aanbeeld', 's', 'been'],\n",
       " 'aanbenen': ['aan', 'been'],\n",
       " 'aanbehoren': ['aan', 'be', 'hoor'],\n",
       " 'aanbellen': ['aan', 'bel'],\n",
       " 'aanbelanden': ['aan', 'be', 'land'],\n",
       " 'aanbelangen': ['aan', 'belang'],\n",
       " 'aanbermen': ['aan', 'berm'],\n",
       " 'aanbesteder': ['aan', 'besteed', 'er'],\n",
       " 'aanbesteding': ['aan', 'besteed', 'ing'],\n",
       " 'aanbesteden': ['aan', 'besteed'],\n",
       " 'aanbesterven': ['aan', 'be', 'sterf'],\n",
       " 'aanbeteren': ['aan', 'beter'],\n",
       " 'aanbevelen': ['aan', 'beveel'],\n",
       " 'aanbevelenswaard': ['aan', 'beveel', 's', 'waard'],\n",
       " 'aanbevelenswaardig': ['aan', 'beveel', 's', 'waarde', 'ig'],\n",
       " 'aanbeveling': ['aan', 'beveel', 'ing'],\n",
       " 'aanbidden': ['aan', 'bid'],\n",
       " 'aanbiddelijk': ['aan', 'bid', 'elijk'],\n",
       " 'aanbiddenswaardig': ['aan', 'bid', 's', 'waarde', 'ig'],\n",
       " 'aanbidder': ['aan', 'bid', 'er'],\n",
       " 'aanbidding': ['aan', 'bid', 'ing'],\n",
       " 'aanbieden': ['aan', 'bied'],\n",
       " 'aanbijten': ['aan', 'bijt'],\n",
       " 'aanbikken': ['aan', 'bik'],\n",
       " 'aanbinden': ['aan', 'bind'],\n",
       " 'aanblazen': ['aan', 'blaas'],\n",
       " 'aanblaffen': ['aan', 'blaf'],\n",
       " 'aanblazing': ['aan', 'blaas', 'ing'],\n",
       " 'aanblijven': ['aan', 'blijf'],\n",
       " 'aanblikken': ['aan', 'blik'],\n",
       " 'aanboeken': ['aan', 'boek'],\n",
       " 'aanbonzen': ['aan', 'bons'],\n",
       " 'aanboren': ['aan', 'boor'],\n",
       " 'aanbotsen': ['aan', 'bots'],\n",
       " 'aanbouwen': ['aan', 'bouw'],\n",
       " 'aanbraden': ['aan', 'braad'],\n",
       " 'aanbranden': ['aan', 'brand'],\n",
       " 'aanbrassen': ['aan', 'bras'],\n",
       " 'aanbreken': ['aan', 'breek'],\n",
       " 'aanbreien': ['aan', 'brei'],\n",
       " 'aanbrengen': ['aan', 'breng'],\n",
       " 'aanbriesen': ['aan', 'bries'],\n",
       " 'aanbruisen': ['aan', 'bruis'],\n",
       " 'aanbrullen': ['aan', 'brul'],\n",
       " 'aanbulderen': ['aan', 'bulder'],\n",
       " 'aandachttrekkerij': ['aandacht', 'trek', 'erij', 'NV'],\n",
       " 'aandammen': ['aan', 'dam'],\n",
       " 'aandamming': ['aan', 'dam', 'ing'],\n",
       " 'aandeelhebber': ['aan', 'deel', 'heb', 'er', 'NV'],\n",
       " 'aandelenkapitaal': ['aan', 'deel', 'en', 'kapitaal'],\n",
       " 'aandelenoptie': ['aan', 'deel', 'en', 'optie'],\n",
       " 'aandelenpakket': ['aan', 'deel', 'en', 'pakket'],\n",
       " 'aandelenportefeuille': ['aan', 'deel', 'en', 'portefeuille'],\n",
       " 'aandienen': ['aan', 'dien'],\n",
       " 'aandiepen': ['aan', 'diep'],\n",
       " 'aandijken': ['aan', 'dijk'],\n",
       " 'aandikken': ['aan', 'dik'],\n",
       " 'aandoen': ['aan', 'doe'],\n",
       " 'aandoening': ['aan', 'doe', 'ing'],\n",
       " 'aandoenlijk': ['aan', 'doe', 'lijk'],\n",
       " 'aandragen': ['aan', 'draag'],\n",
       " 'aandraaien': ['aan', 'draai'],\n",
       " 'aandraven': ['aan', 'draaf'],\n",
       " 'aandrager': ['aan', 'draag', 'er'],\n",
       " 'aandrentelen': ['aan', 'drentel'],\n",
       " 'aandrijven': ['aan', 'drijf'],\n",
       " 'aandrijver': ['aan', 'drijf', 'er'],\n",
       " 'aandrijving': ['aan', 'drijf', 'ing'],\n",
       " 'aandringen': ['aan', 'dring'],\n",
       " 'aandruisen': ['aan', 'druis'],\n",
       " 'aandrukken': ['aan', 'druk'],\n",
       " 'aanduiden': ['aan', 'duid'],\n",
       " 'aandurven': ['aan', 'durf'],\n",
       " 'aanduwen': ['aan', 'duw'],\n",
       " 'aandweilen': ['aan', 'dweil'],\n",
       " 'aaneenbinden': ['aaneen', 'B', 'bind'],\n",
       " 'aaneenbrengen': ['aaneen', 'B', 'breng'],\n",
       " 'aaneendriegen': ['aaneen', 'B', 'drieg'],\n",
       " 'aaneenflansen': ['aaneen', 'B', 'flans'],\n",
       " 'aaneengrenzen': ['aaneen', 'B', 'grens'],\n",
       " 'aaneengroeien': ['aaneen', 'B', 'groei'],\n",
       " 'aaneenhaken': ['aaneen', 'B', 'haak'],\n",
       " 'aaneenhangen': ['aaneen', 'B', 'hang'],\n",
       " 'aaneenhechten': ['aaneen', 'B', 'hecht'],\n",
       " 'aaneenhouden': ['aaneen', 'B', 'houd'],\n",
       " 'aaneenketenen': ['aaneen', 'B', 'keten'],\n",
       " 'aaneenkleven': ['aaneen', 'B', 'kleef'],\n",
       " 'aaneenklinken': ['aaneen', 'B', 'klink'],\n",
       " 'aaneenkluisteren': ['aaneen', 'B', 'kluister'],\n",
       " 'aaneenknopen': ['aaneen', 'B', 'knoop'],\n",
       " 'aaneenkoeken': ['aaneen', 'B', 'koek'],\n",
       " 'aaneenkoppelen': ['aaneen', 'B', 'koppel'],\n",
       " 'aaneenlijmen': ['aaneen', 'B', 'lijm'],\n",
       " 'aaneennaaien': ['aaneen', 'B', 'naai'],\n",
       " 'aaneenpassen': ['aaneen', 'B', 'pas'],\n",
       " 'aaneenplakken': ['aaneen', 'B', 'plak'],\n",
       " 'aaneenrijgen': ['aaneen', 'B', 'rijg'],\n",
       " 'aaneenschakelen': ['aaneen', 'B', 'schakel'],\n",
       " 'aaneenschrijven': ['aaneen', 'B', 'schrijf'],\n",
       " 'aaneensluiten': ['aaneen', 'B', 'sluit'],\n",
       " 'aaneensmeden': ['aaneen', 'B', 'smeed'],\n",
       " 'aaneenspijkeren': ['aaneen', 'B', 'spijker'],\n",
       " 'aaneenvoegen': ['aaneen', 'B', 'voeg'],\n",
       " 'aaneenzetten': ['aaneen', 'B', 'zet'],\n",
       " 'aaneenzitten': ['aaneen', 'B', 'zit'],\n",
       " 'aanerven': ['aan', 'erf'],\n",
       " 'aanfietsen': ['aan', 'fiets'],\n",
       " 'aanflitsen': ['aan', 'flits'],\n",
       " 'aanfloepen': ['aan', 'floep'],\n",
       " 'aanfluiten': ['aan', 'fluit'],\n",
       " 'aanfokken': ['aan', 'fok'],\n",
       " 'aanfokking': ['aan', 'fok', 'ing'],\n",
       " 'aanfruiten': ['aan', 'fruit'],\n",
       " 'aangaan': ['aan', 'ga'],\n",
       " 'aangapen': ['aan', 'gaap'],\n",
       " 'aangeven': ['aan', 'geef'],\n",
       " 'aangespen': ['aan', 'gesp'],\n",
       " 'aangever': ['aan', 'geef', 'er'],\n",
       " 'aangeving': ['aan', 'geef', 'ing'],\n",
       " 'aangieren': ['aan', 'gier'],\n",
       " 'aangieten': ['aan', 'giet'],\n",
       " 'aanglimmen': ['aan', 'glim'],\n",
       " 'aangloeien': ['aan', 'gloei'],\n",
       " 'aangluren': ['aan', 'gluur'],\n",
       " 'aangolven': ['aan', 'golf'],\n",
       " 'aangorden': ['aan', 'gord'],\n",
       " 'aangraven': ['aan', 'graaf'],\n",
       " 'aangrauwen': ['aan', 'grauw'],\n",
       " 'aangraving': ['aan', 'graaf', 'ing'],\n",
       " 'aangrijnzen': ['aan', 'grijns'],\n",
       " 'aangrijpen': ['aan', 'grijp'],\n",
       " 'aangrimmen': ['aan', 'grim'],\n",
       " 'aangrinniken': ['aan', 'grinnik'],\n",
       " 'aangroeien': ['aan', 'groei'],\n",
       " 'aangrommen': ['aan', 'grom'],\n",
       " 'aanhaken': ['aan', 'haak'],\n",
       " 'aanhalen': ['aan', 'haal'],\n",
       " 'aanhalerig': ['aan', 'haal', 'erig'],\n",
       " 'aanhalig': ['aan', 'haal', 'ig'],\n",
       " 'aanhaling': ['aan', 'haal', 'ing'],\n",
       " 'aanhangen': ['aan', 'hang'],\n",
       " 'aanhankelijk': ['aan', 'hang', 'elijk'],\n",
       " 'aanharden': ['aan', 'hard'],\n",
       " 'aanharken': ['aan', 'hark'],\n",
       " 'aanhebben': ['aan', 'heb'],\n",
       " 'aanhechten': ['aan', 'hecht'],\n",
       " 'aanheffen': ['aan', 'hef'],\n",
       " 'aanheffer': ['aan', 'hef', 'er'],\n",
       " 'aanheffing': ['aan', 'hef', 'ing'],\n",
       " 'aanhikken': ['aan', 'hik'],\n",
       " 'aanhinken': ['aan', 'hink'],\n",
       " 'aanhitsen': ['aan', 'hits'],\n",
       " 'aanhobbelen': ['aan', 'hobbel'],\n",
       " 'aanhollen': ['aan', 'hol'],\n",
       " 'aanhopen': ['aan', 'hoop'],\n",
       " 'aanhoren': ['aan', 'hoor'],\n",
       " 'aanhoping': ['aan', 'hoop', 'ing'],\n",
       " 'aanhouden': ['aan', 'houd'],\n",
       " 'aanhuppelen': ['aan', 'huppel'],\n",
       " 'aanhuwen': ['aan', 'huw'],\n",
       " 'aanjagen': ['aan', 'jaag'],\n",
       " 'aanjager': ['aan', 'jaag', 'er'],\n",
       " 'aankaarten': ['aan', 'kaart'],\n",
       " 'aankakken': ['aan', 'kak'],\n",
       " 'aankalken': ['aan', 'kalk'],\n",
       " 'aankunnen': ['aan', 'kan'],\n",
       " 'aankanten': ['aan', 'kant'],\n",
       " 'aankappen': ['aan', 'kap'],\n",
       " 'aankeffen': ['aan', 'kef'],\n",
       " 'aankerven': ['aan', 'kerf'],\n",
       " 'aankijken': ['aan', 'kijk'],\n",
       " 'aanklagen': ['aan', 'klaag'],\n",
       " 'aanklager': ['aan', 'klaag', 'er'],\n",
       " 'aanklampen': ['aan', 'klamp'],\n",
       " 'aankleding': ['aan', 'kleed', 'ing'],\n",
       " 'aankleden': ['aan', 'kleed'],\n",
       " 'aankleven': ['aan', 'kleef'],\n",
       " 'aanklemmen': ['aan', 'klem'],\n",
       " 'aankleving': ['aan', 'kleef', 'ing'],\n",
       " 'aanklinken': ['aan', 'klink'],\n",
       " 'aankloppen': ['aan', 'klop'],\n",
       " 'aanklossen': ['aan', 'klos'],\n",
       " 'aanklotsen': ['aan', 'klots'],\n",
       " 'aanknippen': ['aan', 'knip'],\n",
       " 'aanknoeien': ['aan', 'knoei'],\n",
       " 'aanknopen': ['aan', 'knoop'],\n",
       " 'aanknoping': ['aan', 'knoop', 'ing'],\n",
       " 'aankoeken': ['aan', 'koek'],\n",
       " 'aankomen': ['aan', 'kom'],\n",
       " 'aankondigen': ['aan', 'kond', 'ig'],\n",
       " 'aankooien': ['aan', 'kooi'],\n",
       " 'aankopen': ['aan', 'koop'],\n",
       " 'aankoppelen': ['aan', 'koppel'],\n",
       " 'aankorsten': ['aan', 'korst'],\n",
       " 'aankrammen': ['aan', 'kram'],\n",
       " 'aankrijgen': ['aan', 'krijg'],\n",
       " 'aankruien': ['aan', 'krui'],\n",
       " 'aankruisen': ['aan', 'kruis'],\n",
       " 'aankweken': ['aan', 'kweek'],\n",
       " 'aankweking': ['aan', 'kweek', 'ing'],\n",
       " 'aanladen': ['aan', 'laad'],\n",
       " 'aanlachen': ['aan', 'lach'],\n",
       " 'aanlanden': ['aan', 'land'],\n",
       " 'aanlangen': ['aan', 'lang'],\n",
       " 'aanlappen': ['aan', 'lap'],\n",
       " 'aanlassen': ['aan', 'las'],\n",
       " 'aanlassing': ['aan', 'las', 'ing'],\n",
       " 'aanleren': ['aan', 'leer'],\n",
       " 'aanleggen': ['aan', 'leg'],\n",
       " 'aanlegger': ['aan', 'leg', 'er'],\n",
       " 'aanlegging': ['aan', 'leg', 'ing'],\n",
       " 'aanlengen': ['aan', 'leng'],\n",
       " 'aanleunen': ['aan', 'leun'],\n",
       " 'aanlichten': ['aan', 'licht'],\n",
       " 'aanliggen': ['aan', 'lig'],\n",
       " 'aanlijken': ['aan', 'lijk'],\n",
       " 'aanlijmen': ['aan', 'lijm'],\n",
       " 'aanlijnen': ['aan', 'lijn'],\n",
       " 'aanloeien': ['aan', 'loei'],\n",
       " 'aanloeren': ['aan', 'loer'],\n",
       " 'aanloeven': ['aan', 'loef'],\n",
       " 'aanlokken': ['aan', 'lok'],\n",
       " 'aanlokkelijk': ['aan', 'lok', 'elijk'],\n",
       " 'aanlokking': ['aan', 'lok', 'ing'],\n",
       " 'aanlonken': ['aan', 'lonk'],\n",
       " 'aanloden': ['aan', 'lood'],\n",
       " 'aanlopen': ['aan', 'loop'],\n",
       " 'aanloopkosten': ['aan', 'loop', 'kost'],\n",
       " 'aanlooptransformator': ['aan', 'loop', 'transformeer', 'ator', 'NV'],\n",
       " 'aanmaken': ['aan', 'maak'],\n",
       " 'aanmaakblokje': ['aan', 'maak', 'blok'],\n",
       " 'aanmaakkosten': ['aan', 'maak', 'kost'],\n",
       " 'aanmanen': ['aan', 'maan'],\n",
       " 'aanmaning': ['aan', 'maan', 'ing'],\n",
       " 'aanmarcheren': ['aan', 'marcheer'],\n",
       " 'aanmatigen': ['aan', 'matig'],\n",
       " 'aanmeren': ['aan', 'meer'],\n",
       " 'aanmeten': ['aan', 'meet'],\n",
       " 'aanmelden': ['aan', 'meld'],\n",
       " 'aanmengen': ['aan', 'meng'],\n",
       " 'aanmerken': ['aan', 'merk'],\n",
       " 'aanminnig': ['aan', 'min', 'ig'],\n",
       " 'aanmodderen': ['aan', 'modder'],\n",
       " 'aanmoedigen': ['aan', 'moed', 'ig', 'PN'],\n",
       " 'aanmonsteren': ['aan', 'monster'],\n",
       " 'aanmunten': ['aan', 'munt'],\n",
       " 'aannaaien': ['aan', 'naai'],\n",
       " 'aannagelen': ['aan', 'nagel'],\n",
       " 'aannemen': ['aan', 'neem'],\n",
       " 'aannemelijk': ['aan', 'neem', 'elijk'],\n",
       " 'aannemeling': ['aan', 'neem', 'eling'],\n",
       " 'aannemer': ['aan', 'neem', 'er'],\n",
       " 'aanneming': ['aan', 'neem', 'ing'],\n",
       " 'aanpakken': ['aan', 'pak'],\n",
       " 'aanpappen': ['aan', 'pap'],\n",
       " 'aanpassen': ['aan', 'pas'],\n",
       " 'aanpassing': ['aan', 'pas', 'ing'],\n",
       " 'aanpassingsmoeilijkheden': ['aan',\n",
       "  'pas',\n",
       "  'ing',\n",
       "  's',\n",
       "  'moei',\n",
       "  'lijk',\n",
       "  'heid'],\n",
       " 'aanpezen': ['aan', 'pees'],\n",
       " 'aanpersen': ['aan', 'pers'],\n",
       " 'aanpikken': ['aan', 'pik'],\n",
       " 'aanplakken': ['aan', 'plak'],\n",
       " 'aanplakker': ['aan', 'plak', 'er'],\n",
       " 'aanplakking': ['aan', 'plak', 'ing'],\n",
       " 'aanplanten': ['aan', 'plant'],\n",
       " 'aanplempen': ['aan', 'plemp'],\n",
       " 'aanploegen': ['aan', 'ploeg'],\n",
       " 'aanpoten': ['aan', 'poot'],\n",
       " 'aanporren': ['aan', 'por'],\n",
       " 'aanpoting': ['aan', 'poot', 'ing'],\n",
       " 'aanpraten': ['aan', 'praat'],\n",
       " 'aanpreken': ['aan', 'preek'],\n",
       " 'aanprijzen': ['aan', 'prijs'],\n",
       " 'aanprijzer': ['aan', 'prijs', 'er'],\n",
       " 'aanprijzing': ['aan', 'prijs', 'ing'],\n",
       " 'aanprikken': ['aan', 'prik'],\n",
       " 'aanprikkelen': ['aan', 'prikkel'],\n",
       " 'aanpunten': ['aan', 'punt'],\n",
       " 'aanraden': ['aan', 'raad'],\n",
       " 'aanraken': ['aan', 'raak'],\n",
       " 'aanrazen': ['aan', 'raas'],\n",
       " 'aanrader': ['aan', 'raad', 'er'],\n",
       " 'aanraking': ['aan', 'raak', 'ing'],\n",
       " 'aanrechten': ['aan', 'recht'],\n",
       " 'aanrechtkastje': ['aanrecht', 'kast'],\n",
       " 'aanreiken': ['aan', 'reik'],\n",
       " 'aanrekenen': ['aan', 'reken'],\n",
       " 'aanrennen': ['aan', 'ren'],\n",
       " 'aanrichten': ['aan', 'richt'],\n",
       " 'aanrijden': ['aan', 'rijd'],\n",
       " 'aanrijgen': ['aan', 'rijg'],\n",
       " 'aanrijpen': ['aan', 'rijp'],\n",
       " 'aanrissen': ['aan', 'ris'],\n",
       " 'aanristen': ['aan', 'rist'],\n",
       " 'aanroeien': ['aan', 'roei'],\n",
       " 'aanroepen': ['aan', 'roep'],\n",
       " 'aanroeren': ['aan', 'roer'],\n",
       " 'aanroesten': ['aan', 'roest'],\n",
       " 'aanrollen': ['aan', 'rol'],\n",
       " 'aanrommelen': ['aan', 'rommel'],\n",
       " 'aanroken': ['aan', 'rook'],\n",
       " 'aanruisen': ['aan', 'ruis'],\n",
       " 'aanrukken': ['aan', 'ruk'],\n",
       " 'aanschaffen': ['aan', 'schaf'],\n",
       " 'aanschaffing': ['aan', 'schaf', 'ing'],\n",
       " 'aanschakelen': ['aan', 'schakel'],\n",
       " 'aanscharrelen': ['aan', 'scharrel'],\n",
       " 'aanschellen': ['aan', 'schel'],\n",
       " 'aanscherpen': ['aan', 'scherp'],\n",
       " 'aanschieten': ['aan', 'schiet'],\n",
       " 'aanschikken': ['aan', 'schik'],\n",
       " 'aanschoffelen': ['aan', 'schoffel'],\n",
       " 'aanschoppen': ['aan', 'schop'],\n",
       " 'aanschouwen': ['aan', 'schouw'],\n",
       " 'aanschrappen': ['aan', 'schrap'],\n",
       " 'aanschrijden': ['aan', 'schrijd'],\n",
       " 'aanschrijven': ['aan', 'schrijf'],\n",
       " 'aanschrijving': ['aan', 'schrijf', 'ing'],\n",
       " 'aanschroeven': ['aan', 'schroef'],\n",
       " 'aanschuinen': ['aan', 'schuin'],\n",
       " 'aanschuiven': ['aan', 'schuif'],\n",
       " 'aansjokken': ['aan', 'sjok'],\n",
       " 'aansjorren': ['aan', 'sjor'],\n",
       " 'aansjorring': ['aan', 'sjor', 'ing'],\n",
       " 'aansjouwen': ['aan', 'sjouw'],\n",
       " 'aanslaan': ['aan', 'sla'],\n",
       " 'aanslepen': ['aan', 'sleep'],\n",
       " 'aanslenteren': ['aan', 'slenter'],\n",
       " 'aansleuren': ['aan', 'sleur'],\n",
       " 'aanslibben': ['aan', 'slib'],\n",
       " 'aanslibbing': ['aan', 'slib', 'ing'],\n",
       " 'aanslijken': ['aan', 'slijk'],\n",
       " 'aanslijmen': ['aan', 'slijm'],\n",
       " 'aanslijpen': ['aan', 'slijp'],\n",
       " 'aansloffen': ['aan', 'slof'],\n",
       " 'aansluipen': ['aan', 'sluip'],\n",
       " 'aansluiten': ['aan', 'sluit'],\n",
       " 'aansluitingskosten': ['aan', 'sluit', 'ing', 's', 'kost'],\n",
       " 'aansmeden': ['aan', 'smeed'],\n",
       " 'aansmeren': ['aan', 'smeer'],\n",
       " 'aansmering': ['aan', 'smeer', 'ing'],\n",
       " 'aansmijten': ['aan', 'smijt'],\n",
       " 'aansnauwen': ['aan', 'snauw'],\n",
       " 'aansnellen': ['aan', 'snel'],\n",
       " 'aansnijden': ['aan', 'snijd'],\n",
       " 'aansnoeren': ['aan', 'snoer'],\n",
       " 'aansnorren': ['aan', 'snor'],\n",
       " 'aanspannen': ['aan', 'span'],\n",
       " 'aanspanner': ['aan', 'span', 'er'],\n",
       " 'aanspanning': ['aan', 'span', 'ing'],\n",
       " 'aanspelen': ['aan', 'speel'],\n",
       " 'aanspeten': ['aan', 'speet'],\n",
       " 'aanspelden': ['aan', 'speld'],\n",
       " 'aanspijkeren': ['aan', 'spijker'],\n",
       " 'aanspinnen': ['aan', 'spin'],\n",
       " 'aanspoeden': ['aan', 'spoed'],\n",
       " 'aanspoelen': ['aan', 'spoel'],\n",
       " 'aansporen': ['aan', 'spoor'],\n",
       " 'aansporing': ['aan', 'spoor', 'ing'],\n",
       " 'aansprakelijk': ['aan', 'spreek', 'elijk'],\n",
       " 'aanspreken': ['aan', 'spreek'],\n",
       " 'aanspreker': ['aan', 'spreek', 'er'],\n",
       " 'aanspreking': ['aan', 'spreek', 'ing'],\n",
       " 'aanspringen': ['aan', 'spring'],\n",
       " 'aanstaan': ['aan', 'sta'],\n",
       " 'aanstaren': ['aan', 'staar'],\n",
       " 'aanstampen': ['aan', 'stamp'],\n",
       " 'aanstappen': ['aan', 'stap'],\n",
       " 'aansteken': ['aan', 'steek'],\n",
       " 'aanstekelijk': ['aan', 'steek', 'elijk'],\n",
       " 'aansteker': ['aan', 'steek', 'er'],\n",
       " 'aansteking': ['aan', 'steek', 'ing'],\n",
       " 'aanstellen': ['aan', 'stel'],\n",
       " 'aansteller': ['aan', 'stel', 'er'],\n",
       " 'aanstellerig': ['aan', 'stel', 'erig'],\n",
       " 'aanstellerij': ['aan', 'stel', 'erij'],\n",
       " 'aanstelling': ['aan', 'stel', 'ing'],\n",
       " 'aansterken': ['aan', 'sterk'],\n",
       " 'aansterven': ['aan', 'sterf'],\n",
       " 'aanstevenen': ['aan', 'steven'],\n",
       " 'aanstichten': ['aan', 'sticht'],\n",
       " 'aanstiefelen': ['aan', 'stiefel'],\n",
       " 'aanstijven': ['aan', 'stijf'],\n",
       " 'aanstikken': ['aan', 'stik'],\n",
       " 'aanstippen': ['aan', 'stip'],\n",
       " 'aanstipping': ['aan', 'stip', 'ing'],\n",
       " 'aanstoker': ['aan', 'stook', 'er'],\n",
       " 'aanstoken': ['aan', 'stook'],\n",
       " 'aanstomen': ['aan', 'stoom'],\n",
       " 'aanstoten': ['aan', 'stoot'],\n",
       " 'aanstoppen': ['aan', 'stop'],\n",
       " 'aanstormen': ['aan', 'storm'],\n",
       " 'aanstorten': ['aan', 'stort'],\n",
       " 'aanstotelijk': ['aan', 'stoot', 'elijk'],\n",
       " 'aanstoting': ['aan', 'stoot', 'ing'],\n",
       " 'aanstouwen': ['aan', 'stouw'],\n",
       " 'aanstranden': ['aan', 'strand'],\n",
       " 'aanstrepen': ['aan', 'streep'],\n",
       " 'aanstreping': ['aan', 'streep', 'ing'],\n",
       " 'aanstrijken': ['aan', 'strijk'],\n",
       " 'aanstrikken': ['aan', 'strik'],\n",
       " 'aanstrompelen': ['aan', 'strompel'],\n",
       " 'aanstromen': ['aan', 'stroom'],\n",
       " 'aanstuiven': ['aan', 'stuif'],\n",
       " 'aanstuiving': ['aan', 'stuif', 'ing'],\n",
       " 'aansturen': ['aan', 'stuur'],\n",
       " 'aanstuwen': ['aan', 'stuw'],\n",
       " 'aansukkelen': ['aan', 'sukkel'],\n",
       " 'aantakelen': ['aan', 'takel'],\n",
       " 'aantappen': ['aan', 'tap'],\n",
       " 'aantasten': ['aan', 'tast'],\n",
       " 'aantelen': ['aan', 'teel'],\n",
       " 'aantekenen': ['aan', 'teken'],\n",
       " 'aanteling': ['aan', 'teel', 'ing'],\n",
       " 'aantikken': ['aan', 'tik'],\n",
       " 'aantimmeren': ['aan', 'timmer'],\n",
       " 'aantoning': ['aan', 'toon', 'ing'],\n",
       " 'aantonen': ['aan', 'toon'],\n",
       " 'aantrappen': ['aan', 'trap'],\n",
       " 'aantreden': ['aan', 'treed'],\n",
       " 'aantreeplaats': ['aan', 'treed', 'plaats'],\n",
       " 'aantreffen': ['aan', 'tref'],\n",
       " 'aantrekken': ['aan', 'trek'],\n",
       " 'aantrekkelijk': ['aan', 'trek', 'elijk'],\n",
       " 'aantrekker': ['aan', 'trek', 'er'],\n",
       " 'aantrekking': ['aan', 'trek', 'ing'],\n",
       " 'aantrippelen': ['aan', 'trippel'],\n",
       " 'aanturen': ['aan', 'tuur'],\n",
       " 'aanvaren': ['aan', 'vaar'],\n",
       " 'aanvallen': ['aan', 'val'],\n",
       " 'aanvallenderwijs': ['aan', 'val', 'enderwijs', 'B', 'B'],\n",
       " 'aanvallenderwijze': ['aan', 'val', 'enderwijze', 'B', 'B'],\n",
       " 'aanvaller': ['aan', 'val', 'er'],\n",
       " 'aanvallig': ['aan', 'val', 'ig'],\n",
       " 'aanvangen': ['aan', 'vang'],\n",
       " 'aanvankelijk': ['aan', 'vang', 'elijk'],\n",
       " 'aanvaring': ['aan', 'vaar', 'ing'],\n",
       " 'aanvatten': ['aan', 'vat'],\n",
       " 'aanvatting': ['aan', 'vat', 'ing'],\n",
       " 'aanvechten': ['aan', 'vecht'],\n",
       " 'aanvegen': ['aan', 'veeg'],\n",
       " 'aanvetten': ['aan', 'vet'],\n",
       " 'aanvijlen': ['aan', 'vijl'],\n",
       " 'aanvijzen': ['aan', 'vijs'],\n",
       " 'aanvlammen': ['aan', 'vlam'],\n",
       " 'aanvlechten': ['aan', 'vlecht'],\n",
       " 'aanvliegen': ['aan', 'vlieg'],\n",
       " 'aanvloeien': ['aan', 'vloei'],\n",
       " 'aanvlotten': ['aan', 'vlot'],\n",
       " 'aanvoegen': ['aan', 'voeg'],\n",
       " 'aanvoelen': ['aan', 'voel'],\n",
       " 'aanvoeren': ['aan', 'voer'],\n",
       " 'aanvragen': ['aan', 'vraag'],\n",
       " 'aanvrager': ['aan', 'vraag', 'er'],\n",
       " 'aanvreten': ['aan', 'vreet'],\n",
       " 'aanvullen': ['aan', 'vul'],\n",
       " 'aanvulling': ['aan', 'vul', 'ing'],\n",
       " 'aanvullingstroepen': ['aan', 'vul', 'ing', 's', 'troep'],\n",
       " 'aanvuring': ['aan', 'vuur', 'ing'],\n",
       " 'aanvuren': ['aan', 'vuur'],\n",
       " 'aanwaaien': ['aan', 'waai'],\n",
       " 'aanwaggelen': ['aan', 'waggel'],\n",
       " 'aanwakkeren': ['aan', 'wakker'],\n",
       " 'aanwandelen': ['aan', 'wandel'],\n",
       " 'aanwassen': ['aan', 'was'],\n",
       " 'aanwassing': ['aan', 'was', 'ing'],\n",
       " 'aanweven': ['aan', 'weef'],\n",
       " 'aanwennen': ['aan', 'wen'],\n",
       " 'aanwenden': ['aan', 'wend'],\n",
       " 'aanwenning': ['aan', 'wen', 'ing'],\n",
       " 'aanwentelen': ['aan', 'wentel'],\n",
       " 'aanwerpen': ['aan', 'werp'],\n",
       " 'aanwerven': ['aan', 'werf'],\n",
       " 'aanwerver': ['aan', 'werf', 'er'],\n",
       " 'aanwerving': ['aan', 'werf', 'ing'],\n",
       " 'aanwetten': ['aan', 'wet'],\n",
       " 'aanwijzen': ['aan', 'wijs'],\n",
       " 'aanwijzer': ['aan', 'wijs', 'er'],\n",
       " 'aanwijzing': ['aan', 'wijs', 'ing'],\n",
       " 'aanwinnen': ['aan', 'win'],\n",
       " 'aanwinning': ['aan', 'win', 'ing'],\n",
       " 'aanwippen': ['aan', 'wip'],\n",
       " 'aanwoekeren': ['aan', 'woeker'],\n",
       " 'aanwrijven': ['aan', 'wrijf'],\n",
       " 'aanwrijving': ['aan', 'wrijf', 'ing'],\n",
       " 'aanzaaien': ['aan', 'zaai'],\n",
       " 'aanzakken': ['aan', 'zak'],\n",
       " 'aanzanden': ['aan', 'zand'],\n",
       " 'aanzeggen': ['aan', 'zeg'],\n",
       " 'aanzegger': ['aan', 'zeg', 'er'],\n",
       " 'aanzegging': ['aan', 'zeg', 'ing'],\n",
       " 'aanzeilen': ['aan', 'zeil'],\n",
       " 'aanzetten': ['aan', 'zet'],\n",
       " 'aanzetter': ['aan', 'zet', 'er'],\n",
       " 'aanzetting': ['aan', 'zet', 'ing'],\n",
       " 'aanzeulen': ['aan', 'zeul'],\n",
       " 'aanzitten': ['aan', 'zit'],\n",
       " 'aanzoeken': ['aan', 'zoek'],\n",
       " 'aanzoeten': ['aan', 'zoet'],\n",
       " 'aanzuigen': ['aan', 'zuig'],\n",
       " 'aanzuiveren': ['aan', 'zuiver'],\n",
       " 'aanzwaaien': ['aan', 'zwaai'],\n",
       " 'aanzwepen': ['aan', 'zweep'],\n",
       " 'aanzweven': ['aan', 'zweef'],\n",
       " 'aanzwellen': ['aan', 'zwel'],\n",
       " 'aanzwemmen': ['aan', 'zwem'],\n",
       " 'aanzwengelen': ['aan', 'zwengel'],\n",
       " 'aanzwoegen': ['aan', 'zwoeg'],\n",
       " 'aapjessnuif': ['aap', 's', 'snuif'],\n",
       " 'aapjeszeep': ['aap', 's', 'zeep'],\n",
       " 'aren': ['aar'],\n",
       " 'aarden': ['aarde', 'en'],\n",
       " 'aardamandel': ['aarde', 'amandel'],\n",
       " 'aardappel': ['aarde', 'appel'],\n",
       " 'aardappelhakker': ['aarde', 'appel', 'hak', 'er', 'NV'],\n",
       " 'aardappelmesje': ['aarde', 'appel', 'mes'],\n",
       " 'aardappelpoter': ['aarde', 'appel', 'poot', 'er', 'NV'],\n",
       " 'aardappelrooien': ['aarde', 'appel', 'rooi'],\n",
       " 'aardappelschiller': ['aarde', 'appel', 'schil', 'er', 'NV'],\n",
       " 'aardappelschilmesje': ['aarde', 'appel', 'schilmes'],\n",
       " 'aardappelvlokken': ['aarde', 'appel', 'vlok'],\n",
       " 'aardas': ['aarde', 'as'],\n",
       " 'aardatmosfeer': ['aarde', 'atmosfeer'],\n",
       " 'aardbaan': ['aarde', 'baan'],\n",
       " 'aardberging': ['aarde', 'berg', 'ing', 'NV'],\n",
       " 'aardbeving': ['aarde', 'beef', 'ing'],\n",
       " 'aardbevingsmeter': ['aarde', 'beef', 'ing', 's', 'Vx', 'meet', 'er', 'NxV'],\n",
       " 'aardbewoner': ['aarde', 'be', 'woon', 'er', 'NV'],\n",
       " 'aardbewoonster': ['aarde', 'be', 'woon', 'ster', 'NV'],\n",
       " 'aardbij': ['aarde', 'bij'],\n",
       " 'aardbodem': ['aarde', 'bodem'],\n",
       " 'aardbol': ['aarde', 'bol'],\n",
       " 'aardboog': ['aarde', 'boog'],\n",
       " 'aardboor': ['aarde', 'boor'],\n",
       " 'aardbrand': ['aarde', 'brand'],\n",
       " 'aardbuil': ['aarde', 'buil'],\n",
       " 'aardduivel': ['aarde', 'duivel'],\n",
       " 'aardgas': ['aarde', 'gas'],\n",
       " 'aardgasbaten': ['aarde', 'gas', 'baat'],\n",
       " 'aardgeest': ['aarde', 'geest'],\n",
       " 'aardgewas': ['aarde', 'ge', 'was'],\n",
       " 'aardglobe': ['aarde', 'globe'],\n",
       " 'aardgoed': ['aarde', 'goed'],\n",
       " 'aardgordel': ['aarde', 'gordel'],\n",
       " 'aardhars': ['aarde', 'hars'],\n",
       " 'aardhommel': ['aarde', 'hommel'],\n",
       " 'aardhoop': ['aarde', 'hoop'],\n",
       " 'aardkastanje': ['aarde', 'kastanje'],\n",
       " 'aardkern': ['aarde', 'kern'],\n",
       " 'aardklomp': ['aarde', 'klomp'],\n",
       " 'aardklont': ['aarde', 'klont'],\n",
       " 'aardkloot': ['aarde', 'kloot'],\n",
       " 'aardkluit': ['aarde', 'kluit'],\n",
       " 'aardkorst': ['aarde', 'korst'],\n",
       " 'aardkrekel': ['aarde', 'krekel'],\n",
       " 'aardkromming': ['aarde', 'krom', 'ing'],\n",
       " 'aardkuil': ['aarde', 'kuil'],\n",
       " 'aardkunde': ['aarde', 'kunde'],\n",
       " 'aardkundig': ['aarde', 'kunde', 'ig'],\n",
       " 'aardlaag': ['aarde', 'laag'],\n",
       " 'aardleiding': ['aarde', 'leid', 'ing'],\n",
       " 'aardlevering': ['aarde', 'lever', 'ing'],\n",
       " 'aardmagnetisme': ['aarde', 'magnetisme'],\n",
       " 'aardmannetje': ['aarde', 'man'],\n",
       " 'aardmassa': ['aarde', 'massa'],\n",
       " 'aardmeetkunde': ['aarde', 'meet', 'kunde'],\n",
       " 'aardmetalen': ['aarde', 'metaal'],\n",
       " 'aardmeting': ['aarde', 'meet', 'ing', 'NV'],\n",
       " 'aardmijt': ['aarde', 'mijt'],\n",
       " 'aardmolm': ['aarde', 'molm'],\n",
       " 'aardmuis': ['aarde', 'muis'],\n",
       " 'aardnoot': ['aarde', 'noot'],\n",
       " 'aardnotenolie': ['aarde', 'noot', 'en', 'olie'],\n",
       " 'aardolie': ['aarde', 'olie'],\n",
       " 'aardoppervlak': ['aarde', 'opper', 'vlak'],\n",
       " 'aardoppervlakte': ['aarde', 'opper', 'vlak', 'te'],\n",
       " 'aardpeer': ['aarde', 'peer'],\n",
       " 'aardpek': ['aarde', 'pek'],\n",
       " 'aardplooi': ['aarde', 'plooi'],\n",
       " 'aardpool': ['aarde', 'pool'],\n",
       " 'aardprofiel': ['aarde', 'profiel'],\n",
       " 'aardrijk': ['aarde', 'rijk'],\n",
       " 'aardrijkskundig': ['aarde', 'rijk', 's', 'kunde', 'ig'],\n",
       " 'aardrol': ['aarde', 'rol'],\n",
       " 'aardrook': ['aarde', 'rook'],\n",
       " 'aardrups': ['aarde', 'rups'],\n",
       " 'aards': ['aarde', 's'],\n",
       " 'aardschaduw': ['aarde', 'schaduw'],\n",
       " 'aardschijn': ['aarde', 'schijn'],\n",
       " 'aardschok': ['aarde', 'schok'],\n",
       " 'aardschors': ['aarde', 'schors'],\n",
       " 'aardschudding': ['aarde', 'schud', 'ing'],\n",
       " 'aardsgezind': ['aarde', 's', 'gezind'],\n",
       " 'aardslak': ['aarde', 'slak'],\n",
       " 'aardslang': ['aarde', 'slang'],\n",
       " 'aardsluiting': ['aarde', 'sluit', 'ing'],\n",
       " 'aardspin': ['aarde', 'spin'],\n",
       " 'aardster': ['aarde', 'ster'],\n",
       " 'aardstorting': ['aarde', 'stort', 'ing'],\n",
       " 'aardstraal': ['aarde', 'straal'],\n",
       " 'aardstralenkastje': ['aarde', 'straal', 'en', 'kast'],\n",
       " 'aardstraling': ['aarde', 'straal', 'ing'],\n",
       " 'aardstroom': ['aarde', 'stroom'],\n",
       " 'aardtor': ['aarde', 'tor'],\n",
       " 'aardtrilling': ['aarde', 'tril', 'ing'],\n",
       " 'aardvarken': ['aarde', 'varken'],\n",
       " 'aardvast': ['aarde', 'vast'],\n",
       " 'aardveil': ['aarde', 'veil'],\n",
       " 'aardverbinding': ['aarde', 'ver', 'bind', 'ing'],\n",
       " 'aardverschuiving': ['aarde', 'ver', 'schuif', 'ing'],\n",
       " 'aardverf': ['aarde', 'verf'],\n",
       " 'aardvlo': ['aarde', 'vlo'],\n",
       " 'aardvork': ['aarde', 'vork'],\n",
       " 'aardvrucht': ['aarde', 'vrucht'],\n",
       " 'aardwarmte': ['aarde', 'warm', 'te'],\n",
       " 'aardwas': ['aarde', 'was'],\n",
       " 'aardwerk': ['aarde', 'werk'],\n",
       " 'aardwetenschappen': ['aarde', 'weten', 'schap'],\n",
       " 'aardwinde': ['aarde', 'winde'],\n",
       " 'aardwolf': ['aarde', 'wolf'],\n",
       " 'aardworm': ['aarde', 'worm'],\n",
       " 'aartsbisschoppelijk': ['aarts', 'bisschop', 'elijk'],\n",
       " 'aarzelen': ['aarzel'],\n",
       " 'aaseter': ['aas', 'eet', 'er', 'NV'],\n",
       " 'aasjager': ['aas', 'jaag', 'er', 'NV'],\n",
       " 'aatje': ['aat'],\n",
       " 'aasje': ['aas'],\n",
       " 'azen': ['aas'],\n",
       " 'abandonneren': ['abandon', 'eer'],\n",
       " 'abandonnement': ['abandon', 'eer', 'ement'],\n",
       " 'abbatiaal': ['abt', 'aal'],\n",
       " 'abbreviatie': ['abbrevieer', 'atie'],\n",
       " 'abbreviatuur': ['abbrevieer', 'atuur'],\n",
       " 'abc-boek': ['abc', 'boek'],\n",
       " 'ABC-wapens': ['abc', 'wapen'],\n",
       " 'abdicatie': ['abdiceer', 'atie'],\n",
       " 'abdominaal': ['abdomen', 'aal'],\n",
       " 'abelenlaan': ['abeel', 'en', 'laan'],\n",
       " 'A-biljet': ['a', 'biljet'],\n",
       " 'abnormaliteit': ['abnormaal', 'iteit'],\n",
       " 'abolitie': ['aboleer', 'itie'],\n",
       " 'A-bom': ['a', 'bom'],\n",
       " 'abondance': ['abondant', 'nce'],\n",
       " 'abonnement': ['abonneer', 'ement'],\n",
       " 'aborteren': ['abortus', 'eer'],\n",
       " 'aborteur': ['abortus', 'eer', 'eur'],\n",
       " 'abortief': ['abortus', 'ief'],\n",
       " 'abricoteren': ['abrikoos', 'eer'],\n",
       " 'abrikozeboom': ['abrikoos', 'e', 'boom'],\n",
       " 'abrikozengelei': ['abrikoos', 'en', 'gelei'],\n",
       " 'abrikozentaart': ['abrikoos', 'en', 'taart'],\n",
       " 'abrikozepit': ['abrikoos', 'e', 'pit'],\n",
       " 'abrikozeschil': ['abrikoos', 'e', 'schil'],\n",
       " 'absence': ['absent', 'nce'],\n",
       " 'absenteren': ['absent', 'eer'],\n",
       " 'absolutie': ['absolveer', 'utie'],\n",
       " 'absorbaat': ['absorbeer', 'aat'],\n",
       " 'abstinent': ['abstineer', 'ent'],\n",
       " 'abstraheren': ['abstract', 'eer'],\n",
       " 'abstrahering': ['abstract', 'eer', 'ing'],\n",
       " 'abuseren': ['abuis', 'eer'],\n",
       " 'abusief': ['abuis', 'ief'],\n",
       " 'academie': ['academisch', 'ie'],\n",
       " 'acceleratie': ['accelereer', 'atie'],\n",
       " 'accelerator': ['accelereer', 'ator'],\n",
       " 'accentuatie': ['accent', 'ueer', 'atie'],\n",
       " 'accentueren': ['accent', 'ueer'],\n",
       " 'accentuering': ['accent', 'ueer', 'ing'],\n",
       " 'accentverlegging': ['accent', 'ver', 'leg', 'ing', 'NV'],\n",
       " 'acceptabel': ['accept', 'eer', 'abel'],\n",
       " 'acceptant': ['accept', 'eer', 'ant'],\n",
       " 'acceptatie': ['accept', 'eer', 'atie'],\n",
       " 'accepteren': ['accept', 'eer'],\n",
       " 'accessie': ['acces', 'ie'],\n",
       " 'accijnsrechten': ['accijns', 'recht'],\n",
       " 'acclimatisatie': ['acclimatiseer', 'atie'],\n",
       " 'acclimatisering': ['acclimatiseer', 'ing'],\n",
       " 'accommodatie': ['accommodeer', 'atie'],\n",
       " 'accompagnateur': ['accompagneer', 'ateur'],\n",
       " 'accompagnement': ['accompagneer', 'ement'],\n",
       " 'accoucheur': ['accoucheer', 'eur'],\n",
       " 'accountants-administratieconsulent': ['accountant',\n",
       "  's',\n",
       "  'NN',\n",
       "  'administreer',\n",
       "  'atie',\n",
       "  'consulent'],\n",
       " 'accumulatie': ['accumuleer', 'atie'],\n",
       " 'accumulatief': ['accumuleer', 'atie', 'ief'],\n",
       " 'accumulator': ['accumuleer', 'ator'],\n",
       " 'accuratesse': ['accuraat', 'esse'],\n",
       " 'accusatie': ['accuseer', 'atie'],\n",
       " 'accuseren': ['accuseer'],\n",
       " 'achilleshiel': ['Achilles', 'hiel'],\n",
       " 'achillespees': ['Achilles', 'pees'],\n",
       " 'a-christelijk': ['a', 'christen', 'elijk'],\n",
       " 'achten': ['acht'],\n",
       " 'achtdaags': ['acht', 'Q', 'dag', 's', 'QN'],\n",
       " 'achtenswaard': ['acht', 's', 'waard'],\n",
       " 'achtenswaardig': ['acht', 's', 'waarde', 'ig'],\n",
       " 'achteraanblijven': ['achter', 'B', 'aan', 'B', 'blijf'],\n",
       " 'achteraangaan': ['achter', 'B', 'aan', 'B', 'ga'],\n",
       " 'achteraankomen': ['achter', 'B', 'aan', 'B', 'kom'],\n",
       " 'achteraanlopen': ['achter', 'B', 'aan', 'B', 'loop'],\n",
       " 'achteraanrennen': ['achter', 'B', 'aan', 'B', 'ren'],\n",
       " 'achteraanzitten': ['achter', 'B', 'aan', 'B', 'zit'],\n",
       " 'achterblijven': ['achter', 'B', 'blijf'],\n",
       " 'achterblijver': ['achter', 'B', 'blijf', 'er'],\n",
       " 'achtergaan': ['achter', 'B', 'ga'],\n",
       " 'achtergrondinformatie': ['achter', 'B', 'grond', 'informeer', 'atie', 'NV'],\n",
       " 'achterhalen': ['achter', 'B', 'haal'],\n",
       " 'achterhaling': ['achter', 'B', 'haal', 'ing'],\n",
       " 'achterhandsbeentje': ['achter', 'B', 'hand', 's', 'been'],\n",
       " 'achterhouden': ['achter', 'B', 'houd'],\n",
       " 'achterklappen': ['achter', 'B', 'klap'],\n",
       " 'achterlaten': ['achter', 'B', 'laat'],\n",
       " 'achterlating': ['achter', 'B', 'laat', 'ing'],\n",
       " 'achterliggen': ['achter', 'B', 'lig'],\n",
       " 'achterligger': ['achter', 'B', 'lig', 'er'],\n",
       " 'achterlopen': ['achter', 'B', 'loop'],\n",
       " 'achterloper': ['achter', 'B', 'loop', 'er'],\n",
       " 'achternadoen': ['achterna', 'B', 'doe'],\n",
       " 'achternagaan': ['achterna', 'B', 'ga'],\n",
       " 'achternageven': ['achterna', 'B', 'geef'],\n",
       " 'achternalopen': ['achterna', 'B', 'loop'],\n",
       " 'achternarijden': ['achterna', 'B', 'rijd'],\n",
       " 'achternasturen': ['achterna', 'B', 'stuur'],\n",
       " 'achternazenden': ['achterna', 'B', 'zend'],\n",
       " 'achternazetten': ['achterna', 'B', 'zet'],\n",
       " 'achternazitten': ['achterna', 'B', 'zit'],\n",
       " 'achteromkijken': ['achter', 'om', 'B', 'kijk'],\n",
       " 'achteromlopen': ['achter', 'om', 'B', 'loop'],\n",
       " 'achteromzien': ['achter', 'om', 'B', 'zie'],\n",
       " 'achteropkomen': ['achter', 'op', 'B', 'kom'],\n",
       " 'achteroplopen': ['achter', 'op', 'B', 'loop'],\n",
       " 'achteropraken': ['achter', 'op', 'B', 'raak'],\n",
       " 'achteroverdrukken': ['achter', 'over', 'B', 'druk'],\n",
       " 'achteroverliggen': ['achter', 'over', 'B', 'lig'],\n",
       " 'achteroverslaan': ['achter', 'over', 'B', 'sla'],\n",
       " 'achterovervallen': ['achter', 'B', 'over', 'val'],\n",
       " 'achterstaan': ['achter', 'B', 'sta'],\n",
       " 'achterstallig': ['achter', 'B', 'stal', 'ig'],\n",
       " 'achterstellen': ['achter', 'B', 'stel'],\n",
       " 'achterstelling': ['achter', 'B', 'stel', 'ing'],\n",
       " 'achteruitboeren': ['achter', 'B', 'uit', 'B', 'B', 'boer'],\n",
       " 'achteruitdeinzen': ['achter', 'B', 'uit', 'B', 'B', 'deins'],\n",
       " 'achteruitgaan': ['achter', 'B', 'uit', 'B', 'B', 'ga'],\n",
       " 'achteruitkrabbelen': ['achter', 'B', 'uit', 'B', 'B', 'krabbel'],\n",
       " 'achteruitleren': ['achter', 'B', 'uit', 'B', 'B', 'leer'],\n",
       " 'achteruitlopen': ['achter', 'B', 'uit', 'loop'],\n",
       " 'achteruitmarcheren': ['achter', 'B', 'uit', 'B', 'B', 'marcheer'],\n",
       " 'achteruitraken': ['achter', 'B', 'uit', 'B', 'B', 'raak'],\n",
       " 'achteruitrijden': ['achter', 'B', 'uit', 'B', 'B', 'rijd'],\n",
       " 'achteruitrijlamp': ['achter', 'B', 'uit', 'B', 'B', 'rijd', 'lamp'],\n",
       " 'achteruitschoppen': ['achter', 'B', 'uit', 'B', 'B', 'schop'],\n",
       " 'achteruitschuiven': ['achter', 'B', 'uit', 'B', 'B', 'schuif'],\n",
       " 'achteruitslaan': ['achter', 'B', 'uit', 'B', 'B', 'sla'],\n",
       " 'achteruitsteken': ['achter', 'B', 'uit', 'B', 'B', 'steek'],\n",
       " 'achteruitvallen': ['achter', 'B', 'uit', 'B', 'B', 'val'],\n",
       " 'achteruitvliegen': ['achter', 'B', 'uit', 'B', 'B', 'vlieg'],\n",
       " 'achteruitwerken': ['achter', 'B', 'uit', 'B', 'B', 'werk'],\n",
       " 'achteruitwijken': ['achter', 'B', 'uit', 'B', 'B', 'wijk'],\n",
       " 'achteruitzetten': ['achter', 'B', 'uit', 'B', 'B', 'zet'],\n",
       " 'achtervoegen': ['achter', 'B', 'voeg'],\n",
       " 'achtervolgen': ['achter', 'B', 'volg'],\n",
       " 'achterwaren': ['achter', 'B', 'waar'],\n",
       " 'achterwielaandrijving': ['achter', 'B', 'wiel', 'aan', 'drijf', 'ing', 'NV'],\n",
       " 'achterzeilen': ['achter', 'B', 'zeil'],\n",
       " 'achtjarig': ['acht', 'Q', 'jaar', 'ig', 'QN'],\n",
       " 'achtpotig': ['acht', 'Q', 'poot', 'ig', 'QN'],\n",
       " 'achttiende-eeuws': ['acht',\n",
       "  'Q',\n",
       "  'tien',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'de',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'eeuw',\n",
       "  's',\n",
       "  'QN'],\n",
       " 'achttienjarig': ['acht', 'Q', 'tien', 'Q', 'Q', 'jaar', 'ig', 'QN'],\n",
       " 'achttienurig': ['acht', 'Q', 'tien', 'Q', 'Q', 'uur', 'ig', 'QN'],\n",
       " 'achturemis': ['acht', 'Q', 'uur', 'e', 'QN', 'mis'],\n",
       " 'achturendag': ['acht', 'Q', 'uur', 'en', 'QN', 'dag'],\n",
       " 'achturig': ['acht', 'Q', 'uur', 'ig', 'QN'],\n",
       " 'achtvlakkig': ['acht', 'Q', 'vlak', 'ig', 'QN'],\n",
       " 'achtzijdig': ['acht', 'Q', 'zijde', 'ig', 'QN'],\n",
       " 'acidimetrie': ['acidimeter', 'ie'],\n",
       " 'aconceptief': ['a', 'Nx', 'concept', 'ie', 'ief', 'xN'],\n",
       " 'acquisitief': ['acquisitie', 'ief'],\n",
       " 'acquitteren': ['acquit', 'eer'],\n",
       " 'acrobate': ['acrobaat', 'e'],\n",
       " 'acrobatentoer': ['acrobaat', 'en', 'toer'],\n",
       " 'acrobatie': ['acrobaat', 'isch', 'ie'],\n",
       " 'acrobatiek': ['acrobaat', 'isch', 'iek'],\n",
       " 'acrobatisch': ['acrobaat', 'isch'],\n",
       " 'acteur': ['acteer', 'eur'],\n",
       " 'actieveling': ['actie', 'ief', 'eling'],\n",
       " 'actinisch': ['actine', 'isch'],\n",
       " 'activeren': ['actief', 'eer'],\n",
       " 'activering': ['actief', 'eer', 'ing'],\n",
       " 'activiteit': ['actie', 'ief', 'iteit'],\n",
       " 'actualiseren': ['actueel', 'eer'],\n",
       " 'actualisering': ['actueel', 'eer', 'ing'],\n",
       " 'actualiteit': ['actueel', 'iteit'],\n",
       " 'actuariaat': ['actuaris', 'aat'],\n",
       " 'actuarieel': ['actuaris', 'eel'],\n",
       " 'acupuncturist': ['acupunctuur', 'ist'],\n",
       " 'adamsappel': ['Adam', 's', 'appel'],\n",
       " 'adamskostuum': ['Adam', 's', 'kostuum'],\n",
       " 'adaptatie': ['adapteer', 'atie'],\n",
       " 'adaptief': ['adapteer', 'atie', 'ief'],\n",
       " 'additie': ['addeer', 'itie'],\n",
       " 'additief': ['addeer', 'itie', 'ief'],\n",
       " 'additioneel': ['addeer', 'itie', 'ioneel'],\n",
       " 'adelen': ['adel'],\n",
       " 'ademen': ['adem'],\n",
       " 'adembeklemmend': ['adem', 'be', 'klem', 'end', 'NV'],\n",
       " 'adembenemend': ['adem', 'be', 'neem', 'end', 'NV'],\n",
       " 'ademhalen': ['adem', 'haal'],\n",
       " 'ademhaling': ['adem', 'haal', 'ing'],\n",
       " 'ademhalingswerktuigen': ['adem', 'haal', 'ing', 's', 'werk', 'tuig'],\n",
       " 'aderen': ['ader'],\n",
       " 'aderiseren': ['ader', 'iseer'],\n",
       " 'aderlaten': ['ader', 'laat'],\n",
       " 'aderlating': ['ader', 'laat', 'ing'],\n",
       " 'aderontsteking': ['ader', 'ontsteek', 'ing', 'NV'],\n",
       " 'adjectivisch': ['adjectief', 'isch'],\n",
       " 'adjudant-onderofficier': ['adjudant', 'onder', 'officier'],\n",
       " 'adjunct-administrateur': ['adjunct', 'administreer', 'ateur'],\n",
       " 'adjunct-commies': ['adjunct', 'commies'],\n",
       " 'adjunct-commissaris': ['adjunct', 'commissaris'],\n",
       " 'adjunct-directeur': ['adjunct', 'directeur'],\n",
       " 'adjunct-hoofdredacteur': ['adjunct', 'hoofd', 'redacteur'],\n",
       " 'adjunct-secretaris': ['adjunct', 'secretaris'],\n",
       " 'administrateur': ['administreer', 'ateur'],\n",
       " 'administratie': ['administreer', 'atie'],\n",
       " 'administratiekosten': ['administreer', 'atie', 'kost'],\n",
       " 'administratief': ['administreer', 'atie', 'ief'],\n",
       " 'admiraal-generaal': ['admiraal', 'generaal'],\n",
       " 'admiraalzeilen': ['admiraal', 'zeil'],\n",
       " 'admissie-examen': ['admissie', 'examen'],\n",
       " 'adnominaal': ['ad', 'Nx', 'nomen', 'aal', 'xN'],\n",
       " 'adoniseren': ['adonis', 'eer'],\n",
       " 'adoptant': ['adopteer', 'ant'],\n",
       " 'adoptiefouders': ['adoptie', 'ief', 'ouder'],\n",
       " 'adoptief': ['adoptie', 'ief'],\n",
       " 'adorabel': ['adoreer', 'abel'],\n",
       " 'adoratie': ['adoreer', 'atie'],\n",
       " 'adrenaline-injectie': ['adrenaline', 'injectie'],\n",
       " 'adressant': ['adres', 'eer', 'ant'],\n",
       " 'adresschrijver': ['adres', 'schrijf', 'er', 'NV'],\n",
       " 'adresseren': ['adres', 'eer'],\n",
       " 'adressenbank': ['adres', 'en', 'bank'],\n",
       " 'adressenlijst': ['adres', 'en', 'lijst'],\n",
       " 'adressenschrijver': ['adres', 'en', 'Vx', 'schrijf', 'er', 'NxV'],\n",
       " 'adressering': ['adres', 'eer', 'ing'],\n",
       " 'adverbiaal': ['adverbium', 'aal'],\n",
       " 'advertentie': ['adverteer', 'entie'],\n",
       " 'advertentie-exploitatie': ['adverteer', 'entie', 'exploiteer', 'atie'],\n",
       " 'advertentie-inkomst': ['adverteer', 'entie', 'in', 'kom', 'st'],\n",
       " 'advertentiekosten': ['adverteer', 'entie', 'kost'],\n",
       " 'adviseren': ['advies', 'eer'],\n",
       " 'adviseur': ['advies', 'eer', 'eur'],\n",
       " 'advocaatje': ['advocaat'],\n",
       " 'advocaat-fiscaal': ['advocaat', 'fiscaal'],\n",
       " 'advocaat-generaal': ['advocaat', 'generaal'],\n",
       " 'advocate': ['advocaat', 'e'],\n",
       " 'advocatenbureau': ['advocaat', 'en', 'bureau'],\n",
       " 'advocatencollectief': ['advocaat', 'en', 'collectief'],\n",
       " 'advocatenfirma': ['advocaat', 'en', 'firma'],\n",
       " 'advocatenkamer': ['advocaat', 'en', 'kamer'],\n",
       " 'advocatenkantoor': ['advocaat', 'en', 'kantoor'],\n",
       " 'advocatenpraktijk': ['advocaat', 'en', 'praktijk'],\n",
       " 'advocatenstreek': ['advocaat', 'en', 'streek'],\n",
       " 'advocaterij': ['advocaat', 'erij'],\n",
       " 'advocatie': ['advocaat', 'ie'],\n",
       " 'advocatuur': ['advocaat', 'uur'],\n",
       " 'aeratie': ['aereer', 'atie'],\n",
       " 'aeronautiek': ['aero', 'nautisch', 'iek'],\n",
       " 'afbaarden': ['af', 'baard'],\n",
       " 'afbakken': ['af', 'bak'],\n",
       " 'afbakenen': ['af', 'baken'],\n",
       " 'afbarsten': ['af', 'barst'],\n",
       " 'afbedelen': ['af', 'bedel'],\n",
       " 'afbeelden': ['af', 'beeld'],\n",
       " 'afbenen': ['af', 'been'],\n",
       " 'afbeitelen': ['af', 'beitel'],\n",
       " 'afbekken': ['af', 'bek'],\n",
       " 'afbellen': ['af', 'bel'],\n",
       " 'afbestellen': ['af', 'bestel'],\n",
       " 'afbestelling': ['af', 'bestel', 'ing'],\n",
       " 'afbetten': ['af', 'bet'],\n",
       " 'afbetalen': ['af', 'betaal'],\n",
       " 'afbetaling': ['af', 'betaal', 'ing'],\n",
       " 'afbeulen': ['af', 'beul'],\n",
       " 'afbidden': ['af', 'bid'],\n",
       " 'afbidding': ['af', 'bid', 'ing'],\n",
       " 'afbieden': ['af', 'bied'],\n",
       " 'afbietsen': ['af', 'biets'],\n",
       " 'afbiezen': ['af', 'bies'],\n",
       " 'afbijten': ['af', 'bijt'],\n",
       " 'afbikken': ['af', 'bik'],\n",
       " 'afbiljoenen': ['af', 'biljoen'],\n",
       " 'afbinden': ['af', 'bind'],\n",
       " 'afbladen': ['af', 'blad'],\n",
       " 'afblaren': ['af', 'blaar'],\n",
       " 'afblazen': ['af', 'blaas'],\n",
       " 'afbladderen': ['af', 'bladder'],\n",
       " 'afbladeren': ['af', 'blader'],\n",
       " 'afblaffen': ['af', 'blaf'],\n",
       " 'afblijven': ['af', 'blijf'],\n",
       " 'afbliksemen': ['af', 'bliksem'],\n",
       " 'afblokken': ['af', 'blok'],\n",
       " 'afbluffen': ['af', 'bluf'],\n",
       " 'afblussen': ['af', 'blus'],\n",
       " 'afboeken': ['af', 'boek'],\n",
       " 'afboenen': ['af', 'boen'],\n",
       " 'afboeten': ['af', 'boet'],\n",
       " 'afbollen': ['af', 'bol'],\n",
       " 'afbonken': ['af', 'bonk'],\n",
       " 'afbonzen': ['af', 'bons'],\n",
       " 'afbomen': ['af', 'boom'],\n",
       " 'afborstelen': ['af', 'borstel'],\n",
       " 'afbottelen': ['af', 'bottel'],\n",
       " 'afbouwen': ['af', 'bouw'],\n",
       " 'afbramen': ['af', 'braam'],\n",
       " 'afbranden': ['af', 'brand'],\n",
       " 'afbrassen': ['af', 'bras'],\n",
       " 'afbreken': ['af', 'breek'],\n",
       " 'afbreien': ['af', 'brei'],\n",
       " 'afbreker': ['af', 'breek', 'er'],\n",
       " 'afbreking': ['af', 'breek', 'ing'],\n",
       " 'afbrengen': ['af', 'breng'],\n",
       " 'afbrijnen': ['af', 'brijn'],\n",
       " 'afbroddelen': ['af', 'broddel'],\n",
       " 'afbrokkelen': ['af', 'brokkel'],\n",
       " 'afbuigen': ['af', 'buig'],\n",
       " 'afbuitelen': ['af', 'buitel'],\n",
       " 'afchecken': ['af', 'check'],\n",
       " 'afcommanderen': ['af', 'commandeer'],\n",
       " 'afconcluderen': ['af', 'concludeer'],\n",
       " 'afdalen': ['af', 'daal'],\n",
       " 'afdaling': ['af', 'daal', 'ing'],\n",
       " 'afdammen': ['af', 'dam'],\n",
       " 'afdamming': ['af', 'dam', 'ing'],\n",
       " 'afdanken': ['af', 'dank'],\n",
       " 'afdankertje': ['af', 'dank', 'er'],\n",
       " 'afdansen': ['af', 'dans'],\n",
       " 'afdelen': ['af', 'deel'],\n",
       " 'afdeinzen': ['af', 'deins'],\n",
       " 'afdekken': ['af', 'dek'],\n",
       " 'afdekking': ['af', 'dek', 'ing'],\n",
       " 'afdeling': ['af', 'deel', 'ing'],\n",
       " 'afdelven': ['af', 'delf'],\n",
       " 'afdichten': ['af', 'dicht'],\n",
       " 'afdienen': ['af', 'dien'],\n",
       " 'afdieven': ['af', 'dief'],\n",
       " 'afdijken': ['af', 'dijk'],\n",
       " 'afdingen': ['af', 'ding'],\n",
       " 'afdoen': ['af', 'doe'],\n",
       " 'afdoener': ['af', 'doe', 'er'],\n",
       " 'afdokken': ['af', 'dok'],\n",
       " 'afdonderen': ['af', 'donder'],\n",
       " 'afdolen': ['af', 'dool'],\n",
       " 'afdoppen': ['af', 'dop'],\n",
       " 'afdorsen': ['af', 'dors'],\n",
       " 'afdouwen': ['af', 'douw'],\n",
       " 'afdragen': ['af', 'draag'],\n",
       " 'afdraaien': ['af', 'draai'],\n",
       " 'afdraven': ['af', 'draaf'],\n",
       " 'afdrager': ['af', 'draag', 'er'],\n",
       " 'afdreggen': ['af', 'dreg'],\n",
       " 'afdreigen': ['af', 'dreig'],\n",
       " 'afdrentelen': ['af', 'drentel'],\n",
       " 'afdrijven': ['af', 'drijf'],\n",
       " 'afdrijving': ['af', 'drijf', 'ing'],\n",
       " 'afdringen': ['af', 'dring'],\n",
       " 'afdrinken': ['af', 'drink'],\n",
       " 'afdroging': ['af', 'droog', 'ing'],\n",
       " 'afdrogen': ['af', 'droog'],\n",
       " 'afdroppelen': ['af', 'droppel'],\n",
       " 'afdruipen': ['af', 'druip'],\n",
       " 'afdrukken': ['af', 'druk'],\n",
       " 'afdruppen': ['af', 'drup'],\n",
       " 'afdruppelen': ['af', 'druppel'],\n",
       " 'afduikelen': ['af', 'duikel'],\n",
       " 'afduvelen': ['af', 'duvel'],\n",
       " 'afduwen': ['af', 'duw'],\n",
       " 'afdwalen': ['af', 'dwaal'],\n",
       " 'afdwaling': ['af', 'dwaal', 'ing'],\n",
       " 'afdweilen': ['af', 'dweil'],\n",
       " 'afdwingen': ['af', 'dwing'],\n",
       " 'afeten': ['af', 'eet'],\n",
       " 'afeisen': ['af', 'eis'],\n",
       " 'af-fabriekprijs': ['af', 'fabriek', 'prijs'],\n",
       " 'affakkelen': ['af', 'fakkel'],\n",
       " 'affectatie': ['affecteer', 'atie'],\n",
       " 'affectief': ['affect', 'ie', 'ief'],\n",
       " 'affichering': ['afficheer', 'ing'],\n",
       " 'affietsen': ['af', 'fiets'],\n",
       " 'affiliatie': ['affilieer', 'atie'],\n",
       " 'affineren': ['affineer'],\n",
       " ...}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dik2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_verbs(base):\n",
    "\n",
    "    verbs = {}\n",
    "    rest = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for word, dic in base.items():\n",
    "        \n",
    "        seg = dic['segments1']\n",
    "        split1 = seg.split('+')\n",
    "        split2 = dic['segments2']\n",
    "\n",
    "        concat1 = ''.join(split1)\n",
    "        concat2 = ''.join(split2)\n",
    "\n",
    "        if concat2 != word and len(seg) > 0:\n",
    "\n",
    "\n",
    "            if dic['cat'] == 'V':\n",
    "\n",
    "                verbs[word] = split2\n",
    "            \n",
    "            else:\n",
    "\n",
    "                rest[word] = split2\n",
    "\n",
    "\n",
    "    return verbs, rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, n = split_verbs(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, segs in v.items():\n",
    "    if segs[-1] == 'en':\n",
    "        print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aalbessengelei': ['aal', 'bes', 'en', 'gelei'],\n",
       " 'aalbessenjam': ['aal', 'bes', 'en', 'jam'],\n",
       " 'aalbessenjenever': ['aal', 'bes', 'en', 'jenever'],\n",
       " 'aalbessesap': ['aal', 'bes', 'e', 'sap'],\n",
       " 'aalbessestruik': ['aal', 'bes', 'e', 'struik'],\n",
       " 'aalmoezenier': ['aalmoes', 'enier'],\n",
       " 'aalmoezenierskamer': ['aalmoes', 'enier', 's', 'kamer'],\n",
       " 'aalsteker': ['aal', 'steek', 'er', 'NV'],\n",
       " 'aalvormig': ['aal', 'vorm', 'ig', 'NN'],\n",
       " 'aambeeldsbeentje': ['aambeeld', 's', 'been'],\n",
       " 'aamborstig': ['aam', 'borst', 'ig', 'NN'],\n",
       " 'aamborstigheid': ['aam', 'borst', 'ig', 'NN', 'heid'],\n",
       " 'aanaarding': ['aan', 'aarde', 'ing'],\n",
       " 'aanaardploeg': ['aan', 'aarde', 'ploeg'],\n",
       " 'aanbeeldsbeentje': ['aanbeeld', 's', 'been'],\n",
       " 'aanbesteder': ['aan', 'besteed', 'er'],\n",
       " 'aanbesteding': ['aan', 'besteed', 'ing'],\n",
       " 'aanbetaling': ['aan', 'betaal', 'ing'],\n",
       " 'aanbevelenswaard': ['aan', 'beveel', 's', 'waard'],\n",
       " 'aanbevelenswaardig': ['aan', 'beveel', 's', 'waarde', 'ig'],\n",
       " 'aanbeveling': ['aan', 'beveel', 'ing'],\n",
       " 'aanbevelingsbrief': ['aan', 'beveel', 'ing', 's', 'brief'],\n",
       " 'aanbiddelijk': ['aan', 'bid', 'elijk'],\n",
       " 'aanbiddenswaardig': ['aan', 'bid', 's', 'waarde', 'ig'],\n",
       " 'aanbidder': ['aan', 'bid', 'er'],\n",
       " 'aanbidding': ['aan', 'bid', 'ing'],\n",
       " 'aanblazing': ['aan', 'blaas', 'ing'],\n",
       " 'aandachtsconcentratie': ['aandacht', 's', 'concentreer', 'atie'],\n",
       " 'aandachttrekkerij': ['aandacht', 'trek', 'erij', 'NV'],\n",
       " 'aandamming': ['aan', 'dam', 'ing'],\n",
       " 'aandeelhebber': ['aan', 'deel', 'heb', 'er', 'NV'],\n",
       " 'aandeelhouder': ['aan', 'deel', 'houd', 'er', 'NV'],\n",
       " 'aandeelhoudersvergadering': ['aan',\n",
       "  'deel',\n",
       "  'houd',\n",
       "  'er',\n",
       "  'NV',\n",
       "  's',\n",
       "  'vergader',\n",
       "  'ing'],\n",
       " 'aandelenkapitaal': ['aan', 'deel', 'en', 'kapitaal'],\n",
       " 'aandelenoptie': ['aan', 'deel', 'en', 'optie'],\n",
       " 'aandelenpakket': ['aan', 'deel', 'en', 'pakket'],\n",
       " 'aandelenportefeuille': ['aan', 'deel', 'en', 'portefeuille'],\n",
       " 'aandoening': ['aan', 'doe', 'ing'],\n",
       " 'aandoenlijk': ['aan', 'doe', 'lijk'],\n",
       " 'aandoenlijkheid': ['aan', 'doe', 'lijk', 'heid'],\n",
       " 'aandrager': ['aan', 'draag', 'er'],\n",
       " 'aandrijver': ['aan', 'drijf', 'er'],\n",
       " 'aandrijving': ['aan', 'drijf', 'ing'],\n",
       " 'aaneengeboren': ['aaneen', 'B', 'geboren'],\n",
       " 'aaneengroeiing': ['aaneen', 'B', 'groei', 'ing'],\n",
       " 'aaneenkoppeling': ['aaneen', 'B', 'koppel', 'ing'],\n",
       " 'aaneenrijging': ['aaneen', 'B', 'rijg', 'ing'],\n",
       " 'aaneenschakeling': ['aaneen', 'B', 'schakel', 'ing'],\n",
       " 'aaneensluiting': ['aaneen', 'B', 'sluit', 'ing'],\n",
       " 'aaneenvoeging': ['aaneen', 'B', 'voeg', 'ing'],\n",
       " 'aanfokking': ['aan', 'fok', 'ing'],\n",
       " 'aangever': ['aan', 'geef', 'er'],\n",
       " 'aangeving': ['aan', 'geef', 'ing'],\n",
       " 'aangezichtsligging': ['aan', 'ge', 'zicht', 's', 'lig', 'ing'],\n",
       " 'aangraving': ['aan', 'graaf', 'ing'],\n",
       " 'aanhalerig': ['aan', 'haal', 'erig'],\n",
       " 'aanhalerigheid': ['aan', 'haal', 'erig', 'heid'],\n",
       " 'aanhalig': ['aan', 'haal', 'ig'],\n",
       " 'aanhaligheid': ['aan', 'haal', 'ig', 'heid'],\n",
       " 'aanhaling': ['aan', 'haal', 'ing'],\n",
       " 'aanhalingsteken': ['aan', 'haal', 'ing', 's', 'teken'],\n",
       " 'aanhankelijk': ['aan', 'hang', 'elijk'],\n",
       " 'aanhankelijkheid': ['aan', 'hang', 'elijk', 'heid'],\n",
       " 'aanheffer': ['aan', 'hef', 'er'],\n",
       " 'aanheffing': ['aan', 'hef', 'ing'],\n",
       " 'aanhoping': ['aan', 'hoop', 'ing'],\n",
       " 'aanjager': ['aan', 'jaag', 'er'],\n",
       " 'aanklager': ['aan', 'klaag', 'er'],\n",
       " 'aankleding': ['aan', 'kleed', 'ing'],\n",
       " 'aankleving': ['aan', 'kleef', 'ing'],\n",
       " 'aanknoping': ['aan', 'knoop', 'ing'],\n",
       " 'aanknopingspunt': ['aan', 'knoop', 'ing', 's', 'punt'],\n",
       " 'aankweking': ['aan', 'kweek', 'ing'],\n",
       " 'aanlassing': ['aan', 'las', 'ing'],\n",
       " 'aanlegger': ['aan', 'leg', 'er'],\n",
       " 'aanlegging': ['aan', 'leg', 'ing'],\n",
       " 'aanlokkelijk': ['aan', 'lok', 'elijk'],\n",
       " 'aanlokkelijkheid': ['aan', 'lok', 'elijk', 'heid'],\n",
       " 'aanlokking': ['aan', 'lok', 'ing'],\n",
       " 'aanloopkosten': ['aan', 'loop', 'kost'],\n",
       " 'aanlooppeiler': ['aan', 'loop', 'peil', 'er', 'NV'],\n",
       " 'aanlooptransformator': ['aan', 'loop', 'transformeer', 'ator', 'NV'],\n",
       " 'aanmaakblokje': ['aan', 'maak', 'blok'],\n",
       " 'aanmaakkosten': ['aan', 'maak', 'kost'],\n",
       " 'aanmaning': ['aan', 'maan', 'ing'],\n",
       " 'aanminnig': ['aan', 'min', 'ig'],\n",
       " 'aanminnigheid': ['aan', 'min', 'ig', 'heid'],\n",
       " 'aanmoediging': ['aan', 'moed', 'ig', 'PN', 'ing'],\n",
       " 'aanmoedigingsprijs': ['aan', 'moed', 'ig', 'PN', 'ing', 's', 'prijs'],\n",
       " 'aanmonding': ['aan', 'mond', 'ing', 'PN'],\n",
       " 'aannemelijk': ['aan', 'neem', 'elijk'],\n",
       " 'aannemelijkheid': ['aan', 'neem', 'elijk', 'heid'],\n",
       " 'aannemeling': ['aan', 'neem', 'eling'],\n",
       " 'aannemelinge': ['aan', 'neem', 'eling', 'e'],\n",
       " 'aannemer': ['aan', 'neem', 'er'],\n",
       " 'aannemersfirma': ['aan', 'neem', 'er', 's', 'firma'],\n",
       " 'aanneming': ['aan', 'neem', 'ing'],\n",
       " 'aannemingsbeleid': ['aan', 'neem', 'ing', 's', 'beleid'],\n",
       " 'aannemingsbiljet': ['aan', 'neem', 'ing', 's', 'biljet'],\n",
       " 'aannemingsmaatschappij': ['aan', 'neem', 'ing', 's', 'maatschappij'],\n",
       " 'aannemingssom': ['aan', 'neem', 'ing', 's', 'som'],\n",
       " 'aanpassing': ['aan', 'pas', 'ing'],\n",
       " 'aanpassingsbeleid': ['aan', 'pas', 'ing', 's', 'beleid'],\n",
       " 'aanpassingsgedrag': ['aan', 'pas', 'ing', 's', 'gedrag'],\n",
       " 'aanpassingsmanoeuvre': ['aan', 'pas', 'ing', 's', 'manoeuvre'],\n",
       " 'aanpassingsmechanisme': ['aan', 'pas', 'ing', 's', 'mechanisme'],\n",
       " 'aanpassingsmoeilijkheden': ['aan',\n",
       "  'pas',\n",
       "  'ing',\n",
       "  's',\n",
       "  'moei',\n",
       "  'lijk',\n",
       "  'heid'],\n",
       " 'aanpassingsmogelijkheid': ['aan', 'pas', 'ing', 's', 'mogelijk', 'heid'],\n",
       " 'aanpassingsperiode': ['aan', 'pas', 'ing', 's', 'periode'],\n",
       " 'aanpassingsprobleem': ['aan', 'pas', 'ing', 's', 'probleem'],\n",
       " 'aanpassingsproces': ['aan', 'pas', 'ing', 's', 'proces'],\n",
       " 'aanpassingsstoornis': ['aan', 'pas', 'ing', 's', 'stoor', 'nis'],\n",
       " 'aanpassingsstrategie': ['aan', 'pas', 'ing', 's', 'strategisch', 'ie'],\n",
       " 'aanpassingsvermogen': ['aan', 'pas', 'ing', 's', 'vermogen'],\n",
       " 'aanplakker': ['aan', 'plak', 'er'],\n",
       " 'aanplakking': ['aan', 'plak', 'ing'],\n",
       " 'aanpoting': ['aan', 'poot', 'ing'],\n",
       " 'aanprijzer': ['aan', 'prijs', 'er'],\n",
       " 'aanprijzing': ['aan', 'prijs', 'ing'],\n",
       " 'aanrader': ['aan', 'raad', 'er'],\n",
       " 'aanraking': ['aan', 'raak', 'ing'],\n",
       " 'aanrakingsangst': ['aan', 'raak', 'ing', 's', 'angst'],\n",
       " 'aanrakingspunt': ['aan', 'raak', 'ing', 's', 'punt'],\n",
       " 'aanrechtkastje': ['aanrecht', 'kast'],\n",
       " 'aanschaffing': ['aan', 'schaf', 'ing'],\n",
       " 'aanschrijving': ['aan', 'schrijf', 'ing'],\n",
       " 'aanschrijvingsbiljet': ['aan', 'schrijf', 'ing', 's', 'biljet'],\n",
       " 'aansjorring': ['aan', 'sjor', 'ing'],\n",
       " 'aanslibbing': ['aan', 'slib', 'ing'],\n",
       " 'aansluitingskosten': ['aan', 'sluit', 'ing', 's', 'kost'],\n",
       " 'aansmering': ['aan', 'smeer', 'ing'],\n",
       " 'aanspanner': ['aan', 'span', 'er'],\n",
       " 'aanspanning': ['aan', 'span', 'ing'],\n",
       " 'aansporing': ['aan', 'spoor', 'ing'],\n",
       " 'aansprakelijk': ['aan', 'spreek', 'elijk'],\n",
       " 'aansprakelijkheid': ['aan', 'spreek', 'elijk', 'heid'],\n",
       " 'aansprakelijkheidsverzekering': ['aan',\n",
       "  'spreek',\n",
       "  'elijk',\n",
       "  'heid',\n",
       "  's',\n",
       "  'ver',\n",
       "  'zeker',\n",
       "  'ing'],\n",
       " 'aanspreker': ['aan', 'spreek', 'er'],\n",
       " 'aanspreking': ['aan', 'spreek', 'ing'],\n",
       " 'aanstekelijk': ['aan', 'steek', 'elijk'],\n",
       " 'aanstekelijkheid': ['aan', 'steek', 'elijk', 'heid'],\n",
       " 'aansteker': ['aan', 'steek', 'er'],\n",
       " 'aansteking': ['aan', 'steek', 'ing'],\n",
       " 'aansteller': ['aan', 'stel', 'er'],\n",
       " 'aanstellerig': ['aan', 'stel', 'erig'],\n",
       " 'aanstellerigheid': ['aan', 'stel', 'erig', 'heid'],\n",
       " 'aanstellerij': ['aan', 'stel', 'erij'],\n",
       " 'aanstelling': ['aan', 'stel', 'ing'],\n",
       " 'aanstellingsbeleid': ['aan', 'stel', 'ing', 's', 'beleid'],\n",
       " 'aanstellingsbrief': ['aan', 'stel', 'ing', 's', 'brief'],\n",
       " 'aanstipping': ['aan', 'stip', 'ing'],\n",
       " 'aanstoker': ['aan', 'stook', 'er'],\n",
       " 'aanstotelijk': ['aan', 'stoot', 'elijk'],\n",
       " 'aanstotelijkheid': ['aan', 'stoot', 'elijk', 'heid'],\n",
       " 'aanstoting': ['aan', 'stoot', 'ing'],\n",
       " 'aanstreping': ['aan', 'streep', 'ing'],\n",
       " 'aanstuiving': ['aan', 'stuif', 'ing'],\n",
       " 'aanteling': ['aan', 'teel', 'ing'],\n",
       " 'aantoning': ['aan', 'toon', 'ing'],\n",
       " 'aantreeplaats': ['aan', 'treed', 'plaats'],\n",
       " 'aantrekkelijk': ['aan', 'trek', 'elijk'],\n",
       " 'aantrekkelijkheid': ['aan', 'trek', 'elijk', 'heid'],\n",
       " 'aantrekker': ['aan', 'trek', 'er'],\n",
       " 'aantrekking': ['aan', 'trek', 'ing'],\n",
       " 'aantrekkingskracht': ['aan', 'trek', 'ing', 's', 'kracht'],\n",
       " 'aantrekkingsvermogen': ['aan', 'trek', 'ing', 's', 'vermogen'],\n",
       " 'aanvallenderwijs': ['aan', 'val', 'enderwijs', 'B', 'B'],\n",
       " 'aanvallenderwijze': ['aan', 'val', 'enderwijze', 'B', 'B'],\n",
       " 'aanvaller': ['aan', 'val', 'er'],\n",
       " 'aanvallig': ['aan', 'val', 'ig'],\n",
       " 'aanvalligheid': ['aan', 'val', 'ig', 'heid'],\n",
       " 'aanvalspositie': ['aanval', 's', 'pose', 'eer', 'itie'],\n",
       " 'aanvalstactiek': ['aanval', 's', 'tact', 'isch', 'iek'],\n",
       " 'aanvangssituatie': ['aanvang', 's', 'situeer', 'atie'],\n",
       " 'aanvankelijk': ['aan', 'vang', 'elijk'],\n",
       " 'aanvaring': ['aan', 'vaar', 'ing'],\n",
       " 'aanvaringsschot': ['aan', 'vaar', 'ing', 's', 'schot'],\n",
       " 'aanvatting': ['aan', 'vat', 'ing'],\n",
       " 'aanvrager': ['aan', 'vraag', 'er'],\n",
       " 'aanvulling': ['aan', 'vul', 'ing'],\n",
       " 'aanvullingsbegroting': ['aan', 'vul', 'ing', 's', 'be', 'groot', 'ing'],\n",
       " 'aanvullingsexamen': ['aan', 'vul', 'ing', 's', 'examen'],\n",
       " 'aanvullingskohier': ['aan', 'vul', 'ing', 's', 'kohier'],\n",
       " 'aanvullingstroepen': ['aan', 'vul', 'ing', 's', 'troep'],\n",
       " 'aanvuring': ['aan', 'vuur', 'ing'],\n",
       " 'aanwassing': ['aan', 'was', 'ing'],\n",
       " 'aanwenning': ['aan', 'wen', 'ing'],\n",
       " 'aanwerver': ['aan', 'werf', 'er'],\n",
       " 'aanwerving': ['aan', 'werf', 'ing'],\n",
       " 'aanwijzer': ['aan', 'wijs', 'er'],\n",
       " 'aanwijzing': ['aan', 'wijs', 'ing'],\n",
       " 'aanwijzingsbevoegdheid': ['aan', 'wijs', 'ing', 's', 'bevoegd', 'heid'],\n",
       " 'aanwijzingsbord': ['aan', 'wijs', 'ing', 's', 'bord'],\n",
       " 'aanwinning': ['aan', 'win', 'ing'],\n",
       " 'aanwrijving': ['aan', 'wrijf', 'ing'],\n",
       " 'aanzegger': ['aan', 'zeg', 'er'],\n",
       " 'aanzegging': ['aan', 'zeg', 'ing'],\n",
       " 'aanzetter': ['aan', 'zet', 'er'],\n",
       " 'aanzetting': ['aan', 'zet', 'ing'],\n",
       " 'aapjessnuif': ['aap', 's', 'snuif'],\n",
       " 'aapjeszeep': ['aap', 's', 'zeep'],\n",
       " 'aarden': ['aarde', 'en'],\n",
       " 'aardamandel': ['aarde', 'amandel'],\n",
       " 'aardappel': ['aarde', 'appel'],\n",
       " 'aardappelakker': ['aarde', 'appel', 'akker'],\n",
       " 'aardappelbak': ['aarde', 'appel', 'bak'],\n",
       " 'aardappelboer': ['aarde', 'appel', 'boer'],\n",
       " 'aardappelbovist': ['aarde', 'appel', 'bovist'],\n",
       " 'aardappelbuik': ['aarde', 'appel', 'buik'],\n",
       " 'aardappelcampagne': ['aarde', 'appel', 'campagne'],\n",
       " 'aardappelcroquet': ['aarde', 'appel', 'croquet'],\n",
       " 'aardappeldeeg': ['aarde', 'appel', 'deeg'],\n",
       " 'aardappelhakker': ['aarde', 'appel', 'hak', 'er', 'NV'],\n",
       " 'aardappelkelder': ['aarde', 'appel', 'kelder'],\n",
       " 'aardappelkever': ['aarde', 'appel', 'kever'],\n",
       " 'aardappelknol': ['aarde', 'appel', 'knol'],\n",
       " 'aardappelkriel': ['aarde', 'appel', 'kriel'],\n",
       " 'aardappelmeel': ['aarde', 'appel', 'meel'],\n",
       " 'aardappelmesje': ['aarde', 'appel', 'mes'],\n",
       " 'aardappelmoeheid': ['aarde', 'appel', 'moe', 'heid'],\n",
       " 'aardappelpan': ['aarde', 'appel', 'pan'],\n",
       " 'aardappelplant': ['aarde', 'appel', 'plant'],\n",
       " 'aardappelpoter': ['aarde', 'appel', 'poot', 'er', 'NV'],\n",
       " 'aardappelpuree': ['aarde', 'appel', 'puree'],\n",
       " 'aardappelrooier': ['aarde', 'appel', 'rooi', 'er'],\n",
       " 'aardappelsalade': ['aarde', 'appel', 'salade'],\n",
       " 'aardappelschijf': ['aarde', 'appel', 'schijf'],\n",
       " 'aardappelschiller': ['aarde', 'appel', 'schil', 'er', 'NV'],\n",
       " 'aardappelschilmesje': ['aarde', 'appel', 'schilmes'],\n",
       " 'aardappelsoep': ['aarde', 'appel', 'soep'],\n",
       " 'aardappelstijfsel': ['aarde', 'appel', 'stijf', 'sel'],\n",
       " 'aardappelstroop': ['aarde', 'appel', 'stroop'],\n",
       " 'aardappelveld': ['aarde', 'appel', 'veld'],\n",
       " 'aardappelvlokken': ['aarde', 'appel', 'vlok'],\n",
       " 'aardappelziekte': ['aarde', 'appel', 'ziek', 'te'],\n",
       " 'aardas': ['aarde', 'as'],\n",
       " 'aardatmosfeer': ['aarde', 'atmosfeer'],\n",
       " 'aardbaan': ['aarde', 'baan'],\n",
       " 'aardberging': ['aarde', 'berg', 'ing', 'NV'],\n",
       " 'aardbeving': ['aarde', 'beef', 'ing'],\n",
       " 'aardbevingsgebied': ['aarde', 'beef', 'ing', 's', 'gebied'],\n",
       " 'aardbevingsgolf': ['aarde', 'beef', 'ing', 's', 'golf'],\n",
       " 'aardbevingsgordel': ['aarde', 'beef', 'ing', 's', 'gordel'],\n",
       " 'aardbevingshaard': ['aarde', 'beef', 'ing', 's', 'haard'],\n",
       " 'aardbevingsmeter': ['aarde', 'beef', 'ing', 's', 'Vx', 'meet', 'er', 'NxV'],\n",
       " 'aardbewoner': ['aarde', 'be', 'woon', 'er', 'NV'],\n",
       " 'aardbewoonster': ['aarde', 'be', 'woon', 'ster', 'NV'],\n",
       " 'aardbij': ['aarde', 'bij'],\n",
       " 'aardbodem': ['aarde', 'bodem'],\n",
       " 'aardbol': ['aarde', 'bol'],\n",
       " 'aardboog': ['aarde', 'boog'],\n",
       " 'aardboor': ['aarde', 'boor'],\n",
       " 'aardbrand': ['aarde', 'brand'],\n",
       " 'aardbuil': ['aarde', 'buil'],\n",
       " 'aardduivel': ['aarde', 'duivel'],\n",
       " 'aardgas': ['aarde', 'gas'],\n",
       " 'aardgasbaten': ['aarde', 'gas', 'baat'],\n",
       " 'aardgasbel': ['aarde', 'gas', 'bel'],\n",
       " 'aardgasnet': ['aarde', 'gas', 'net'],\n",
       " 'aardgasopbrengst': ['aarde', 'gas', 'op', 'breng', 'st'],\n",
       " 'aardgastanker': ['aarde', 'gas', 'tank', 'er'],\n",
       " 'aardgasterminal': ['aarde', 'gas', 'terminal'],\n",
       " 'aardgeest': ['aarde', 'geest'],\n",
       " 'aardgewas': ['aarde', 'ge', 'was'],\n",
       " 'aardglobe': ['aarde', 'globe'],\n",
       " 'aardgoed': ['aarde', 'goed'],\n",
       " 'aardgordel': ['aarde', 'gordel'],\n",
       " 'aardhars': ['aarde', 'hars'],\n",
       " 'aardhommel': ['aarde', 'hommel'],\n",
       " 'aardhoop': ['aarde', 'hoop'],\n",
       " 'aardigjes': ['aardig', 'jes', 'B', 'B'],\n",
       " 'aardkastanje': ['aarde', 'kastanje'],\n",
       " 'aardkern': ['aarde', 'kern'],\n",
       " 'aardklomp': ['aarde', 'klomp'],\n",
       " 'aardklont': ['aarde', 'klont'],\n",
       " 'aardkloot': ['aarde', 'kloot'],\n",
       " 'aardkluit': ['aarde', 'kluit'],\n",
       " 'aardkorst': ['aarde', 'korst'],\n",
       " 'aardkrekel': ['aarde', 'krekel'],\n",
       " 'aardkromming': ['aarde', 'krom', 'ing'],\n",
       " 'aardkuil': ['aarde', 'kuil'],\n",
       " 'aardkunde': ['aarde', 'kunde'],\n",
       " 'aardkundig': ['aarde', 'kunde', 'ig'],\n",
       " 'aardlaag': ['aarde', 'laag'],\n",
       " 'aardleiding': ['aarde', 'leid', 'ing'],\n",
       " 'aardlevering': ['aarde', 'lever', 'ing'],\n",
       " 'aardmagnetisme': ['aarde', 'magnetisme'],\n",
       " 'aardmannetje': ['aarde', 'man'],\n",
       " 'aardmassa': ['aarde', 'massa'],\n",
       " 'aardmeetkunde': ['aarde', 'meet', 'kunde'],\n",
       " 'aardmetalen': ['aarde', 'metaal'],\n",
       " 'aardmeting': ['aarde', 'meet', 'ing', 'NV'],\n",
       " 'aardmijt': ['aarde', 'mijt'],\n",
       " 'aardmolm': ['aarde', 'molm'],\n",
       " 'aardmuis': ['aarde', 'muis'],\n",
       " 'aardnoot': ['aarde', 'noot'],\n",
       " 'aardnotenolie': ['aarde', 'noot', 'en', 'olie'],\n",
       " 'aardolie': ['aarde', 'olie'],\n",
       " 'aardolieprodukt': ['aarde', 'olie', 'produkt'],\n",
       " 'aardoppervlak': ['aarde', 'opper', 'vlak'],\n",
       " 'aardoppervlakte': ['aarde', 'opper', 'vlak', 'te'],\n",
       " 'aardpeer': ['aarde', 'peer'],\n",
       " 'aardpek': ['aarde', 'pek'],\n",
       " 'aardplooi': ['aarde', 'plooi'],\n",
       " 'aardpool': ['aarde', 'pool'],\n",
       " 'aardprofiel': ['aarde', 'profiel'],\n",
       " 'aardrijk': ['aarde', 'rijk'],\n",
       " 'aardrijkskunde': ['aarde', 'rijk', 's', 'kunde'],\n",
       " 'aardrijkskundeboek': ['aarde', 'rijk', 's', 'kunde', 'boek'],\n",
       " 'aardrijkskundig': ['aarde', 'rijk', 's', 'kunde', 'ig'],\n",
       " 'aardrol': ['aarde', 'rol'],\n",
       " 'aardrook': ['aarde', 'rook'],\n",
       " 'aardrups': ['aarde', 'rups'],\n",
       " 'aards': ['aarde', 's'],\n",
       " 'aardschaduw': ['aarde', 'schaduw'],\n",
       " 'aardschijn': ['aarde', 'schijn'],\n",
       " 'aardschok': ['aarde', 'schok'],\n",
       " 'aardschors': ['aarde', 'schors'],\n",
       " 'aardschudding': ['aarde', 'schud', 'ing'],\n",
       " 'aardsgezind': ['aarde', 's', 'gezind'],\n",
       " 'aardsgezindheid': ['aarde', 's', 'gezind', 'heid'],\n",
       " 'aardsheid': ['aarde', 's', 'heid'],\n",
       " 'aardslak': ['aarde', 'slak'],\n",
       " 'aardslang': ['aarde', 'slang'],\n",
       " 'aardsluiting': ['aarde', 'sluit', 'ing'],\n",
       " 'aardspin': ['aarde', 'spin'],\n",
       " 'aardster': ['aarde', 'ster'],\n",
       " 'aardstorting': ['aarde', 'stort', 'ing'],\n",
       " 'aardstraal': ['aarde', 'straal'],\n",
       " 'aardstralenkastje': ['aarde', 'straal', 'en', 'kast'],\n",
       " 'aardstraling': ['aarde', 'straal', 'ing'],\n",
       " 'aardstroom': ['aarde', 'stroom'],\n",
       " 'aardtor': ['aarde', 'tor'],\n",
       " 'aardtrilling': ['aarde', 'tril', 'ing'],\n",
       " 'aardvarken': ['aarde', 'varken'],\n",
       " 'aardvast': ['aarde', 'vast'],\n",
       " 'aardveil': ['aarde', 'veil'],\n",
       " 'aardverbinding': ['aarde', 'ver', 'bind', 'ing'],\n",
       " 'aardverschuiving': ['aarde', 'ver', 'schuif', 'ing'],\n",
       " 'aardverf': ['aarde', 'verf'],\n",
       " 'aardvlo': ['aarde', 'vlo'],\n",
       " 'aardvork': ['aarde', 'vork'],\n",
       " 'aardvrucht': ['aarde', 'vrucht'],\n",
       " 'aardwarmte': ['aarde', 'warm', 'te'],\n",
       " 'aardwas': ['aarde', 'was'],\n",
       " 'aardwerk': ['aarde', 'werk'],\n",
       " 'aardwerker': ['aarde', 'werk', 'er'],\n",
       " 'aardwetenschappen': ['aarde', 'weten', 'schap'],\n",
       " 'aardwinde': ['aarde', 'winde'],\n",
       " 'aardwolf': ['aarde', 'wolf'],\n",
       " 'aardworm': ['aarde', 'worm'],\n",
       " 'aartsbisschoppelijk': ['aarts', 'bisschop', 'elijk'],\n",
       " 'aartsconservatief': ['aarts', 'conserveer', 'atie', 'ief'],\n",
       " 'aartsdeugniet': ['aarts', 'deug', 'niet', 'B'],\n",
       " 'aartsliefhebber': ['aarts', 'lief', 'heb', 'er'],\n",
       " 'aartsverrader': ['aarts', 'verraad', 'er'],\n",
       " 'aarvormig': ['aar', 'vorm', 'ig', 'NN'],\n",
       " 'aaseter': ['aas', 'eet', 'er', 'NV'],\n",
       " 'aasjager': ['aas', 'jaag', 'er', 'NV'],\n",
       " 'aatje': ['aat'],\n",
       " 'aasje': ['aas'],\n",
       " 'abandonnement': ['abandon', 'eer', 'ement'],\n",
       " 'abbatiaal': ['abt', 'aal'],\n",
       " 'abbreviatie': ['abbrevieer', 'atie'],\n",
       " 'abbreviatuur': ['abbrevieer', 'atuur'],\n",
       " 'abc-boek': ['abc', 'boek'],\n",
       " 'ABC-wapens': ['abc', 'wapen'],\n",
       " 'abdicatie': ['abdiceer', 'atie'],\n",
       " 'abdominaal': ['abdomen', 'aal'],\n",
       " 'abelenlaan': ['abeel', 'en', 'laan'],\n",
       " 'A-biljet': ['a', 'biljet'],\n",
       " 'abnormaliteit': ['abnormaal', 'iteit'],\n",
       " 'abolitie': ['aboleer', 'itie'],\n",
       " 'A-bom': ['a', 'bom'],\n",
       " 'abondance': ['abondant', 'nce'],\n",
       " 'abonnement': ['abonneer', 'ement'],\n",
       " 'abonnementhouder': ['abonneer', 'ement', 'houd', 'er', 'NV'],\n",
       " 'abonnementhoudster': ['abonneer', 'ement', 'houd', 'ster', 'NV'],\n",
       " 'abonnementsconcert': ['abonneer', 'ement', 's', 'concert'],\n",
       " 'abonnementshonorarium': ['abonneer', 'ement', 's', 'honorarium'],\n",
       " 'abonnementskaart': ['abonneer', 'ement', 's', 'kaart'],\n",
       " 'abonnementsprijsverhoging': ['abonneer',\n",
       "  'ement',\n",
       "  's',\n",
       "  'prijs',\n",
       "  'ver',\n",
       "  'hoog',\n",
       "  'ing',\n",
       "  'NV'],\n",
       " 'abonnementstarief': ['abonneer', 'ement', 's', 'tarief'],\n",
       " 'abonnementsvoorstelling': ['abonneer',\n",
       "  'ement',\n",
       "  's',\n",
       "  'voor',\n",
       "  'B',\n",
       "  'stel',\n",
       "  'ing'],\n",
       " 'aborteur': ['abortus', 'eer', 'eur'],\n",
       " 'abortief': ['abortus', 'ief'],\n",
       " 'abortuskliniek': ['abortus', 'klinisch', 'iek'],\n",
       " 'abrikozeboom': ['abrikoos', 'e', 'boom'],\n",
       " 'abrikozengelei': ['abrikoos', 'en', 'gelei'],\n",
       " 'abrikozentaart': ['abrikoos', 'en', 'taart'],\n",
       " 'abrikozepit': ['abrikoos', 'e', 'pit'],\n",
       " 'abrikozeschil': ['abrikoos', 'e', 'schil'],\n",
       " 'absence': ['absent', 'nce'],\n",
       " 'absolutie': ['absolveer', 'utie'],\n",
       " 'absorbaat': ['absorbeer', 'aat'],\n",
       " 'abstinent': ['abstineer', 'ent'],\n",
       " 'abstinentie': ['abstineer', 'ent', 'ie'],\n",
       " 'abstinentiedag': ['abstineer', 'ent', 'ie', 'dag'],\n",
       " 'abstinentiesyndroom': ['abstineer', 'ent', 'ie', 'syndroom'],\n",
       " 'abstinentieverschijnsel': ['abstineer', 'ent', 'ie', 'verschijn', 'sel'],\n",
       " 'abstrahering': ['abstract', 'eer', 'ing'],\n",
       " 'abusief': ['abuis', 'ief'],\n",
       " 'academie': ['academisch', 'ie'],\n",
       " 'academiedag': ['academisch', 'ie', 'dag'],\n",
       " 'academiegebouw': ['academisch', 'ie', 'ge', 'bouw'],\n",
       " 'academiejaar': ['academisch', 'ie', 'jaar'],\n",
       " 'academiestad': ['academisch', 'ie', 'stad'],\n",
       " 'academievergadering': ['academisch', 'ie', 'vergader', 'ing'],\n",
       " 'academievriend': ['academisch', 'ie', 'vriend'],\n",
       " 'acceleratie': ['accelereer', 'atie'],\n",
       " 'acceleratiepomp': ['accelereer', 'atie', 'pomp'],\n",
       " 'acceleratieproef': ['accelereer', 'atie', 'proef'],\n",
       " 'acceleratievermogen': ['accelereer', 'atie', 'vermogen'],\n",
       " 'accelerator': ['accelereer', 'ator'],\n",
       " 'accentuatie': ['accent', 'ueer', 'atie'],\n",
       " 'accentuering': ['accent', 'ueer', 'ing'],\n",
       " 'accentverlegging': ['accent', 'ver', 'leg', 'ing', 'NV'],\n",
       " 'accentverschuiving': ['accent', 'ver', 'schuif', 'ing'],\n",
       " 'acceptabel': ['accept', 'eer', 'abel'],\n",
       " 'acceptant': ['accept', 'eer', 'ant'],\n",
       " 'acceptatie': ['accept', 'eer', 'atie'],\n",
       " 'acceptatiegraad': ['accept', 'eer', 'atie', 'graad'],\n",
       " 'accessie': ['acces', 'ie'],\n",
       " 'accijnsrechten': ['accijns', 'recht'],\n",
       " 'acclimatisatie': ['acclimatiseer', 'atie'],\n",
       " 'acclimatisatieproces': ['acclimatiseer', 'atie', 'proces'],\n",
       " 'acclimatisatiestation': ['acclimatiseer', 'atie', 'station'],\n",
       " 'acclimatisatietuin': ['acclimatiseer', 'atie', 'tuin'],\n",
       " 'acclimatisering': ['acclimatiseer', 'ing'],\n",
       " 'accommodatie': ['accommodeer', 'atie'],\n",
       " 'accommodatiebeleid': ['accommodeer', 'atie', 'beleid'],\n",
       " 'accommodatieflat': ['accommodeer', 'atie', 'flat'],\n",
       " 'accommodatieplatform': ['accommodeer', 'atie', 'platform'],\n",
       " 'accommodatievermogen': ['accommodeer', 'atie', 'vermogen'],\n",
       " 'accompagnateur': ['accompagneer', 'ateur'],\n",
       " 'accompagnement': ['accompagneer', 'ement'],\n",
       " 'accoucheur': ['accoucheer', 'eur'],\n",
       " 'accountants-administratieconsulent': ['accountant',\n",
       "  's',\n",
       "  'NN',\n",
       "  'administreer',\n",
       "  'atie',\n",
       "  'consulent'],\n",
       " 'accumulatie': ['accumuleer', 'atie'],\n",
       " 'accumulatietheorie': ['accumuleer', 'atie', 'theorie'],\n",
       " 'accumulatief': ['accumuleer', 'atie', 'ief'],\n",
       " 'accumulator': ['accumuleer', 'ator'],\n",
       " 'accumulatorcentrale': ['accumuleer', 'ator', 'centrum', 'aal', 'e'],\n",
       " 'accumulatorenbatterij': ['accumuleer', 'ator', 'en', 'batterij'],\n",
       " 'accuratesse': ['accuraat', 'esse'],\n",
       " 'accusatie': ['accuseer', 'atie'],\n",
       " 'achilleshiel': ['Achilles', 'hiel'],\n",
       " 'achillespees': ['Achilles', 'pees'],\n",
       " 'a-christelijk': ['a', 'christen', 'elijk'],\n",
       " 'achtarm': ['acht', 'Q', 'arm'],\n",
       " 'achtarmig': ['acht', 'Q', 'arm', 'ig', 'QN'],\n",
       " 'achtdaags': ['acht', 'Q', 'dag', 's', 'QN'],\n",
       " 'achtdubbel': ['acht', 'Q', 'dubbel'],\n",
       " 'achtduizend': ['acht', 'Q', 'duizend', 'Q', 'Q'],\n",
       " 'achtduizendste': ['acht', 'Q', 'duizend', 'Q', 'Q', 'ste', 'Q', 'Q', 'Q'],\n",
       " 'achtender': ['acht', 'Q', 'end', 'er', 'QN'],\n",
       " 'achtendertig': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'drie',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtendertigste': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'drie',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtenswaard': ['acht', 's', 'waard'],\n",
       " 'achtenswaardig': ['acht', 's', 'waarde', 'ig'],\n",
       " 'achtenswaardigheid': ['acht', 's', 'waarde', 'ig', 'heid'],\n",
       " 'achtentwintig': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'twee',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtentwintigduizend': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'twee',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'duizend',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtentwintigduizendste': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'twee',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'duizend',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtentwintigste': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'twee',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achteraan': ['achter', 'B', 'aan', 'B'],\n",
       " 'achteraandrijving': ['achter', 'B', 'aan', 'drijf', 'ing'],\n",
       " 'achteraanzicht': ['achter', 'B', 'aanzicht'],\n",
       " 'achteraf': ['achter', 'af', 'B'],\n",
       " 'achterafbuurt': ['achter', 'af', 'B', 'buurt'],\n",
       " 'achterafje': ['achter', 'af', 'B', 'je', 'B'],\n",
       " 'achterafstraat': ['achter', 'af', 'B', 'straat'],\n",
       " 'achteras': ['achter', 'B', 'as'],\n",
       " 'achterbak': ['achter', 'B', 'bak'],\n",
       " 'achterbalk': ['achter', 'B', 'balk'],\n",
       " 'achterbalkon': ['achter', 'B', 'balkon'],\n",
       " 'achterban': ['achter', 'B', 'ban'],\n",
       " 'achterband': ['achter', 'B', 'band'],\n",
       " 'achterbank': ['achter', 'B', 'bank'],\n",
       " 'achterbeen': ['achter', 'B', 'been'],\n",
       " 'achterbil': ['achter', 'B', 'bil'],\n",
       " 'achterblijfster': ['achter', 'B', 'blijf', 'ster'],\n",
       " 'achterblijver': ['achter', 'B', 'blijf', 'er'],\n",
       " 'achterboom': ['achter', 'B', 'boom'],\n",
       " 'achterbout': ['achter', 'B', 'bout'],\n",
       " 'achterbuur': ['achter', 'B', 'buur'],\n",
       " 'achterbuurman': ['achter', 'B', 'buur', 'man'],\n",
       " 'achterbuurt': ['achter', 'B', 'buurt'],\n",
       " 'achterbuurttaal': ['achter', 'B', 'buurt', 'taal'],\n",
       " 'achterbuurvrouw': ['achter', 'B', 'buur', 'vrouw'],\n",
       " 'achterdak': ['achter', 'B', 'dak'],\n",
       " 'achterdeel': ['achter', 'B', 'deel'],\n",
       " 'achterdek': ['achter', 'B', 'dek'],\n",
       " 'achterdeur': ['achter', 'B', 'deur'],\n",
       " 'achterdijks': ['achter', 'dijk', 's', 'PN'],\n",
       " 'achterdoek': ['achter', 'B', 'doek'],\n",
       " 'achtereenvolgend': ['achtereen', 'B', 'volgend'],\n",
       " 'achtereind': ['achter', 'B', 'eind'],\n",
       " 'achtereinde': ['achter', 'B', 'einde'],\n",
       " 'achterelkaar': ['achter', 'B', 'elkaar', 'O', 'B'],\n",
       " 'achterelkander': ['achter', 'B', 'elkander', 'O', 'B'],\n",
       " 'achtererf': ['achter', 'B', 'erf'],\n",
       " 'achterflap': ['achter', 'B', 'flap'],\n",
       " 'achtergalerij': ['achter', 'B', 'galerij'],\n",
       " 'achtergang': ['achter', 'B', 'gang'],\n",
       " 'achtergebouw': ['achter', 'B', 'ge', 'bouw'],\n",
       " 'achtergedeelte': ['achter', 'B', 'ge', 'Nx', 'deel', 'te', 'xN'],\n",
       " 'achtergevel': ['achter', 'B', 'gevel'],\n",
       " 'achtergracht': ['achter', 'B', 'gracht'],\n",
       " 'achtergrond': ['achter', 'B', 'grond'],\n",
       " 'achtergrondartikel': ['achter', 'B', 'grond', 'artikel'],\n",
       " 'achtergronddecor': ['achter', 'B', 'grond', 'decor'],\n",
       " 'achtergrondfiguur': ['achter', 'B', 'grond', 'figuur'],\n",
       " 'achtergrondgegeven': ['achter', 'B', 'grond', 'gegeven'],\n",
       " 'achtergrondgeheugen': ['achter', 'B', 'grond', 'geheugen'],\n",
       " 'achtergrondgeluid': ['achter', 'B', 'grond', 'ge', 'luid'],\n",
       " 'achtergrondgesprek': ['achter', 'B', 'grond', 'gesprek'],\n",
       " 'achtergrondinformatie': ['achter', 'B', 'grond', 'informeer', 'atie', 'NV'],\n",
       " 'achtergrondkoor': ['achter', 'B', 'grond', 'koor'],\n",
       " 'achtergrondmateriaal': ['achter', 'B', 'grond', 'materie', 'aal'],\n",
       " 'achtergrondmotief': ['achter', 'B', 'grond', 'motief'],\n",
       " 'achtergrondmuziek': ['achter', 'B', 'grond', 'muziek'],\n",
       " 'achtergrondstraling': ['achter', 'B', 'grond', 'straal', 'ing'],\n",
       " 'achtergrondstudie': ['achter', 'B', 'grond', 'studie'],\n",
       " 'achterhaalbaar': ['achter', 'B', 'haal', 'baar'],\n",
       " 'achterhaling': ['achter', 'B', 'haal', 'ing'],\n",
       " 'achterham': ['achter', 'B', 'ham'],\n",
       " 'achterhand': ['achter', 'B', 'hand'],\n",
       " 'achterhandsbeentje': ['achter', 'B', 'hand', 's', 'been'],\n",
       " 'achterheen': ['achter', 'B', 'heen', 'B', 'B'],\n",
       " 'achterhesp': ['achter', 'B', 'hesp'],\n",
       " 'achterhoede': ['achter', 'B', 'hoede'],\n",
       " 'achterhoedegevecht': ['achter', 'B', 'hoede', 'ge', 'vecht'],\n",
       " 'achterhoedespeelster': ['achter', 'B', 'hoede', 'speel', 'ster'],\n",
       " 'achterhoedespeler': ['achter', 'B', 'hoede', 'speel', 'er'],\n",
       " 'achterhoek': ['achter', 'B', 'hoek'],\n",
       " 'achterhoofd': ['achter', 'B', 'hoofd'],\n",
       " 'achterhoofdsbeen': ['achter', 'B', 'hoofd', 's', 'been'],\n",
       " 'achterhoofdsknobbel': ['achter', 'B', 'hoofd', 's', 'knobbel'],\n",
       " 'achterhoofdsligging': ['achter', 'B', 'hoofd', 's', 'lig', 'ing'],\n",
       " 'achterhouding': ['achter', 'B', 'houd', 'ing'],\n",
       " 'achterhout': ['achter', 'B', 'hout'],\n",
       " 'achterhuis': ['achter', 'B', 'huis'],\n",
       " 'achterin': ['achter', 'in', 'B'],\n",
       " 'achteringang': ['achter', 'B', 'ingang'],\n",
       " 'achterkamer': ['achter', 'B', 'kamer'],\n",
       " 'achterkant': ['achter', 'B', 'kant'],\n",
       " 'achterkasteel': ['achter', 'B', 'kasteel'],\n",
       " 'achterkeuken': ['achter', 'B', 'keuken'],\n",
       " 'achterkleindochter': ['achter', 'B', 'kleindochter'],\n",
       " 'achterkleinkind': ['achter', 'B', 'kleinkind'],\n",
       " 'achterkleinzoon': ['achter', 'B', 'kleinzoon'],\n",
       " 'achterklep': ['achter', 'B', 'klep'],\n",
       " 'achterklinker': ['achter', 'B', 'klink', 'er'],\n",
       " 'achterkwab': ['achter', 'B', 'kwab'],\n",
       " 'achterkwartier': ['achter', 'B', 'kwart', 'ier'],\n",
       " 'achterlader': ['achter', 'B', 'laad', 'er'],\n",
       " 'achterland': ['achter', 'B', 'land'],\n",
       " 'achterlap': ['achter', 'B', 'lap'],\n",
       " 'achterlast': ['achter', 'B', 'last'],\n",
       " 'achterlastig': ['achter', 'B', 'last', 'ig'],\n",
       " 'achterlating': ['achter', 'B', 'laat', 'ing'],\n",
       " 'achterleen': ['achter', 'B', 'leen'],\n",
       " 'achterleenheer': ['achter', 'B', 'leen', 'heer'],\n",
       " 'achterleenman': ['achter', 'B', 'leen', 'man'],\n",
       " 'achterlichaam': ['achter', 'B', 'lichaam'],\n",
       " 'achterlicht': ['achter', 'B', 'licht'],\n",
       " 'achterligger': ['achter', 'B', 'lig', 'er'],\n",
       " 'achterlijfssegment': ['achter', 'B', 'lijf', 's', 'segment'],\n",
       " 'achterlijk': ['achter', 'B', 'lijk', 'B'],\n",
       " 'achterlijkheid': ['achter', 'B', 'lijk', 'B', 'heid'],\n",
       " 'achterlijf': ['achter', 'B', 'lijf'],\n",
       " 'achterloper': ['achter', 'B', 'loop', 'er'],\n",
       " 'achterluik': ['achter', 'B', 'luik'],\n",
       " 'achterman': ['achter', 'B', 'man'],\n",
       " 'achtermiddag': ['achter', 'B', 'middag'],\n",
       " 'achternaad': ['achter', 'B', 'naad'],\n",
       " 'achternaam': ['achter', 'B', 'naam'],\n",
       " 'achternageloop': ['achterna', 'B', 'ge', 'loop'],\n",
       " 'achternamiddag': ['achter', 'B', 'na', 'middag'],\n",
       " 'achterneef': ['achter', 'B', 'neef'],\n",
       " 'achternicht': ['achter', 'B', 'nicht'],\n",
       " 'achteronder': ['achter', 'B', 'onder', 'B'],\n",
       " 'achterop': ['achter', 'op', 'B'],\n",
       " 'achteros': ['achter', 'B', 'os'],\n",
       " 'achterover': ['achter', 'over', 'B'],\n",
       " 'achterpaard': ['achter', 'B', 'paard'],\n",
       " 'achterpad': ['achter', 'B', 'pad'],\n",
       " 'achterpagina': ['achter', 'B', 'pagina'],\n",
       " 'achterpand': ['achter', 'B', 'pand'],\n",
       " 'achterplaats': ['achter', 'B', 'plaats'],\n",
       " 'achterplan': ['achter', 'B', 'plan'],\n",
       " 'achterplecht': ['achter', 'B', 'plecht'],\n",
       " 'achterpoort': ['achter', 'B', 'poort'],\n",
       " 'achterpoot': ['achter', 'B', 'poot'],\n",
       " 'achterruit': ['achter', 'B', 'ruit'],\n",
       " 'achterruitverwarming': ['achter', 'B', 'ruit', 'ver', 'warm', 'ing', 'NV'],\n",
       " 'achterschip': ['achter', 'B', 'schip'],\n",
       " 'achterspatbord': ['achter', 'B', 'spat', 'bord'],\n",
       " 'achterspeler': ['achter', 'B', 'speel', 'er'],\n",
       " 'achterspoiler': ['achter', 'B', 'spoiler'],\n",
       " 'achterstal': ['achter', 'B', 'stal'],\n",
       " 'achterstallig': ['achter', 'B', 'stal', 'ig'],\n",
       " 'achterstalligheid': ['achter', 'B', 'stal', 'ig', 'heid'],\n",
       " 'achterstand': ['achter', 'B', 'stand'],\n",
       " 'achterstandsbeleid': ['achter', 'B', 'stand', 's', 'beleid'],\n",
       " 'achterstandsituatie': ['achter', 'B', 'stand', 'situeer', 'atie'],\n",
       " 'achterstandspositie': ['achter', 'B', 'stand', 's', 'pose', 'eer', 'itie'],\n",
       " 'achterstandssituatie': ['achter', 'B', 'stand', 's', 'situeer', 'atie'],\n",
       " 'achtersteek': ['achter', 'B', 'steek'],\n",
       " 'achterstel': ['achter', 'B', 'stel'],\n",
       " 'achterstelling': ['achter', 'B', 'stel', 'ing'],\n",
       " 'achtersteven': ['achter', 'B', 'steven'],\n",
       " 'achterstevoren': ['achterste', 'voren', 'B', 'B'],\n",
       " 'achterstraat': ['achter', 'B', 'straat'],\n",
       " 'achterstreng': ['achter', 'B', 'streng'],\n",
       " 'achterstuk': ['achter', 'B', 'stuk'],\n",
       " 'achtertalie': ['achter', 'B', 'talie'],\n",
       " 'achtertuin': ['achter', 'B', 'tuin'],\n",
       " 'achteruitgang': ['achter', 'B', 'uit', 'gang'],\n",
       " 'achteruitkijkspiegel': ['achter', 'B', 'uit', 'B', 'B', 'kijk', 'spiegel'],\n",
       " 'achteruitrijlamp': ['achter', 'B', 'uit', 'B', 'B', 'rijd', 'lamp'],\n",
       " 'achtervanger': ['achter', 'B', 'vang', 'er'],\n",
       " 'achtervertrek': ['achter', 'B', 'vertrek'],\n",
       " 'achtervoeging': ['achter', 'B', 'voeg', 'ing'],\n",
       " 'achtervoegsel': ['achter', 'B', 'voeg', 'sel'],\n",
       " 'achtervoet': ['achter', 'B', 'voet'],\n",
       " 'achtervolger': ['achter', 'B', 'volg', 'er'],\n",
       " 'achtervolging': ['achter', 'B', 'volg', 'ing'],\n",
       " 'achtervolgingswaanzin': ['achter', 'B', 'volg', 'ing', 's', 'waan', 'zin'],\n",
       " 'achtervolgingswedstrijd': ['achter',\n",
       "  'B',\n",
       "  'volg',\n",
       "  'ing',\n",
       "  's',\n",
       "  'wed',\n",
       "  'strijd'],\n",
       " 'achtervolgster': ['achter', 'B', 'volg', 'ster'],\n",
       " 'achterwaarster': ['achter', 'B', 'waar', 'ster'],\n",
       " 'achterwaarts': ['achter', 'B', 'waarts', 'B'],\n",
       " 'achterwacht': ['achter', 'B', 'wacht'],\n",
       " 'achterwagen': ['achter', 'B', 'wagen'],\n",
       " 'achterweg': ['achter', 'B', 'weg'],\n",
       " 'achterwiel': ['achter', 'B', 'wiel'],\n",
       " 'achterwielaandrijving': ['achter', 'B', 'wiel', 'aan', 'drijf', 'ing', 'NV'],\n",
       " 'achterzak': ['achter', 'B', 'zak'],\n",
       " 'achterzij': ['achter', 'B', 'zij'],\n",
       " 'achterzijde': ['achter', 'B', 'zijde'],\n",
       " 'achterzolder': ['achter', 'B', 'zolder'],\n",
       " 'achthoek': ['acht', 'Q', 'hoek'],\n",
       " 'achthoekig': ['acht', 'Q', 'hoek', 'ig', 'QN'],\n",
       " 'achthonderd': ['acht', 'Q', 'honderd', 'Q', 'Q'],\n",
       " 'achthonderdduizend': ['acht', 'Q', 'honderd', 'Q', 'Q', 'duizend', 'Q', 'Q'],\n",
       " 'achthonderdduizendste': ['acht',\n",
       "  'Q',\n",
       "  'honderd',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'duizend',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achthonderdste': ['acht', 'Q', 'honderd', 'Q', 'Q', 'ste', 'Q', 'Q', 'Q'],\n",
       " 'achtjarig': ['acht', 'Q', 'jaar', 'ig', 'QN'],\n",
       " 'achtkant': ['acht', 'Q', 'kant'],\n",
       " 'achtkantig': ['acht', 'Q', 'kant', 'ig', 'QN'],\n",
       " 'achtmaal': ['acht', 'Q', 'maal', 'B'],\n",
       " 'achtmaands': ['acht', 'Q', 'maand', 's', 'QN'],\n",
       " 'achtpotig': ['acht', 'Q', 'poot', 'ig', 'QN'],\n",
       " 'achtregelig': ['acht', 'Q', 'regel', 'ig', 'QN'],\n",
       " 'achtspan': ['acht', 'Q', 'span'],\n",
       " 'achttal': ['acht', 'Q', 'tal'],\n",
       " 'achttien': ['acht', 'Q', 'tien', 'Q', 'Q'],\n",
       " 'achttiende': ['acht', 'Q', 'tien', 'Q', 'Q', 'de', 'Q', 'Q', 'Q'],\n",
       " 'achttiende-eeuws': ['acht',\n",
       "  'Q',\n",
       "  'tien',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'de',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'eeuw',\n",
       "  's',\n",
       "  'QN'],\n",
       " 'achttienduizend': ['acht', 'Q', 'tien', 'Q', 'Q', 'duizend', 'Q', 'Q'],\n",
       " 'achttienduizendste': ['acht',\n",
       "  'Q',\n",
       "  'tien',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'duizend',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achttienhonderd': ['acht', 'Q', 'tien', 'Q', 'Q', 'honderd', 'Q', 'Q'],\n",
       " 'achttienhonderdste': ['acht',\n",
       "  'Q',\n",
       "  'tien',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'honderd',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achttienjarig': ['acht', 'Q', 'tien', 'Q', 'Q', 'jaar', 'ig', 'QN'],\n",
       " 'achttienmaander': ['acht', 'Q', 'tien', 'Q', 'Q', 'maand', 'er', 'QN'],\n",
       " 'achttienurig': ['acht', 'Q', 'tien', 'Q', 'Q', 'uur', 'ig', 'QN'],\n",
       " 'achturemis': ['acht', 'Q', 'uur', 'e', 'QN', 'mis'],\n",
       " 'achturendag': ['acht', 'Q', 'uur', 'en', 'QN', 'dag'],\n",
       " 'achturig': ['acht', 'Q', 'uur', 'ig', 'QN'],\n",
       " 'achtvlak': ['acht', 'Q', 'vlak'],\n",
       " 'achtvlakkig': ['acht', 'Q', 'vlak', 'ig', 'QN'],\n",
       " 'achtvoetig': ['acht', 'Q', 'voet', 'ig', 'QN'],\n",
       " 'achtzijdig': ['acht', 'Q', 'zijde', 'ig', 'QN'],\n",
       " 'acidimetrie': ['acidimeter', 'ie'],\n",
       " 'aconceptief': ['a', 'Nx', 'concept', 'ie', 'ief', 'xN'],\n",
       " 'acquisitief': ['acquisitie', 'ief'],\n",
       " 'acrobate': ['acrobaat', 'e'],\n",
       " 'acrobatentoer': ['acrobaat', 'en', 'toer'],\n",
       " 'acrobatie': ['acrobaat', 'isch', 'ie'],\n",
       " 'acrobatiek': ['acrobaat', 'isch', 'iek'],\n",
       " 'acrobatisch': ['acrobaat', 'isch'],\n",
       " 'acteur': ['acteer', 'eur'],\n",
       " 'acteursfilm': ['acteer', 'eur', 's', 'film'],\n",
       " 'acteurskwaliteit': ['acteer', 'eur', 's', 'kwaliteit'],\n",
       " 'acteursloopbaan': ['acteer', 'eur', 's', 'loop', 'baan'],\n",
       " 'acteursprestatie': ['acteer', 'eur', 's', 'presteer', 'atie'],\n",
       " 'actieveling': ['actie', 'ief', 'eling'],\n",
       " 'actievoerster': ['actie', 'voer', 'ster', 'NV'],\n",
       " 'actinisch': ['actine', 'isch'],\n",
       " 'activering': ['actief', 'eer', 'ing'],\n",
       " 'activeringsschool': ['actief', 'eer', 'ing', 's', 'school'],\n",
       " 'activiteit': ['actie', 'ief', 'iteit'],\n",
       " 'activiteitenanalyse': ['actie', 'ief', 'iteit', 'en', 'analyse'],\n",
       " 'activiteitencentrum': ['actie', 'ief', 'iteit', 'en', 'centrum'],\n",
       " 'activiteitenpakket': ['actie', 'ief', 'iteit', 'en', 'pakket'],\n",
       " 'activiteitenprogramma': ['actie', 'ief', 'iteit', 'en', 'programma'],\n",
       " 'activiteitsniveau': ['actie', 'ief', 'iteit', 's', 'niveau'],\n",
       " 'actualisering': ['actueel', 'eer', 'ing'],\n",
       " 'actualiteit': ['actueel', 'iteit'],\n",
       " 'actualiteitenprogramma': ['actueel', 'iteit', 'en', 'programma'],\n",
       " 'actualiteitenrubriek': ['actueel', 'iteit', 'en', 'rubriek'],\n",
       " 'actualiteitskarakter': ['actueel', 'iteit', 's', 'karakter'],\n",
       " 'actuariaat': ['actuaris', 'aat'],\n",
       " 'actuarieel': ['actuaris', 'eel'],\n",
       " 'acultureel': ['a', 'cultuur', 'eel'],\n",
       " 'acupuncturist': ['acupunctuur', 'ist'],\n",
       " 'adamsappel': ['Adam', 's', 'appel'],\n",
       " 'adamskostuum': ['Adam', 's', 'kostuum'],\n",
       " 'adaptatie': ['adapteer', 'atie'],\n",
       " 'adaptief': ['adapteer', 'atie', 'ief'],\n",
       " 'additie': ['addeer', 'itie'],\n",
       " 'additief': ['addeer', 'itie', 'ief'],\n",
       " 'additioneel': ['addeer', 'itie', 'ioneel'],\n",
       " 'adembeklemmend': ['adem', 'be', 'klem', 'end', 'NV'],\n",
       " 'adembenemend': ['adem', 'be', 'neem', 'end', 'NV'],\n",
       " 'ademhaling': ['adem', 'haal', 'ing'],\n",
       " 'ademhalingsapparaat': ['adem', 'haal', 'ing', 's', 'apparaat'],\n",
       " 'ademhalingscentrum': ['adem', 'haal', 'ing', 's', 'centrum'],\n",
       " 'ademhalingsdepressie': ['adem', 'haal', 'ing', 's', 'depressie'],\n",
       " 'ademhalingsfrequentie': ['adem', 'haal', 'ing', 's', 'frequent', 'ie'],\n",
       " 'ademhalingsfunctie': ['adem', 'haal', 'ing', 's', 'functie'],\n",
       " 'ademhalingsgymnastiek': ['adem', 'haal', 'ing', 's', 'gymnastisch', 'iek'],\n",
       " 'ademhalingsinsufficientie': ['adem',\n",
       "  'haal',\n",
       "  'ing',\n",
       "  's',\n",
       "  'in',\n",
       "  'sufficient',\n",
       "  'ie'],\n",
       " 'ademhalingsklacht': ['adem', 'haal', 'ing', 's', 'klacht'],\n",
       " 'ademhalingsmoeilijkheid': ['adem',\n",
       "  'haal',\n",
       "  'ing',\n",
       "  's',\n",
       "  'moei',\n",
       "  'lijk',\n",
       "  'heid'],\n",
       " 'ademhalingsoefening': ['adem', 'haal', 'ing', 's', 'oefen', 'ing'],\n",
       " 'ademhalingsorgaan': ['adem', 'haal', 'ing', 's', 'orgaan'],\n",
       " 'ademhalingsprobleem': ['adem', 'haal', 'ing', 's', 'probleem'],\n",
       " 'ademhalingsritme': ['adem', 'haal', 'ing', 's', 'ritme'],\n",
       " 'ademhalingsstoornis': ['adem', 'haal', 'ing', 's', 'stoor', 'nis'],\n",
       " 'ademhalingssysteem': ['adem', 'haal', 'ing', 's', 'systeem'],\n",
       " 'ademhalingstechniek': ['adem', 'haal', 'ing', 's', 'technisch', 'iek'],\n",
       " 'ademhalingstherapie': ['adem', 'haal', 'ing', 's', 'therapie'],\n",
       " 'ademhalingswerktuigen': ['adem', 'haal', 'ing', 's', 'werk', 'tuig'],\n",
       " 'aderlating': ['ader', 'laat', 'ing'],\n",
       " 'aderontsteking': ['ader', 'ontsteek', 'ing', 'NV'],\n",
       " 'aderverkalking': ['ader', 'ver', 'kalk', 'ing', 'NV'],\n",
       " 'adhesiebetuiging': ['adhesie', 'be', 'tuig', 'ing', 'NV'],\n",
       " 'adjectivisch': ['adjectief', 'isch'],\n",
       " 'adjudant-onderofficier': ['adjudant', 'onder', 'officier'],\n",
       " 'adjunct-administrateur': ['adjunct', 'administreer', 'ateur'],\n",
       " 'adjunct-commies': ['adjunct', 'commies'],\n",
       " 'adjunct-commissaris': ['adjunct', 'commissaris'],\n",
       " 'adjunct-directeur': ['adjunct', 'directeur'],\n",
       " 'adjunct-hoofdredacteur': ['adjunct', 'hoofd', 'redacteur'],\n",
       " 'adjunct-secretaris': ['adjunct', 'secretaris'],\n",
       " 'administrateur': ['administreer', 'ateur'],\n",
       " 'administratie': ['administreer', 'atie'],\n",
       " 'administratiefrechtelijk': ['administreer', 'atie', 'ief', 'recht', 'elijk'],\n",
       " 'administratiegebouw': ['administreer', 'atie', 'ge', 'bouw'],\n",
       " 'administratiekantoor': ['administreer', 'atie', 'kantoor'],\n",
       " 'administratiekosten': ['administreer', 'atie', 'kost'],\n",
       " 'administratief': ['administreer', 'atie', 'ief'],\n",
       " 'admiraal-generaal': ['admiraal', 'generaal'],\n",
       " 'admissie-examen': ['admissie', 'examen'],\n",
       " 'adnominaal': ['ad', 'Nx', 'nomen', 'aal', 'xN'],\n",
       " 'adolescentiepsychologie': ['adolescent', 'ie', 'psychologisch', 'ie'],\n",
       " 'adoptant': ['adopteer', 'ant'],\n",
       " 'adoptiefkind': ['adoptie', 'ief', 'kind'],\n",
       " 'adoptiefouders': ['adoptie', 'ief', 'ouder'],\n",
       " 'adoptiefzoon': ['adoptie', 'ief', 'zoon'],\n",
       " 'adoptief': ['adoptie', 'ief'],\n",
       " 'adorabel': ['adoreer', 'abel'],\n",
       " 'adoratie': ['adoreer', 'atie'],\n",
       " 'adrenaline-injectie': ['adrenaline', 'injectie'],\n",
       " 'adressant': ['adres', 'eer', 'ant'],\n",
       " 'adressante': ['adres', 'eer', 'ant', 'e'],\n",
       " 'adresschrijver': ['adres', 'schrijf', 'er', 'NV'],\n",
       " 'adresseermachine': ['adres', 'eer', 'machine'],\n",
       " 'adressenbank': ['adres', 'en', 'bank'],\n",
       " 'adressenlijst': ['adres', 'en', 'lijst'],\n",
       " 'adressenschrijver': ['adres', 'en', 'Vx', 'schrijf', 'er', 'NxV'],\n",
       " 'adressering': ['adres', 'eer', 'ing'],\n",
       " 'adreswijziging': ['adres', 'wijzig', 'ing', 'NV'],\n",
       " 'adverbiaal': ['adverbium', 'aal'],\n",
       " 'advertentie': ['adverteer', 'entie'],\n",
       " 'advertentieacquisiteur': ['adverteer', 'entie', 'acquisiteur'],\n",
       " 'advertentieacquisitie': ['adverteer', 'entie', 'acquisitie'],\n",
       " 'advertentiebeleid': ['adverteer', 'entie', 'beleid'],\n",
       " 'advertentiebezetting': ['adverteer', 'entie', 'be', 'zet', 'ing'],\n",
       " 'advertentieblad': ['adverteer', 'entie', 'blad'],\n",
       " 'advertentiebureau': ['adverteer', 'entie', 'bureau'],\n",
       " 'advertentiecampagne': ['adverteer', 'entie', 'campagne'],\n",
       " 'advertentie-exploitatie': ['adverteer', 'entie', 'exploiteer', 'atie'],\n",
       " 'advertentie-inkomst': ['adverteer', 'entie', 'in', 'kom', 'st'],\n",
       " 'advertentiekolom': ['adverteer', 'entie', 'kolom'],\n",
       " 'advertentiekosten': ['adverteer', 'entie', 'kost'],\n",
       " 'advertentiepagina': ['adverteer', 'entie', 'pagina'],\n",
       " 'advertentieruimte': ['adverteer', 'entie', 'ruim', 'te'],\n",
       " 'advertentietarief': ['adverteer', 'entie', 'tarief'],\n",
       " 'advertentietekst': ['adverteer', 'entie', 'tekst'],\n",
       " 'advertentievolume': ['adverteer', 'entie', 'volume'],\n",
       " 'adviescommissie': ['advies', 'con', 'missie'],\n",
       " 'adviseur': ['advies', 'eer', 'eur'],\n",
       " 'advocaatje': ['advocaat'],\n",
       " 'advocaat-fiscaal': ['advocaat', 'fiscaal'],\n",
       " 'advocaat-generaal': ['advocaat', 'generaal'],\n",
       " 'advocate': ['advocaat', 'e'],\n",
       " 'advocatenbureau': ['advocaat', 'en', 'bureau'],\n",
       " 'advocatencollectief': ['advocaat', 'en', 'collectief'],\n",
       " 'advocatenfirma': ['advocaat', 'en', 'firma'],\n",
       " 'advocatenkamer': ['advocaat', 'en', 'kamer'],\n",
       " 'advocatenkantoor': ['advocaat', 'en', 'kantoor'],\n",
       " 'advocatenpraktijk': ['advocaat', 'en', 'praktijk'],\n",
       " 'advocatenstreek': ['advocaat', 'en', 'streek'],\n",
       " 'advocaterij': ['advocaat', 'erij'],\n",
       " 'advocatie': ['advocaat', 'ie'],\n",
       " 'advocatuur': ['advocaat', 'uur'],\n",
       " 'aeratie': ['aereer', 'atie'],\n",
       " 'aerofobie': ['aero', 'fobisch', 'ie'],\n",
       " 'aerometer': ['aero', 'meet', 'er'],\n",
       " 'aeronautiek': ['aero', 'nautisch', 'iek'],\n",
       " 'aerosolverpakking': ['aero', 'sol', 'ver', 'pak', 'ing'],\n",
       " 'afbestelling': ['af', 'bestel', 'ing'],\n",
       " 'afbetaling': ['af', 'betaal', 'ing'],\n",
       " 'afbetalingscontract': ['af', 'betaal', 'ing', 's', 'contract'],\n",
       " 'afbetalingsstelsel': ['af', 'betaal', 'ing', 's', 'stel', 'sel'],\n",
       " 'afbetalingssysteem': ['af', 'betaal', 'ing', 's', 'systeem'],\n",
       " 'afbetalingstermijn': ['af', 'betaal', 'ing', 's', 'termijn'],\n",
       " 'afbidding': ['af', 'bid', 'ing'],\n",
       " 'afbraakmateriaal': ['af', 'braak', 'materie', 'aal'],\n",
       " 'afbreker': ['af', 'breek', 'er'],\n",
       " 'afbreking': ['af', 'breek', 'ing'],\n",
       " 'afbrekingsteken': ['af', 'breek', 'ing', 's', 'teken'],\n",
       " 'afdaling': ['af', 'daal', 'ing'],\n",
       " 'afdalingsproces': ['af', 'daal', 'ing', 's', 'proces'],\n",
       " 'afdamming': ['af', 'dam', 'ing'],\n",
       " 'afdankertje': ['af', 'dank', 'er'],\n",
       " 'afdekking': ['af', 'dek', 'ing'],\n",
       " 'afdeling': ['af', 'deel', 'ing'],\n",
       " 'afdelingsarts': ['af', 'deel', 'ing', 's', 'arts'],\n",
       " 'afdelingsbestuur': ['af', 'deel', 'ing', 's', 'bestuur'],\n",
       " 'afdelingsbibliotheek': ['af', 'deel', 'ing', 's', 'bibliotheek'],\n",
       " 'afdelingsbijeenkomst': ['af',\n",
       "  'deel',\n",
       "  'ing',\n",
       "  's',\n",
       "  'bijeen',\n",
       "  'B',\n",
       "  'kom',\n",
       "  'st'],\n",
       " 'afdelingschef': ['af', 'deel', 'ing', 's', 'chef'],\n",
       " 'afdelingshoofd': ['af', 'deel', 'ing', 's', 'hoofd'],\n",
       " 'afdelingsniveau': ['af', 'deel', 'ing', 's', 'niveau'],\n",
       " 'afdelingsonderzoek': ['af', 'deel', 'ing', 's', 'onderzoek'],\n",
       " 'afdelingsorganisatie': ['af', 'deel', 'ing', 's', 'orgaan', 'iseer', 'atie'],\n",
       " 'afdelingsvergadering': ['af', 'deel', 'ing', 's', 'vergader', 'ing'],\n",
       " 'afdoener': ['af', 'doe', 'er'],\n",
       " 'afdrager': ['af', 'draag', 'er'],\n",
       " 'afdrijving': ['af', 'drijf', 'ing'],\n",
       " 'afdroging': ['af', 'droog', 'ing'],\n",
       " 'afdrukpapier': ['af', 'druk', 'paap', 'ier'],\n",
       " 'afdwaling': ['af', 'dwaal', 'ing'],\n",
       " 'af-fabriekprijs': ['af', 'fabriek', 'prijs'],\n",
       " 'affectatie': ['affecteer', 'atie'],\n",
       " 'affectief': ['affect', 'ie', 'ief'],\n",
       " 'affichering': ['afficheer', 'ing'],\n",
       " 'affiliatie': ['affilieer', 'atie'],\n",
       " 'affirmatie': ['affirmeer', 'atie'],\n",
       " 'affirmatief': ['affirmeer', 'atie', 'ief'],\n",
       " 'afgeving': ['af', 'geef', 'ing'],\n",
       " 'afgietseldiertje': ['af', 'giet', 'sel', 'dier'],\n",
       " 'afgodendienares': ['afgod', 'en', 'dien', 'aar', 'es'],\n",
       " 'afgraving': ['af', 'graaf', 'ing'],\n",
       " 'afgrijselijk': ['afgrijzen', 'elijk'],\n",
       " 'afgrijselijkheid': ['afgrijzen', 'elijk', 'heid'],\n",
       " 'afgrijslijk': ['afgrijzen', 'lijk'],\n",
       " 'afgrijslijkheid': ['afgrijzen', 'lijk', 'heid'],\n",
       " 'afgrijzenwekkend': ['afgrijzen', 'wek', 'end', 'NV'],\n",
       " 'afhaalrestaurant': ['af', 'haal', 'restaureer', 'ant'],\n",
       " 'afhaker': ['af', 'haak', 'er'],\n",
       " 'afhaler': ['af', 'haal', 'er'],\n",
       " 'afhaling': ['af', 'haal', 'ing'],\n",
       " 'afhandig': ['af', 'hand', 'ig', 'PN'],\n",
       " 'afhankelijk': ['af', 'hang', 'elijk'],\n",
       " 'afhankelijkheid': ['af', 'hang', 'elijk', 'heid'],\n",
       " 'afhankelijkheidsbehoefte': ['af', 'hang', 'elijk', 'heid', 's', 'behoefte'],\n",
       " 'afhankelijkheidspositie': ['af',\n",
       "  'hang',\n",
       "  'elijk',\n",
       "  'heid',\n",
       "  's',\n",
       "  'pose',\n",
       "  'eer',\n",
       "  'itie'],\n",
       " 'afhankelijkheidsrelatie': ['af', 'hang', 'elijk', 'heid', 's', 'relatie'],\n",
       " 'afhelling': ['af', 'hel', 'ing'],\n",
       " 'afhuring': ['af', 'huur', 'ing'],\n",
       " 'afkading': ['af', 'kade', 'ing'],\n",
       " 'afkalving': ['af', 'kalf', 'ing'],\n",
       " 'afkamming': ['af', 'kam', 'ing'],\n",
       " 'afkapping': ['af', 'kap', 'ing'],\n",
       " 'afkappingsteken': ['af', 'kap', 'ing', 's', 'teken'],\n",
       " 'afkerig': ['afkeer', 'ig'],\n",
       " 'afkerigheid': ['afkeer', 'ig', 'heid'],\n",
       " 'afkering': ['af', 'keer', 'ing'],\n",
       " 'afkeurenswaard': ['af', 'keur', 's', 'waard'],\n",
       " 'afkeurenswaardig': ['af', 'keur', 's', 'waarde', 'ig'],\n",
       " 'afklemming': ['af', 'klem', 'ing'],\n",
       " 'afklopper': ['af', 'klop', 'er'],\n",
       " 'afklopping': ['af', 'klop', 'ing'],\n",
       " 'afknaging': ['af', 'knaag', 'ing'],\n",
       " 'afknapper': ['af', 'knap', 'er'],\n",
       " 'afknelling': ['af', 'knel', 'ing'],\n",
       " 'afknotting': ['af', 'knot', 'ing'],\n",
       " 'afkoker': ['af', 'kook', 'er'],\n",
       " 'afkoopbaarstelling': ['af', 'koop', 'baar', 'stel', 'ing'],\n",
       " 'afkoping': ['af', 'koop', 'ing'],\n",
       " 'afkrabber': ['af', 'krab', 'er'],\n",
       " 'aflader': ['af', 'laad', 'er'],\n",
       " 'aflading': ['af', 'laad', 'ing'],\n",
       " 'aflandig': ['af', 'land', 'ig', 'PN'],\n",
       " 'aflating': ['af', 'laat', 'ing'],\n",
       " 'aflegger': ['af', 'leg', 'er'],\n",
       " 'aflegging': ['af', 'leg', 'ing'],\n",
       " 'afleidkundig': ['af', 'leid', 'kunde', 'ig'],\n",
       " 'aflezer': ['af', 'lees', 'er'],\n",
       " 'aflezing': ['af', 'lees', 'ing'],\n",
       " 'aflokking': ['af', 'lok', 'ing'],\n",
       " 'aflosser': ['af', 'los', 'er'],\n",
       " 'aflossing': ['af', 'los', 'ing'],\n",
       " 'aflossingsploeg': ['af', 'los', 'ing', 's', 'ploeg'],\n",
       " 'aflossingstermijn': ['af', 'los', 'ing', 's', 'termijn'],\n",
       " 'aflossingswedstrijd': ['af', 'los', 'ing', 's', 'wed', 'strijd'],\n",
       " 'afluisterapparatuur': ['af', 'luister', 'apparaat', 'uur'],\n",
       " 'afluisterpraktijken': ['af', 'luister', 'praktijk'],\n",
       " 'afmaker': ['af', 'maak', 'er'],\n",
       " 'afmaking': ['af', 'maak', 'ing'],\n",
       " 'afmatting': ['af', 'mat', 'ing'],\n",
       " 'afmeting': ['af', 'meet', 'ing'],\n",
       " 'afmuring': ['af', 'muur', 'ing'],\n",
       " 'afname': ['af', 'neem'],\n",
       " 'afnemer': ['af', 'neem', 'er'],\n",
       " 'afnemerskrediet': ['af', 'neem', 'er', 's', 'krediet'],\n",
       " 'afneming': ['af', 'neem', 'ing'],\n",
       " 'afonie': ['afoon', 'ie'],\n",
       " 'afpakking': ['af', 'pak', 'ing'],\n",
       " 'afpaling': ['af', 'paal', 'ing'],\n",
       " 'afpassing': ['af', 'pas', 'ing'],\n",
       " 'afplatting': ['af', 'plat', 'ing'],\n",
       " 'afpluizing': ['af', 'pluis', 'ing'],\n",
       " 'afreding': ['af', 'reed', 'ing'],\n",
       " 'afreehekel': ['af', 'reed', 'hekel'],\n",
       " 'afrikanisering': ['Afrikaan', 'iseer', 'ing'],\n",
       " 'afrodisie': ['afrodisiacum', 'ie'],\n",
       " 'afromer': ['af', 'room', 'er'],\n",
       " 'afroming': ['af', 'room', 'ing'],\n",
       " 'afrossing': ['af', 'ros', 'ing'],\n",
       " 'afrotting': ['af', 'rot', 'ing'],\n",
       " 'afroving': ['af', 'roof', 'ing'],\n",
       " 'afrukking': ['af', 'ruk', 'ing'],\n",
       " 'afschaffer': ['af', 'schaf', 'er'],\n",
       " 'afschaffergenootschap': ['af', 'schaf', 'er', 'genoot', 'schap'],\n",
       " 'afschaffing': ['af', 'schaf', 'ing'],\n",
       " 'afschaveling': ['afschaveel', 'ing'],\n",
       " 'afscheidsvoorstelling': ['afscheid', 's', 'voor', 'B', 'stel', 'ing'],\n",
       " 'afscheper': ['af', 'scheep', 'er'],\n",
       " 'afscheping': ['af', 'scheep', 'ing'],\n",
       " 'afschering': ['af', 'scheer', 'ing'],\n",
       " 'afscherving': ['af', 'scherf', 'ing'],\n",
       " 'afschrabber': ['af', 'schrab', 'er'],\n",
       " 'afschraper': ['af', 'schraap', 'er'],\n",
       " 'afschrijver': ['af', 'schrijf', 'er'],\n",
       " 'afschrijving': ['af', 'schrijf', 'ing'],\n",
       " 'afschrijvingsbank': ['af', 'schrijf', 'ing', 's', 'bank'],\n",
       " 'afschrijvingsperiode': ['af', 'schrijf', 'ing', 's', 'periode'],\n",
       " 'afschrikking': ['af', 'schrik', 'ing'],\n",
       " 'afschrikwekkend': ['af', 'schrik', 'wek', 'end', 'NV'],\n",
       " 'afschuiving': ['af', 'schuif', 'ing'],\n",
       " 'afschuring': ['af', 'schuur', 'ing'],\n",
       " 'afschutting': ['af', 'schut', 'ing'],\n",
       " 'afschuwwekkend': ['afschuw', 'wek', 'end', 'NV'],\n",
       " 'afsleping': ['af', 'sleep', 'ing'],\n",
       " 'afsloting': ['af', 'sloot', 'ing'],\n",
       " 'afsloving': ['af', 'sloof', 'ing'],\n",
       " 'afsmeking': ['af', 'smeek', 'ing'],\n",
       " 'afsnijschaar': ['af', 'snijd', 'schaar'],\n",
       " 'afsnijsel': ['af', 'snijd', 'sel'],\n",
       " 'afspanning': ['af', 'span', 'ing'],\n",
       " 'afspatting': ['af', 'spat', 'ing'],\n",
       " 'afspeelapparatuur': ['af', 'speel', 'apparaat', 'uur'],\n",
       " 'afstammeling': ['af', 'stam', 'eling'],\n",
       " 'afstammelinge': ['af', 'stam', 'eling', 'e'],\n",
       " 'afstamming': ['af', 'stam', 'ing'],\n",
       " 'afstammingsleer': ['af', 'stam', 'ing', 's', 'leer'],\n",
       " 'afstammingstheorie': ['af', 'stam', 'ing', 's', 'theorie'],\n",
       " 'afstandmeter': ['afstand', 'meet', 'er', 'NV'],\n",
       " 'afstandmeting': ['afstand', 'meet', 'ing', 'NV'],\n",
       " 'afstandsbepaling': ['afstand', 's', 'Vx', 'be', 'paal', 'ing', 'NxV'],\n",
       " 'afstandsbesturing': ['afstand', 's', 'be', 'stuur', 'ing'],\n",
       " 'afstandswijzer': ['afstand', 's', 'Vx', 'wijs', 'er', 'NxV'],\n",
       " 'afsteker': ['af', 'steek', 'er'],\n",
       " 'afsteking': ['af', 'steek', 'ing'],\n",
       " 'afstelling': ['af', 'stel', 'ing'],\n",
       " 'afstemmer': ['af', 'stem', 'er'],\n",
       " 'afstemming': ['af', 'stem', 'ing'],\n",
       " 'afstemmingsprobleem': ['af', 'stem', 'ing', 's', 'probleem'],\n",
       " 'afsterving': ['af', 'sterf', 'ing'],\n",
       " 'afstervingsproces': ['af', 'sterf', 'ing', 's', 'proces'],\n",
       " 'afstotelijk': ['af', 'stoot', 'elijk'],\n",
       " 'afstoting': ['af', 'stoot', 'ing'],\n",
       " 'afstotingskracht': ['af', 'stoot', 'ing', 's', 'kracht'],\n",
       " 'afstotingsreactie': ['af', 'stoot', 'ing', 's', 're', 'actie'],\n",
       " 'afstraffing': ['af', 'straf', 'ing'],\n",
       " 'afstraling': ['af', 'straal', 'ing'],\n",
       " 'afstroming': ['af', 'stroom', 'ing'],\n",
       " 'afstuiving': ['af', 'stuif', 'ing'],\n",
       " 'aftakking': ['af', 'tak', 'ing'],\n",
       " 'aftapper': ['af', 'tap', 'er'],\n",
       " 'aftapping': ['af', 'tap', 'ing'],\n",
       " 'aftelliedje': ['af', 'tel', 'lied'],\n",
       " 'aftelling': ['af', 'tel', 'ing'],\n",
       " ...}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_en(df):\n",
    "\n",
    "    out = {}\n",
    "    same = {}\n",
    "\n",
    "    for word, segs in df.items():\n",
    "        # if word[-2:] == 'en':\n",
    "        #     out[word] = segs + ['en']\n",
    "        # else:\n",
    "        #     same[word] = segs\n",
    "        \n",
    "        out[word] = segs + ['en']\n",
    "    \n",
    "\n",
    "    \n",
    "    return out, same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2, same = add_en(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['a'],\n",
       " 'Aafje': [''],\n",
       " 'Aafke': [''],\n",
       " 'Aagje': [''],\n",
       " 'aagt': ['aagt'],\n",
       " 'aagtappel': ['aagt', 'appel'],\n",
       " 'aai': ['aai'],\n",
       " 'aaiing': ['aai', 'ing'],\n",
       " 'aak': ['aak'],\n",
       " 'aal': ['aal'],\n",
       " 'aaltje': [''],\n",
       " 'aaltjes': [''],\n",
       " 'aalbes': ['aal', 'bes'],\n",
       " 'aalbessengelei': ['aalbes', 'en', 'gelei'],\n",
       " 'aalbessenjam': ['aalbes', 'en', 'jam'],\n",
       " 'aalbessenjenever': ['aalbes', 'en', 'jenever'],\n",
       " 'aalbessesap': ['aalbes', 'e', 'sap'],\n",
       " 'aalbessestruik': ['aalbes', 'e', 'struik'],\n",
       " 'Aalders': [''],\n",
       " 'aalelger': ['aal', 'elger'],\n",
       " 'aalfuik': ['aal', 'fuik'],\n",
       " 'aalgeer': [''],\n",
       " 'aalglad': ['aal', 'glad'],\n",
       " 'aalkaar': ['aal', 'kaar'],\n",
       " 'aalkast': ['aal', 'kast'],\n",
       " 'aalkorf': ['aal', 'korf'],\n",
       " 'aalkuip': ['aal', 'kuip'],\n",
       " 'aalkwab': ['aal', 'kwab'],\n",
       " 'aalkwabbe': [''],\n",
       " 'aalmoes': [''],\n",
       " 'aalmoezenier': ['aalmoes', 'enier'],\n",
       " 'aalmoezenierskamer': ['aalmoezenier', 's', 'kamer'],\n",
       " 'aalpomp': ['aal', 'pomp'],\n",
       " 'aalput': ['aal', 'put'],\n",
       " 'aalreep': ['aal', 'reep'],\n",
       " 'aalreiger': ['aal', 'reiger'],\n",
       " 'aalschaar': ['aal', 'schaar'],\n",
       " 'aalscholver': ['aal', 'scholver'],\n",
       " 'aalshuid': ['aal', 's', 'huid'],\n",
       " 'aalskruik': ['aal', 's', 'kruik'],\n",
       " 'Aalsmeer': [''],\n",
       " 'aalspeer': ['aal', 'speer'],\n",
       " 'Aalst': [''],\n",
       " 'aalstal': ['aal', 'stal'],\n",
       " 'aalsteek': ['aal', 'steek'],\n",
       " 'aalsteker': ['aal', 'steek', 'er'],\n",
       " 'aalsvel': ['aal', 's', 'vel'],\n",
       " 'aalt': ['aalt'],\n",
       " 'a-al-tolletje': [''],\n",
       " 'aalvork': ['aal', 'vork'],\n",
       " 'aalvormig': ['aal', 'vorm', 'ig'],\n",
       " 'aam': ['aam'],\n",
       " 'aambeeld': [''],\n",
       " 'aambeeldsbeentje': ['aambeeld', 's', 'been'],\n",
       " 'aambeeldsblok': ['aambeeld', 's', 'blok'],\n",
       " 'aambei': [''],\n",
       " 'aambeienkruid': ['aambei', 'en', 'kruid'],\n",
       " 'aamborstig': ['aam', 'borst', 'ig'],\n",
       " 'aamborstigheid': ['aamborstig', 'heid'],\n",
       " 'aamt': ['aamt'],\n",
       " 'aan': ['aan'],\n",
       " 'aanaarding': ['aanaard', 'ing'],\n",
       " 'aanaardploeg': ['aanaard', 'ploeg'],\n",
       " 'aanademing': [''],\n",
       " 'aanbaksel': ['aanbak', 'sel'],\n",
       " 'aanbeeld': [''],\n",
       " 'aanbeeldsbeentje': ['aanbeeld', 's', 'been'],\n",
       " 'aanbeeldsblok': ['aanbeeld', 's', 'blok'],\n",
       " 'aanbelang': ['aan', 'belang'],\n",
       " 'aanberming': ['aanberm', 'ing'],\n",
       " 'aanbesteder': ['aanbesteed', 'er'],\n",
       " 'aanbesteding': ['aanbesteed', 'ing'],\n",
       " 'aanbetaling': ['aan', 'betaling'],\n",
       " 'aanbevelenswaard': ['aanbeveel', 's', 'waard'],\n",
       " 'aanbevelenswaardig': ['aanbeveel', 's', 'waardig'],\n",
       " 'aanbeveling': ['aanbeveel', 'ing'],\n",
       " 'aanbevelingsbrief': ['aanbeveling', 's', 'brief'],\n",
       " 'aanbiddelijk': ['aanbid', 'elijk'],\n",
       " 'aanbiddenswaardig': ['aanbid', 's', 'waardig'],\n",
       " 'aanbidder': ['aanbid', 'er'],\n",
       " 'aanbidding': ['aanbid', 'ing'],\n",
       " 'aanbidster': ['aanbid', 'ster'],\n",
       " 'aanbieding': ['aanbied', 'ing'],\n",
       " 'aanbiedingsbrief': ['aanbieding', 's', 'brief'],\n",
       " 'aanblazing': ['aanblaas', 'ing'],\n",
       " 'aanblik': ['aan', 'blik'],\n",
       " 'aanbod': [''],\n",
       " 'aanbodcurve': ['aanbod', 'curve'],\n",
       " 'aanbodstructuur': ['aanbod', 'structuur'],\n",
       " 'aanbouw': [''],\n",
       " 'aanbouwing': ['aanbouw', 'ing'],\n",
       " 'aanbouwsel': ['aanbouw', 'sel'],\n",
       " 'aanbreisel': ['aanbrei', 'sel'],\n",
       " 'aanbreng': [''],\n",
       " 'aanbrenger': ['aanbreng', 'er'],\n",
       " 'aanbrenging': ['aanbreng', 'ing'],\n",
       " 'aanbrengpremie': ['aanbreng', 'premie'],\n",
       " 'aanbrengst': ['aanbreng', 'st'],\n",
       " 'aanbrug': ['aan', 'brug'],\n",
       " 'aandacht': [''],\n",
       " 'aandachtig': [''],\n",
       " 'aandachtigheid': ['aandachtig', 'heid'],\n",
       " 'aandachtsconcentratie': ['aandacht', 's', 'concentratie'],\n",
       " 'aandachtseenheid': ['aandacht', 's', 'eenheid'],\n",
       " 'aandachtsproces': ['aandacht', 's', 'proces'],\n",
       " 'aandachtsstreep': ['aandacht', 's', 'streep'],\n",
       " 'aandachtsteken': ['aandacht', 's', 'teken'],\n",
       " 'aandachtsveld': ['aandacht', 's', 'veld'],\n",
       " 'aandachttrekkerij': ['aandacht', 'trek', 'erij'],\n",
       " 'aandak': ['aan', 'dak'],\n",
       " 'aandamming': ['aandam', 'ing'],\n",
       " 'aandeel': ['aan', 'deel'],\n",
       " 'aandeelbewijs': ['aandeel', 'bewijs'],\n",
       " 'aandeelhebber': ['aandeel', 'heb', 'er'],\n",
       " 'aandeelhouder': ['aandeel', 'houd', 'er'],\n",
       " 'aandeelhoudersvergadering': ['aandeelhouder', 's', 'vergadering'],\n",
       " 'aandelenkapitaal': ['aandeel', 'en', 'kapitaal'],\n",
       " 'aandelenoptie': ['aandeel', 'en', 'optie'],\n",
       " 'aandelenpakket': ['aandeel', 'en', 'pakket'],\n",
       " 'aandelenportefeuille': ['aandeel', 'en', 'portefeuille'],\n",
       " 'aandenken': ['aan', 'denken'],\n",
       " 'aandijking': ['aandijk', 'ing'],\n",
       " 'aandoening': ['aandoe', 'ing'],\n",
       " 'aandoenlijk': ['aandoe', 'lijk'],\n",
       " 'aandoenlijkheid': ['aandoenlijk', 'heid'],\n",
       " 'aandrager': ['aandraag', 'er'],\n",
       " 'aandrang': [''],\n",
       " 'aandrift': ['aan', 'drift'],\n",
       " 'aandrijfas': ['aandrijf', 'as'],\n",
       " 'aandrijfketting': ['aandrijf', 'ketting'],\n",
       " 'aandrijfkracht': ['aandrijf', 'kracht'],\n",
       " 'aandrijfsysteem': ['aandrijf', 'systeem'],\n",
       " 'aandrijver': ['aandrijf', 'er'],\n",
       " 'aandrijving': ['aandrijf', 'ing'],\n",
       " 'aanduiding': ['aanduid', 'ing'],\n",
       " 'aaneen': [''],\n",
       " 'aaneengeboren': ['aaneen', 'geboren'],\n",
       " 'aaneengeschakeld': [''],\n",
       " 'aaneengesloten': [''],\n",
       " 'aaneengroeiing': ['aaneengroei', 'ing'],\n",
       " 'aaneenkoppeling': ['aaneenkoppel', 'ing'],\n",
       " 'aaneenrijging': ['aaneenrijg', 'ing'],\n",
       " 'aaneenschakelend': [''],\n",
       " 'aaneenschakeling': ['aaneenschakel', 'ing'],\n",
       " 'aaneensluiting': ['aaneensluit', 'ing'],\n",
       " 'aaneenvoeging': ['aaneenvoeg', 'ing'],\n",
       " 'aanfluiting': ['aanfluit', 'ing'],\n",
       " 'aanfok': [''],\n",
       " 'aanfokking': ['aanfok', 'ing'],\n",
       " 'aangaande': [''],\n",
       " 'aangebedene': [''],\n",
       " 'aangeblazen': [''],\n",
       " 'aangebonden': [''],\n",
       " 'aangeboren': ['aan', 'geboren'],\n",
       " 'aangeborenheid': ['aangeboren', 'heid'],\n",
       " 'aangebrand': [''],\n",
       " 'aangedaan': [''],\n",
       " 'aangeefster': ['aangeef', 'ster'],\n",
       " 'aangeerfd': [''],\n",
       " 'aangehuwd': [''],\n",
       " 'aangeklaagde': [''],\n",
       " 'aangekleed': [''],\n",
       " 'aangelande': ['aangeland', 'e'],\n",
       " 'aangeleerd': [''],\n",
       " 'aangelegd': [''],\n",
       " 'aangelegen': [''],\n",
       " 'aangelegenheid': ['aangelegen', 'heid'],\n",
       " 'aangeleund': [''],\n",
       " 'aangenaam': [''],\n",
       " 'aangenaamheid': ['aangenaam', 'heid'],\n",
       " 'aangenomen': [''],\n",
       " 'aangepast': [''],\n",
       " 'aangeschoten': [''],\n",
       " 'aangeschreven': [''],\n",
       " 'aangeslagen': [''],\n",
       " 'aangestoken': [''],\n",
       " 'aangetekend': [''],\n",
       " 'aangetogen': [''],\n",
       " 'aangetrouwd': [''],\n",
       " 'aangever': ['aangeef', 'er'],\n",
       " 'aangeving': ['aangeef', 'ing'],\n",
       " 'aangewezen': [''],\n",
       " 'aangezicht': ['aan', 'gezicht'],\n",
       " 'aangezichtsligging': ['aangezicht', 's', 'ligging'],\n",
       " 'aangezichtspijn': ['aangezicht', 's', 'pijn'],\n",
       " 'aangezien': [''],\n",
       " 'aangietkleur': ['aangiet', 'kleur'],\n",
       " 'aangifte': [''],\n",
       " 'aangiftebereidheid': ['aangifte', 'bereidheid'],\n",
       " 'aangiftebiljet': ['aangifte', 'biljet'],\n",
       " 'aangifteformulier': ['aangifte', 'formulier'],\n",
       " 'aangifteplicht': ['aangifte', 'plicht'],\n",
       " 'aangraving': ['aangraaf', 'ing'],\n",
       " 'aangrenzend': ['aan', 'grenzend'],\n",
       " 'aangrijpend': [''],\n",
       " 'aangrijping': ['aangrijp', 'ing'],\n",
       " 'aangrijpingspunt': ['aangrijping', 's', 'punt'],\n",
       " 'aangroei': [''],\n",
       " 'aangroeiing': ['aangroei', 'ing'],\n",
       " 'aanhalerig': ['aanhaal', 'erig'],\n",
       " 'aanhalerigheid': ['aanhalerig', 'heid'],\n",
       " 'aanhalig': ['aanhaal', 'ig'],\n",
       " 'aanhaligheid': ['aanhalig', 'heid'],\n",
       " 'aanhaling': ['aanhaal', 'ing'],\n",
       " 'aanhalingsteken': ['aanhaling', 's', 'teken'],\n",
       " 'aanhang': [''],\n",
       " 'aanhangeling': ['aanhang', 'eling'],\n",
       " 'aanhangelinge': ['aanhangeling', 'e'],\n",
       " 'aanhanger': ['aanhang', 'er'],\n",
       " 'aanhangig': ['aanhang', 'ig'],\n",
       " 'aanhangsel': ['aanhang', 'sel'],\n",
       " 'aanhangster': ['aanhang', 'ster'],\n",
       " 'aanhangwagen': ['aanhang', 'wagen'],\n",
       " 'aanhankelijk': ['aanhang', 'elijk'],\n",
       " 'aanhankelijkheid': ['aanhankelijk', 'heid'],\n",
       " 'aanharding': ['aanhard', 'ing'],\n",
       " 'aanhechting': ['aanhecht', 'ing'],\n",
       " 'aanhechtingspunt': ['aanhechting', 's', 'punt'],\n",
       " 'aanhechtsel': ['aanhecht', 'sel'],\n",
       " 'aanhef': [''],\n",
       " 'aanheffer': ['aanhef', 'er'],\n",
       " 'aanheffing': ['aanhef', 'ing'],\n",
       " 'aanhitser': ['aanhits', 'er'],\n",
       " 'aanhitsing': ['aanhits', 'ing'],\n",
       " 'aanhoorder': ['aanhoor', 'der'],\n",
       " 'aanhoorster': ['aanhoor', 'ster'],\n",
       " 'aanhoping': ['aanhoop', 'ing'],\n",
       " 'aanhorig': [''],\n",
       " 'aanhorigheid': ['aanhorig', 'heid'],\n",
       " 'aanhoudend': [''],\n",
       " 'aanhoudendheid': ['aanhoudend', 'heid'],\n",
       " 'aanhouder': ['aanhoud', 'er'],\n",
       " 'aanhouderij': ['aanhoud', 'erij'],\n",
       " 'aanhouding': ['aanhoud', 'ing'],\n",
       " 'aanhoudingsbevel': ['aanhouding', 's', 'bevel'],\n",
       " 'aanhoudingspremie': ['aanhouding', 's', 'premie'],\n",
       " 'aanhoudster': ['aanhoud', 'ster'],\n",
       " 'aanhuwing': ['aanhuw', 'ing'],\n",
       " 'aanjager': ['aanjaag', 'er'],\n",
       " 'aankap': [''],\n",
       " 'aanklaagster': ['aanklaag', 'ster'],\n",
       " 'aanklacht': [''],\n",
       " 'aanklager': ['aanklaag', 'er'],\n",
       " 'aanklamping': ['aanklamp', 'ing'],\n",
       " 'aankleding': ['aankleed', 'ing'],\n",
       " 'aankleef': [''],\n",
       " 'aankleve': [''],\n",
       " 'aankleving': ['aankleef', 'ing'],\n",
       " 'aanknoping': ['aanknoop', 'ing'],\n",
       " 'aanknopingspunt': ['aanknoping', 's', 'punt'],\n",
       " 'aankomeling': ['aankom', 'eling'],\n",
       " 'aankomelinge': ['aankomeling', 'e'],\n",
       " 'aankomelingschap': ['aankomeling', 'schap'],\n",
       " 'aankomend': [''],\n",
       " 'aankomst': ['aankom', 'st'],\n",
       " 'aankomstdatum': ['aankomst', 'datum'],\n",
       " 'aankomsthal': ['aankomst', 'hal'],\n",
       " 'aankomsttijd': ['aankomst', 'tijd'],\n",
       " 'aankondiger': ['aankondig', 'er'],\n",
       " 'aankondiging': ['aankondig', 'ing'],\n",
       " 'aankondigster': ['aankondig', 'ster'],\n",
       " 'aankoop': ['aan', 'koop'],\n",
       " 'aankoopsom': ['aankoop', 'som'],\n",
       " 'aankoppeling': ['aankoppel', 'ing'],\n",
       " 'aankorsting': ['aankorst', 'ing'],\n",
       " 'aankruiing': ['aankrui', 'ing'],\n",
       " 'aankweek': [''],\n",
       " 'aankweking': ['aankweek', 'ing'],\n",
       " 'aanlandig': ['aanland', 'ig'],\n",
       " 'aanlanding': ['aanland', 'ing'],\n",
       " 'aanlassing': ['aanlas', 'ing'],\n",
       " 'aanleg': [''],\n",
       " 'aanlegger': ['aanleg', 'er'],\n",
       " 'aanlegging': ['aanleg', 'ing'],\n",
       " 'aanleghaven': ['aanleg', 'haven'],\n",
       " 'aanlegplaats': ['aanleg', 'plaats'],\n",
       " 'aanlegsteiger': ['aanleg', 'steiger'],\n",
       " 'aanlegster': ['aanleg', 'ster'],\n",
       " 'aanleiden': [''],\n",
       " 'aanleidend': [''],\n",
       " 'aanleiding': ['aan', 'leid', 'ing'],\n",
       " 'aanleuning': ['aanleun', 'ing'],\n",
       " 'aanleuningspunt': ['aanleuning', 's', 'punt'],\n",
       " 'aanliggend': [''],\n",
       " 'aanlokkelijk': ['aanlok', 'elijk'],\n",
       " 'aanlokkelijkheid': ['aanlokkelijk', 'heid'],\n",
       " 'aanlokking': ['aanlok', 'ing'],\n",
       " 'aanloksel': ['aanlok', 'sel'],\n",
       " 'aanloop': ['aan', 'loop'],\n",
       " 'aanloophaven': ['aanloop', 'haven'],\n",
       " 'aanloopkleur': ['aanloop', 'kleur'],\n",
       " 'aanloopkosten': ['aanloop', 'kost'],\n",
       " 'aanlooppeiler': ['aanloop', 'peil', 'er'],\n",
       " 'aanloopperiode': ['aanloop', 'periode'],\n",
       " 'aanloopspreekuur': ['aanloop', 'spreekuur'],\n",
       " 'aanlooptijd': ['aanloop', 'tijd'],\n",
       " 'aanlooptransformator': ['aanloop', 'transformeer', 'ator'],\n",
       " 'aanmaak': [''],\n",
       " 'aanmaakblokje': ['aanmaak', 'blok'],\n",
       " 'aanmaakhout': ['aanmaak', 'hout'],\n",
       " 'aanmaakhoutje': [''],\n",
       " 'aanmaakkosten': ['aanmaak', 'kost'],\n",
       " 'aanmaning': ['aanmaan', 'ing'],\n",
       " 'aanmatigend': [''],\n",
       " 'aanmatiging': ['aanmatig', 'ing'],\n",
       " 'aanmelding': ['aanmeld', 'ing'],\n",
       " 'aanmeldingsformulier': ['aanmelding', 's', 'formulier'],\n",
       " 'aanmenging': ['aanmeng', 'ing'],\n",
       " 'aanmerkelijk': ['aanmerk', 'elijk'],\n",
       " 'aanmerking': ['aanmerk', 'ing'],\n",
       " 'aanminnig': ['aan', 'min', 'ig'],\n",
       " 'aanminnigheid': ['aanminnig', 'heid'],\n",
       " 'aanmoediging': ['aanmoedig', 'ing'],\n",
       " 'aanmoedigingsprijs': ['aanmoediging', 's', 'prijs'],\n",
       " 'aanmonding': ['aan', 'mond', 'ing'],\n",
       " 'aanmonstering': ['aanmonster', 'ing'],\n",
       " 'aanmunting': ['aanmunt', 'ing'],\n",
       " 'aanname': [''],\n",
       " 'aannamebeleid': ['aanname', 'beleid'],\n",
       " 'aanneembaar': ['aanneem', 'baar'],\n",
       " 'aanneemsom': ['aanneem', 'som'],\n",
       " 'aanneemster': ['aanneem', 'ster'],\n",
       " 'aannemelijk': ['aanneem', 'elijk'],\n",
       " 'aannemelijkheid': ['aannemelijk', 'heid'],\n",
       " 'aannemeling': ['aanneem', 'eling'],\n",
       " 'aannemelinge': ['aannemeling', 'e'],\n",
       " 'aannemer': ['aanneem', 'er'],\n",
       " 'aannemersfirma': ['aannemer', 's', 'firma'],\n",
       " 'aanneming': ['aanneem', 'ing'],\n",
       " 'aannemingsbeleid': ['aanneming', 's', 'beleid'],\n",
       " 'aannemingsbiljet': ['aanneming', 's', 'biljet'],\n",
       " 'aannemingsmaatschappij': ['aanneming', 's', 'maatschappij'],\n",
       " 'aannemingssom': ['aanneming', 's', 'som'],\n",
       " 'aanpak': [''],\n",
       " 'aanpalend': ['aan', 'palend'],\n",
       " 'aanpassing': ['aanpas', 'ing'],\n",
       " 'aanpassingsbeleid': ['aanpassing', 's', 'beleid'],\n",
       " 'aanpassingsgedrag': ['aanpassing', 's', 'gedrag'],\n",
       " 'aanpassingsmanoeuvre': ['aanpassing', 's', 'manoeuvre'],\n",
       " 'aanpassingsmechanisme': ['aanpassing', 's', 'mechanisme'],\n",
       " 'aanpassingsmoeilijkheden': ['aanpassing', 's', 'moeilijkheid'],\n",
       " 'aanpassingsmogelijkheid': ['aanpassing', 's', 'mogelijkheid'],\n",
       " 'aanpassingsperiode': ['aanpassing', 's', 'periode'],\n",
       " 'aanpassingsprobleem': ['aanpassing', 's', 'probleem'],\n",
       " 'aanpassingsproces': ['aanpassing', 's', 'proces'],\n",
       " 'aanpassingsstoornis': ['aanpassing', 's', 'stoornis'],\n",
       " 'aanpassingsstrategie': ['aanpassing', 's', 'strategie'],\n",
       " 'aanpassingsvermogen': ['aanpassing', 's', 'vermogen'],\n",
       " 'aanpeil': [''],\n",
       " 'aanpersing': ['aanpers', 'ing'],\n",
       " 'aanplakbiljet': ['aanplak', 'biljet'],\n",
       " 'aanplakbord': ['aanplak', 'bord'],\n",
       " 'aanplakbrief': ['aanplak', 'brief'],\n",
       " 'aanplakker': ['aanplak', 'er'],\n",
       " 'aanplakking': ['aanplak', 'ing'],\n",
       " 'aanplakzuil': ['aanplak', 'zuil'],\n",
       " 'aanplant': [''],\n",
       " 'aanplanting': ['aanplant', 'ing'],\n",
       " 'aanplemping': ['aanplemp', 'ing'],\n",
       " 'aanpoting': ['aanpoot', 'ing'],\n",
       " 'aanprijzer': ['aanprijs', 'er'],\n",
       " 'aanprijzing': ['aanprijs', 'ing'],\n",
       " 'aanprikkeling': ['aanprikkel', 'ing'],\n",
       " 'aanpunter': ['aanpunt', 'er'],\n",
       " 'aanpunting': ['aanpunt', 'ing'],\n",
       " 'aanrader': ['aanraad', 'er'],\n",
       " 'aanraking': ['aanraak', 'ing'],\n",
       " 'aanrakingsangst': ['aanraking', 's', 'angst'],\n",
       " 'aanrakingspunt': ['aanraking', 's', 'punt'],\n",
       " 'aanranden': [''],\n",
       " 'aanrander': ['aanrand', 'er'],\n",
       " 'aanranding': ['aanrand', 'ing'],\n",
       " 'aanrandster': ['aanrand', 'ster'],\n",
       " 'aanrazeren': [''],\n",
       " 'aanrecht': [''],\n",
       " 'aanrechtbank': ['aanrecht', 'bank'],\n",
       " 'aanrechtblad': ['aanrecht', 'blad'],\n",
       " 'aanrechting': ['aanrecht', 'ing'],\n",
       " 'aanrechtkastje': ['aanrecht', 'kast'],\n",
       " 'aanrechtkeuken': ['aanrecht', 'keuken'],\n",
       " 'aanrechttafel': ['aanrecht', 'tafel'],\n",
       " 'aanrijding': ['aanrijd', 'ing'],\n",
       " 'aanroep': ['aan', 'roep'],\n",
       " 'aanroeping': ['aanroep', 'ing'],\n",
       " 'aanschaf': [''],\n",
       " 'aanschaffing': ['aanschaf', 'ing'],\n",
       " 'aanscherping': ['aanscherp', 'ing'],\n",
       " 'aanschijn': [''],\n",
       " 'aanschouwelijk': ['aanschouw', 'elijk'],\n",
       " 'aanschouwelijkheid': ['aanschouwelijk', 'heid'],\n",
       " 'aanschouwing': ['aanschouw', 'ing'],\n",
       " 'aanschouwingsonderwijs': ['aanschouwing', 's', 'onderwijs'],\n",
       " 'aanschouwingsvermogen': ['aanschouwing', 's', 'vermogen'],\n",
       " 'aanschrijving': ['aanschrijf', 'ing'],\n",
       " 'aanschrijvingsbiljet': ['aanschrijving', 's', 'biljet'],\n",
       " 'aansjorring': ['aansjor', 'ing'],\n",
       " 'aanslaander': [''],\n",
       " 'aanslag': [''],\n",
       " 'aanslagbeitel': ['aanslag', 'beitel'],\n",
       " 'aanslagbiljet': ['aanslag', 'biljet'],\n",
       " 'aanslaghouding': ['aanslag', 'houding'],\n",
       " 'aanslagsteen': [''],\n",
       " 'aanslibbing': ['aanslib', 'ing'],\n",
       " 'aanslibsel': ['aanslib', 'sel'],\n",
       " 'aanslijking': ['aanslijk', 'ing'],\n",
       " 'aansluiting': ['aansluit', 'ing'],\n",
       " 'aansluitingskosten': ['aansluiting', 's', 'kost'],\n",
       " 'aansluitingsmoeilijkheid': ['aansluiting', 's', 'moeilijkheid'],\n",
       " 'aansluitingsmogelijkheid': ['aansluiting', 's', 'mogelijkheid'],\n",
       " 'aansluitingsplaats': ['aansluiting', 's', 'plaats'],\n",
       " 'aansluitingsprobleem': ['aansluiting', 's', 'probleem'],\n",
       " 'aansluitingspunt': ['aansluiting', 's', 'punt'],\n",
       " 'aansmering': ['aansmeer', 'ing'],\n",
       " 'aansnede': ['aan', 'snede'],\n",
       " 'aansnee': ['aan', 'snee'],\n",
       " 'aansnijding': ['aansnijd', 'ing'],\n",
       " 'aanspanner': ['aanspan', 'er'],\n",
       " 'aanspanning': ['aanspan', 'ing'],\n",
       " 'aanspoeling': ['aanspoel', 'ing'],\n",
       " 'aanspoelsel': ['aanspoel', 'sel'],\n",
       " 'aanspoorder': ['aanspoor', 'der'],\n",
       " 'aansporing': ['aanspoor', 'ing'],\n",
       " 'aanspraak': ['aan', 'spraak'],\n",
       " 'aansprakelijk': ['aanspreek', 'elijk'],\n",
       " 'aansprakelijkheid': ['aansprakelijk', 'heid'],\n",
       " 'aansprakelijkheidsverzekering': ['aansprakelijkheid', 's', 'verzekering'],\n",
       " 'aanspreekbaar': ['aanspreek', 'baar'],\n",
       " 'aanspreekbaarheid': ['aanspreekbaar', 'heid'],\n",
       " 'aanspreekster': ['aanspreek', 'ster'],\n",
       " 'aanspreektitel': ['aanspreek', 'titel'],\n",
       " 'aanspreekvorm': ['aanspreek', 'vorm'],\n",
       " 'aanspreker': ['aanspreek', 'er'],\n",
       " 'aanspreking': ['aanspreek', 'ing'],\n",
       " 'aanstaand': [''],\n",
       " 'aanstaande': [''],\n",
       " 'aanstalten': [''],\n",
       " 'aanstamper': ['aanstamp', 'er'],\n",
       " 'aanstamping': ['aanstamp', 'ing'],\n",
       " 'aansteekvlam': ['aansteek', 'vlam'],\n",
       " 'aanstekelijk': ['aansteek', 'elijk'],\n",
       " 'aanstekelijkheid': ['aanstekelijk', 'heid'],\n",
       " 'aansteker': ['aansteek', 'er'],\n",
       " 'aansteking': ['aansteek', 'ing'],\n",
       " 'aansteller': ['aanstel', 'er'],\n",
       " 'aanstellerig': ['aanstel', 'erig'],\n",
       " 'aanstellerigheid': ['aanstellerig', 'heid'],\n",
       " 'aanstellerij': ['aanstel', 'erij'],\n",
       " 'aanstelleritis': [''],\n",
       " 'aanstelling': ['aanstel', 'ing'],\n",
       " 'aanstellingsbeleid': ['aanstelling', 's', 'beleid'],\n",
       " 'aanstellingsbrief': ['aanstelling', 's', 'brief'],\n",
       " 'aanstelster': ['aanstel', 'ster'],\n",
       " 'aanstichter': ['aansticht', 'er'],\n",
       " 'aanstichting': ['aansticht', 'ing'],\n",
       " 'aanstichtster': ['aansticht', 'ster'],\n",
       " 'aanstipping': ['aanstip', 'ing'],\n",
       " 'aanstoker': ['aanstook', 'er'],\n",
       " 'aanstonds': [''],\n",
       " 'aanstookster': ['aanstook', 'ster'],\n",
       " 'aanstoot': ['aan', 'stoot'],\n",
       " 'aanstorting': ['aanstort', 'ing'],\n",
       " 'aanstotelijk': ['aanstoot', 'elijk'],\n",
       " 'aanstotelijkheid': ['aanstotelijk', 'heid'],\n",
       " 'aanstotend': [''],\n",
       " 'aanstoting': ['aanstoot', 'ing'],\n",
       " 'aanstreping': ['aanstreep', 'ing'],\n",
       " 'aanstuiving': ['aanstuif', 'ing'],\n",
       " 'aantal': ['aan', 'tal'],\n",
       " 'aantasting': ['aantast', 'ing'],\n",
       " 'aanteelt': [''],\n",
       " 'aantekenaar': ['aanteken', 'aar'],\n",
       " 'aantekenboek': ['aanteken', 'boek'],\n",
       " 'aantekengeld': ['aanteken', 'geld'],\n",
       " 'aantekening': ['aanteken', 'ing'],\n",
       " 'aantekeningspartij': ['aantekening', 's', 'partij'],\n",
       " 'aantekenkantoor': ['aanteken', 'kantoor'],\n",
       " 'aantekenpartij': ['aanteken', 'partij'],\n",
       " 'aantekenrecht': ['aanteken', 'recht'],\n",
       " 'aantekenschrift': ['aanteken', 'schrift'],\n",
       " 'aanteling': ['aanteel', 'ing'],\n",
       " 'aantijgen': [''],\n",
       " 'aantijger': ['aantijg', 'er'],\n",
       " 'aantijging': ['aantijg', 'ing'],\n",
       " 'Aantjes': [''],\n",
       " 'aantocht': [''],\n",
       " 'aantonend': [''],\n",
       " 'aantoning': ['aantoon', 'ing'],\n",
       " 'aantoonbaar': ['aantoon', 'baar'],\n",
       " 'aantoonbaarheid': ['aantoonbaar', 'heid'],\n",
       " 'aantrede': [''],\n",
       " 'aantree': [''],\n",
       " 'aantreeplaats': ['aantreed', 'plaats'],\n",
       " 'aantrek': [''],\n",
       " 'aantrekkelijk': ['aantrek', 'elijk'],\n",
       " 'aantrekkelijkheid': ['aantrekkelijk', 'heid'],\n",
       " 'aantrekker': ['aantrek', 'er'],\n",
       " 'aantrekking': ['aantrek', 'ing'],\n",
       " 'aantrekkingskracht': ['aantrekking', 's', 'kracht'],\n",
       " 'aantrekkingsvermogen': ['aantrekking', 's', 'vermogen'],\n",
       " 'aantrouwing': ['aan', 'trouw', 'ing'],\n",
       " 'aanvaarden': [''],\n",
       " 'aanvaardbaar': ['aanvaard', 'baar'],\n",
       " 'aanvaardbaarheid': ['aanvaardbaar', 'heid'],\n",
       " 'aanvaarding': ['aanvaard', 'ing'],\n",
       " 'aanvaardingsproces': ['aanvaarding', 's', 'proces'],\n",
       " 'aanvaarpaal': ['aanvaar', 'paal'],\n",
       " 'aanvaart': ['aan', 'vaart'],\n",
       " 'aanval': [''],\n",
       " 'aanvallend': [''],\n",
       " 'aanvallenderwijs': ['aanval', 'enderwijs'],\n",
       " 'aanvallenderwijze': ['aanval', 'enderwijze'],\n",
       " 'aanvaller': ['aanval', 'er'],\n",
       " 'aanvallig': ['aanval', 'ig'],\n",
       " 'aanvalligheid': ['aanvallig', 'heid'],\n",
       " 'aanvalsactie': ['aanval', 's', 'actie'],\n",
       " 'aanvalsbasis': ['aanval', 's', 'basis'],\n",
       " 'aanvalsbevel': ['aanval', 's', 'bevel'],\n",
       " 'aanvalscolonne': ['aanval', 's', 'colonne'],\n",
       " 'aanvalsdrift': ['aanval', 's', 'drift'],\n",
       " 'aanvalsfront': ['aanval', 's', 'front'],\n",
       " 'aanvalskracht': ['aanval', 's', 'kracht'],\n",
       " 'aanvalskreet': ['aanval', 's', 'kreet'],\n",
       " 'aanvalslinie': ['aanval', 's', 'linie'],\n",
       " 'aanvalsoorlog': ['aanval', 's', 'oorlog'],\n",
       " 'aanvalsplan': ['aanval', 's', 'plan'],\n",
       " 'aanvalspositie': ['aanval', 's', 'positie'],\n",
       " 'aanvalssein': ['aanval', 's', 'sein'],\n",
       " 'aanvalstactiek': ['aanval', 's', 'tactiek'],\n",
       " 'aanvalsteken': ['aanval', 's', 'teken'],\n",
       " 'aanvalster': ['aanval', 'ster'],\n",
       " 'aanvalswapen': ['aanval', 's', 'wapen'],\n",
       " 'aanvalswijs': ['aanval', 's', 'wijs'],\n",
       " 'aanvalswijze': ['aanval', 's', 'wijze'],\n",
       " 'aanvang': [''],\n",
       " 'aanvanger': ['aanvang', 'er'],\n",
       " 'aanvangsdatum': ['aanvang', 's', 'datum'],\n",
       " 'aanvangsjaar': ['aanvang', 's', 'jaar'],\n",
       " 'aanvangsklas': ['aanvang', 's', 'klas'],\n",
       " 'aanvangsklasse': ['aanvang', 's', 'klasse'],\n",
       " 'aanvangsperiode': ['aanvang', 's', 'periode'],\n",
       " 'aanvangspunt': ['aanvang', 's', 'punt'],\n",
       " 'aanvangssalaris': ['aanvang', 's', 'salaris'],\n",
       " 'aanvangssituatie': ['aanvang', 's', 'situatie'],\n",
       " 'aanvangssnelheid': ['aanvang', 's', 'snelheid'],\n",
       " 'aanvangsstadium': ['aanvang', 's', 'stadium'],\n",
       " 'aanvangstijd': ['aanvang', 's', 'tijd'],\n",
       " 'aanvangstijdstip': ['aanvang', 's', 'tijdstip'],\n",
       " 'aanvangsuur': ['aanvang', 's', 'uur'],\n",
       " 'aanvankelijk': ['aanvang', 'elijk'],\n",
       " 'aanvaring': ['aanvaar', 'ing'],\n",
       " 'aanvaringsschot': ['aanvaring', 's', 'schot'],\n",
       " 'aanvatting': ['aanvat', 'ing'],\n",
       " 'aanvechtbaar': ['aanvecht', 'baar'],\n",
       " 'aanvechting': ['aanvecht', 'ing'],\n",
       " 'aanverstorven': ['aan', 'verstorven'],\n",
       " 'aanverwant': ['aan', 'verwant'],\n",
       " 'aanverwante': ['aanverwant', 'e'],\n",
       " 'aanverwantschap': ['aanverwant', 'schap'],\n",
       " 'aanvijl': ['aan', 'vijl'],\n",
       " 'aanvijlsblok': ['aanvijl', 's', 'blok'],\n",
       " 'aanvlieging': ['aanvlieg', 'ing'],\n",
       " 'aanvliegroute': ['aanvlieg', 'route'],\n",
       " 'aanvoegend': [''],\n",
       " 'aanvoeging': ['aanvoeg', 'ing'],\n",
       " 'aanvoegsel': ['aanvoeg', 'sel'],\n",
       " 'aanvoeling': ['aanvoel', 'ing'],\n",
       " 'aanvoelingsvermogen': ['aanvoeling', 's', 'vermogen'],\n",
       " 'aanvoer': [''],\n",
       " 'aanvoerbuis': ['aanvoer', 'buis'],\n",
       " 'aanvoerder': ['aanvoer', 'der'],\n",
       " 'aanvoerhaven': ['aanvoer', 'haven'],\n",
       " 'aanvoering': ['aanvoer', 'ing'],\n",
       " 'aanvoerpijp': ['aanvoer', 'pijp'],\n",
       " 'aanvoerrol': ['aanvoer', 'rol'],\n",
       " 'aanvoerster': ['aanvoer', 'ster'],\n",
       " 'aanvraag': ['aan', 'vraag'],\n",
       " 'aanvraagprocedure': ['aanvraag', 'procedure'],\n",
       " 'aanvraagster': ['aanvraag', 'ster'],\n",
       " 'aanvrage': [''],\n",
       " 'aanvrager': ['aanvraag', 'er'],\n",
       " 'aanvullend': [''],\n",
       " 'aanvulling': ['aanvul', 'ing'],\n",
       " 'aanvullingsbegroting': ['aanvulling', 's', 'begroting'],\n",
       " 'aanvullingsexamen': ['aanvulling', 's', 'examen'],\n",
       " 'aanvullingskohier': ['aanvulling', 's', 'kohier'],\n",
       " 'aanvullingstroepen': ['aanvulling', 's', 'troep'],\n",
       " 'aanvulsel': ['aanvul', 'sel'],\n",
       " 'aanvuring': ['aanvuur', 'ing'],\n",
       " 'aanwas': [''],\n",
       " 'aanwassing': ['aanwas', 'ing'],\n",
       " 'aanwendbaar': ['aanwend', 'baar'],\n",
       " 'aanwendbaarheid': ['aanwendbaar', 'heid'],\n",
       " 'aanwending': ['aanwend', 'ing'],\n",
       " 'aanwendingsmogelijkheid': ['aanwending', 's', 'mogelijkheid'],\n",
       " 'aanwenning': ['aanwen', 'ing'],\n",
       " 'aanwensel': ['aanwen', 'sel'],\n",
       " 'aanwerver': ['aanwerf', 'er'],\n",
       " 'aanwerving': ['aanwerf', 'ing'],\n",
       " 'aanwezend': [''],\n",
       " 'aanwezig': [''],\n",
       " 'aanwezige': [''],\n",
       " 'aanwezigheid': ['aanwezig', 'heid'],\n",
       " 'aanwezigheidslijst': ['aanwezigheid', 's', 'lijst'],\n",
       " 'aanwijsbaar': ['aanwijs', 'baar'],\n",
       " 'aanwijsstok': ['aanwijs', 'stok'],\n",
       " 'aanwijzend': [''],\n",
       " 'aanwijzer': ['aanwijs', 'er'],\n",
       " 'aanwijzing': ['aanwijs', 'ing'],\n",
       " 'aanwijzingsbevoegdheid': ['aanwijzing', 's', 'bevoegdheid'],\n",
       " 'aanwijzingsbord': ['aanwijzing', 's', 'bord'],\n",
       " 'aanwinning': ['aanwin', 'ing'],\n",
       " 'aanwinst': ['aanwin', 'st'],\n",
       " 'aanwonenden': [''],\n",
       " 'aanwrijving': ['aanwrijf', 'ing'],\n",
       " 'aanzeg': [''],\n",
       " 'aanzegger': ['aanzeg', 'er'],\n",
       " 'aanzegging': ['aanzeg', 'ing'],\n",
       " 'aanzeiling': ['aanzeil', 'ing'],\n",
       " 'aanzet': ['aan', 'zet'],\n",
       " 'aanzethamer': ['aanzet', 'hamer'],\n",
       " 'aanzetriem': ['aanzet', 'riem'],\n",
       " 'aanzetschroef': ['aanzet', 'schroef'],\n",
       " 'aanzetsel': ['aanzet', 'sel'],\n",
       " 'aanzetslinger': ['aanzet', 'slinger'],\n",
       " 'aanzetstaal': ['aanzet', 'staal'],\n",
       " 'aanzetsteen': ['aanzet', 'steen'],\n",
       " 'aanzetster': ['aanzet', 'ster'],\n",
       " 'aanzetstok': ['aanzet', 'stok'],\n",
       " 'aanzetstuk': ['aanzet', 'stuk'],\n",
       " 'aanzetter': ['aanzet', 'er'],\n",
       " 'aanzetting': ['aanzet', 'ing'],\n",
       " 'aanzetvijl': ['aanzet', 'vijl'],\n",
       " 'aanzicht': [''],\n",
       " 'aanzien': [''],\n",
       " 'aanziend': [''],\n",
       " 'aanzienlijk': ['aanzien', 'lijk'],\n",
       " 'aanzienlijkheid': ['aanzienlijk', 'heid'],\n",
       " 'aanzijn': ['aan', 'zijn'],\n",
       " 'aanzoek': [''],\n",
       " 'aanzoeker': ['aanzoek', 'er'],\n",
       " 'aanzuiging': ['aanzuig', 'ing'],\n",
       " 'aanzuivering': ['aanzuiver', 'ing'],\n",
       " 'aanzwellend': [''],\n",
       " 'aap': ['aap'],\n",
       " 'aapje': [''],\n",
       " 'aapachtig': ['aap', 'achtig'],\n",
       " 'aapjessnuif': ['aap', 's', 'snuif'],\n",
       " 'aapjeszeep': ['aap', 's', 'zeep'],\n",
       " 'aapmens': ['aap', 'mens'],\n",
       " 'aar': ['aar'],\n",
       " 'aarbussel': ['aar', 'bussel'],\n",
       " 'aard': ['aard'],\n",
       " 'aarden': ['aarde', 'en'],\n",
       " 'aardachtig': ['aard', 'achtig'],\n",
       " 'aardaker': ['aard', 'aker'],\n",
       " 'aardalkalimetalen': [''],\n",
       " 'aardamandel': ['aarde', 'amandel'],\n",
       " 'aardappel': ['aarde', 'appel'],\n",
       " 'aardappelakker': ['aardappel', 'akker'],\n",
       " 'aardappelbak': ['aardappel', 'bak'],\n",
       " 'aardappelboer': ['aardappel', 'boer'],\n",
       " 'aardappelbovist': ['aardappel', 'bovist'],\n",
       " 'aardappelbuik': ['aardappel', 'buik'],\n",
       " 'aardappelcampagne': ['aardappel', 'campagne'],\n",
       " 'aardappelcroquet': ['aardappel', 'croquet'],\n",
       " 'aardappeldeeg': ['aardappel', 'deeg'],\n",
       " 'aardappelhakker': ['aardappel', 'hak', 'er'],\n",
       " 'aardappelkelder': ['aardappel', 'kelder'],\n",
       " 'aardappelkever': ['aardappel', 'kever'],\n",
       " 'aardappelknol': ['aardappel', 'knol'],\n",
       " 'aardappelkriel': ['aardappel', 'kriel'],\n",
       " 'aardappelmeel': ['aardappel', 'meel'],\n",
       " 'aardappelmesje': ['aardappel', 'mes'],\n",
       " 'aardappelmoeheid': ['aardappel', 'moeheid'],\n",
       " 'aardappelpan': ['aardappel', 'pan'],\n",
       " 'aardappelplant': ['aardappel', 'plant'],\n",
       " 'aardappelpoter': ['aardappel', 'poot', 'er'],\n",
       " 'aardappelpuree': ['aardappel', 'puree'],\n",
       " 'aardappelrooier': ['aardappelrooi', 'er'],\n",
       " 'aardappelsalade': ['aardappel', 'salade'],\n",
       " 'aardappelschijf': ['aardappel', 'schijf'],\n",
       " 'aardappelschiller': ['aardappel', 'schil', 'er'],\n",
       " 'aardappelschillertje': [''],\n",
       " 'aardappelschilmesje': ['aardappel', 'schilmes'],\n",
       " 'aardappelsoep': ['aardappel', 'soep'],\n",
       " 'aardappelstijfsel': ['aardappel', 'stijfsel'],\n",
       " 'aardappelstroop': ['aardappel', 'stroop'],\n",
       " 'aardappelveld': ['aardappel', 'veld'],\n",
       " 'aardappelvlokken': ['aardappel', 'vlok'],\n",
       " 'aardappelziekte': ['aardappel', 'ziekte'],\n",
       " 'aardas': ['aarde', 'as'],\n",
       " 'aardatmosfeer': ['aarde', 'atmosfeer'],\n",
       " 'aardbaan': ['aarde', 'baan'],\n",
       " 'aardbei': [''],\n",
       " 'aardbeiboom': ['aardbei', 'boom'],\n",
       " 'aardbeienbed': ['aardbei', 'en', 'bed'],\n",
       " 'aardbeiengelei': ['aardbei', 'en', 'gelei'],\n",
       " 'aardbeienijs': ['aardbei', 'en', 'ijs'],\n",
       " 'aardbeienjam': ['aardbei', 'en', 'jam'],\n",
       " 'aardbeienneus': ['aardbei', 'en', 'neus'],\n",
       " 'aardbeiensorbet': ['aardbei', 'en', 'sorbet'],\n",
       " 'aardbeientaart': ['aardbei', 'en', 'taart'],\n",
       " 'aardbeienteelt': ['aardbei', 'en', 'teelt'],\n",
       " 'aardbeientijd': ['aardbei', 'en', 'tijd'],\n",
       " 'aardbeiklaver': ['aardbei', 'klaver'],\n",
       " 'aardbeiloof': ['aardbei', 'loof'],\n",
       " 'aardbeiplant': ['aardbei', 'plant'],\n",
       " 'aardbeistruik': ['aardbei', 'struik'],\n",
       " 'aardberging': ['aarde', 'berg', 'ing'],\n",
       " 'aardbeving': ['aarde', 'beving'],\n",
       " 'aardbevingsgebied': ['aardbeving', 's', 'gebied'],\n",
       " 'aardbevingsgolf': ['aardbeving', 's', 'golf'],\n",
       " 'aardbevingsgordel': ['aardbeving', 's', 'gordel'],\n",
       " 'aardbevingshaard': ['aardbeving', 's', 'haard'],\n",
       " 'aardbevingsmeter': ['aardbeving', 's', 'meet', 'er'],\n",
       " 'aardbewoner': ['aarde', 'bewoon', 'er'],\n",
       " 'aardbewoonster': ['aarde', 'bewoon', 'ster'],\n",
       " 'aardbij': ['aarde', 'bij'],\n",
       " 'aardbodem': ['aarde', 'bodem'],\n",
       " 'aardbol': ['aarde', 'bol'],\n",
       " 'aardboog': ['aarde', 'boog'],\n",
       " 'aardboor': ['aarde', 'boor'],\n",
       " 'aardbrand': ['aarde', 'brand'],\n",
       " 'aardbuil': ['aarde', 'buil'],\n",
       " 'aarddraad': ['aard', 'draad'],\n",
       " 'aardduivel': ['aarde', 'duivel'],\n",
       " 'aarde': ['aarde'],\n",
       " 'aardebaan': ['aarde', 'baan'],\n",
       " 'aardedonker': ['aarde', 'donker'],\n",
       " 'aardegoed': ['aarde', 'goed'],\n",
       " 'aardelektrode': ['aard', 'elektrode'],\n",
       " 'Aardenne': [''],\n",
       " 'aardeteken': ['aarde', 'teken'],\n",
       " 'aardeweg': ['aarde', 'weg'],\n",
       " 'aardewerk': [''],\n",
       " 'aardewerken': ['aardewerk', 'en'],\n",
       " 'aardewerker': ['aardewerk', 'er'],\n",
       " 'aardewerkfabriek': ['aardewerk', 'fabriek'],\n",
       " 'aardewerkschuit': ['aardewerk', 'schuit'],\n",
       " 'aardewerkwinkel': ['aarde', 'werkwinkel'],\n",
       " 'aardewind': [''],\n",
       " 'aardfout': ['aard', 'fout'],\n",
       " 'aardgas': ['aarde', 'gas'],\n",
       " 'aardgasbaten': ['aardgas', 'baat'],\n",
       " 'aardgasbel': ['aardgas', 'bel'],\n",
       " 'aardgasnet': ['aardgas', 'net'],\n",
       " 'aardgasopbrengst': ['aardgas', 'opbrengst'],\n",
       " 'aardgastanker': ['aardgas', 'tanker'],\n",
       " 'aardgasterminal': ['aardgas', 'terminal'],\n",
       " 'aardgeest': ['aarde', 'geest'],\n",
       " 'aardgewas': ['aarde', 'gewas'],\n",
       " 'aardglobe': ['aarde', 'globe'],\n",
       " 'aardgoed': ['aarde', 'goed'],\n",
       " 'aardgordel': ['aarde', 'gordel'],\n",
       " 'aardhars': ['aarde', 'hars'],\n",
       " 'aardhommel': ['aarde', 'hommel'],\n",
       " 'aardhoop': ['aarde', 'hoop'],\n",
       " 'aardig': [''],\n",
       " 'aardigheid': ['aardig', 'heid'],\n",
       " 'aardigjes': ['aardig', 'jes'],\n",
       " 'aarding': ['aard', 'ing'],\n",
       " 'aardkastanje': ['aarde', 'kastanje'],\n",
       " 'aardkern': ['aarde', 'kern'],\n",
       " 'aardklem': ['aard', 'klem'],\n",
       " 'aardklomp': ['aarde', 'klomp'],\n",
       " 'aardklont': ['aarde', 'klont'],\n",
       " 'aardkloot': ['aarde', 'kloot'],\n",
       " 'aardkluit': ['aarde', 'kluit'],\n",
       " 'aardkorst': ['aarde', 'korst'],\n",
       " 'aardkrekel': ['aarde', 'krekel'],\n",
       " 'aardkromming': ['aarde', 'kromming'],\n",
       " 'aardkuil': ['aarde', 'kuil'],\n",
       " 'aardkunde': ['aarde', 'kunde'],\n",
       " 'aardkundig': ['aardkunde', 'ig'],\n",
       " 'aardkundige': [''],\n",
       " 'aardlaag': ['aarde', 'laag'],\n",
       " 'aardleiding': ['aarde', 'leiding'],\n",
       " 'aardlevering': ['aarde', 'levering'],\n",
       " 'aardmagnetisch': [''],\n",
       " 'aardmagnetisme': ['aarde', 'magnetisme'],\n",
       " 'aardmannetje': ['aarde', 'man'],\n",
       " 'aardmassa': ['aarde', 'massa'],\n",
       " 'aardmeetkunde': ['aarde', 'meetkunde'],\n",
       " 'aardmeetkunst': [''],\n",
       " 'aardmetalen': ['aarde', 'metaal'],\n",
       " 'aardmeting': ['aarde', 'meet', 'ing'],\n",
       " 'aardmijt': ['aarde', 'mijt'],\n",
       " 'aardmolm': ['aarde', 'molm'],\n",
       " 'aardmuis': ['aarde', 'muis'],\n",
       " 'aardnoot': ['aarde', 'noot'],\n",
       " 'aardnotenolie': ['aardnoot', 'en', 'olie'],\n",
       " 'aardolie': ['aarde', 'olie'],\n",
       " 'aardolieprodukt': ['aardolie', 'produkt'],\n",
       " 'aardoppervlak': ['aarde', 'oppervlak'],\n",
       " 'aardoppervlakte': ['aarde', 'oppervlakte'],\n",
       " 'aardpeer': ['aarde', 'peer'],\n",
       " 'aardpek': ['aarde', 'pek'],\n",
       " 'aardpijler': [''],\n",
       " 'aardplooi': ['aarde', 'plooi'],\n",
       " 'aardpool': ['aarde', 'pool'],\n",
       " 'aardprofiel': ['aarde', 'profiel'],\n",
       " 'aardrijk': ['aarde', 'rijk'],\n",
       " 'aardrijkskunde': ['aardrijk', 's', 'kunde'],\n",
       " 'aardrijkskundeboek': ['aardrijkskunde', 'boek'],\n",
       " 'aardrijkskundig': ['aardrijkskunde', 'ig'],\n",
       " 'aardrijkskundige': [''],\n",
       " 'aardrol': ['aarde', 'rol'],\n",
       " 'aardrook': ['aarde', 'rook'],\n",
       " 'aardrups': ['aarde', 'rups'],\n",
       " 'aards': ['aarde', 's'],\n",
       " 'aardschaduw': ['aarde', 'schaduw'],\n",
       " 'aardschijn': ['aarde', 'schijn'],\n",
       " 'aardschok': ['aarde', 'schok'],\n",
       " 'aardschors': ['aarde', 'schors'],\n",
       " 'aardschudding': ['aarde', 'schudding'],\n",
       " 'aardsgezind': ['aarde', 's', 'gezind'],\n",
       " 'aardsgezindheid': ['aardsgezind', 'heid'],\n",
       " 'aardsheid': ['aards', 'heid'],\n",
       " 'aardslak': ['aarde', 'slak'],\n",
       " 'aardslang': ['aarde', 'slang'],\n",
       " 'aardsluiting': ['aarde', 'sluiting'],\n",
       " 'aardspin': ['aarde', 'spin'],\n",
       " 'aardster': ['aarde', 'ster'],\n",
       " 'aardstorting': ['aarde', 'storting'],\n",
       " 'aardstraal': ['aarde', 'straal'],\n",
       " 'aardstralenkastje': ['aardstraal', 'en', 'kast'],\n",
       " 'aardstraling': ['aarde', 'straling'],\n",
       " 'aardstroom': ['aarde', 'stroom'],\n",
       " 'aardtor': ['aarde', 'tor'],\n",
       " 'aardtrilling': ['aarde', 'trilling'],\n",
       " 'aardvarken': ['aarde', 'varken'],\n",
       " 'aardvast': ['aarde', 'vast'],\n",
       " 'aardveil': ['aarde', 'veil'],\n",
       " 'aardverbinding': ['aarde', 'verbinding'],\n",
       " 'aardverschuiving': ['aarde', 'verschuiving'],\n",
       " 'aardverf': ['aarde', 'verf'],\n",
       " 'aardvlo': ['aarde', 'vlo'],\n",
       " 'aardvork': ['aarde', 'vork'],\n",
       " 'aardvrucht': ['aarde', 'vrucht'],\n",
       " 'aardwarmte': ['aarde', 'warmte'],\n",
       " 'aardwas': ['aarde', 'was'],\n",
       " 'aardwerk': ['aarde', 'werk'],\n",
       " 'aardwerker': ['aardwerk', 'er'],\n",
       " 'aardwetenschappen': ['aarde', 'wetenschap'],\n",
       " 'aardwind': [''],\n",
       " 'aardwinde': ['aarde', 'winde'],\n",
       " 'aardwolf': ['aarde', 'wolf'],\n",
       " 'aardworm': ['aarde', 'worm'],\n",
       " 'Aargau': [''],\n",
       " 'Aarlen': [''],\n",
       " 'aarling': [''],\n",
       " 'Aaron': [''],\n",
       " 'Aarschot': [''],\n",
       " 'aarsdarm': ['aars', 'darm'],\n",
       " 'aarsgat': ['aars', 'gat'],\n",
       " 'aarskramp': ['aars', 'kramp'],\n",
       " 'aarsmade': ['aars', 'made'],\n",
       " 'aarsopening': ['aars', 'opening'],\n",
       " 'aarsvin': ['aars', 'vin'],\n",
       " 'Aart': [''],\n",
       " 'aartsbedrieger': ['aarts', 'bedrieger'],\n",
       " 'aartsbedriegster': ['aarts', 'bedriegster'],\n",
       " 'aartsbisdom': ['aarts', 'bisdom'],\n",
       " 'aartsbisschop': ['aarts', 'bisschop'],\n",
       " 'aartsbisschoppelijk': ['aartsbisschop', 'elijk'],\n",
       " 'aartsbooswicht': ['aarts', 'booswicht'],\n",
       " 'aartsbroederschap': ['aarts', 'broederschap'],\n",
       " 'aartsconservatief': ['aarts', 'conservatief'],\n",
       " 'aartsdeugniet': ['aarts', 'deugniet'],\n",
       " 'aartsdiaken': ['aarts', 'diaken'],\n",
       " 'aartsdiakenschap': ['aartsdiaken', 'schap'],\n",
       " 'aartsdiocees': ['aarts', 'diocees'],\n",
       " 'aartsdom': ['aarts', 'dom'],\n",
       " 'aartsdomkop': ['aarts', 'domkop'],\n",
       " 'aartsengel': ['aarts', 'engel'],\n",
       " 'aartshertog': ['aarts', 'hertog'],\n",
       " 'aartshertogdom': ['aartshertog', 'dom'],\n",
       " 'aartshertogelijk': ['aarts', 'hertogelijk'],\n",
       " 'aartshertogin': ['aarts', 'hertogin'],\n",
       " 'aartshuichelaar': ['aarts', 'huichelaar'],\n",
       " 'aartskanselier': ['aarts', 'kanselier'],\n",
       " 'aartsketter': ['aarts', 'ketter'],\n",
       " 'aartslelijk': ['aarts', 'lelijk'],\n",
       " 'aartsleugenaar': ['aarts', 'leugenaar'],\n",
       " 'aartsliefhebber': ['aarts', 'liefhebber'],\n",
       " 'aartslui': ['aarts', 'lui'],\n",
       " 'aartsluiaard': ['aartslui', 'aard'],\n",
       " 'aartsmoeilijk': ['aarts', 'moeilijk'],\n",
       " 'aartspriester': ['aarts', 'priester'],\n",
       " 'aartspriesterschap': ['aartspriester', 'schap'],\n",
       " 'aartsrivaal': ['aarts', 'rivaal'],\n",
       " 'aartsschelm': ['aarts', 'schelm'],\n",
       " 'aartstwijfelaar': ['aarts', 'twijfelaar'],\n",
       " 'aartsvader': ['aarts', 'vader'],\n",
       " 'aartsvaderlijk': ['aartsvader', 'lijk'],\n",
       " 'aartsverrader': ['aarts', 'verrader'],\n",
       " 'aartsvijand': ['aarts', 'vijand'],\n",
       " 'aarvormig': ['aar', 'vorm', 'ig'],\n",
       " 'aars': ['aars'],\n",
       " 'aarzeling': ['aarzel', 'ing'],\n",
       " 'aasbloem': ['aas', 'bloem'],\n",
       " 'aasdier': ['aas', 'dier'],\n",
       " 'aaseter': ['aas', 'eet', 'er'],\n",
       " 'aasgier': ['aas', 'gier'],\n",
       " 'aasjager': ['aas', 'jaag', 'er'],\n",
       " 'aaskever': ['aas', 'kever'],\n",
       " 'aastor': ['aas', 'tor'],\n",
       " 'aasvlieg': ['aas', 'vlieg'],\n",
       " 'aasvogel': ['aas', 'vogel'],\n",
       " 'aaszak': ['aas', 'zak'],\n",
       " 'aatje': ['aat'],\n",
       " 'aas': ['aas'],\n",
       " 'aasje': ['aas'],\n",
       " 'Ab': [''],\n",
       " 'abactis': [''],\n",
       " 'abacus': [''],\n",
       " 'abandon': [''],\n",
       " 'abandonnement': ['abandonneer', 'ement'],\n",
       " 'abat-jour': [''],\n",
       " 'abattoir': [''],\n",
       " 'abbatiaal': ['abt', 'aal'],\n",
       " 'abbe': ['abbe'],\n",
       " 'abberdaan': [''],\n",
       " 'Abbeville': [''],\n",
       " 'abbreviatie': ['abbrevieer', 'atie'],\n",
       " 'abbreviatuur': ['abbrevieer', 'atuur'],\n",
       " 'abbrevieren': [''],\n",
       " 'abc': [''],\n",
       " 'abc-boek': ['abc', 'boek'],\n",
       " 'abces': [''],\n",
       " 'Abcoude': [''],\n",
       " 'ABC-wapens': ['abc', 'wapen'],\n",
       " 'Abdallah': [''],\n",
       " 'abdicatie': ['abdiceer', 'atie'],\n",
       " 'abdiceren': [''],\n",
       " 'abdij': [''],\n",
       " 'abdijkerk': ['abdij', 'kerk'],\n",
       " 'abdijschool': ['abdij', 'school'],\n",
       " 'abdijsiroop': ['abdij', 'siroop'],\n",
       " 'abdiqueren': [''],\n",
       " 'abdis': [''],\n",
       " 'abdomen': [''],\n",
       " 'abdominaal': ['abdomen', 'aal'],\n",
       " 'abductie': [''],\n",
       " 'Abe': [''],\n",
       " 'abecedarium': [''],\n",
       " 'abeel': ['abeel'],\n",
       " 'abeelboom': ['abeel', 'boom'],\n",
       " 'abel': [''],\n",
       " 'abelenlaan': ['abeel', 'en', 'laan'],\n",
       " 'Abeltje': [''],\n",
       " 'Aberdeen': [''],\n",
       " 'aberratie': [''],\n",
       " 'Abidjan': [''],\n",
       " 'Abilene': [''],\n",
       " 'A-biljet': ['a', 'biljet'],\n",
       " 'abiturient': [''],\n",
       " 'abituriente': ['abiturient', 'e'],\n",
       " 'abject': [''],\n",
       " 'ablatie': [''],\n",
       " 'ablatief': [''],\n",
       " 'ablativus': [''],\n",
       " 'ablaut': [''],\n",
       " 'ablutie': [''],\n",
       " 'Abma': [''],\n",
       " 'abnormaal': [''],\n",
       " 'abnormaliteit': ['abnormaal', 'iteit'],\n",
       " 'aboleren': [''],\n",
       " 'abolitie': ['aboleer', 'itie'],\n",
       " 'abolitionist': [''],\n",
       " 'abolitionistisch': ['abolitionist', 'isch'],\n",
       " 'A-bom': ['a', 'bom'],\n",
       " 'abominabel': [''],\n",
       " 'abondance': ['abondant', 'nce'],\n",
       " 'abondant': [''],\n",
       " 'abonnee': [''],\n",
       " 'abonneren': [''],\n",
       " 'abonneetelevisie': ['abonnee', 'televisie'],\n",
       " 'abonnement': ['abonneer', 'ement'],\n",
       " 'abonnementhouder': ['abonnement', 'houd', 'er'],\n",
       " 'abonnementhoudster': ['abonnement', 'houd', 'ster'],\n",
       " 'abonnementsconcert': ['abonnement', 's', 'concert'],\n",
       " 'abonnementshonorarium': ['abonnement', 's', 'honorarium'],\n",
       " 'abonnementskaart': ['abonnement', 's', 'kaart'],\n",
       " 'abonnementsprijsverhoging': ['abonnement', 's', 'prijsverhoging'],\n",
       " 'abonnementstarief': ['abonnement', 's', 'tarief'],\n",
       " 'abonnementsvoorstelling': ['abonnement', 's', 'voorstelling'],\n",
       " 'aborigines': [''],\n",
       " 'aborteur': ['aborteer', 'eur'],\n",
       " 'aborteuse': [''],\n",
       " 'abortief': ['abortus', 'ief'],\n",
       " 'abortoir': [''],\n",
       " 'abortus': [''],\n",
       " 'abortuskliniek': ['abortus', 'kliniek'],\n",
       " 'abortuskwestie': ['abortus', 'kwestie'],\n",
       " 'abortuspraktijk': ['abortus', 'praktijk'],\n",
       " 'abortusregeling': ['abortus', 'regeling'],\n",
       " 'abortusvraagstuk': ['abortus', 'vraagstuk'],\n",
       " 'abortuswet': ['abortus', 'wet'],\n",
       " 'abracadabra': [''],\n",
       " ...}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = {}\n",
    "for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d88b4992e5b06b322ead3277a6c0c22aea73de159b15016e3d5eb1aecc84f355"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
