{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will develop a custom tokenizer, train it and store it.\n",
    "\n",
    "\n",
    "In order to do this, this notebook consists of the following sections:\n",
    "- Data preparation: loading all required data in the proper form\n",
    "- EDA: exploration of the data [of dit niet meer?]\n",
    "- Creating a dictionary with the morphological segmentations of Dutch words\n",
    "- Creating the tokenizer using this dictionary\n",
    "- Evaluating the tokenizer and comparing it to other tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two main sources of data:\n",
    "- OSCAR: a corpus with a lot of Dutch text data\n",
    "- CELEX: a database with information about Dutch words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSCAR \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of ways to work with the OSCAR corpus. The main choice we have to make is whether we want to download the corpus to our personal computer first, or download the dataset (in segments, as the dataset is too large to lead into memory at once) from the Hugging Face library when we want to use it for a certain task. \n",
    "\n",
    "Downloading the corpus manually is done in 45 segments. This means we could load one of these segments into memory at once, but it is easier to make a generator that behaves in the same way as the one that is necessary for streaming the dataset directly from Hugging Face, so that our functions can handle both. \n",
    "\n",
    "We will also create a small dataset in that can be used for testing some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset, DatasetDict\n",
    "# import os\n",
    "\n",
    "\n",
    "# # function that returns a dictionary with a generator for every existing OSCAR file in this computer\n",
    "# def create_local_oscar_generators(data_path, i=0, j=0):\n",
    "\n",
    "#     out = {}\n",
    "    \n",
    "#     if j > i:\n",
    "#         n = j - i\n",
    "\n",
    "#         for x in range(i, j+1):\n",
    "#             full_path = os.path.join(data_path, 'OSCAR', f'nl_part_{x}.txt')\n",
    "#             if os.path.isfile(full_path):\n",
    "#                 out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "        \n",
    "#         if len(out) != n + 1:\n",
    "#             print('Not all parts requested are on this computer')\n",
    "    \n",
    "#     else:\n",
    "\n",
    "#         for i in range(1, 50):\n",
    "#             full_path = os.path.join(data_path, 'OSCAR', f'nl_part_{i}.txt')\n",
    "#             if os.path.isfile(full_path):\n",
    "#                 out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# # function that creates one generator out of multiple generators\n",
    "# def create_super_generator(generator_dict, list_input=False):\n",
    "\n",
    "#     if list_input:\n",
    "#         for generator in generator_dict:\n",
    "#             yield from generator\n",
    "#     else:\n",
    "#         for generator in generator_dict.values():\n",
    "#             yield from generator\n",
    "\n",
    "\n",
    "# # one function to create OSCAR generator by combining n parts of the dataset, from part i to part j\n",
    "# def create_super_local_oscar_generator(data_path, i=0, j=0):\n",
    "    \n",
    "#     if j > i:\n",
    "#         generators = create_local_oscar_generators(data_path, i=i, j=j)\n",
    "#     else:\n",
    "#         generators = create_local_oscar_generators(data_path)\n",
    "\n",
    "#     return create_super_generator(generators)\n",
    "\n",
    "\n",
    "# # function to create a dataset with text \n",
    "# def create_test_set(dataset_generator, start, end):\n",
    "#     it = iter(dataset_generator)\n",
    "#     for _ in range(start):\n",
    "#         next(it)\n",
    "#     for _ in range(end - start + 1):\n",
    "#         yield next(it)\n",
    "\n",
    "\n",
    "# # function to turn a generator that returns a dictionary with 'text' as key into a generator of the values\n",
    "# def create_text_generator(gen):\n",
    "#     for i in gen:\n",
    "#         yield i['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set path to datasets\n",
    "# data_path = '/Users/jan/Documents/Master/Thesis/Code/Datasets'\n",
    "\n",
    "# # download from huggingface\n",
    "# dataset_from_hub = load_dataset('oscar', 'unshuffled_deduplicated_nl', split='train', streaming=True, trust_remote_code=True)\n",
    "\n",
    "# # create from local files\n",
    "# oscar1 = os.path.join(data_path, 'OSCAR', 'nl_part_1.txt')\n",
    "# data_files = {\"train\": oscar1}\n",
    "# oscar_it_dict = load_dataset('text', data_files=data_files, split='train', streaming=True)\n",
    "\n",
    "# # create dictionary with a generator for every part\n",
    "# gen_dict = create_local_oscar_generators(data_path)\n",
    "\n",
    "# # create from local files\n",
    "# oscar_gen_1 = gen_dict['oscar1']\n",
    "# oscar_gen_2 = gen_dict['oscar2']\n",
    "\n",
    "# # create super generator from all OSCAR files on computer\n",
    "# oscar_gen_super = create_super_local_oscar_generator(data_path)\n",
    "\n",
    "# # create small dataset (uneven number of lines)\n",
    "# oscar_gen_small = create_test_set(oscar_gen_1, 0, 100007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CELEX database consists of more than 10 datasets, all focused on different features of language. For out purpuses, we use two of these datasets:\n",
    "- one with morphological segmentations\n",
    "- one with information that we can use to create groups of related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to datasets\n",
    "data_path = '/Users/jan/Documents/Master/Thesis/Code/Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "celex = os.path.join(data_path, 'CELEX-2-NL', 'DUTCH', 'DML', 'DML.CD')\n",
    "celex2 = os.path.join(data_path, 'CELEX-2-NL', 'DUTCH', 'DFW', 'DFW.CD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simlex(simlex999, scores=False):\n",
    "    # create list with a tuple for every word pair in the form of (word_1, word_2, similarity score, POS-tag)\n",
    "    word_pairs = []\n",
    "\n",
    "    # create a set with all words\n",
    "    words_set = set([])\n",
    "\n",
    "    with open(simlex999) as simlex:\n",
    "        \n",
    "        next(simlex) # skip first line\n",
    "        \n",
    "        for line in simlex:\n",
    "    \n",
    "            split = line.strip().split('\\t')\n",
    "            word_pairs.append(tuple(split))\n",
    "            words_set.add(split[0])\n",
    "            words_set.add(split[1])\n",
    "\n",
    "    # create a list of unique words\n",
    "    simlex_words = list(words_set)\n",
    "\n",
    "    if scores:\n",
    "        return word_pairs\n",
    "    else:\n",
    "        return simlex_words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_path = os.path.join(data_path, 'SimLex-999', 'SimLex-999-Dutch-final.txt')\n",
    "simlex_words = load_simlex(simlex_path)\n",
    "simlex_pairs = load_simlex(simlex_path, scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morfessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an existing module that is based on several (statistical) methods to morphilogically segment a word. A model is trained with a list of words. We will first do this for English and then for Dutch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import words\n",
    "\n",
    "\n",
    "# # using nltk word corpus as training data\n",
    "# words = words.words()\n",
    "# outfile = open(\"words\", \"w\")\n",
    "# for word in words:\n",
    "#     outfile.write(word+\"\\n\")\n",
    "\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n"
     ]
    }
   ],
   "source": [
    "# import math\n",
    "# import morfessor\n",
    "\n",
    "# # function for adjusting the counts of each compound\n",
    "# def log_func(x):\n",
    "#     return int(round(math.log(x + 1, 2)))\n",
    "\n",
    "# infile = \"words\"\n",
    "# io = morfessor.MorfessorIO()\n",
    "# train_data = list(io.read_corpus_file(infile))\n",
    "# model = morfessor.BaselineModel()\n",
    "# model.load_data(train_data, count_modifier=log_func)\n",
    "# model.train_batch()\n",
    "# io.write_binary_model_file(\"model.bin\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un', 'test', 'ably']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model_file = \"model.bin\"\n",
    "# io = morfessor.MorfessorIO()\n",
    "# model = io.read_binary_model_file(model_file)\n",
    "\n",
    "# word = 'untestably'\n",
    "# # for segmenting new words we use the viterbi_segment(compound) method\n",
    "# print(model.viterbi_segment(word)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dutch version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a Dutch model now. For this we only need a list of Dutch words. I have used this one: https://github.com/OpenTaal/opentaal-wordlist\n",
    "\n",
    "\n",
    "It contains over 400.000 Dutch words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n",
      "...........................................................\n"
     ]
    }
   ],
   "source": [
    "# def log_func(x):\n",
    "#     return int(round(math.log(x + 1, 2)))\n",
    "\n",
    "# infile = \"wordlist.txt\"\n",
    "# io = morfessor.MorfessorIO()\n",
    "# train_data = list(io.read_corpus_file(infile))\n",
    "# model_nl = morfessor.BaselineModel()\n",
    "# model_nl.load_data(train_data, count_modifier=log_func)\n",
    "# model_nl.train_batch()\n",
    "# io.write_binary_model_file(\"model_nl.bin\", model_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['huis', 'arrest']\n"
     ]
    }
   ],
   "source": [
    "# model_file = \"model_nl.bin\"\n",
    "# io = morfessor.MorfessorIO()\n",
    "# model_nl = io.read_binary_model_file(model_file)\n",
    "\n",
    "# word = 'huisarrest'\n",
    "# # for segmenting new words we use the viterbi_segment(compound) method\n",
    "# print(model_nl.viterbi_segment(word)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to use this model in our tokenization algorithm. Let's first see how long it takes to tokenize all 400.000 words with this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_nl = []\n",
    "\n",
    "# with open('wordlist.txt') as file:\n",
    "#     for i, line in enumerate(file):\n",
    "#         words_nl.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmented_words = {}\n",
    "# for word in words_nl:\n",
    "#     segmented_words[word] = model_nl.viterbi_segment(word)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily this is pretty fast, which means no problems will arise when we use it in our tokenization algorithm.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomTokenizerMorfessor:\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.vocab = {'UNK': 0}\n",
    "#         self.n = 0\n",
    "#         self.max_vocab_size = 50000\n",
    "#         self.model = morfessor.MorfessorIO().read_binary_model_file(\"model_nl.bin\") # this could of course be done differently, for instance by passing the model as argument, but it's fine for now\n",
    "    \n",
    "#     def get_vocab(self):\n",
    "#         return self.vocab # note: we should probably use a getter here, but for now this is ok\n",
    "    \n",
    "#     def normalize(self, seq):\n",
    "#         return seq.lower() \n",
    "    \n",
    "#     def pre_tokenize(self, seq):\n",
    "#         return seq.split()\n",
    "    \n",
    "#     def create_vocab(self, tokens):\n",
    "#         for token in tokens:\n",
    "#             if token not in self.vocab and len(self.get_vocab()) < self.max_vocab_size:\n",
    "#                 self.n += 1\n",
    "#                 self.vocab[token] = self.n\n",
    "    \n",
    "#     def encode(self, seq):\n",
    "#         seq = self.pre_tokenize(self.normalize(seq))\n",
    "#         seq = [self.model.viterbi_segment(word)[0] for word in seq]\n",
    "#         seq = [item for sublist in seq for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "#         return [self.vocab[token] if token in self.vocab else self.vocab['UNK'] for token in seq]\n",
    "    \n",
    "#     def decode(self, ids: list[int]):\n",
    "#         assert type(ids) == list\n",
    "#         assert type(ids[0]) == int   # dit kan wel netter, volgens mij kan het al met alleen type hints\n",
    "#         inverted_vocab = {value: key for key, value in self.vocab.items()}  # met een getter zou je dit niet elke keer opnieuw hoeven doen. Maar let altijd op of als je de een update je de ander ook update\n",
    "#         out = ''\n",
    "#         for idx in ids:\n",
    "#             out += inverted_vocab[idx] + ' '\n",
    "#         return out\n",
    "    \n",
    "#     def tokenize(self, seq):\n",
    "#         inverted_vocab = {value: key for key, value in self.vocab.items()}  # met een getter zou je dit niet elke keer opnieuw hoeven doen. Maar let altijd op of als je de een update je de ander ook update\n",
    "#         return [inverted_vocab[idx] if idx in inverted_vocab else inverted_vocab[0] for idx in self.encode(seq)]\n",
    "\n",
    "#     def __call__(self, seq):\n",
    "#         ids = self.encode(seq)\n",
    "#         types = [0 for token in ids]\n",
    "#         attention = [1 for token in ids]\n",
    "#         return {'input_ids': ids, 'token_type_ids': types, 'attention_mask': attention}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to use this morphological segmentation model in our tokenizer. Let's first see in how many unique parts the 400.000 words are split up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parts = set([])\n",
    "\n",
    "# for i in segmented_words.values():\n",
    "#     for j in i:\n",
    "#         parts.add(j)\n",
    "\n",
    "# parts = list(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 413937 words in the database are split up into 46463 unique units\n"
     ]
    }
   ],
   "source": [
    "# print(f'The {len(segmented_words)} words in the database are split up into {len(parts)} unique units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the more than 400.000 words can be represented by less than 47.000 tokens. This is actually a fairly common vocabulary size, so the first thing we can do is build a tokenizer with these 47.000 tokens as the vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA (CELEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find some more things about our dataset. In the 9th column we have the morphemes of a word. There are four options here:\n",
    "1. the entry is empty (because the word cannot be segmented and the word itself is not a morpheme)\n",
    "2. the entry has one morpheme that is identical with the word\n",
    "3. the entry has one morpheme that is not identical with the word\n",
    "4. the entry contains multiple morphemes, that when concatenated are identical to the word\n",
    "5. the entry contains multiple morphemes, that when concatenated are not identical to the word\n",
    "\n",
    "Let's see how often these things occur. We will first do this for the initial segmentations, so without an extra segmentation of parts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def initial_stats_celex(celex, print_info=True):\n",
    "\n",
    "#     n1 = {}\n",
    "#     n2 = {}\n",
    "#     n3 = {}\n",
    "#     n4 = {}\n",
    "#     n5 = {}\n",
    "#     doubles = {}\n",
    "\n",
    "\n",
    "#     with open(celex) as cd:\n",
    "#         for i, line in enumerate(cd):\n",
    "            \n",
    "#             line = line.strip().split('\\\\')\n",
    "            \n",
    "#             word = line[1]\n",
    "#             seg = line[8]\n",
    "#             morph = line[12]\n",
    "            \n",
    "#             if word in n1 or word in n2 or word in n3 or word in n4 or word in n5:\n",
    "#                 doubles[word] = i+1\n",
    "\n",
    "#             if len(seg) == 0:\n",
    "#                 n1[word] = i+1\n",
    "            \n",
    "#             else:\n",
    "#                 if not '+' in seg:\n",
    "#                     if word == seg:\n",
    "#                         n2[word] = i+1\n",
    "#                     else:\n",
    "#                         n3[word] = (i+1, seg)\n",
    "            \n",
    "#                 else:\n",
    "#                     split = seg.split('+')\n",
    "#                     concat = ''.join(split)\n",
    "\n",
    "#                     if concat == word:\n",
    "#                         n4[word] = i+1\n",
    "#                     else:\n",
    "#                         n5[word] = (i+1, seg)\n",
    "\n",
    "#     j = len(n1) + len(n2) + len(n3) + len(n4) + len(n5)\n",
    "\n",
    "#     print('---- Numbers for initial segmentation ----')\n",
    "#     print(f'Option 1 occurs {len(n1)} times ({round(100*len(n1)/j, 1)}%)')\n",
    "#     print(f'Option 2 occurs {len(n2)} times ({round(100*len(n2)/j, 1)}%)')\n",
    "#     print(f'Option 3 occurs {len(n3)} times ({round(100*len(n3)/j, 1)}%)')\n",
    "#     print(f'Option 4 occurs {len(n4)} times ({round(100*len(n4)/j, 1)}%)')\n",
    "#     print(f'Option 5 occurs {len(n5)} times ({round(100*len(n5)/j, 1)}%)')\n",
    "\n",
    "\n",
    "\n",
    "#     # do the same after an extra loop\n",
    "    \n",
    "# def stats_after_loop(segmentations):\n",
    "\n",
    "#     n1 = {}\n",
    "#     n2 = {}\n",
    "#     n3 = {}\n",
    "#     n4 = {}\n",
    "#     n5 = {}\n",
    "\n",
    "#     for word, seg in segmentations.items():\n",
    "#         if len(seg) == 0:\n",
    "#             n1[word] = seg\n",
    "#         if len(seg) == 1:\n",
    "#             if word == seg[0]:\n",
    "#                 n2[word] = seg\n",
    "#             else:\n",
    "#                 n3[word] = seg\n",
    "#         if len(seg) > 1:\n",
    "#             if word == ''.join(seg):\n",
    "#                 n4[word] = seg\n",
    "#             else:\n",
    "#                 n5[word] = seg \n",
    "\n",
    "\n",
    "#     j = len(n1) + len(n2) + len(n3) + len(n4) + len(n5)\n",
    "\n",
    "#     print('---- Numbers after extra segmentation step ----')\n",
    "#     print(f'Option 1 occurs {len(n1)} times ({round(100*len(n1)/j, 1)}%)')\n",
    "#     print(f'Option 2 occurs {len(n2)} times ({round(100*len(n2)/j, 1)}%)')\n",
    "#     print(f'Option 3 occurs {len(n3)} times ({round(100*len(n3)/j, 1)}%)')\n",
    "#     print(f'Option 4 occurs {len(n4)} times ({round(100*len(n4)/j, 1)}%)')\n",
    "#     print(f'Option 5 occurs {len(n5)} times ({round(100*len(n5)/j, 1)}%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that there are words that occur more than once in the dataset. Let's see how many times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates occur 539 times (0.0043%)\n"
     ]
    }
   ],
   "source": [
    "# def count_duplicates(celex):\n",
    "\n",
    "#     dub = {}\n",
    "#     duplicates = {}\n",
    "\n",
    "#     with open(celex) as cd:\n",
    "#         for i, line in enumerate(cd):\n",
    "            \n",
    "#             line = line.strip().split('\\\\')\n",
    "            \n",
    "#             word = line[1]\n",
    "#             seg = line[8]\n",
    "#             morph = line[12]\n",
    "\n",
    "#             if not word in dub:\n",
    "#                 dub[word] = seg\n",
    "            \n",
    "#             else:\n",
    "#                 if not dub[word] == seg:\n",
    "#                     duplicates[word] = (i, dub[word], seg)\n",
    "\n",
    "\n",
    "#     print(f'Duplicates occur {len(duplicates)} times ({round(len(duplicates)/i, 4)}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a segmentation dictionary from CELEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to create dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import json\n",
    "\n",
    "def load_json(path):\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        my_dict = json.load(f)\n",
    "    return my_dict\n",
    "\n",
    "def store_json(path, object):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(object, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_substrings(input_string):\n",
    "    \n",
    "    # Regular expression to match sequences of letters\n",
    "    pattern = re.compile(r'([a-zA-Z]+)')\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = pattern.findall(input_string)\n",
    "    \n",
    "    return [part for part in matches if not part in ['N', 'V', 'P', 'A', 'PA', 'PV']]\n",
    "\n",
    "\n",
    "\n",
    "def create_initial_dataframe(celex):\n",
    "    \n",
    "    new_dict2 = {}\n",
    "\n",
    "    with open(celex) as cd:\n",
    "        for line in cd:\n",
    "\n",
    "            \n",
    "            line = line.strip().split('\\\\')\n",
    "\n",
    "            \n",
    "            if line[12] == '':\n",
    "                cat = line[-1]\n",
    "            else:\n",
    "                cat = line[12][-2]\n",
    "\n",
    "            word = line[1]\n",
    "            seg = line[8]\n",
    "            morph = line[12]\n",
    "            parts = extract_substrings(morph)\n",
    "\n",
    "            new_dict2[word] = {'cat': cat, 'segments1': seg, 'segments2': parts, 'info': morph}\n",
    "\n",
    "    return new_dict2\n",
    "\n",
    "\n",
    "def create_segmentations_from_base(base, only_same_spelling=False):\n",
    "\n",
    "    new_dict_updated2 = {}\n",
    "\n",
    "    for word, dic in base.items():\n",
    "        \n",
    "        seg = dic['segments1']\n",
    "        split1 = seg.split('+')\n",
    "        split2 = dic['segments2']\n",
    "\n",
    "        concat1 = ''.join(split1)\n",
    "        concat2 = ''.join(split2)\n",
    "\n",
    "        if only_same_spelling:\n",
    "            if word == concat2:\n",
    "                new_dict_updated2[word] = split2\n",
    "            else:\n",
    "                if word == concat1:\n",
    "                        new_dict_updated2[word] = split1\n",
    "                else:\n",
    "                    if len(base[word]['segments1']) == 0 and len(base[word]['segments2']) == 0:\n",
    "                        new_dict_updated2[word] = []\n",
    "        else:\n",
    "            if word == concat2:\n",
    "                new_dict_updated2[word] = split2\n",
    "            else:\n",
    "                if word == concat1:\n",
    "                        new_dict_updated2[word] = split1\n",
    "                else:\n",
    "                    if len(base[word]['segments1']) == 0 and len(base[word]['segments2']) == 0:\n",
    "                        new_dict_updated2[word] = []\n",
    "                    else:\n",
    "                        if len(split1) > len(split2):\n",
    "                            new_dict_updated2[word] = split1\n",
    "                        else:\n",
    "                            new_dict_updated2[word] = split2\n",
    "        \n",
    "    return new_dict_updated2\n",
    "\n",
    "\n",
    "def add_basic_verbs(df, base):\n",
    "\n",
    "    new_dict_updated2 = copy.deepcopy(df)\n",
    "\n",
    "    for word, dic in base.items():\n",
    "        \n",
    "        seg = dic['segments1']\n",
    "        split1 = seg.split('+')\n",
    "        split2 = dic['segments2']\n",
    "\n",
    "        concat1 = ''.join(split1)\n",
    "        concat2 = ''.join(split2)\n",
    "\n",
    "        if dic['cat'] == 'V' and concat2 + 'en' == word:\n",
    "            split2.append('en')\n",
    "            new_dict_updated2[word] = split2\n",
    "\n",
    "        else:\n",
    "            if dic['cat'] == 'V' and concat1 + 'en' == word:\n",
    "                split1.append('en')\n",
    "                new_dict_updated2[word] = split1\n",
    "  \n",
    "    \n",
    "    return new_dict_updated2\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentations_extra_loop(df):\n",
    "    \n",
    "    segmentations_new = {}\n",
    "\n",
    "    n1 = 0\n",
    "\n",
    "    for word, segments in df.items():\n",
    "        seg = []\n",
    "        for unit in segments:\n",
    "            if not unit in df:\n",
    "                seg.append(unit)\n",
    "            else:\n",
    "                if len(df[unit]) == 0:\n",
    "                    seg.append(unit)\n",
    "                elif len(df[unit]) == 1:   # note: we must choose whether we want to replace words that have a single morpheme that is not identical with the word\n",
    "                    #seg.append(unit)      # we do this in another function now, so I don't do it here\n",
    "                    seg.append(df[unit][0])\n",
    "                else:\n",
    "                    seg += df[unit] \n",
    "    \n",
    "        segmentations_new[word] = seg\n",
    "    \n",
    "    return segmentations_new\n",
    "\n",
    "\n",
    "# this function adds all the morphemes in a dictionary to the dictionary with the morpheme as key and as value\n",
    "def add_morphemes_to_dict(d):\n",
    "\n",
    "    dic = d\n",
    "    n = 0\n",
    "\n",
    "    morfs = set([])\n",
    "\n",
    "    for word, segs in dic.items():\n",
    "        for seg in segs:\n",
    "            morfs.add(seg)\n",
    "\n",
    "    for morf in morfs:\n",
    "        if not morf in dic or len(dic[morf]) == 0:\n",
    "            n += 1\n",
    "            dic[morf] = [morf]\n",
    "\n",
    "    return dic\n",
    "\n",
    "\n",
    "\n",
    "# this function adds the word as segmentation of itself for all words that have an empty list as segmentation\n",
    "def add_empty_segmentations(df):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for word, seg in df.items():\n",
    "        if len(seg) == 0:\n",
    "            out[word] = [word]\n",
    "        else:\n",
    "            out[word] = seg\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# this function replaces the single morphemes that are not identical with the word with the word\n",
    "def replace_non_identical_morphs(df):\n",
    "     \n",
    "\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for word, seg in df.items():\n",
    "        if len(seg) == 1 and not word == seg[0]:\n",
    "            out[word] = [word]\n",
    "        else:\n",
    "            out[word] = seg\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create dictionary with related words for every word\n",
    "def create_word_fams(celex2):\n",
    "\n",
    "    word_fams = {}\n",
    "\n",
    "    with open(celex2) as cd:\n",
    "        for line in cd:\n",
    "            line = line.strip().split('\\\\')\n",
    "            word = line[1]\n",
    "            fam = line[2]\n",
    "            word_fams[word] = fam\n",
    "    \n",
    "    return word_fams\n",
    "\n",
    "\n",
    "# function to make 'inverse' dict by value\n",
    "def group_keys_by_value(input_dict):\n",
    "\n",
    "    value_to_keys = {}\n",
    "    for key, value in input_dict.items():\n",
    "        if value not in value_to_keys:\n",
    "            value_to_keys[value] = []\n",
    "        value_to_keys[value].append(key)\n",
    "  \n",
    "    output_dict = {key: [k for k in value_to_keys[input_dict[key]] if k != key] for key in input_dict}\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "\n",
    "# function to create extra segmentation dataframe for a suffix\n",
    "def create_extra_dataframe(df, word_fams, suffix):\n",
    "\n",
    "    word_groups = group_keys_by_value(word_fams)\n",
    "    \n",
    "    related_words = {word: rels for word, rels in word_groups.items() if word in initial_dataframe}\n",
    "\n",
    "    plus = {}\n",
    "    segmentations_extra = {}\n",
    "\n",
    "    for word in segmentations:\n",
    "        for rel in related_words[word]:\n",
    "            if not rel in segmentations and word + suffix == rel:\n",
    "                plus[word] = rel\n",
    "\n",
    "    for word, mult in plus.items():\n",
    "        segmentations_extra[mult] = segmentations[word] + [suffix]\n",
    "    \n",
    "    return segmentations_extra\n",
    "\n",
    "\n",
    "\n",
    "def remove_ortho_changes(df):\n",
    "\n",
    "\n",
    "    return {word: seg for word, seg in df.items() if ''.join(seg) == word}\n",
    "\n",
    "\n",
    "# function to add conjugations of verbs\n",
    "# the non_words parameter is for the greedy / non-greedy approach\n",
    "def create_verb_segmentations(base, groups, non_words=False):\n",
    "\n",
    "    extra_segmentations = {}\n",
    "\n",
    "    if non_words:\n",
    "\n",
    "        for word, dic in base.items():\n",
    "            \n",
    "            seg = dic['segments1']\n",
    "            split1 = seg.split('+')\n",
    "            split2 = dic['segments2']\n",
    "\n",
    "            concat1 = ''.join(split1)\n",
    "            concat2 = ''.join(split2)\n",
    "\n",
    "\n",
    "            if dic['cat'] == 'V' and concat2 + 'en' == word:  # waarom gebeurt dit nooit?\n",
    "\n",
    "\n",
    "                extra_segmentations[concat2 + 'de'] = split2 + ['de']\n",
    "                extra_segmentations[concat2 + 'den'] = split2 + ['den']\n",
    "                extra_segmentations[concat2 + 'end'] = split2 + ['end']\n",
    "                extra_segmentations[concat2 + 'ende'] = split2 + ['end', 'e']\n",
    "                extra_segmentations[concat2 + 't'] = split2 + ['t']\n",
    "                extra_segmentations['ge' + concat2 + 'd'] = ['ge'] + split2 + ['d']\n",
    "                extra_segmentations['ge' + concat2 + 't'] = ['ge'] + split2 + ['t']\n",
    "\n",
    "                extra_segmentations[concat2 + 'er'] = split2 + ['er']\n",
    "                extra_segmentations[concat2 + 'eur'] = split2 + ['eur']\n",
    "                extra_segmentations[concat2 + 'ster'] = split2 + ['ster']\n",
    "                extra_segmentations[concat2 + 'euse'] = split2 + ['euse']\n",
    "\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if dic['cat'] == 'V' and concat1 + 'en' == word:\n",
    "\n",
    "\n",
    "                    extra_segmentations[concat1 + 'de'] = split1 + ['de']\n",
    "                    extra_segmentations[concat1 + 'den'] = split1 + ['den']\n",
    "                    extra_segmentations[concat1 + 'end'] = split1 + ['end']\n",
    "                    extra_segmentations[concat1 + 'ende'] = split1 + ['end', 'e']\n",
    "                    extra_segmentations[concat1 + 't'] = split1 + ['t']\n",
    "                    extra_segmentations['ge' + concat1 + 'd'] = ['ge'] + split1 + ['d']\n",
    "                    extra_segmentations['ge' + concat1 + 't'] = ['ge'] + split1 + ['t']\n",
    "\n",
    "                    extra_segmentations[concat1 + 'er'] = split2 + ['er']\n",
    "                    extra_segmentations[concat1 + 'eur'] = split2 + ['eur']\n",
    "                    extra_segmentations[concat1 + 'ster'] = split2 + ['ster']\n",
    "                    extra_segmentations[concat1 + 'euse'] = split2 + ['euse']\n",
    "\n",
    "                    # nog toevoegen: werkwoorden als wegfietsen -> weg-ge-fiets-t\n",
    "                    # hoe herken je deze? niet-greedy is het wel te doen denk ik\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        for word, dic in base.items():\n",
    "            \n",
    "            seg = dic['segments1']\n",
    "            split1 = seg.split('+')\n",
    "            split2 = dic['segments2']\n",
    "\n",
    "            concat1 = ''.join(split1)\n",
    "            concat2 = ''.join(split2)\n",
    "\n",
    "\n",
    "            if dic['cat'] == 'V' and concat2 + 'en' == word:  # waarom gebeurt dit nooit?\n",
    "\n",
    "                if concat2 + 'de' in groups[word] :\n",
    "                    extra_segmentations[concat2 + 'de'] = split2 + ['de']\n",
    "                if concat2 + 'den' in groups[word] :\n",
    "                    extra_segmentations[concat2 + 'den'] = split2 + ['den']\n",
    "                if concat2 + 'end' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'end'] = split2 + ['end']\n",
    "                if concat2 + 'ende' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'ende'] = split2 + ['end', 'e']\n",
    "                if concat2 + 't' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 't'] = split2 + ['t']\n",
    "                if 'ge' + concat2 + 'd' in groups[word]:\n",
    "                    extra_segmentations['ge' + concat2 + 'd'] = ['ge'] + split2 + ['d']\n",
    "                if 'ge' + concat2 + 't' in groups[word]:\n",
    "                    extra_segmentations['ge' + concat2 + 't'] = ['ge'] + split2 + ['t']\n",
    "                if  concat2 + 'er' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'er'] = split2 + ['er']\n",
    "                if  concat2 + 'eur' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'eur'] = split2 + ['eur']\n",
    "                if  concat2 + 'ster' in groups[word]:\n",
    "                    extra_segmentations[concat2 + 'ster'] = split2 + ['ster']\n",
    "                if  concat2 + 'euse' in groups[word]:\n",
    "                        extra_segmentations[concat2 + 'euse'] = split2 + ['euse']\n",
    "\n",
    "\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if dic['cat'] == 'V' and concat1 + 'en' == word:\n",
    "\n",
    "                    if concat1 + 'de' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'de'] = split1 + ['de']\n",
    "                    if concat1 + 'den' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'den'] = split1 + ['den']\n",
    "                    if concat1 + 'end' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'end'] = split1 + ['end']\n",
    "                    if concat1 + 'ende' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'ende'] = split1 + ['end', 'e']\n",
    "                    if concat1 + 't' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 't'] = split1 + ['t']\n",
    "                    if 'ge' + concat1 + 'd' in groups[word]:\n",
    "                        extra_segmentations['ge' + concat1 + 'd'] = ['ge'] + split1 + ['d']\n",
    "                    if 'ge' + concat1 + 't' in groups[word]:\n",
    "                        extra_segmentations['ge' + concat1 + 't'] = ['ge'] + split1 + ['t']\n",
    "                    if  concat2 + 'er' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'er'] = split2 + ['er']\n",
    "                    if  concat2 + 'eur' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'eur'] = split2 + ['eur']\n",
    "                    if  concat2 + 'ster' in groups[word]:\n",
    "                        extra_segmentations[concat1 + 'ster'] = split2 + ['ster']\n",
    "                    if  concat2 + 'euse' in groups[word]:\n",
    "                            extra_segmentations[concat1 + 'euse'] = split2 + ['euse']\n",
    "        \n",
    "    return extra_segmentations\n",
    "\n",
    "\n",
    "def add_plurals_(dic):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    morphemes = set([])\n",
    "    for word, segs in dic.items():\n",
    "        for seg in segs:\n",
    "            morphemes.add(seg)\n",
    "    \n",
    "    for word, segs in dic.items():\n",
    "        out[word] = segs\n",
    "    \n",
    "    for word, segs in dic.items():\n",
    "        concat = ''.join(segs)\n",
    "        if word == concat + 'en':\n",
    "            out[word] = segs + ['en']\n",
    "        if word == concat + 's':\n",
    "            out[word] = segs + ['s']\n",
    "        if word == concat + 'je':\n",
    "            out[word] = segs + ['je']\n",
    "        if word == concat + 'jes':\n",
    "            out[word] = segs + ['je', 's']\n",
    "        if word == concat + 'tje':\n",
    "            out[word] = segs + ['tje']\n",
    "        if word == concat + 'tjes':\n",
    "            out[word] = segs + ['tje', 's']\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def create_n_segmentations(df, n):\n",
    "\n",
    "    return {word: segments for word, segments in df.items() if len(segments) >= n}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_noun_segmentations(df, groups, word_freqs, non_words=False, n_min=2):\n",
    "\n",
    "\n",
    "    prefixes = ['be', 'ge', 'her', 'on', 'ont', 'tegen', 'ver', 'aarts', 'opper', 'super', 'hyper', 'ultra', 'wan', 'vice', 'vice-', 'sub', 'anti', 'pro', 'ex', 'ex-', \n",
    "                'oud-', 'oud', 'niet-', 'niet', 'non-', 'non', 'her', 'weder', 're-', 'oer', 'pre', 'pre-', 'post', 'post-' 'inter', 'auto', 'neo', 'neo-', 'pan', 'pseudo', \n",
    "                'pan-', 'pseudo-', 'pseudo', 'anti-']\n",
    "    suffixes = ['aar', 'eur', 'achtig', 'es', 'aard', 'erd', 'heid', 'ig', 'erig', 'ij', 'in', 'ing', 'je', 'tje', 'lijk', 'schap', 'sel', 'te', 'teit',\n",
    "               'tie', 'tor', 'trix', 'ette', 'trice', 's', 'e', 'schap', 'en']\n",
    "    \n",
    "\n",
    "    if non_words:\n",
    "\n",
    "        segmentations_extra = {}\n",
    "\n",
    "        for word in df:\n",
    "            for suffix in suffixes:\n",
    "                segmentations_extra[word + suffix] = df[word] + [suffix]\n",
    "        \n",
    "        for word in df:\n",
    "            for prefix in prefixes:\n",
    "                segmentations_extra[prefix + word] = [prefix] + df[word] \n",
    "    \n",
    "    else:\n",
    "\n",
    "        segmentations_extra = {}\n",
    "\n",
    "        for word in df:\n",
    "            for suffix in suffixes:\n",
    "                if word + suffix in word_freqs:\n",
    "                    segmentations_extra[word + suffix] = df[word] + [suffix]\n",
    "\n",
    "        for word in df:\n",
    "            for prefix in prefixes:\n",
    "                if prefix + word in word_freqs:\n",
    "                    segmentations_extra[prefix + word] = [prefix] + df[word] \n",
    "\n",
    "        \n",
    "        for word in df:\n",
    "            for suffix in suffix:\n",
    "                for prefix in prefix:\n",
    "                    if prefix + word + suffix in word_freqs:\n",
    "                        segmentations_extra[prefix + word + suffix] = [prefix] + df[word] + [suffix]\n",
    "        \n",
    "        for word in df:\n",
    "            for suffix in suffixes:\n",
    "                for suffix2 in suffixes:\n",
    "                    if word + suffix + suffix2 in word_freqs:\n",
    "                        segmentations_extra[word + suffix + suffix2] = df[word] + [suffix] + [suffix2]\n",
    "        \n",
    "\n",
    "        for word in df:\n",
    "            for prefix in prefixes:\n",
    "                for prefix2 in suffixes:\n",
    "                    if prefix + prefix2 + word in word_freqs:\n",
    "                        segmentations_extra[prefix + prefix2 +word] = [prefix] + [prefix2] + df[word]\n",
    "\n",
    "        # for word in df:\n",
    "        #     for suffix in suffixes:\n",
    "        #         for suffix2 in suffixes:\n",
    "        #             for prefix in prefixes:\n",
    "        #                 if prefix + word + suffix + suffix2 in word_freqs:\n",
    "        #                     segmentations_extra[prefix + word + suffix + suffix2] = [prefix] + df[word] + [suffix] + [suffix2]\n",
    "\n",
    "        # for word in df:\n",
    "        #     for prefix in prefixes:\n",
    "        #         for prefix2 in suffixes:\n",
    "        #             for suffix in suffixes:\n",
    "        #                 if prefix + prefix2 + word + suffix in word_freqs:\n",
    "        #                     segmentations_extra[prefix + prefix2 + word + suffix] = [prefix] + [prefix2] + df[word] + [suffix]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # else:\n",
    "\n",
    "    #     related_words = {word: rels for word, rels in groups.items() if word in df}\n",
    "\n",
    "    #     segmentations_extra = {}\n",
    "\n",
    "    #     for word in df:\n",
    "    #         if word in related_words:\n",
    "    #             for rel in related_words[word]:\n",
    "    #                 for suffix in suffixes:\n",
    "    #                     if rel in df:\n",
    "    #                         if len(df[rel]) < n_min and word + suffix == rel:  # OR if word + suffix == rel:\n",
    "    #                             segmentations_extra[word + suffix] = df[word] + [suffix]\n",
    "    #                     else:\n",
    "    #                         segmentations_extra[word + suffix] = df[word] + [suffix]\n",
    "\n",
    "        \n",
    "    #     for word in df:\n",
    "    #         if word in related_words:\n",
    "    #             for rel in related_words[word]:\n",
    "    #                 for prefix in prefixes:\n",
    "    #                     if rel in df:\n",
    "    #                         if len(df[rel]) < n_min and word + prefix == rel: # OR if word + suffix == rel:\n",
    "    #                             segmentations_extra[prefix + word] = [prefix] + df[word] \n",
    "    #                     else:\n",
    "    #                         segmentations_extra[prefix + word] = [prefix] + df[word] \n",
    "  \n",
    "    \n",
    "    return segmentations_extra\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_compounds_(df, word_freqs, replace=False):\n",
    "\n",
    "\n",
    "    extra = {}\n",
    "\n",
    "\n",
    "\n",
    "    for word in df:\n",
    "        for word2 in df:\n",
    "            if word + word2 in word_freqs:\n",
    "                extra[word + word2] = df[word] + df[word2]\n",
    "    \n",
    "    if replace:\n",
    "        return df | extra\n",
    "\n",
    "    else: \n",
    "        return extra | df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_dictionaries_verb(dic1, dic2, replace=True, n_min=2):\n",
    "    \n",
    "    out = {word: segs for word, segs in dic1.items()}\n",
    "    words_not_to_be_replaced = ['beurt', 'buit', 'dorst', 'geit', 'luid', 'geluid', 'pracht', 'rijt', 'ruit', 'geruit', 'sliert', 'spijt', 'spuit', 'tuit', 'vlijt', 'vorst']\n",
    "    \n",
    "    if replace:\n",
    "        for word, segs in dic2.items():\n",
    "            if not word in words_not_to_be_replaced:\n",
    "                out[word] = segs\n",
    "    else:\n",
    "        for word, segs in dic2.items():\n",
    "            if word in out:\n",
    "                pass\n",
    "            else:\n",
    "                out[word] = segs\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_dictionaries_nouns(dic1, dic2, replace=True, n_min=2):\n",
    "    \n",
    "    out = {word: segs for word, segs in dic1.items()}\n",
    "    \n",
    "    if replace:\n",
    "        for word, segs in dic2.items():\n",
    "                out[word] = segs\n",
    "    else:\n",
    "        for word, segs in dic2.items():\n",
    "            if word in out:\n",
    "                if len(segs) >= 2 and segs[0] == 'on' and segs[1] == 'ge':\n",
    "                    out[word] = segs\n",
    "            else:\n",
    "                out[word] = segs\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def count_morphemes(df):\n",
    "\n",
    "    total = set([])\n",
    "    out = set([])\n",
    "    for word, segs in df.items():\n",
    "        out.add(segs[0])\n",
    "        for seg in segs:\n",
    "            total.add(seg)\n",
    "    print(f'There are {len(total)} morphemes, out of these {len(out)} appear at the begining of a word')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_words_not_in_corpus(df, word_freqs, treshold=0):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    if treshold > 0:\n",
    "        for word, segs in df.items():\n",
    "            if word in word_freqs:\n",
    "                if word_freqs[word] > treshold:\n",
    "                    out[word] = segs\n",
    "\n",
    "    else:\n",
    "\n",
    "        for word, segs in df.items():\n",
    "            if word in word_freqs:\n",
    "                out[word] = segs\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "###  Complete function to create a dictionary from the database  ###\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "def create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs, extra_loop=True, add_morphemes=True, \n",
    "                                   add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=False,\n",
    "                                   add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "                                   add_compounds=True, replace_compounds=False, remove_ortho=True, remove_not_in_corpus=False, meta_data=False, print_info=True):\n",
    "    \n",
    "    # create base dictionary of dictionaries for every word in the dataset\n",
    "    base = create_initial_dataframe(segmentation_data)\n",
    "    stats = {}\n",
    "\n",
    "    # create initial segmentation dictionary\n",
    "    dic = create_segmentations_from_base(base)\n",
    "\n",
    "    # add basic verbs\n",
    "    dic = add_basic_verbs(dic, base)\n",
    "\n",
    "    # print stats\n",
    "    n0 = len([word for word, segs in dic.items() if len(segs) == 0])\n",
    "    n1 = len([word for word, segs in dic.items() if len(segs) == 1])\n",
    "    n2 = len([word for word, segs in dic.items() if len(segs) > 1])\n",
    "    stats['size_0'] = n0\n",
    "    stats['size_1'] = n1\n",
    "    stats['size_2+'] = n2\n",
    "    if print_info:\n",
    "        print(f'''There are {len(dic)} entries in the database. Out of these:\n",
    "          - {n0} words have no segmentations\n",
    "          - {n1} words have a single morpheme as segmentation \n",
    "          - {n2} words are split up into multiple morphemes\\n''')\n",
    "\n",
    "\n",
    "    # add possible further segmentations of segments\n",
    "    d = copy.deepcopy(dic)\n",
    "    if extra_loop:\n",
    "        dic = create_segmentations_extra_loop(dic)\n",
    "    \n",
    "        # print stats\n",
    "        loop_changes = [word for word in dic if not dic[word] == d[word] or not word in d]\n",
    "        n3 = len(loop_changes)\n",
    "        stats['loop changes'] = loop_changes\n",
    "        stats['number of loop changes'] = n3\n",
    "        if print_info:\n",
    "            print(f'- Including the extra loop has increased the number of morphemes for {n3} words [total size = {len(dic)}]')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # add every morpheme in the segmentations as entry to the dictionary\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_morphemes:\n",
    "        dic = add_morphemes_to_dict(dic)\n",
    "\n",
    "        # print stats\n",
    "        morphs_added = set(dic) - set(d)\n",
    "        n4 = len(morphs_added)\n",
    "        stats['morphemes added'] = morphs_added\n",
    "        stats['number of morphs added'] = n4\n",
    "        if print_info:\n",
    "            print(f'- {n4} Morphemes were added as entry to the dictionary [total size = {len(dic)}]')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # add every word with no segmentation to the dictionary with itself as value\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_empty:\n",
    "        dic = add_empty_segmentations(dic)\n",
    "        \n",
    "        # print stats\n",
    "        added_words = set([word for word, seg in d.items() if len(seg) == 0]) - set([word for word, seg in dic.items() if len(seg) == 0])\n",
    "        n5 = len(added_words)\n",
    "        stats['identical words added'] = list(added_words)\n",
    "        stats['number of idenitical words added'] = n5\n",
    "        if print_info:\n",
    "            print(f'- By choosing to add the words with no segmentation to the dictionary, {n5} segmentations were added [total size = {len(dic)}]')\n",
    "    \n",
    "\n",
    "    # add plurals\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_plurals:\n",
    "        dic = add_plurals_(dic)\n",
    "\n",
    "    \n",
    "    # replace the single morphemes that are not identical with the word with the word\n",
    "    d = copy.deepcopy(dic)\n",
    "    stats['non identical words'] = [word for word, seg in d.items() if len(seg) == 1 and not word == seg[0]]\n",
    "    if replace_non_identical:\n",
    "        dic = replace_non_identical_morphs(dic)\n",
    "        words_replaced = set([word for word, seg in d.items() if len(seg) == 1 and not word == seg[0]]) - set([word for word, seg in dic.items() if len(seg) == 1 and not word == seg[0]])\n",
    "        n6 = len(words_replaced)\n",
    "        stats['number of non identical words replaced'] = n6\n",
    "        \n",
    "        # print stats\n",
    "        if print_info:\n",
    "            print(f'- {n6} Non-identical single morph words were replaced with the identical word [total size = {len(dic)}]')\n",
    "    \n",
    "\n",
    "    # load data with word families\n",
    "    word_fams = create_word_fams(word_family_data)\n",
    "    word_groups = group_keys_by_value(word_fams)\n",
    "\n",
    "\n",
    "    # add verb conjugation\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_verbs:\n",
    "        if greedy_verb:\n",
    "            extra = create_verb_segmentations(base, word_groups, True)\n",
    "            if replace_verbs:\n",
    "                dic = merge_dictionaries_verb(dic, extra, replace=True, n_min=2)\n",
    "                # if remove_not_in_corpus:\n",
    "                #     dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "            else:\n",
    "                dic = merge_dictionaries_verb(dic, extra, replace=False)\n",
    "                # if remove_not_in_corpus:\n",
    "                #     dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            extra = create_verb_segmentations(base, word_groups, False)\n",
    "            if replace_verbs:\n",
    "                dic = merge_dictionaries_verb(dic, extra, replace=True, n_min=2)\n",
    "                # if remove_not_in_corpus:\n",
    "                #     dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "            else:\n",
    "                dic = merge_dictionaries_verb(dic, extra, replace=False)\n",
    "                # if remove_not_in_corpus:\n",
    "                #     dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "            \n",
    "        \n",
    "        # print stats\n",
    "        verb_additions = set(dic) - set(d)\n",
    "        n7 = len(verb_additions)\n",
    "        stats['verb conjugates added'] = verb_additions\n",
    "        stats['number of verb conjugates added'] = n7\n",
    "        if print_info:\n",
    "            if greedy_verb:\n",
    "                print(f'- By choosing to add verbs with a greedy approach, {n7} verb conjugates were added to the dictionary [total size = {len(dic)}]')\n",
    "            else:\n",
    "                print(f'- By choosing to add verbs with a non-greedy approach, {n7} verb conjugates were added to the dictionary [total size = {len(dic)}]')\n",
    "\n",
    "    \n",
    "    # add noun conjugation\n",
    "    d = copy.deepcopy(dic)\n",
    "    if add_nouns:\n",
    "        if greedy_noun:\n",
    "            extra = create_noun_segmentations(dic, word_groups, word_freqs, True)\n",
    "            if replace_nouns:\n",
    "                dic = merge_dictionaries_nouns(dic, extra, replace=True, n_min=2)\n",
    "            else:\n",
    "                dic = merge_dictionaries_nouns(dic, extra, replace=False)\n",
    "        else:\n",
    "            extra = create_noun_segmentations(dic, word_groups, word_freqs, False)\n",
    "            if replace_nouns:\n",
    "                dic = merge_dictionaries_nouns(dic, extra, replace=True, n_min=2)\n",
    "            else:\n",
    "                dic = merge_dictionaries_nouns(dic, extra, replace=False)\n",
    "        \n",
    "        # print stats\n",
    "        noun_additions = set(dic) - set(d)\n",
    "        n8 = len(noun_additions)\n",
    "        stats['noun conjugates added'] = noun_additions\n",
    "        stats['number of noun conjugates added'] = n8\n",
    "        if print_info:\n",
    "            if greedy_noun:\n",
    "                print(f'- By choosing to add nouns with a greedy approach, {n8} noun conjugates were added to the dictionary [total size = {len(dic)}]')\n",
    "            else:\n",
    "                print(f'- By choosing to add nouns with a non-greedy approach, {n8} noun conjugates were added to the dictionary [total size = {len(dic)}]')\n",
    "    \n",
    "\n",
    "\n",
    "    # remove the enties that have less than n morphemes (standard: delete empty segmentations)\n",
    "    d = copy.deepcopy(dic)\n",
    "    dic = {word: segs for word, segs in dic.items() if len(segs) >= min_n_segments}\n",
    "    words_deleted = set(d) - set(dic)\n",
    "    n9 = len(words_deleted)\n",
    "    stats['empty words deleted'] = words_deleted\n",
    "    stats['number of empty words deleted'] = n9\n",
    "    if print_info:\n",
    "        print(f'- By choosing to remove the words with less than {min_n_segments} morpheme(s), {n9} words were deleted [total size = {len(dic)}]')\n",
    "\n",
    "\n",
    "    # remove words with orthograpic changes in the segmentation\n",
    "    if remove_ortho:\n",
    "        d = copy.deepcopy(dic)\n",
    "        dic = remove_ortho_changes(dic)\n",
    "        \n",
    "        # print stats \n",
    "        removed = set(d) - set(dic)\n",
    "        n10 = len(removed)\n",
    "        stats['ortho words deleted'] = removed\n",
    "        stats['number of ortho words deleted'] = n10\n",
    "        if print_info:\n",
    "            print(f'- By choosing to remove the words where a change in spelling in the segmentations occurs, {n10} words were removed [total size = {len(dic)}]')\n",
    "    \n",
    "\n",
    "\n",
    "    # remove words that do not occur in a corpus\n",
    "    if remove_not_in_corpus:\n",
    "        dic = remove_words_not_in_corpus(dic, word_freqs)\n",
    "\n",
    "    # add compounds\n",
    "    if add_compounds:\n",
    "        if replace_compounds:\n",
    "            dic = add_compounds_(dic, word_freqs, True)\n",
    "        else:\n",
    "            dic = add_compounds_(dic, word_freqs, False)\n",
    "\n",
    "\n",
    "    # return just the dictonary, or add meta-data\n",
    "    if meta_data:\n",
    "        return dic, stats\n",
    "    else:\n",
    "        return dic\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10, 2: 30, 3: 40}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1: 10, 2: 20}\n",
    "b = {2: 30, 3: 40}\n",
    "\n",
    "a | b\n",
    "\n",
    "#b | a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to compare dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the tokenizers, we need the following elements:\n",
    "- the simlex words\n",
    "- a corpus in the form of a generator\n",
    "- a corpus in the form of a frequency dictionary\n",
    "\n",
    "We will create various different versions of these three elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_basic(seq):\n",
    "    return [s.strip(string.punctuation) for s in seq.strip().split()]\n",
    "\n",
    "def preprocess_lower(seq):\n",
    "    return [s.strip(string.punctuation) for s in seq.strip().lower().split()]\n",
    "\n",
    "def preprocess_bpe(seq, tokenizer):\n",
    "    return [word.replace('Ġ', '') for word in [word for word, offset in tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)]]\n",
    "\n",
    "\n",
    "# this function counts the number of times words in a dataframe occur in a corpus, taking the corpus as generator\n",
    "def count_frequency_from_generator(words, corpus_generator):\n",
    "\n",
    "    words_in = 0\n",
    "    words_out = 0\n",
    "\n",
    "    for i in corpus_generator:\n",
    "        text = preprocess_lower(i) # andere preproces mogelijk\n",
    "        for word in text:\n",
    "            if word in words:\n",
    "                words_in += 1\n",
    "            else:\n",
    "                words_out += 1\n",
    "    \n",
    "    print(f'{round(100 * words_in / (words_in + words_out), 1)}% of words in the corpus are in the celex database')\n",
    "    print(f'{round(100 * words_out / (words_in + words_out), 1)}% of words are not')\n",
    "\n",
    "    return (words_in, words_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function creates a word frequency dictionary for a corpus, so that we can count faster later on\n",
    "def create_word_freqs_from_corpus(corpus_generator, sorted=False):\n",
    "    \n",
    "    word_freqs = {}\n",
    "\n",
    "    for i in corpus_generator:     \n",
    "        text = preprocess_basic(i)\n",
    "        for word in text:\n",
    "            if word in word_freqs:\n",
    "                word_freqs[word] += 1\n",
    "            else:\n",
    "                word_freqs[word] = 1\n",
    "    \n",
    "    if sorted:\n",
    "        word_freqs = dict(sorted(word_freqs.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "\n",
    "# this function creates a word frequency dictionary for a corpus, so that we can count faster later on\n",
    "# a progress bar was added\n",
    "def create_word_freqs_from_local_corpus(corpus_generator, sort=False, progress=True, path=0, prep_lower=False):\n",
    "    \n",
    "    if progress:\n",
    "        print(f'Estimating the size of the dataset ...\\n')\n",
    "        if path == 0:\n",
    "            assert path == 1, 'Enter path to get progress bar, or set progress=False to perform the function without one'\n",
    "        else:\n",
    "            size = get_size_for_local(path)\n",
    "    \n",
    "        word_freqs = {}\n",
    "        \n",
    "        for i in range(1):\n",
    "            if i == 0:\n",
    "                print(f'Data size: {format_with_dots(size)} lines of text! Generating the frequency dictionary ...')\n",
    "\n",
    "        if prep_lower:\n",
    "\n",
    "            for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "                text = preprocess_lower(i)\n",
    "                for word in text:\n",
    "                    if word in word_freqs:\n",
    "                        word_freqs[word] += 1\n",
    "                    else:\n",
    "                        word_freqs[word] = 1\n",
    "        \n",
    "        else:\n",
    "\n",
    "            for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "                text = preprocess_basic(i)\n",
    "                print(text)\n",
    "                for word in text:\n",
    "                    if word in word_freqs:\n",
    "                        word_freqs[word] += 1\n",
    "                    else:\n",
    "                        word_freqs[word] = 1\n",
    "    \n",
    "    else:\n",
    "\n",
    "        print('Performing task without progress bar')\n",
    "\n",
    "        word_freqs = {}\n",
    "\n",
    "        for i in corpus_generator:     \n",
    "            text = preprocess_basic(i)\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "        \n",
    "    if sort:\n",
    "        word_freqs = dict(sorted(word_freqs.items(), key=lambda item: item[1], reverse=True)) \n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "# this function creates a frequency dictionary for a corpus loaded with a generator, especially usefull for streaming from huggingface server\n",
    "def create_word_freqs_from_online_corpus(corpus_generator, sorted=False, progress=True, avg_size=6750000, n_files=45):\n",
    "\n",
    "    size = n_files * avg_size\n",
    "    \n",
    "    if progress:\n",
    "        print(f'The estimated size of the entire corpus is around {format_with_dots(size)} lines of text!')\n",
    "        \n",
    "        word_freqs = {}\n",
    "\n",
    "        for i in range(1):\n",
    "            if i == 0:\n",
    "                print(f'Generating the frequency dictionary ...\\n')\n",
    "\n",
    "        for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "            text = preprocess_basic(i['text'])\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "\n",
    "def get_size_for_local(path):\n",
    "    with open(path) as osc:\n",
    "        n = 0\n",
    "        for line in osc:\n",
    "            n+= 1\n",
    "        return n \n",
    "\n",
    "def format_with_dots(number):\n",
    "    return f\"{number:,}\".replace(\",\", \".\")\n",
    "\n",
    "\n",
    "# this function counts how many of the words in a dataframe occur at least once in the corpus, which is printed\n",
    "# it returns two lists, one with the words in the corpus, one with the words not in the corpus\n",
    "# update: now also returns frequencies\n",
    "def dataset_in_corpus(df, word_freqs, lower=False, print_info=True):\n",
    "\n",
    "    words_in = {}\n",
    "    words_out = []\n",
    "\n",
    "    if lower:\n",
    "\n",
    "        word_freqs_lower = {key.lower(): value for key, value in word_freqs.items()}\n",
    "\n",
    "        for word in df:\n",
    "            if word in word_freqs or word in word_freqs_lower:\n",
    "                if word in words_in:\n",
    "                    if word in word_freqs:\n",
    "                        words_in[word] += word_freqs[word]\n",
    "                    else:\n",
    "                        words_in[word] += word_freqs_lower[word]\n",
    "                else:\n",
    "                    if word in word_freqs:\n",
    "                        words_in[word] = word_freqs[word]\n",
    "                    else:\n",
    "                        words_in[word] = word_freqs_lower[word]\n",
    "\n",
    "            else:\n",
    "                words_out.append(word)\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        for word in df:\n",
    "            if word in word_freqs:\n",
    "                if word in words_in:\n",
    "                    words_in[word] += word_freqs[word]\n",
    "                else:\n",
    "                    words_in[word] = word_freqs[word]\n",
    "            \n",
    "            else:\n",
    "                words_out.append(word)\n",
    "\n",
    "    \n",
    "    n_in = len(words_in)\n",
    "    n_out = len(words_out)\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'{round(100 * n_in / (n_in + n_out), 1)}% of words in the dataset are in the corpus')\n",
    "        print(f'{round(100 * n_out / (n_in + n_out), 1)}% of words are not\\n')\n",
    "\n",
    "    return words_in, words_out\n",
    "\n",
    "\n",
    "# this function calculates the number of words in the corpus that are in a dataframe. \n",
    "# two prints are made: one for every word in the corpus that is in the dataframe, one for every unique word in the corpus that is in the dataframe\n",
    "# the function returns four dictionaries (in/not in dataframe - all/unique)\n",
    "def corpus_in_dataset(df, word_freqs, lower=False, print_info=True):\n",
    "\n",
    "    n_in = 0\n",
    "    n_out = 0\n",
    "\n",
    "    n_in_abs = 0\n",
    "    n_out_abs = 0\n",
    "\n",
    "    words_in = []\n",
    "    words_out = []\n",
    "\n",
    "    if lower:\n",
    "\n",
    "        for word in word_freqs:\n",
    "            if word in df or word.lower() in df:\n",
    "                n_in += word_freqs[word]\n",
    "                n_in_abs += 1\n",
    "                words_in.append(word)\n",
    "            else:\n",
    "                n_out += word_freqs[word]\n",
    "                n_out_abs += 1\n",
    "                words_out.append(word)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for word in word_freqs:\n",
    "            if word in df:\n",
    "                n_in += word_freqs[word]\n",
    "                n_in_abs += 1\n",
    "                words_in.append(word)\n",
    "            else:\n",
    "                n_out += word_freqs[word]\n",
    "                n_out_abs += 1\n",
    "                words_out.append(word)\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'{round(100 * n_in / (n_in + n_out), 1)}% of words in the corpus are in the dataset')\n",
    "        print(f'{round(100 * n_out / (n_in + n_out), 1)}% of words are not\\n')\n",
    "\n",
    "        print(f'{round(100 * n_in_abs / (n_in_abs + n_out_abs), 1)}% of unique words in the corpus are in the dataset')\n",
    "        print(f'{round(100 * n_out_abs / (n_in_abs + n_out_abs), 1)}% of unique words are not\\n')\n",
    "\n",
    "    return words_in, words_out, n_in, n_out, n_in_abs, n_out_abs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function uses the previous two functions to give a 'complete' picture of the relationship between a dataframe and the corpus\n",
    "def compare_dataset_and_corpus(df, word_freqs, lower_=False, print_info_=True):\n",
    "\n",
    "    n_corpus = sum(word_freqs.values())\n",
    "    n_dataset = len(df)\n",
    "\n",
    "    if print_info_:\n",
    "        print(f'There are {n_corpus} words in the corpus')\n",
    "        print(f'There are {n_dataset} words in the dataset\\n')\n",
    "\n",
    "    a, b, c, d, e, f = corpus_in_dataset(df, word_freqs, lower=lower_, print_info=print_info_)\n",
    "    g, h = dataset_in_corpus(df, word_freqs, lower=lower_, print_info=print_info_)\n",
    "    \n",
    "    #return g, b, f\n",
    "    return {'in both': g, 'not in dataset': b, 'not in corpus': h, 'n in both': c, 'n not in dataset': d, 'n in corpus': len(g), 'n not in corpus': len(h)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function is not finished yet\n",
    "# def compare_segmentations_and_corpus(df, word_freqs, lower=False):\n",
    "\n",
    "#     a = {word for word, segments in df.items() if len(segments) == 0}\n",
    "#     b = {seg for segments in df.values() for seg in segments if len(segments) == 1}\n",
    "#     c = {seg for segments in df.values() for seg in segments if len(segments) > 1}\n",
    "\n",
    "#     tokens_max = a | b | c\n",
    "#     tokens_min = c\n",
    "#     tokens_x = b | c\n",
    "\n",
    "\n",
    "\n",
    "# this function calculates the percentage of words that have no orthographic changes in the segmentation that have at least two moprhemes\n",
    "# it does this in relation to a corpus,  so based on the number of times it occurs in the corpus\n",
    "def count_ortho(df, word_freqs, lower=False):\n",
    "\n",
    "    segmentations = {word: segments for word, segments in df.items() if len(segments) >= 2}\n",
    "\n",
    "    seg = {word for word, segments in segmentations.items() if ''.join(segments) == word}\n",
    "    no_seg = {word for word, segments in segmentations.items() if ''.join(segments) != word}\n",
    "\n",
    "    n_in = 0\n",
    "    n_out = 0\n",
    "\n",
    "    n_total = sum(word_freqs.values())\n",
    "\n",
    "    if lower:\n",
    "\n",
    "        for word in word_freqs:\n",
    "            if word in seg or word.lower() in seg:\n",
    "                n_in += word_freqs[word]\n",
    "            elif word in no_seg or word.lower() in no_seg:\n",
    "                n_out += word_freqs[word]\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for word in word_freqs:\n",
    "            if word in seg:\n",
    "                n_in += word_freqs[word]\n",
    "            elif word in no_seg:\n",
    "                n_out += word_freqs[word]\n",
    "\n",
    "\n",
    "    print(f'{round(100 * n_in / (n_in + n_out), 1)}% of segmentable words in the corpus are segmented via the dict')\n",
    "    print(f'This is equal to {round(100 * n_in / n_total, 1)}% of words in the corpus \\n')\n",
    "\n",
    "\n",
    "\n",
    "def sort_dictionary(df, descending=True):\n",
    "\n",
    "    if descending:\n",
    "         sorted_dict = dict(sorted(df.items(), key=lambda item: item[1], reverse=True))\n",
    "    else:\n",
    "        sorted_dict = dict(sorted(df.items(), key=lambda item: item[1]))\n",
    "    \n",
    "    return sorted_dict\n",
    "\n",
    "\n",
    "\n",
    "def combine_dictionaries(*dictionaries):\n",
    "    out = {}\n",
    "    for dictionary in dictionaries:\n",
    "        for word, freq in dictionary.items():\n",
    "            if word in out:\n",
    "                out[word] += freq\n",
    "            else:\n",
    "                out[word] = freq\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_multiple_dicts_and_copora(frequency_dictionaries, datasets):\n",
    "    \n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    for i, freq in enumerate(frequency_dictionaries):\n",
    "        x = f'Corpus {i+1}'\n",
    "        results1[x] = {}\n",
    "        results2[x] = {}\n",
    "\n",
    "\n",
    "        for j, data in enumerate(datasets):\n",
    "\n",
    "\n",
    "            y = f'Segmentations {j+1}'\n",
    "    \n",
    "\n",
    "            result = compare_dataset_and_corpus(data, freq, print_info_=False)\n",
    "            in_both = result['in both']\n",
    "            not_in_data = result['not in dataset']\n",
    "            not_in_corpus = result['not in corpus']\n",
    "            n_in_both = result['n in both']\n",
    "            n_not_in_data = result['n not in dataset']\n",
    "            n_in_corpus = result['n in corpus']\n",
    "            n_not_in_corpus = result['n not in corpus']\n",
    "\n",
    "\n",
    "            a = round(100 * n_in_both / (n_in_both + n_not_in_data), 1)\n",
    "            b = round(100 * n_in_corpus / (n_in_corpus + n_not_in_corpus), 1)\n",
    "\n",
    "            results1[x][y] = a\n",
    "            results2[x][y] = b\n",
    "    \n",
    "    df1 = pd.DataFrame(results1) #.T\n",
    "    df2 = pd.DataFrame(results2) #.T\n",
    "            \n",
    "\n",
    "    print(df1)\n",
    "    print('\\n')\n",
    "    print(df2)\n",
    "\n",
    "\n",
    "def compare_multiple_corpora(frequency_dictionaries, dataset):\n",
    "    \n",
    "    results1 = {}\n",
    "\n",
    "    \n",
    "    for i, freq in enumerate(frequency_dictionaries):\n",
    "        x = f'Corpus {i+1}'\n",
    "        results1[x] = {}\n",
    "\n",
    "        result = compare_dataset_and_corpus(dataset, freq, print_info_=False)\n",
    "        in_both = result['in both']\n",
    "        not_in_data = result['not in dataset']\n",
    "        not_in_corpus = result['not in corpus']\n",
    "        n_in_both = result['n in both']\n",
    "        n_not_in_data = result['n not in dataset']\n",
    "        n_in_corpus = result['n in corpus']\n",
    "        n_not_in_corpus = result['n not in corpus']\n",
    "\n",
    "\n",
    "        a = round(100 * n_in_both / (n_in_both + n_not_in_data), 1)\n",
    "        b = round(100 * n_in_corpus / (n_in_corpus + n_not_in_corpus), 1)\n",
    "\n",
    "        results1[x]['A'] = a\n",
    "        results1[x]['B'] = b\n",
    "\n",
    "    \n",
    "    df1 = pd.DataFrame(results1) #.T  \n",
    "\n",
    "    return df1\n",
    "\n",
    "\n",
    "\n",
    "def compare_multiple_dicts(frequency_dictionary, datasets):\n",
    "    \n",
    "    results1 = {}\n",
    "\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        x = f'Segmentations dictionary {i+1}'\n",
    "        results1[x] = {}\n",
    "\n",
    "        result = compare_dataset_and_corpus(dataset, frequency_dictionary, print_info_=False)\n",
    "        in_both = result['in both']\n",
    "        not_in_data = result['not in dataset']\n",
    "        not_in_corpus = result['not in corpus']\n",
    "        n_in_both = result['n in both']\n",
    "        n_not_in_data = result['n not in dataset']\n",
    "        n_in_corpus = result['n in corpus']\n",
    "        n_not_in_corpus = result['n not in corpus']\n",
    "\n",
    "\n",
    "        a = round(100 * n_in_both / (n_in_both + n_not_in_data), 1)\n",
    "        b = round(100 * n_in_corpus / (n_in_corpus + n_not_in_corpus), 1)\n",
    "\n",
    "        results1[x]['Corpus words in segmentations dict (%)'] = a\n",
    "        results1[x]['Segmentations dict words in corpus (%)'] = b\n",
    "\n",
    "    \n",
    "    df1 = pd.DataFrame(results1).T  \n",
    "\n",
    "    return df1\n",
    "\n",
    "\n",
    "def compare_only_dictionaries(dict1, dict2, return_dict=False):\n",
    "\n",
    "    diff = []\n",
    "    not_in_2 = []\n",
    "    not_in_1 = []\n",
    "    \n",
    "    for word, segs in dict1.items():\n",
    "        if word in dict2:\n",
    "            if not segs == dict2[word]:\n",
    "                diff.append(word)\n",
    "        else:\n",
    "            not_in_2.append(word)\n",
    "    \n",
    "    for word, segs in dict2.items():\n",
    "        if word in dict1:\n",
    "            if not segs == dict1[word]:\n",
    "                diff.append(word)\n",
    "        else:\n",
    "            not_in_1.append(word)\n",
    "\n",
    "    dic = {word: (dict1[word], dict2[word]) for word in diff}\n",
    "\n",
    "    if return_dict:\n",
    "        return dic, not_in_2, not_in_1\n",
    "    else:\n",
    "        return diff, not_in_2, not_in_1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_sets(a, b, print_info=True):\n",
    "\n",
    "    incl = []\n",
    "    excl = []\n",
    "\n",
    "    for word in a:\n",
    "        if word in b:\n",
    "            incl.append(word)\n",
    "        else:\n",
    "            excl.append(word)\n",
    "\n",
    "    p_in = 100 * len(incl) / len(a)\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'{round(p_in, 2)}% of words in set a are in set b')\n",
    "    \n",
    "    return incl, excl\n",
    "\n",
    "\n",
    "def compare_dict_simlex(sim, dic, print_info=True):\n",
    "\n",
    "    incl = []\n",
    "    excl = []\n",
    "    mult = 0\n",
    "\n",
    "    for word in sim:\n",
    "        if word in dic:\n",
    "            incl.append(word)\n",
    "            if len(dic[word]) > 1:\n",
    "                mult += 1\n",
    "        else:\n",
    "            excl.append(word)\n",
    "\n",
    "    p_in = 100 * len(incl) / len(sim)\n",
    "    p_mult = 100 * mult / len(sim)\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'{round(p_in, 2)}% of words in simlex are in the dictionary')\n",
    "        print(f'{round(p_mult, 2)}% of words in simlex are in the dictionary and have more than one segment')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def return_number_of_morphemes(dic):\n",
    "    out = set([])\n",
    "    for word, segs in dic.items():\n",
    "        for seg in segs:\n",
    "            out.add(seg)\n",
    "    return len(out)\n",
    "\n",
    "\n",
    "def count_morphemes_extra(df, print_info=True):\n",
    "\n",
    "    total = set([])\n",
    "    begin = set([])\n",
    "    mid = set([])\n",
    "\n",
    "    for word, segs in df.items():\n",
    "        begin.add(segs[0])\n",
    "        if len(segs) > 1:\n",
    "           for item in segs[1:]:\n",
    "               mid.add(item)\n",
    "        for seg in segs:\n",
    "            total.add(seg)\n",
    "\n",
    "    not_at_begin = mid - begin\n",
    "\n",
    "    size = len(total) + len(begin) - len(not_at_begin)\n",
    "\n",
    "    if print_info:\n",
    "    \n",
    "        print(f'There are {len(total)} morphemes, out of these {len(begin)} appear at the begining of a word')\n",
    "        print(f'{len(not_at_begin)} morphemes do not appear at the beginning. This means that the vocabulary has a size of {size} tokens (only lowercase).')\n",
    "    \n",
    "    else:\n",
    "        return size\n",
    "\n",
    "\n",
    "\n",
    "def return_morphemes(df, form='list'):\n",
    "\n",
    "    out = set([])\n",
    "    for word, segs in df.items():\n",
    "        for seg in segs:\n",
    "            out.add(seg)\n",
    "    \n",
    "    if form == 'list':\n",
    "        return list(out)\n",
    "    else:\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating word frequency dictionaries for the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for first 4 parts of OSCAR\n",
    "word_freqs_4 = load_json('word_freqs_all_lower.json')\n",
    "\n",
    "# dictionary for first 20 parts of OSCAR\n",
    "word_freqs_20 = load_json('/Users/jan/Documents/Master/Thesis/Code/Snellius/Outputs/frequencies20.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of different dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create some different versions of the segmentation dictionory. We can do this with one functions, which has a lot of boolean parameters to specify our choices. \n",
    "\n",
    "\n",
    "\n",
    "The possible choices we have are:\n",
    "- extra_loop: chech whether a morpheme of a word is in the dictionary with a segmentation itself. If so, replace with this extra segmentation.\n",
    "- add_morphemes: add the morphemes that are not in the dictionary as key to the dictionary, with as segmentation the identical morpheme\n",
    "- add_empty: for the words with no segmentation, add the identical word as the segmentation of the word. \n",
    "- replace_non_identical: for words that have a single morpheme as segmentation that is not identical to the word, replace the morpheme with the identical word\n",
    "- add_verbs: add the conjugation of every verb\n",
    "- greedy_verb: do this in a way that also non-existent words will enter the dictionary\n",
    "- add_nouns: add the conjugation of every noun\n",
    "- greedy_noun: do this in a way that also non-existent words will enter the dictionary\n",
    "- replace_conjugates: creating these inflections of words can lead to words that are already in the dictionary. Choose whether we want to replace them in this case. \n",
    "- min_n_segments: return only the words with at least n morphemes as segmentation. Automatically set to n = 1.\n",
    "- remove_ortho: remove all words for which the concatenated morphemes are not identical to the word\n",
    "- meta_data: return an additional dictionary with meta data about the dictionary\n",
    "- print_info: print information related to (the creation of) the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_data = celex\n",
    "word_family_data = celex2\n",
    "\n",
    "word_fams = create_word_fams(word_family_data)\n",
    "word_groups = group_keys_by_value(word_fams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of extra loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of adding morphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of adding words with emppty segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of replacing words with one mopheme that is not identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of adding verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of adding nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# no_nouns = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=False, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)\n",
    "\n",
    "# with_nouns = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87854"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'with_nouns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6t/7jzn66s57nvb6j7rsh2w2dmr0000gn/T/ipykernel_2648/3856953988.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_nouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'with_nouns' is not defined"
     ]
    }
   ],
   "source": [
    "len(with_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of replacing words with these newly formed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_replace = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=True, min_n_segments=1, \n",
    "#                                    remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)\n",
    "\n",
    "\n",
    "# no_replace = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = compare_only_dictionaries(no_replace, with_replace, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of replacing compunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m comps_no_replace  \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_segmentation_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_family_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_freqs_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_morphemes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43madd_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_plurals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_non_identical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_verbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy_verb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43madd_nouns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy_noun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_verbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_nouns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_n_segments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43madd_compounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_compounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_ortho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_not_in_corpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 830\u001b[0m, in \u001b[0;36mcreate_segmentation_dictionary\u001b[0;34m(segmentation_data, word_family_data, word_freqs, extra_loop, add_morphemes, add_empty, add_plurals, replace_non_identical, add_verbs, greedy_verb, add_nouns, greedy_noun, replace_verbs, replace_nouns, min_n_segments, add_compounds, replace_compounds, remove_ortho, remove_not_in_corpus, meta_data, print_info)\u001b[0m\n\u001b[1;32m    828\u001b[0m         dic \u001b[38;5;241m=\u001b[39m add_compounds_(dic, word_freqs, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 830\u001b[0m         dic \u001b[38;5;241m=\u001b[39m \u001b[43madd_compounds_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_freqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# return just the dictonary, or add meta-data\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta_data:\n",
      "Cell \u001b[0;32mIn[46], line 539\u001b[0m, in \u001b[0;36madd_compounds_\u001b[0;34m(df, word_freqs, replace)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word2 \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[0;32m--> 539\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mword2\u001b[49m \u001b[38;5;129;01min\u001b[39;00m word_freqs:\n\u001b[1;32m    540\u001b[0m             extra[word \u001b[38;5;241m+\u001b[39m word2] \u001b[38;5;241m=\u001b[39m df[word] \u001b[38;5;241m+\u001b[39m df[word2]\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# comps_no_replace  = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    add_compounds=True, replace_compounds=False, remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comps_replace = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "#                                    add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "#                                    add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "#                                    add_compounds=True, replace_compounds=True, remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: the optimal dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final dictionary will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_dictionary = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "                                   add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=True,\n",
    "                                   add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "                                   add_compounds=False, replace_compounds=False, remove_ortho=True, remove_not_in_corpus=True, meta_data=False, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m segmentation_dictionary2 \u001b[38;5;241m=\u001b[39m \u001b[43madd_compounds_\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation_dictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_freqs_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 539\u001b[0m, in \u001b[0;36madd_compounds_\u001b[0;34m(df, word_freqs, replace)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word2 \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[0;32m--> 539\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mword2\u001b[49m \u001b[38;5;129;01min\u001b[39;00m word_freqs:\n\u001b[1;32m    540\u001b[0m             extra[word \u001b[38;5;241m+\u001b[39m word2] \u001b[38;5;241m=\u001b[39m df[word] \u001b[38;5;241m+\u001b[39m df[word2]\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segmentation_dictionary2 = add_compounds_(segmentation_dictionary, word_freqs_20, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_json('/Users/jan/Documents/Master/Thesis/Code/seg_dict_with_compounds.json', segmentation_dictionary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dictionary in a json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_json('/Users/jan/Documents/Master/Thesis/Code/seg_dict.json', segmentation_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if there are words for which the segmentations do not add up to the the identical word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = segmentation_dictionary\n",
    "\n",
    "for word in d:\n",
    "    concat = ''.join(d[word])\n",
    "    if word != concat:\n",
    "        print(word, d[word])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons with the words in Dutch SimLex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.65% of words in simlex are in the dictionary\n",
      "19.71% of words in simlex are in the dictionary and have more than one segment\n"
     ]
    }
   ],
   "source": [
    "compare_dict_simlex(simlex_words, segmentation_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.65% of words in simlex are in the dictionary\n",
      "19.71% of words in simlex are in the dictionary and have more than one segment\n"
     ]
    }
   ],
   "source": [
    "compare_dict_simlex(simlex_words, sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with the text corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.6% of words in the corpus are in the dataset\n",
      "27.4% of words are not\n",
      "\n",
      "1.3% of unique words in the corpus are in the dataset\n",
      "98.7% of unique words are not\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = corpus_in_dataset(segmentation_dictionary, word_freqs_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.6% of words in the corpus are in the dataset\n",
      "27.4% of words are not\n",
      "\n",
      "1.3% of unique words in the corpus are in the dataset\n",
      "98.7% of unique words are not\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = corpus_in_dataset(sd, word_freqs_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of tokens our vocabulary will have from this segmentation dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13602 morphemes, out of these 13299 appear at the begining of a word\n",
      "303 morphemes do not appear at the beginning. This means that the vocabulary has a size of 26598 tokens (only lowercase).\n"
     ]
    }
   ],
   "source": [
    "count_morphemes_extra(segmentation_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three parts:\n",
    "- creating the vocabulary\n",
    "- tokenizing text\n",
    "- detokenizing tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The vocabulary is formed from two sources:\n",
    "- dataset with morphemes\n",
    "- BPE\n",
    "\n",
    "(In reality we there is not one vocabulary created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphemes\n",
    "\n",
    "We first create the set of morphemes, which we take from the segmentation dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13609 in the dictionary. Due to a difference between the start and not-start of a word, this means 26626 tokens in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "seg_dict = segmentation_dictionary\n",
    "\n",
    "# OR load from disk:\n",
    "# seg_dict = \n",
    "\n",
    "morphemes = return_morphemes(seg_dict)\n",
    "\n",
    "print(f'There are {len(morphemes)} in the dictionary. Due to a difference between the start and not-start of a word, this means {count_morphemes_extra(seg_dict, print_info=False)} tokens in the vocabulary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the number of morphemes and the desired size of the vocabulary, we can train a BPE algorithm to tokenize the words that are not in our dictionary.\n",
    "\n",
    "In order to do this we must preprocess the data in a way that takes the words out, and that converts it lowercase. \n",
    "\n",
    "The best way in our case is to create new text files, so we define a function that returens the converted text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer_x = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "segmentation_dictionary = segmentation_dictionary\n",
    "\n",
    "def lowercase_text(item):\n",
    "    return item.lower()\n",
    "\n",
    "def remove_words(item):\n",
    "    text = tokenizer_x._tokenizer.pre_tokenizer.pre_tokenize_str(item)\n",
    "    words_a = [word for word, offset in text]\n",
    "    words_b = [word.replace('Ġ', '') for word in words_a]\n",
    "    out = []\n",
    "    for i, word in enumerate(words_b):\n",
    "        if not word in segmentation_dictionary:\n",
    "            out.append(words_a[i])\n",
    "    return tokenizer_x.convert_tokens_to_string(out)\n",
    "\n",
    "def convert_text(input):\n",
    "    with open(input) as inp:\n",
    "        with open(input[:-4] + '_converted.txt', 'w') as outp:\n",
    "            for line in inp:\n",
    "                line = lowercase_text(line)\n",
    "                line = remove_words(line)\n",
    "                outp.write(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this function to one file here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_text('/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the text files to train BPE with, we can do this for a desired vocabulary size. \n",
    "\n",
    "This is the code to do it locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import datasets\n",
    "\n",
    "paths = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short_converted.txt'\n",
    "\n",
    "# set size\n",
    "desired_vocab_size = 35000\n",
    "n_extra_tokens = desired_vocab_size - count_morphemes_extra(segmentation_dictionary, print_info=False)\n",
    "\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer_30 = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer_30.train(files=paths, vocab_size=n_extra_tokens, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])\n",
    "\n",
    "\n",
    "# save\n",
    "tokenizer_30.save_model('/home/scur2141/tokenizer_test/t30')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paths = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short_converted.txt'\n",
    "\n",
    "# set size\n",
    "desired_vocab_size = 35000\n",
    "n_extra_tokens = desired_vocab_size - count_morphemes_extra(segmentation_dictionary, print_info=False)\n",
    "\n",
    "\n",
    "def create_text_generator(gen):\n",
    "    for i in gen:\n",
    "        yield i['text']\n",
    "\n",
    "\n",
    "path = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt'\n",
    "oscar_short = load_dataset('text', data_files={\"train\": path}, split='train')\n",
    "oscar_short_it = load_dataset('text', data_files={\"train\": path}, split='train', streaming=True)\n",
    "\n",
    "dataset = create_text_generator(oscar_short_it)\n",
    "\n",
    "\n",
    "# load an existing BPE tokenizer\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "new_tokenizer = old_tokenizer.train_new_from_iterator(dataset, n_extra_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we have done this on the Snellus computer. So we will load them here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "t30 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/tokenizeXX/t30\", max_len=512)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now that we have the two components for our tokenizer, we can combine them to form a single tokenizer. \n",
    "\n",
    "We will do this in a tokenizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nog toevoegen:\n",
    "#    - return_tensors method, die ervoor zorgt dat de input ids enzo als een tensor worden gegeven (of dit al standaard doen) \n",
    "# [deze zit in de call method zie voorbeeld: inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# overigens heb je die andere methods ook nodig (padding & truncation)\n",
    "\n",
    "\n",
    "## DEZE NIET AANPASSEN ##\n",
    "\n",
    "\n",
    "\n",
    "# class CustomTokenizerMP:\n",
    "\n",
    "#     def __init__(self, segmentation_dictionary, bpe_tokenizer):\n",
    "        \n",
    "#         self.bpe_tokenizer = bpe_tokenizer\n",
    "#         self.bpe_vocab = self.bpe_tokenizer.get_vocab()\n",
    "\n",
    "\n",
    "#         self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "#         self.seg_dict = {}\n",
    "#         for word, segs in self.segmentations.items():\n",
    "#             out = []\n",
    "#             for i, seg in enumerate(segs):\n",
    "#                 if i == 0:\n",
    "#                     out.append('Ġ' + seg)\n",
    "#                 else:\n",
    "#                     out.append(seg)\n",
    "#             self.seg_dict[word] = out\n",
    "        \n",
    "#         self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "#         self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "#         self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "#         self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "#         self.seg_dict = {}\n",
    "#         for word, segs in self.segmentations.items():\n",
    "#             out = []\n",
    "#             for i, seg in enumerate(segs):\n",
    "#                 if i == 0:\n",
    "#                     out.append('Ġ' + seg)\n",
    "#                 else:\n",
    "#                     out.append(seg)\n",
    "#             self.seg_dict[word] = out\n",
    "        \n",
    "#         self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "#         self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "#         self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "#         self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "\n",
    "#     def get_vocab(self):\n",
    "#         return self.vocab # note: we should probably use a getter here, but for now this is ok\n",
    "\n",
    "\n",
    "#     def encode(self, seq):\n",
    "#         text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "#         return text\n",
    "#         # words_a = [word for word in [word for word, offset in text]]\n",
    "#         # words_b = [word.replace('Ġ', '') for word in [word for word, offset in text]]\n",
    "#         # #print(f'words_a: {words_a}')\n",
    "#         # #print(f'words_b: {words_b}')\n",
    "#         # out = []\n",
    "#         # for i, word_b in enumerate(words_b):\n",
    "#         #     if word_b in self.seg_dict:\n",
    "#         #         out += [self.vocab[seg] for seg in self.seg_dict[word_b]]\n",
    "#         #     else:\n",
    "#         #         if words_a[i][0] == 'Ġ':\n",
    "#         #             out += self.bpe_tokenizer.encode(' ' + word_b)\n",
    "#         #         else: \n",
    "#         #             out += self.bpe_tokenizer.encode(word_b)\n",
    "#         # #print(f'tokenization: {[self.inverted_vocab[id] for id in out]}')\n",
    "#         # #print(f'out = {out}')\n",
    "#         # return out\n",
    "\n",
    "\n",
    "#     def decode(self, ids: list[int]):\n",
    "#         assert type(ids) == list\n",
    "#        # assert type(ids[0]) == int   # dit kan wel netter, volgens mij kan het al met alleen type hints, en dit gaat mis is de list leeg is\n",
    "#         out = ''\n",
    "#         for id in ids:\n",
    "#             word = self.inverted_vocab[id]\n",
    "#             if word[0] == 'Ġ':\n",
    "#                 out += word.replace('Ġ', ' ')\n",
    "#             else:\n",
    "#                 out += word\n",
    "#         return out\n",
    "    \n",
    "    \n",
    "#     def tokenize(self, seq):\n",
    "#         return [self.inverted_vocab[id] for id in self.encode(seq)] \n",
    "   \n",
    "\n",
    "#     def __call__(self, seq):\n",
    "#         ids = self.encode(seq)\n",
    "#         #types = [0 for token in ids]\n",
    "#         attention = [1 for token in ids]\n",
    "#         #return {'input_ids': ids, 'token_type_ids': types, 'attention_mask': attention}\n",
    "#         #return {'input_ids': ids}\n",
    "#         return {'input_ids': ids, 'attention_mask': attention}\n",
    "\n",
    "\n",
    "\n",
    "## DEZE NIET AANPASSEN ##\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomTokenizer:\n",
    "\n",
    "    def __init__(self, segmentation_dictionary, bpe_tokenizer, max_length=512, pad_to_multiple_of=None):\n",
    "        \n",
    "        self.bpe_tokenizer = bpe_tokenizer\n",
    "        self.bpe_vocab = self.bpe_tokenizer.get_vocab()\n",
    "\n",
    "        self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "        self.seg_dict = {}\n",
    "        for word, segs in self.segmentations.items():\n",
    "            out = []\n",
    "            for i, seg in enumerate(segs):\n",
    "                if i == 0:\n",
    "                    out.append('Ġ' + seg)\n",
    "                else:\n",
    "                    out.append(seg)\n",
    "            self.seg_dict[word] = out\n",
    "        \n",
    "        self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "        # self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "        # self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "\n",
    "        self.vocab = self.bpe_vocab.copy()\n",
    "        \n",
    "        for element in self.segments:\n",
    "            if element not in self.vocab:\n",
    "                self.vocab[element] = len(self.vocab) + 1\n",
    "\n",
    "        self.mask_token = \"<mask>\"\n",
    "        self.mask_token_id = self.vocab['<mask>']\n",
    "        self.vocab[self.mask_token_id] = self.vocab['<mask>']\n",
    "        \n",
    "        self.cls_token = \"<s>\"\n",
    "        self.cls_token_id = self.vocab['<s>']\n",
    "        self.vocab[self.cls_token] = self.vocab['<s>']\n",
    "        \n",
    "        self.sep_token = \"</s>\"\n",
    "        self.sep_token_id = self.vocab['</s>']\n",
    "        self.vocab[self.sep_token] = self.vocab['</s>']\n",
    "        \n",
    "        self.pad_token = '<pad>'\n",
    "        self.pad_token_id = self.vocab['<pad>']\n",
    "        self.vocab[self.pad_token] = self.vocab['<pad>']\n",
    "        \n",
    "\n",
    "\n",
    "        # self.unk_token = '<|endoftext|>'\n",
    "        # self.unk_token_id = self.vocab['<|endoftext|>']\n",
    "        # self.vocab[self.unk_token] = self.vocab['<|endoftext|>']\n",
    "        \n",
    "        self.vocab['<unk>'] = len(self.vocab) + 1 \n",
    "        self.unk_token = '<unk>'\n",
    "        self.unk_token_id = self.vocab['<unk>']\n",
    "        self.vocab[self.unk_token] = self.vocab['<unk>']\n",
    "        \n",
    "        # self.bos_token = '<|endoftext|>'\n",
    "        # self.bos_token_id = self.vocab['<|endoftext|>']\n",
    "        # self.vocab[self.bos_token] = self.vocab['<|endoftext|>']\n",
    "\n",
    "        self.bos_token = '<s>'\n",
    "        self.bos_token_id = self.vocab['<s>']\n",
    "        self.vocab[self.bos_token] = self.vocab['<s>']\n",
    "        \n",
    "        self.eos_token = \"</s>\"\n",
    "        self.eos_token_id = self.vocab[\"</s>\"]\n",
    "        self.vocab[self.eos_token] = self.vocab[\"</s>\"]\n",
    "        \n",
    "        self.special_tokens = [self.vocab['<mask>'], self.vocab['<s>'], self.vocab['</s>'], self.vocab['<pad>'], self.vocab['<unk>']]\n",
    "   \n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "    def tokenize(self, seq):\n",
    "\n",
    "        # Implement your token to ID conversion logic here\n",
    "        text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "        words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "        words_b = [word.replace('Ġ', '') for word in [word for word, offset in text]]\n",
    "        tokens = []\n",
    "        for i, word_b in enumerate(words_b):\n",
    "            if word_b in self.seg_dict:\n",
    "                tokens += self.seg_dict[word_b]\n",
    "            else:\n",
    "                if words_a[i][0] == 'Ġ':\n",
    "                    tokens += self.bpe_tokenizer.tokenize(' ' + word_b)\n",
    "                else: \n",
    "                    tokens += self.bpe_tokenizer.tokenize(word_b)    \n",
    "        return tokens\n",
    "        \n",
    "        \n",
    "    def encode(self, seq):\n",
    "\n",
    "\n",
    "        return [self.bos_token_id] + self.convert_tokens_to_ids(self.tokenize(seq)) + [self.eos_token_id]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        if token in self.vocab:\n",
    "            return self.vocab[token]\n",
    "        else:\n",
    "            return self.unk_token_id\n",
    "\n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        if isinstance(tokens, list):\n",
    "            return [self._convert_token_to_id(token) for token in tokens]\n",
    "        return self._convert_token_to_id(tokens)\n",
    "\n",
    "\n",
    "    def _tokenize(self, seq):\n",
    "        text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "        words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "        words_b = [word.replace('Ġ', '') for word in [word for word, offset in text]]\n",
    "        tokens = []\n",
    "        for i, word_b in enumerate(words_b):\n",
    "            if word_b in self.seg_dict:\n",
    "                tokens += self.seg_dict[word_b]\n",
    "            else:\n",
    "                if words_a[i][0] == 'Ġ':\n",
    "                    tokens += self.bpe_tokenizer.tokenize(' ' + word_b)\n",
    "                else: \n",
    "                    tokens += self.bpe_tokenizer.tokenize(word_b)    \n",
    "        return tokens\n",
    "\n",
    "\n",
    "    def __call__(self, text, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "        if isinstance(text, list):\n",
    "            self.batch_encode_plus(text, truncation=truncation, return_tensors=return_tensors, padding=padding, max_length=max_length, add_special_tokens=add_special_tokens)\n",
    "        else:\n",
    "\n",
    "            token_ids = self.encode(text) \n",
    "\n",
    "            if truncation and max_length:\n",
    "                token_ids = [self.bos_token_id] + token_ids[:max_length - 2] + [self.eos_token_id]\n",
    "            if padding and max_length is not None:\n",
    "                token_ids = token_ids + [self.pad_token_id] * (max_length - len(token_ids))\n",
    "            if return_tensors == \"pt\":\n",
    "                return {\"input_ids\": torch.tensor(token_ids, dtype=torch.long)}\n",
    "            return {\"input_ids\": token_ids}\n",
    "\n",
    "\n",
    "    def _convert_id_to_token(self, id):\n",
    "        # Implement your ID to token conversion logic here\n",
    "        return self.inverted_vocab[id]\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        # Convert IDs back to tokens\n",
    "        if isinstance(ids, list):\n",
    "            return [self._convert_id_to_token(id) for id in ids]\n",
    "        return self._convert_id_to_token(ids)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        out = ''\n",
    "        for id in ids:\n",
    "            word = self._convert_id_to_token(id)\n",
    "            if word[0] == 'Ġ':\n",
    "                out += word.replace('Ġ', ' ')\n",
    "            else:\n",
    "                out += word\n",
    "        return out\n",
    "        \n",
    "\n",
    "    def get_special_tokens_mask(self, token_ids, already_has_special_tokens=False):\n",
    "        # Create a mask for special tokens\n",
    "        return [1 if self._is_special_token(token_id) else 0 for token_id in token_ids]\n",
    "\n",
    "\n",
    "    def _is_special_token(self, token_id):\n",
    "        # Implement your logic to check if a token is a special token\n",
    "        if token_id in self.special_tokens:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def batch_encode_plus(self, texts, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "        batch_token_ids = [self.__call__(text, truncation=truncation, max_length=max_length, add_special_tokens=add_special_tokens)[\"input_ids\"] for text in texts]\n",
    "        \n",
    "        if padding:\n",
    "            if max_length is None:\n",
    "                max_length = max(len(ids) for ids in batch_token_ids)\n",
    "            batch_token_ids = [ids + [self.pad_token_id] * (max_length - len(ids)) for ids in batch_token_ids]\n",
    "        \n",
    "        if return_tensors == \"pt\":\n",
    "            return {\"input_ids\": torch.tensor(batch_token_ids, dtype=torch.long)}\n",
    "        return {\"input_ids\": batch_token_ids}\n",
    "\n",
    "\n",
    "    def pad(self, batch, return_tensors=\"pt\", pad_to_multiple_of=None):\n",
    "        if pad_to_multiple_of is None:\n",
    "            pad_to_multiple_of = self.pad_to_multiple_of\n",
    "\n",
    "\n",
    "        input_ids_list = []\n",
    "        for dictionary in batch:\n",
    "            for key, value in dictionary.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    input_ids_list.append(value.tolist())\n",
    "\n",
    "\n",
    "        max_length = self.max_length or max(len(x) for x in input_ids_list)\n",
    "        \n",
    "        if pad_to_multiple_of is not None:\n",
    "            max_length = (max_length + pad_to_multiple_of - 1) // pad_to_multiple_of * pad_to_multiple_of\n",
    "        \n",
    "        padded_batch = []\n",
    "        for seq in input_ids_list:\n",
    "            if len(seq) < max_length:\n",
    "                seq.extend([self.pad_token_id] * (max_length - len(seq)))\n",
    "            padded_batch.append(seq)\n",
    "        \n",
    "        attention_list = []\n",
    "        for inner_list in padded_batch:\n",
    "            p_list = [1 if value < self.vocab_size else 0 for value in inner_list]\n",
    "            attention_list.append(p_list)\n",
    "        \n",
    "        if return_tensors == \"pt\":\n",
    "            return {'input_ids': torch.tensor(padded_batch, dtype=torch.long), 'attention_mask': torch.tensor(attention_list, dtype=torch.long)}\n",
    "        \n",
    "        return {'input_ids': padded_batch, 'attention_mask': attention_list}\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizerWP:\n",
    "\n",
    "    def __init__(self, segmentation_dictionary, wp_tokenizer, max_length=512, pad_to_multiple_of=None):\n",
    "        \n",
    "        self.wp_tokenizer = wp_tokenizer\n",
    "        self.wp_vocab = self.wp_tokenizer.get_vocab()\n",
    "\n",
    "        self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "        self.seg_dict = {}\n",
    "        for word, segs in self.segmentations.items():\n",
    "            out = []\n",
    "            for i, seg in enumerate(segs):\n",
    "                if i == 0:\n",
    "                    out.append(seg)\n",
    "                else:\n",
    "                    out.append('##' + seg)\n",
    "            self.seg_dict[word] = out\n",
    "        \n",
    "        self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "        # self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "        # self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "\n",
    "        self.vocab = self.wp_vocab.copy()\n",
    "        \n",
    "        for element in self.segments:\n",
    "            if element not in self.vocab:\n",
    "                self.vocab[element] = len(self.vocab) + 1\n",
    "        \n",
    "\n",
    "        self.l = len(self.vocab)\n",
    "\n",
    "        self.vocab['<unk>'] = self.l + 1 \n",
    "        self.unk_token = '<unk>'\n",
    "        self.unk_token_id = self.vocab['<unk>']\n",
    "        self.vocab[self.unk_token] = self.vocab['<unk>']\n",
    "\n",
    "        self.vocab['<mask>'] = self.l + 2 \n",
    "        self.mask_token = \"<mask>\"\n",
    "        self.mask_token_id = self.vocab['<mask>']\n",
    "        self.vocab[self.mask_token_id] = self.vocab['<mask>']\n",
    "        \n",
    "        self.vocab['<s>'] = self.l + 3\n",
    "        self.cls_token = \"<s>\"\n",
    "        self.cls_token_id = self.vocab['<s>']\n",
    "        self.vocab[self.cls_token] = self.vocab['<s>']\n",
    "        \n",
    "        self.vocab['</s>'] = self.l + 4\n",
    "        self.sep_token = \"</s>\"\n",
    "        self.sep_token_id = self.vocab['</s>']\n",
    "        self.vocab[self.sep_token] = self.vocab['</s>']\n",
    "        \n",
    "        self.vocab['<pad>'] = self.l + 5\n",
    "        self.pad_token = '<pad>'\n",
    "        self.pad_token_id = self.vocab['<pad>']\n",
    "        self.vocab[self.pad_token] = self.vocab['<pad>']\n",
    "        \n",
    "        self.vocab['<s>'] = self.l + 6\n",
    "        self.bos_token = '<s>'\n",
    "        self.bos_token_id = self.vocab['<s>']\n",
    "        self.vocab[self.bos_token] = self.vocab['<s>']\n",
    "        \n",
    "        self.vocab['</s>'] = self.l + 7 \n",
    "        self.eos_token = \"</s>\"\n",
    "        self.eos_token_id = self.vocab[\"</s>\"]\n",
    "        self.vocab[self.eos_token] = self.vocab[\"</s>\"]\n",
    "        \n",
    "        self.special_tokens = [self.vocab['<mask>'], self.vocab['<s>'], self.vocab['</s>'], self.vocab['<pad>'], self.vocab['<unk>']]\n",
    "   \n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "    def tokenize(self, seq):\n",
    "\n",
    "\n",
    "        text = self.wp_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "        words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "        words_b = [word.replace('##', '') for word in [word for word, offset in text]]\n",
    "        tokens = []\n",
    "        for i, word_b in enumerate(words_b):\n",
    "            if word_b in self.seg_dict:\n",
    "                tokens += self.seg_dict[word_b]\n",
    "            else:\n",
    "                if words_a[i][0] == '##':\n",
    "                    tokens += self.wp_tokenizer.tokenize(word_b)\n",
    "                else: \n",
    "                    tokens += self.wp_tokenizer.tokenize(' ' + word_b)    \n",
    "        return tokens\n",
    "        \n",
    "        \n",
    "    def encode(self, seq):\n",
    "\n",
    "\n",
    "        return [self.bos_token_id] + self.convert_tokens_to_ids(self.tokenize(seq)) + [self.eos_token_id]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        if token in self.vocab:\n",
    "            return self.vocab[token]\n",
    "        else:\n",
    "            return self.unk_token_id\n",
    "\n",
    "    \n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        if isinstance(tokens, list):\n",
    "            return [self._convert_token_to_id(token) for token in tokens]\n",
    "        return self._convert_token_to_id(tokens)\n",
    "\n",
    "\n",
    "    def _tokenize(self, seq):\n",
    "\n",
    "        text = self.wp_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "        words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "        words_b = [word.replace('##', '') for word in [word for word, offset in text]]\n",
    "        tokens = []\n",
    "        for i, word_b in enumerate(words_b):\n",
    "            if word_b in self.seg_dict:\n",
    "                tokens += self.seg_dict[word_b]\n",
    "            else:\n",
    "                if words_a[i][0] == '##':\n",
    "                    tokens += self.wp_tokenizer.tokenize(word_b)\n",
    "                else: \n",
    "                    tokens += self.wp_tokenizer.tokenize(' ' + word_b)    \n",
    "        return tokens\n",
    "\n",
    "\n",
    "    def __call__(self, text, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "        if isinstance(text, list):\n",
    "            self.batch_encode_plus(text, truncation=truncation, return_tensors=return_tensors, padding=padding, max_length=max_length, add_special_tokens=add_special_tokens)\n",
    "        else:\n",
    "\n",
    "            token_ids = self.encode(text) \n",
    "\n",
    "            if truncation and max_length:\n",
    "                token_ids = [self.bos_token_id] + token_ids[:max_length - 2] + [self.eos_token_id]\n",
    "            if padding and max_length is not None:\n",
    "                token_ids = token_ids + [self.pad_token_id] * (max_length - len(token_ids))\n",
    "            if return_tensors == \"pt\":\n",
    "                return {\"input_ids\": torch.tensor(token_ids, dtype=torch.long)}\n",
    "            return {\"input_ids\": token_ids}\n",
    "\n",
    "\n",
    "    def _convert_id_to_token(self, id):\n",
    "        # Implement your ID to token conversion logic here\n",
    "        return self.inverted_vocab[id]\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        # Convert IDs back to tokens\n",
    "        if isinstance(ids, list):\n",
    "            return [self._convert_id_to_token(id) for id in ids]\n",
    "        return self._convert_id_to_token(ids)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        out = ''\n",
    "        for id in ids:\n",
    "            word = self._convert_id_to_token(id)\n",
    "            if word[:2] == '##':\n",
    "                out += word.replace('##', '')\n",
    "            else:\n",
    "                out += ' ' + word\n",
    "        return out\n",
    "        \n",
    "\n",
    "    def get_special_tokens_mask(self, token_ids, already_has_special_tokens=False):\n",
    "        # Create a mask for special tokens\n",
    "        return [1 if self._is_special_token(token_id) else 0 for token_id in token_ids]\n",
    "\n",
    "\n",
    "    def _is_special_token(self, token_id):\n",
    "        # Implement your logic to check if a token is a special token\n",
    "        if token_id in self.special_tokens:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def batch_encode_plus(self, texts, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "        batch_token_ids = [self.__call__(text, truncation=truncation, max_length=max_length, add_special_tokens=add_special_tokens)[\"input_ids\"] for text in texts]\n",
    "        \n",
    "        if padding:\n",
    "            if max_length is None:\n",
    "                max_length = max(len(ids) for ids in batch_token_ids)\n",
    "            batch_token_ids = [ids + [self.pad_token_id] * (max_length - len(ids)) for ids in batch_token_ids]\n",
    "        \n",
    "        if return_tensors == \"pt\":\n",
    "            return {\"input_ids\": torch.tensor(batch_token_ids, dtype=torch.long)}\n",
    "        return {\"input_ids\": batch_token_ids}\n",
    "\n",
    "\n",
    "    def pad(self, batch, return_tensors=\"pt\", pad_to_multiple_of=None):\n",
    "        if pad_to_multiple_of is None:\n",
    "            pad_to_multiple_of = self.pad_to_multiple_of\n",
    "\n",
    "\n",
    "        input_ids_list = []\n",
    "        for dictionary in batch:\n",
    "            for key, value in dictionary.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    input_ids_list.append(value.tolist())\n",
    "\n",
    "\n",
    "        max_length = self.max_length or max(len(x) for x in input_ids_list)\n",
    "        \n",
    "        if pad_to_multiple_of is not None:\n",
    "            max_length = (max_length + pad_to_multiple_of - 1) // pad_to_multiple_of * pad_to_multiple_of\n",
    "        \n",
    "        padded_batch = []\n",
    "        for seq in input_ids_list:\n",
    "            if len(seq) < max_length:\n",
    "                seq.extend([self.pad_token_id] * (max_length - len(seq)))\n",
    "            padded_batch.append(seq)\n",
    "        \n",
    "        attention_list = []\n",
    "        for inner_list in padded_batch:\n",
    "            p_list = [1 if value < self.vocab_size else 0 for value in inner_list]\n",
    "            attention_list.append(p_list)\n",
    "        \n",
    "        if return_tensors == \"pt\":\n",
    "            return {'input_ids': torch.tensor(padded_batch, dtype=torch.long), 'attention_mask': torch.tensor(attention_list, dtype=torch.long)}\n",
    "        \n",
    "        return {'input_ids': padded_batch, 'attention_mask': attention_list}\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "\n",
    "# class CustomTokenizer:\n",
    "\n",
    "#     def __init__(self, segmentation_dictionary, bpe_tokenizer):\n",
    "        \n",
    "#         self.bpe_tokenizer = bpe_tokenizer\n",
    "#         self.bpe_vocab = self.bpe_tokenizer.get_vocab()\n",
    "\n",
    "#         self.segmentations = {word: seg for word, seg in segmentation_dictionary.items() if len(seg) > 0}\n",
    "#         self.seg_dict = {}\n",
    "#         for word, segs in self.segmentations.items():\n",
    "#             out = []\n",
    "#             for i, seg in enumerate(segs):\n",
    "#                 if i == 0:\n",
    "#                     out.append('Ġ' + seg)\n",
    "#                 else:\n",
    "#                     out.append(seg)\n",
    "#             self.seg_dict[word] = out\n",
    "        \n",
    "#         self.segments = {seg for segs in self.seg_dict.values() for seg in segs}\n",
    "#         self.seg_vocab = {seg: (i + len(self.bpe_vocab)) for i, seg in enumerate(self.segments) if not seg in self.bpe_vocab}\n",
    "        \n",
    "#         self.vocab = self.bpe_vocab | self.seg_vocab\n",
    "    \n",
    "#         self.vs = len(self.vocab)\n",
    "#         self.mask_token = \"<mask>\"\n",
    "#         self.mask_token_id = self.vs + 1\n",
    "#         self.vocab[self.mask_token_id] = self.vs + 1\n",
    "#         self.cls_token = \"<s>\"\n",
    "#         self.cls_token_id = self.vs + 2\n",
    "#         self.vocab[self.cls_token] = self.vs + 2\n",
    "#         self.sep_token = \"</s>\"\n",
    "#         self.sep_token_id = self.vs + 3\n",
    "#         self.vocab[self.sep_token] = self.vs + 3\n",
    "#         self.pad_token = '<pad>'\n",
    "#         self.pad_token_id = self.vs + 4\n",
    "#         self.vocab[self.pad_token] = self.vs + 4\n",
    "#         #self.unk_token = '<unk>'\n",
    "#         self.unk_token = '<|endoftext|>'\n",
    "#         self.unk_token_id = self.vs + 5\n",
    "#         self.vocab[self.unk_token] = self.vs + 5\n",
    "#         #self.bos_token = '<s>'\n",
    "#         self.bos_token = '<|endoftext|>'\n",
    "#         self.bos_token_id = self.vs + 6\n",
    "#         self.vocab[self.bos_token] = self.vs + 6\n",
    "#         #self.eos_token = '</s>'\n",
    "#         self.eos_token = '<|endoftext|>'\n",
    "#         self.eos_token_id = self.vs + 7\n",
    "#         self.vocab[self.eos_token] = self.vs + 7\n",
    "        \n",
    "#         self.vocab_size = len(self.vocab)\n",
    "\n",
    "#         self.inverted_vocab = {value: key for key, value in self.vocab.items()}\n",
    "\n",
    "\n",
    "\n",
    "#     def get_vocab(self):\n",
    "#         return self.vocab\n",
    "\n",
    "    \n",
    "#     def tokenize(self, seq):\n",
    "\n",
    "#         # Implement your token to ID conversion logic here\n",
    "#         text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "#         words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "#         words_b = [word.replace('Ġ', '') for word in [word for word, offset in text]]\n",
    "#         tokens = []\n",
    "#         for i, word_b in enumerate(words_b):\n",
    "#             if word_b in self.seg_dict:\n",
    "#                 tokens += self.seg_dict[word_b]\n",
    "#             else:\n",
    "#                 if words_a[i][0] == 'Ġ':\n",
    "#                     tokens += self.bpe_tokenizer.tokenize(' ' + word_b)\n",
    "#                 else: \n",
    "#                     tokens += self.bpe_tokenizer.tokenize(word_b)    \n",
    "#         return tokens\n",
    "        \n",
    "#     def encode(self, seq):\n",
    "#         return self.convert_tokens_to_ids(self.tokenize(seq))\n",
    "\n",
    "\n",
    "#     def _convert_token_to_id(self, token):\n",
    "#         if token in self.vocab:\n",
    "#             return self.vocab[token]\n",
    "#         else:\n",
    "#             return self.unk_token_id\n",
    "\n",
    "    \n",
    "#     def convert_tokens_to_ids(self, tokens):\n",
    "#         if isinstance(tokens, list):\n",
    "#             return [self._convert_token_to_id(token) for token in tokens]\n",
    "#         return self._convert_token_to_id(tokens)\n",
    "\n",
    "\n",
    "#     def _tokenize(self, seq):\n",
    "#         text = self.bpe_tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(seq)\n",
    "#         words_a = [word for word in [word for word, offset in text]]\n",
    "        \n",
    "#         words_b = [word.replace('Ġ', '') for word in [word for word, offset in text]]\n",
    "#         tokens = []\n",
    "#         for i, word_b in enumerate(words_b):\n",
    "#             if word_b in self.seg_dict:\n",
    "#                 tokens += self.seg_dict[word_b]\n",
    "#             else:\n",
    "#                 if words_a[i][0] == 'Ġ':\n",
    "#                     tokens += self.bpe_tokenizer.tokenize(' ' + word_b)\n",
    "#                 else: \n",
    "#                     tokens += self.bpe_tokenizer.tokenize(word_b)    \n",
    "#         return tokens\n",
    "\n",
    "\n",
    "\n",
    "#     def __call__(self, text, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=False):\n",
    "#         if isinstance(text, list):\n",
    "#             self.batch_encode_plus(text, truncation=truncation, return_tensors=return_tensors, padding=padding, max_length=max_length, add_special_tokens=add_special_tokens)\n",
    "#         else:\n",
    "\n",
    "#             token_ids = self.encode(text)  \n",
    "#             if add_special_tokens:\n",
    "#                 token_ids = [self.bos_token_id] + token_ids + [self.eos_token_id]\n",
    "#             if truncation and max_length is not None:\n",
    "#                 token_ids = token_ids[:max_length]\n",
    "#             if padding and max_length is not None:\n",
    "#                 token_ids = token_ids + [self.pad_token_id] * (max_length - len(token_ids))\n",
    "#             if return_tensors == \"pt\":\n",
    "#                 return {\"input_ids\": torch.tensor(token_ids, dtype=torch.long)}\n",
    "#             return {\"input_ids\": token_ids}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     def _convert_id_to_token(self, id):\n",
    "#         # Implement your ID to token conversion logic here\n",
    "#         return self.inverted_vocab[id]\n",
    "\n",
    "#     def convert_ids_to_tokens(self, ids):\n",
    "#         # Convert IDs back to tokens\n",
    "#         if isinstance(ids, list):\n",
    "#             return [self._convert_id_to_token(id) for id in ids]\n",
    "#         return self._convert_id_to_token(ids)\n",
    "    \n",
    "#     def decode(self, ids):\n",
    "#         out = ''\n",
    "#         for id in ids:\n",
    "#             word = self._convert_id_to_token(id)\n",
    "#             if word[0] == 'Ġ':\n",
    "#                 out += word.replace('Ġ', ' ')\n",
    "#             else:\n",
    "#                 out += word\n",
    "#         return out\n",
    "        \n",
    "\n",
    "#     def get_special_tokens_mask(self, token_ids, already_has_special_tokens=False):\n",
    "#         # Create a mask for special tokens\n",
    "#         return [1 if self._is_special_token(token_id) else 0 for token_id in token_ids]\n",
    "\n",
    "\n",
    "#     def _is_special_token(self, token_id):\n",
    "#         # Implement your logic to check if a token is a special token\n",
    "#         if token_id in self.special_tokens:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "\n",
    "\n",
    "\n",
    "#     def batch_encode_plus(self, texts, return_tensors=None, padding=False, truncation=False, max_length=None, add_special_tokens=True):\n",
    "#         batch_token_ids = [self.__call__(text, truncation=truncation, max_length=max_length, add_special_tokens=add_special_tokens)[\"input_ids\"] for text in texts]\n",
    "        \n",
    "#         if padding:\n",
    "#             if max_length is None:\n",
    "#                 max_length = max(len(ids) for ids in batch_token_ids)\n",
    "#             batch_token_ids = [ids + [self.pad_token_id] * (max_length - len(ids)) for ids in batch_token_ids]\n",
    "        \n",
    "#         if return_tensors == \"pt\":\n",
    "#             return {\"input_ids\": torch.tensor(batch_token_ids, dtype=torch.long)}\n",
    "#         return {\"input_ids\": batch_token_ids}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 29.3 ms, total: 1.21 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# import os\n",
    "# import torch\n",
    "# from datasets import Dataset\n",
    "\n",
    "\n",
    "# # pick tokenizer\n",
    "# tokenizer = ff\n",
    "\n",
    "# # pick txt file to transform\n",
    "# text_file_path = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_shorter.txt'\n",
    "\n",
    "# def tokenize_line(line):\n",
    "#     # Specify the max_length parameter to ensure consistent padding\n",
    "#     return {'input_ids': tokenizer(line.strip())['input_ids']}\n",
    "#     #return tokenizer(line, truncation=False, max_length=512, return_tensors='pt', add_special_tokens=False)\n",
    "\n",
    "# # Read the text file and tokenize each line\n",
    "# with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "#     lines = file.readlines()\n",
    "\n",
    "# # Create a list of dictionaries with tokenized lines\n",
    "# tokenized_lines = [tokenize_line(line) for line in lines]\n",
    "\n",
    "# # Create a Hugging Face dataset from the list of dictionaries\n",
    "# dataset = Dataset.from_list(tokenized_lines).with_format(\"torch\")\n",
    "\n",
    "# # save\n",
    "# #dataset.save_to_disk('tokenized_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=ff, mlm=True, mlm_probability=0.15\n",
    "# )\n",
    "\n",
    "# # klein model om te testen\n",
    "# config = RobertaConfig(\n",
    "#     vocab_size=len(tokenizer.get_vocab()),\n",
    "#     max_position_embeddings=514,\n",
    "#     num_attention_heads=6,\n",
    "#     num_hidden_layers=3,\n",
    "#     type_vocab_size=1,\n",
    "# )\n",
    "\n",
    "\n",
    "# model = RobertaForMaskedLM(config=config)\n",
    "\n",
    "# print(f'number of parameters model: {model.num_parameters()}')\n",
    "\n",
    "# from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"/Users/jan/Documents/Master/Thesis/Code/Models/model2\", # note, this is not where the model is saved, just info about training\n",
    "#     overwrite_output_dir=True,\n",
    "#     num_train_epochs=1,\n",
    "#     per_device_train_batch_size=64,\n",
    "#     save_steps=10_000,\n",
    "#     save_total_limit=1000,\n",
    "#     prediction_loss_only=True,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=dataset,\n",
    "# )\n",
    "\n",
    "# %%time\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must now find a way to convert the toke ids to text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_b: ['fietsen']\n",
      "out = [15022]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15022]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laten we fietsen nemen\n",
    "\n",
    "x = CustomTokenizerMorphPiece(segmentations, tokenizer)\n",
    "\n",
    "x.encode('fietsen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fiets'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.decode([15022])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of own tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to evaluate how specific words are tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simlex(simlex999, scores=False):\n",
    "    # create list with a tuple for every word pair in the form of (word_1, word_2, similarity score, POS-tag)\n",
    "    word_pairs = []\n",
    "\n",
    "    # create a set with all words\n",
    "    words_set = set([])\n",
    "\n",
    "    with open(simlex999) as simlex:\n",
    "        \n",
    "        next(simlex) # skip first line\n",
    "        \n",
    "        for line in simlex:\n",
    "    \n",
    "            split = line.strip().split('\\t')\n",
    "            word_pairs.append(tuple(split))\n",
    "            words_set.add(split[0])\n",
    "            words_set.add(split[1])\n",
    "\n",
    "    # create a list of unique words\n",
    "    simlex_words = list(words_set)\n",
    "\n",
    "    if scores:\n",
    "        return word_pairs\n",
    "    else:\n",
    "        return simlex_words\n",
    "\n",
    "def simlex_celex(df, n, simlex_words, exclusive=False, with_segments=False):\n",
    "\n",
    "    d = create_n_segmentations(df, 0)\n",
    "    dic = {}\n",
    "\n",
    "    for i in range(n + 2):\n",
    "        data = create_n_segmentations(df, i)\n",
    "        dic[i] = []\n",
    "        for word in simlex_words:\n",
    "            if word in data:\n",
    "                dic[i].append(word)\n",
    "\n",
    "    if exclusive:\n",
    "        out = list(set(dic[n]) - set(dic[n + 1]))\n",
    "    else:\n",
    "        out = dic[n]\n",
    "    \n",
    "    if with_segments:\n",
    "        out = {word: d[word] for word in out}\n",
    "    \n",
    "    print(f'There are {len(simlex_words)} unique words in the simlex dataset')\n",
    "    \n",
    "    if n != 1:\n",
    "        if exclusive:\n",
    "            print(f'There are {len(out)} words in simlex that have exactly {n} segments in CELEX')\n",
    "        else:\n",
    "            print(f'There are {len(out)} words in simlex that have at least {n} segments in CELEX')\n",
    "    else:\n",
    "        if exclusive:\n",
    "            print(f'There are {len(out)} words in simlex that have exactly {n} segment in CELEX')\n",
    "        else:\n",
    "            print(f'There are {len(out)} words in simlex that have at least {n} segment in CELEX') \n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def tokenizer_segmentations(words, tokenizer, only_splits=False):\n",
    "    \n",
    "    segs = {}\n",
    "\n",
    "    for word in words:\n",
    "        tokenization = tokenizer.tokenize(word)\n",
    "        tokenization = [word.replace('Ġ', '') for word in tokenization]\n",
    "        tokenization = [word.replace('##', '') for word in tokenization]\n",
    "        segs[word] = tokenization\n",
    "    \n",
    "    if only_splits:\n",
    "        return {word: seg for word, seg in segs.items() if len(seg) > 1}\n",
    "    else:\n",
    "        return segs\n",
    "\n",
    "\n",
    "def compare_tokenizer_segmentations(words, *tokenizers):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for tokenizer in tokenizers:\n",
    "        results[tokenizer] = tokenizer_segmentations(words, tokenizer)\n",
    "    \n",
    "    words_same = []\n",
    "    words_diff = []\n",
    "\n",
    "    for word in words:\n",
    "        comp = {}\n",
    "        for tokenizer in results:\n",
    "            comp[tokenizer] = results[tokenizer][word]\n",
    "        iterator = iter(comp.values())\n",
    "        first_value = next(iterator)\n",
    "        if all(value == first_value for value in iterator):\n",
    "            words_same.append(word)\n",
    "        else:\n",
    "            words_diff.append(word)\n",
    "    \n",
    "    diff = {}\n",
    "    for word in words_diff:\n",
    "        c = {}\n",
    "        for i, tokenizer in enumerate(tokenizers):\n",
    "            c[i+1] = results[tokenizer][word]\n",
    "        diff[word] = c\n",
    "\n",
    "    \n",
    "    if len(tokenizers) == 2:\n",
    "        print(f'{len(words_same)} words out of the {len(words)} are tokenized in the same way by both tokenizers')\n",
    "    else:\n",
    "        print(f'{len(words_same)} words out of the {len(words)} are tokenized in the same way by all {len(tokenizers)} tokenizers')\n",
    "\n",
    "    return words_same, words_diff, diff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_tokenizer_with_celex(df, tokenizer):\n",
    "\n",
    "    words = [word for word in df]\n",
    "    segs = tokenizer_segmentations(words, tokenizer)\n",
    "\n",
    "    words_same = []\n",
    "    words_diff = []\n",
    "    diff = {}\n",
    "\n",
    "    for word in df:\n",
    "        if df[word] == segs[word]:\n",
    "            words_same.append(word)\n",
    "        else:\n",
    "            words_diff.append(word)\n",
    "    \n",
    "    diff = {}\n",
    "    for word in words_diff:\n",
    "        if len(segs[word]) >= 2:\n",
    "            c = {}\n",
    "            c['CELEX'] = df[word]\n",
    "            c['tokenizer'] = segs[word]\n",
    "            diff[word] = c\n",
    "    \n",
    "    return words_same, words_diff, diff\n",
    "\n",
    "def return_words_not_in_dict(df, words):\n",
    "    out = []\n",
    "    for word in words:\n",
    "        if word not in df:\n",
    "            out.append(word)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to evaluate speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# function to create a dataset with text \n",
    "def create_test_set(dataset_generator, start, end):\n",
    "    it = iter(dataset_generator)\n",
    "    for _ in range(start):\n",
    "        next(it)\n",
    "    for _ in range(end - start + 1):\n",
    "        yield next(it)\n",
    "\n",
    "\n",
    "# function to measure time a function takes\n",
    "def measure_execution_time(function, *args, **kwargs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    function(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# function to measure how much time it takes for a function to process data\n",
    "# the function here should not take a generator as input\n",
    "# the data is supplied by a generator\n",
    "def measure_time_normal_function_x(data_generator, start, end, function, *args, **kwargs):\n",
    "\n",
    "    gen = create_test_set(data_generator, start, end)\n",
    "    t=0\n",
    "\n",
    "    for i in gen:\n",
    "        text = i['text']\n",
    "        t += measure_execution_time(function, text, *args, **kwargs)\n",
    "    \n",
    "    return t\n",
    "\n",
    "# this function takes a generator and function as input, and measures the time it takes to execute the function for every item in the generator\n",
    "def measure_time_normal_function(data_generator, start, end, function, *args, **kwargs):\n",
    "\n",
    "    gen = create_test_set(data_generator, start, end)\n",
    "    t=0\n",
    "\n",
    "    for i in gen:\n",
    "        t += measure_execution_time(function, i, *args, **kwargs)\n",
    "    \n",
    "    return t\n",
    "\n",
    "\n",
    "# function to measure how much time it takes a function to execute for every item in the generator\n",
    "# same as the function above, but this one is for functions that take a generator as argument\n",
    "def measure_time_generator_function(data_generator, start, end, function, *args, **kwargs):\n",
    "    \n",
    "    gen = create_test_set(data_generator, start, end)\n",
    "    return measure_execution_time(function, gen, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# function to use for the generators that yield dictionaries with 'text' as key\n",
    "# this is for the iterable dictionary provided by hugging face\n",
    "# (We now use a wrapper generator, so probably don't need this anymore)\n",
    "def measure_time_iterable_text_dict(data_generator, start, end, function, *args, **kwargs):\n",
    "    \n",
    "    data_generator = create_text_generator(data_generator)\n",
    "    gen = create_test_set(data_generator, start, end)\n",
    "    return measure_execution_time(function, gen, *args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# function to turn a generator that returns a dictionary with 'text' as key into a generator of the values\n",
    "def create_text_generator(gen):\n",
    "    for i in gen:\n",
    "        yield i['text']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual evaluation and comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the tokenizers, we need the following elements:\n",
    "- the simlex words\n",
    "- a corpus in the form of a generator\n",
    "- a corpus in the form of a frequency dictionary\n",
    "\n",
    "We will create various different versions of these three elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the tokenizers we have trained externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import RobertaTokenizerFast\n",
    "# maakt het uit of we autotokenizer of tokenizerfast gebruiken?\n",
    "\n",
    "\n",
    "t1 = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "t2 = AutoTokenizer.from_pretrained(\"DTAI-KULeuven/robbert-2023-dutch-large\")\n",
    "\n",
    "\n",
    "# WordPiece tokenizers\n",
    "wp_30 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeWP/t30\", max_len=512)\n",
    "wp_40 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeWP/t40\", max_len=512)\n",
    "wp_50 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeWP/t50\", max_len=512)\n",
    "\n",
    "# BPE tokenizer\n",
    "bpe_30 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeBPE/t30\", max_len=512)\n",
    "bpe_40 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeBPE/t40\", max_len=512)\n",
    "bpe_50 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeBPE/t50\", max_len=512)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "t30 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t30\", max_len=512)\n",
    "t32 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t32\", max_len=512)\n",
    "t35 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t35\", max_len=512)\n",
    "t40 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t40\", max_len=512)\n",
    "t45 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t45\", max_len=512)\n",
    "t50 = RobertaTokenizerFast.from_pretrained(\"/Users/jan/Documents/Master/Thesis/Code/Tokenizers/tokenizeXX/t50\", max_len=512)\n",
    "\n",
    "# own custom tokenizers\n",
    "own_30 = CustomTokenizer(segmentation_dictionary, t30)\n",
    "own_32 = CustomTokenizer(segmentation_dictionary, t32)\n",
    "own_35 = CustomTokenizer(segmentation_dictionary, t35)\n",
    "own_40 = CustomTokenizer(segmentation_dictionary, t40)\n",
    "own_45 = CustomTokenizer(segmentation_dictionary, t45)\n",
    "own_50 = CustomTokenizer(segmentation_dictionary, t50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41752"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(own_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ik', 'ga', 'lopen']\n",
      "['ik', 'Ġga', 'Ġlopen']\n",
      "['Ġik', 'Ġga', 'Ġl', 'open']\n"
     ]
    }
   ],
   "source": [
    "print(wp_50.tokenize('ik ga lopen'))\n",
    "print(bpe_50.tokenize('ik ga lopen'))\n",
    "print(own_50.tokenize('ik ga lopen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677 words out of the 1045 are tokenized in the same way by both tokenizers\n"
     ]
    }
   ],
   "source": [
    "a, b, c = compare_tokenizer_segmentations(simlex_words, wp_50, bpe_50)\n",
    "\n",
    "#c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_splits(words, tokenizer):\n",
    "\n",
    "    toks = tokenizer_segmentations(words, tokenizer)\n",
    "\n",
    "    split = {}\n",
    "    no_split = []\n",
    "    for word, segs in toks.items():\n",
    "        if len(segs) > 1:\n",
    "            split[word] = segs\n",
    "        else:\n",
    "            no_split.append(word)\n",
    "    \n",
    "    print(f'Number of words split up: {len(split)}')\n",
    "    print(f'Number of words not split up: {len(no_split)}')\n",
    "\n",
    "    return split, no_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words split up: 161\n",
      "Number of words not split up: 884\n"
     ]
    }
   ],
   "source": [
    "r, t = count_splits(simlex_words, wp_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words split up: 441\n",
      "Number of words not split up: 604\n"
     ]
    }
   ],
   "source": [
    "r, t = count_splits(simlex_words, bpe_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words split up: 390\n",
      "Number of words not split up: 655\n"
     ]
    }
   ],
   "source": [
    "r, t = count_splits(simlex_words, own_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46398"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(own_50.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prachtig ['Ġpracht', 'ig']\n",
      "rekenkunde ['Ġreken', 'kunde']\n",
      "doel ['Ġdoel']\n",
      "gangpad ['Ġgang', 'pad']\n",
      "scheikunde ['sche', 'ik', 'unde']\n",
      "tabak ['Ġtabak']\n",
      "situatie ['situatie']\n",
      "winnen ['w', 'innen']\n",
      "blik ['Ġblik']\n",
      "boom ['Ġboom']\n",
      "baksteen ['Ġbak', 'steen']\n",
      "agressie ['Ġagressie']\n",
      "lezen ['lezen']\n",
      "kapitein ['Ġkapitein']\n",
      "vers ['Ġvers']\n",
      "regio ['Ġregio']\n",
      "ballade ['Ġballade']\n",
      "uitbeelden ['Ġuit', 'beeld', 'en']\n",
      "kraampje ['kra', 'amp', 'je']\n",
      "telefoon ['Ġtelefoon']\n",
      "melodie ['mel', 'od', 'ie']\n",
      "prins ['Ġprins']\n",
      "koor ['Ġkoor']\n",
      "discussie ['Ġdiscussie']\n",
      "monster ['Ġmonster']\n",
      "wortel ['Ġwortel']\n",
      "zelf ['Ġzelf']\n",
      "schildwacht ['Ġschild', 'wacht']\n",
      "macht ['Ġmacht']\n",
      "vrolijk ['Ġvrolijk']\n",
      "motor ['Ġmotor']\n",
      "diamant ['Ġdiamant']\n",
      "theorie ['Ġtheorie']\n",
      "misdaad ['Ġmis', 'daad']\n",
      "emotie ['Ġemotie']\n",
      "zeker ['Ġzeker']\n",
      "mantel ['Ġmantel']\n",
      "aanzien ['Ġaanzien']\n",
      "psychologie ['psych', 'ologie']\n",
      "bijwonen ['bij', 'wonen']\n",
      "doos ['Ġdoos']\n",
      "insect ['inse', 'ct']\n",
      "doen alsof ['Ġdoen', 'Ġalsof']\n",
      "toevoegen ['Ġtoe', 'voeg', 'en']\n",
      "ongeduldig ['Ġon', 'geduld', 'ig']\n",
      "pijpleiding ['Ġpijp', 'leid', 'ing']\n",
      "goedkoop ['Ġgoed', 'koop']\n",
      "acteur ['acteur']\n",
      "dragen ['dragen']\n",
      "verdedigen ['verde', 'digen']\n",
      "vergeten ['Ġvergeten']\n",
      "arts ['Ġarts']\n",
      "jaar ['Ġjaar']\n",
      "erkennen ['er', 'kennen']\n",
      "vermoeden ['Ġvermoeden']\n",
      "wang ['Ġwang']\n",
      "straalvliegtuig ['Ġstraal', 'vlieg', 'tuig']\n",
      "dom ['Ġdom']\n",
      "komen ['Ġkom', 'en']\n",
      "verstikken ['ver', 'st', 'ikken']\n",
      "beeld ['Ġbeeld']\n",
      "gevoel ['Ġge', 'voel']\n",
      "kostuum ['Ġkostuum']\n",
      "gehoorzamen ['geh', 'oor', 'z', 'amen']\n",
      "chocolade ['Ġchocolade']\n",
      "tevredenstellen ['tevreden', 'stellen']\n",
      "bol ['Ġbol']\n",
      "bestelling ['be', 'stelling']\n",
      "infectie ['Ġinfect', 'ie']\n",
      "dieet ['Ġdieet']\n",
      "fles ['Ġfles']\n",
      "achterlaten ['achter', 'laten']\n",
      "onderbuik ['Ġonder', 'buik']\n",
      "klif ['Ġklif']\n",
      "zin ['Ġzin']\n",
      "analyseren ['anal', 'ys', 'eren']\n",
      "stof ['Ġstof']\n",
      "bank ['Ġbank']\n",
      "lus ['Ġlus']\n",
      "bankier ['Ġbank', 'ier']\n",
      "kanon ['Ġkanon']\n",
      "bewustzijn ['Ġbewust', 'zijn']\n",
      "jenever ['Ġjenever']\n",
      "stoer ['Ġstoer']\n",
      "prooi ['Ġprooi']\n",
      "administratie ['administratie']\n",
      "bidden ['bid', 'den']\n",
      "gelukkigheid ['gelukkig', 'heid']\n",
      "keel ['Ġkeel']\n",
      "persoon ['Ġpersoon']\n",
      "mes ['Ġmes']\n",
      "advocaat ['Ġadvocaat']\n",
      "neus ['Ġneus']\n",
      "straal ['Ġstraal']\n",
      "handschoen ['Ġhand', 'schoen']\n",
      "cel ['Ġcel']\n",
      "artikel ['Ġartikel']\n",
      "onderzoeken ['Ġonder', 'zoek', 'en']\n",
      "massa ['Ġmassa']\n",
      "sigaar ['Ġsigaar']\n",
      "kanker ['Ġkanker']\n",
      "marihuana ['mar', 'i', 'hu', 'ana']\n",
      "stroom ['Ġstroom']\n",
      "dame ['Ġdame']\n",
      "stemmen op ['stemmen', 'Ġop']\n",
      "aartsbisschop ['Ġaarts', 'bisschop']\n",
      "been ['Ġbeen']\n",
      "afbeelding ['Ġaf', 'beeld', 'ing']\n",
      "poort ['Ġpoort']\n",
      "filmrol ['Ġfilm', 'rol']\n",
      "illusie ['Ġillusie']\n",
      "stom ['Ġstom']\n",
      "monnik ['Ġmonnik']\n",
      "prinses ['Ġprins', 'es']\n",
      "riem ['Ġriem']\n",
      "communiceren ['commun', 'iceren']\n",
      "pagina ['Ġpagina']\n",
      "onderneming ['onderneming']\n",
      "darm ['Ġdarm']\n",
      "salaris ['Ġsalaris']\n",
      "hersenen ['Ġhersen', 'en']\n",
      "echtgenoot ['Ġecht', 'genoot']\n",
      "pistool ['Ġpistool']\n",
      "doelwit ['Ġdoel', 'wit']\n",
      "zijkant ['Ġzij', 'kant']\n",
      "excursie ['Ġexcursie']\n",
      "regelen ['Ġregel', 'en']\n",
      "viool ['Ġviool']\n",
      "dienstmeisje ['Ġdien', 'st', 'meisje']\n",
      "duidelijk ['Ġduid', 'elijk']\n",
      "graan ['Ġgraan']\n",
      "verkennen ['ver', 'kennen']\n",
      "raket ['Ġraket']\n",
      "onwetendheid ['Ġon', 'wetend', 'heid']\n",
      "slang ['Ġslang']\n",
      "diefstal ['Ġdiefstal']\n",
      "week ['Ġweek']\n",
      "anatomie ['an', 'at', 'omie']\n",
      "frustratie ['f', 'ru', 'stratie']\n",
      "voogd ['Ġvoogd']\n",
      "slecht ['Ġslecht']\n",
      "elleboog ['Ġelleboog']\n",
      "heerlijk ['Ġheer', 'lijk']\n",
      "uithoudingsvermogen ['Ġuithouding', 's', 'vermogen']\n",
      "tijdschrift ['Ġtijd', 'schrift']\n",
      "camera ['Ġcamera']\n",
      "kiezen ['k', 'iezen']\n",
      "wijsheid ['Ġwijs', 'heid']\n",
      "kopen ['kopen']\n",
      "soldaat ['Ġsoldaat']\n",
      "beschaamd ['Ġbeschaamd']\n",
      "havik ['Ġhavik']\n",
      "arm ['Ġarm']\n",
      "juist ['Ġjuist']\n",
      "hoofd ['Ġhoofd']\n",
      "dokter ['Ġdokter']\n",
      "lever ['Ġlever']\n",
      "zon ['Ġzon']\n",
      "lied ['Ġlied']\n",
      "richel ['Ġrichel']\n",
      "vriend ['Ġvriend']\n",
      "voorstellen ['voorstellen']\n",
      "actie ['Ġactie']\n",
      "zelfvertrouwen ['Ġzelf', 'vertrouwen']\n",
      "zonsopgang ['Ġzon', 's', 'op', 'gang']\n",
      "verschijnen ['versch', 'ijnen']\n",
      "stro ['Ġstro']\n",
      "zone ['Ġzone']\n",
      "sap ['Ġsap']\n",
      "sneeuw ['Ġsneeuw']\n",
      "tijdperk ['Ġtijd', 'perk']\n",
      "long ['Ġlong']\n",
      "inspanning ['in', 'spanning']\n",
      "rif ['Ġrif']\n",
      "honing ['Ġhoning']\n",
      "arbeider ['Ġarbeid', 'er']\n",
      "veulen ['Ġveulen']\n",
      "orthodontist ['ort', 'hod', 'ont', 'ist']\n",
      "conditie ['Ġconditie']\n",
      "teen ['Ġteen']\n",
      "drank ['Ġdrank']\n",
      "toren ['Ġtoren']\n",
      "communicatie ['communicatie']\n",
      "machine ['Ġmachine']\n",
      "beschermen ['Ġbe', 'scherm', 'en']\n",
      "deelnemen ['deel', 'nemen']\n",
      "verdrag ['Ġverdrag']\n",
      "oom ['Ġoom']\n",
      "realiseren ['re', 'aliseren']\n",
      "bewijs ['Ġbewijs']\n",
      "bed ['Ġbed']\n",
      "begrafenis ['be', 'gra', 'fen', 'is']\n",
      "heldin ['Ġheld', 'in']\n",
      "koesteren ['Ġkoester', 'en']\n",
      "zetten ['zetten']\n",
      "argument ['Ġargument']\n",
      "universum ['univers', 'um']\n",
      "snel ['Ġsnel']\n",
      "zenuw ['Ġzenuw']\n",
      "taal ['Ġtaal']\n",
      "boter ['Ġboter']\n",
      "opslagplaats ['Ġopslag', 'plaats']\n",
      "zege ['Ġzege']\n",
      "organiseren ['organis', 'eren']\n",
      "hond ['Ġhond']\n",
      "bal ['Ġbal']\n",
      "vereisen ['Ġver', 'eis', 'en']\n",
      "gek ['Ġgek']\n",
      "keuze ['Ġkeuze']\n",
      "boek ['Ġboek']\n",
      "paar ['Ġpaar']\n",
      "eerlijk ['Ġeer', 'lijk']\n",
      "maat ['Ġmaat']\n",
      "chaos ['Ġchaos']\n",
      "partij ['Ġpartij']\n",
      "medium ['Ġmedium']\n",
      "streven ['Ġstreven']\n",
      "kast ['Ġkast']\n",
      "tragedie ['Ġtragedie']\n",
      "activiteit ['activiteit']\n",
      "plezier ['Ġplezier']\n",
      "verdwijnen ['verd', 'wijnen']\n",
      "rijtuig ['rij', 'tuig']\n",
      "orkest ['Ġorkest']\n",
      "opnemen ['op', 'nemen']\n",
      "intrekken ['in', 'trekken']\n",
      "verschrikkelijk ['versch', 'rik', 'kelijk']\n",
      "afwezigheid ['Ġafwezig', 'heid']\n",
      "leider ['Ġleid', 'er']\n",
      "voorbijgaan ['voor', 'bij', 'gaan']\n",
      "lade ['Ġlade']\n",
      "bijbel ['Ġbijbel']\n",
      "verpleegster ['Ġverpleeg', 'ster']\n",
      "vernietigen ['Ġver', 'nietig', 'en']\n",
      "broederschap ['Ġbroeder', 'schap']\n",
      "badkamer ['Ġbad', 'kamer']\n",
      "vermijden ['Ġver', 'mijd', 'en']\n",
      "ontstaan ['ont', 'staan']\n",
      "koningin ['Ġkoning', 'in']\n",
      "onderontwikkeld ['Ġonder', 'ontwikkeld']\n",
      "vermenigvuldigen ['Ġver', 'menigvuldig', 'en']\n",
      "geluk ['Ġge', 'luk']\n",
      "onderwerp ['Ġonderwerp']\n",
      "volwassen ['Ġvolwassen']\n",
      "minnaar ['min', 'naar']\n",
      "politieagent ['pol', 'itie', 'agent']\n",
      "voetbal ['Ġvoet', 'bal']\n",
      "nieuws ['Ġnieuws']\n",
      "lijden ['Ġlijden']\n",
      "biografie ['bi', 'ografie']\n",
      "verwerven ['ver', 'wer', 'ven']\n",
      "zomer ['Ġzomer']\n",
      "kooi ['Ġkooi']\n",
      "molecuul ['mo', 'le', 'cu', 'ul']\n",
      "ziekenhuis ['ziekenhuis']\n",
      "bevolking ['Ġbe', 'volk', 'ing']\n",
      "kabel ['Ġkabel']\n",
      "sluw ['Ġsluw']\n",
      "sla ['Ġsla']\n",
      "ploeg ['Ġploeg']\n",
      "controleren ['control', 'eren']\n",
      "oceaan ['Ġoceaan']\n",
      "bus ['Ġbus']\n",
      "toeter ['Ġtoeter']\n",
      "rechtvaardigen ['recht', 'vaar', 'digen']\n",
      "smal ['Ġsmal']\n",
      "huisdier ['Ġhuis', 'dier']\n",
      "koffie ['Ġkoffie']\n",
      "ijzer ['Ġijzer']\n",
      "bewijzen ['bewijzen']\n",
      "verschillen ['verschillen']\n",
      "kip ['Ġkip']\n",
      "illegaal ['Ġil', 'legaal']\n",
      "oud ['Ġoud']\n",
      "waarde ['Ġwaarde']\n",
      "neiging ['Ġneig', 'ing']\n",
      "smeken ['s', 'me', 'ken']\n",
      "besteden ['be', 'steden']\n",
      "orgaan ['Ġorgaan']\n",
      "beladen ['bel', 'aden']\n",
      "lunch ['Ġlunch']\n",
      "kerel ['Ġkerel']\n",
      "herstellen ['her', 'stellen']\n",
      "esdoorn ['Ġesdoorn']\n",
      "hal ['Ġhal']\n",
      "parade ['par', 'ade']\n",
      "aluminium ['Ġaluminium']\n",
      "avond ['Ġavond']\n",
      "steeg ['Ġsteeg']\n",
      "bouwen ['Ġbouw', 'en']\n",
      "cabine ['Ġcabine']\n",
      "flexibel ['Ġflexibel']\n",
      "piloot ['Ġpiloot']\n",
      "snoep ['Ġsnoep']\n",
      "cocktail ['Ġcocktail']\n",
      "leeftijd ['Ġleef', 'tijd']\n",
      "angstig ['Ġangst', 'ig']\n",
      "helper ['Ġhelp', 'er']\n",
      "redden ['red', 'den']\n",
      "muis ['Ġmuis']\n",
      "industrie ['Ġindustrie']\n",
      "vriendelijk ['Ġvriend', 'elijk']\n",
      "bizar ['Ġbizar']\n",
      "kracht ['Ġkracht']\n",
      "huishoudelijk apparaat ['Ġhuis', 'houd', 'elijk', 'Ġapparaat']\n",
      "schrijver ['schrijver']\n",
      "fraude ['Ġfraude']\n",
      "botten ['bot', 'ten']\n",
      "stellig ['stell', 'ig']\n",
      "koning ['Ġkoning']\n",
      "achterblijven ['achter', 'blijven']\n",
      "gitaar ['Ġgitaar']\n",
      "zelden ['Ġzelden']\n",
      "priester ['Ġpriester']\n",
      "rationaliseren ['r', 'ation', 'aliseren']\n",
      "water ['Ġwater']\n",
      "gevangenis ['Ġgevangenis']\n",
      "pot ['Ġpot']\n",
      "herberg ['Ġherberg']\n",
      "uitbundigheid ['Ġuitbundig', 'heid']\n",
      "spier ['Ġspier']\n",
      "tandarts ['Ġtand', 'arts']\n",
      "vooroordeel ['Ġvoor', 'oor', 'deel']\n",
      "leren ['leren']\n",
      "informatie ['informatie']\n",
      "schemering ['Ġschemer', 'ing']\n",
      "klagen ['k', 'lagen']\n",
      "leraar ['Ġleraar']\n",
      "kapel ['Ġkapel']\n",
      "lokaliseren ['lok', 'aliseren']\n",
      "hogeschool ['hoge', 'school']\n",
      "strand ['Ġstrand']\n",
      "kat ['Ġkat']\n",
      "werkelijkheid ['Ġwerkelijk', 'heid']\n",
      "knie ['Ġknie']\n",
      "overeenkomst ['Ġovereenkom', 'st']\n",
      "griep ['Ġgriep']\n",
      "politicus ['Ġpoliticus']\n",
      "saai ['Ġsaai']\n",
      "blij ['Ġblij']\n",
      "ingang ['Ġingang']\n",
      "nier ['Ġnier']\n",
      "begrijpen ['Ġbe', 'grijp', 'en']\n",
      "herinneren ['her', 'inn', 'eren']\n",
      "schaamte ['Ġschaam', 'te']\n",
      "struik ['Ġstruik']\n",
      "onlangs ['onlangs']\n",
      "decennium ['Ġdecennium']\n",
      "planeet ['Ġplaneet']\n",
      "nacht ['Ġnacht']\n",
      "lichaam ['Ġlichaam']\n",
      "olie ['Ġolie']\n",
      "hotel ['Ġhotel']\n",
      "verkondigen ['verk', 'ond', 'igen']\n",
      "doen ['Ġdoen']\n",
      "hysterie ['hy', 'ster', 'ie']\n",
      "schoonheid ['Ġschoon', 'heid']\n",
      "grootmoedig ['Ġgroot', 'moed', 'ig']\n",
      "mode ['Ġmode']\n",
      "taak ['Ġtaak']\n",
      "benoemen ['Ġbe', 'noem', 'en']\n",
      "zonsondergang ['Ġzon', 's', 'onder', 'gang']\n",
      "taart ['Ġtaart']\n",
      "verbeelding ['Ġver', 'beeld', 'ing']\n",
      "zonneschijn ['zonne', 'schijn']\n",
      "toestaan ['toestaan']\n",
      "aankomen ['Ġaan', 'kom', 'en']\n",
      "mier ['Ġmier']\n",
      "heuvel ['Ġheuvel']\n",
      "manager ['Ġmanager']\n",
      "verminderen ['Ġver', 'minder', 'en']\n",
      "voorspellen ['voor', 'spellen']\n",
      "stam ['Ġstam']\n",
      "kritiek ['krit', 'iek']\n",
      "concluderen ['con', 'cl', 'uderen']\n",
      "ballon ['Ġballon']\n",
      "vernietiging ['Ġver', 'nietig', 'ing']\n",
      "normaal ['Ġnormaal']\n",
      "hengst ['Ġhengst']\n",
      "konijn ['Ġkonijn']\n",
      "overnadenken ['over', 'na', 'denken']\n",
      "bloem ['Ġbloem']\n",
      "willen ['w', 'illen']\n",
      "bisschop ['Ġbisschop']\n",
      "ruggengraat ['rug', 'gen', 'gra', 'at']\n",
      "paragraaf ['Ġparagraaf']\n",
      "reis ['Ġreis']\n",
      "sigaret ['Ġsigaret']\n",
      "president ['president']\n",
      "tas ['Ġtas']\n",
      "zich gedragen ['Ġzich', 'Ġgedragen']\n",
      "datum ['Ġdatum']\n",
      "aanwezigheid ['Ġaanwezig', 'heid']\n",
      "examineren ['ex', 'amin', 'eren']\n",
      "bepalen ['bep', 'alen']\n",
      "duim ['Ġduim']\n",
      "mannen ['mannen']\n",
      "beker ['Ġbeker']\n",
      "visie ['Ġvisie']\n",
      "jachthond ['Ġjacht', 'hond']\n",
      "wurgen ['Ġwurg', 'en']\n",
      "kust ['Ġkust']\n",
      "zuid ['Ġzuid']\n",
      "woord ['Ġwoord']\n",
      "dek ['Ġdek']\n",
      "trui ['Ġtrui']\n",
      "tong ['Ġtong']\n",
      "vuil ['Ġvuil']\n",
      "temperament ['Ġtemperament']\n",
      "nodig hebben ['Ġnodig', 'Ġheb', 'ben']\n",
      "appel ['Ġappel']\n",
      "toestand ['Ġtoestand']\n",
      "trommel ['Ġtrommel']\n",
      "glas ['Ġglas']\n",
      "paard ['Ġpaard']\n",
      "weten ['Ġweten']\n",
      "beginnen ['beg', 'innen']\n",
      "dageraad ['dag', 'er', 'aad']\n",
      "kathedraal ['Ġkathedraal']\n",
      "domineren ['dom', 'ineren']\n",
      "opslaan ['op', 'slaan']\n",
      "tekst ['Ġtekst']\n",
      "lip ['Ġlip']\n",
      "menu ['Ġmenu']\n",
      "appartement ['Ġappartement']\n",
      "basketbal ['Ġbasket', 'bal']\n",
      "volbrengen ['Ġvol', 'breng', 'en']\n",
      "vermogen ['Ġvermogen']\n",
      "tarwe ['Ġtarwe']\n",
      "klaslokaal ['Ġklas', 'lokaal']\n",
      "wetenschap ['Ġweten', 'schap']\n",
      "gewelddadig ['geweld', 'dad', 'ig']\n",
      "portemonnee ['Ġportemonnee']\n",
      "hout ['Ġhout']\n",
      "bij ['Ġbij']\n",
      "uitgang ['Ġuit', 'gang']\n",
      "exotisch ['ex', 'otisch']\n",
      "thema ['Ġthema']\n",
      "plafond ['Ġplafond']\n",
      "binnenkomen ['Ġbinnen', 'kom', 'en']\n",
      "azijn ['Ġazijn']\n",
      "ader ['Ġader']\n",
      "symbool ['Ġsymbool']\n",
      "behouden ['be', 'houden']\n",
      "breekbaar ['Ġbreek', 'baar']\n",
      "beleefd ['Ġbeleefd']\n",
      "vinger ['Ġvinger']\n",
      "katoen ['Ġkatoen']\n",
      "koppig ['kopp', 'ig']\n",
      "verloven ['ver', 'loven']\n",
      "uitbreiden ['uit', 'bre', 'iden']\n",
      "lijken ['Ġlijk', 'en']\n",
      "scherp ['Ġscherp']\n",
      "koel ['Ġkoel']\n",
      "krant ['Ġkrant']\n",
      "film ['Ġfilm']\n",
      "beest ['Ġbeest']\n",
      "vergelijking ['Ġver', 'gelijk', 'ing']\n",
      "ontkenning ['ont', 'kenning']\n",
      "noodgeval ['Ġnood', 'geval']\n",
      "huisje ['huisje']\n",
      "seconde ['Ġseconde']\n",
      "kaart ['Ġkaart']\n",
      "mosterd ['Ġmosterd']\n",
      "vergoeding ['Ġver', 'goed', 'ing']\n",
      "baby ['Ġbaby']\n",
      "immoreel ['Ġim', 'moreel']\n",
      "bord ['Ġbord']\n",
      "sterk ['Ġsterk']\n",
      "pijp ['Ġpijp']\n",
      "cijfer ['Ġcijfer']\n",
      "partner ['Ġpartner']\n",
      "groeien ['Ġgroei', 'en']\n",
      "overwinnen ['over', 'w', 'innen']\n",
      "stelen ['st', 'elen']\n",
      "lift ['Ġlift']\n",
      "rijst ['Ġrijst']\n",
      "overtreding ['over', 'treding']\n",
      "anarchie ['Ġanarchie']\n",
      "definitie ['Ġdefinitie']\n",
      "klas ['Ġklas']\n",
      "brandewijn ['Ġbrand', 'e', 'wijn']\n",
      "koppel ['Ġkoppel']\n",
      "kristal ['Ġkristal']\n",
      "slim ['Ġslim']\n",
      "bedreiging ['Ġbe', 'dreig', 'ing']\n",
      "hut ['Ġhut']\n",
      "marine ['Ġmarine']\n",
      "stijl ['Ġstijl']\n",
      "nemen ['nemen']\n",
      "trouwen ['Ġtrouw', 'en']\n",
      "rabbijn ['Ġrabbijn']\n",
      "maatschappij ['Ġmaatschappij']\n",
      "verwarring ['ver', 'war', 'ring']\n",
      "hemel ['Ġhemel']\n",
      "delen ['delen']\n",
      "avondeten ['Ġavond', 'eten']\n",
      "competentie ['compet', 'entie']\n",
      "heup ['Ġheup']\n",
      "belichamen ['bel', 'ich', 'amen']\n",
      "kennelijk ['Ġkennelijk']\n",
      "deur ['Ġdeur']\n",
      "bovenkant ['Ġboven', 'kant']\n",
      "alcohol ['Ġalcohol']\n",
      "comfort ['Ġcomfort']\n",
      "geloof ['Ġgeloof']\n",
      "kool ['Ġkool']\n",
      "juridische procedures ['jur', 'id', 'ische', 'Ġprocedure', 's']\n",
      "werkgever ['werk', 'gever']\n",
      "raam ['Ġraam']\n",
      "lucht ['Ġlucht']\n",
      "grappig ['Ġgrappig']\n",
      "truc ['Ġtruc']\n",
      "verliezen ['verl', 'iezen']\n",
      "ontmoedigen ['Ġont', 'moed', 'ig', 'en']\n",
      "indruk ['Ġin', 'druk']\n",
      "gebeuren ['Ġgebeuren']\n",
      "hard ['Ġhard']\n",
      "essay ['Ġessay']\n",
      "voorkomen ['voor', 'komen']\n",
      "hoek ['Ġhoek']\n",
      "west ['Ġwest']\n",
      "bedelen ['Ġbedel', 'en']\n",
      "decimeter ['dec', 'imeter']\n",
      "vragen ['vragen']\n",
      "verkrijgen ['Ġver', 'krijg', 'en']\n",
      "literatuur ['Ġliteratuur']\n",
      "gevaar ['Ġgevaar']\n",
      "meter ['meter']\n",
      "rivaal ['Ġrivaal']\n",
      "belasting ['Ġbe', 'last', 'ing']\n",
      "karton ['Ġkarton']\n",
      "krijgen ['Ġkrijg', 'en']\n",
      "jong ['Ġjong']\n",
      "lenen ['lenen']\n",
      "belangrijk ['Ġbelang', 'rijk']\n",
      "moeilijk ['Ġmoei', 'lijk']\n",
      "kalender ['Ġkalender']\n",
      "intuïtie ['int', 'u', 'Ã', 'ĥ', 'Â', '¯', 'tie']\n",
      "verovering ['Ġverover', 'ing']\n",
      "recht ['Ġrecht']\n",
      "interesse ['Ġinteresse']\n",
      "sturen ['sturen']\n",
      "stoppen ['st', 'oppen']\n",
      "zeggen ['Ġzeggen']\n",
      "vloer ['Ġvloer']\n",
      "bier ['Ġbier']\n",
      "wijn ['Ġwijn']\n",
      "metaal ['Ġmetaal']\n",
      "rails ['Ġrail', 's']\n",
      "bel ['Ġbel']\n",
      "aanbevelen ['aan', 'bev', 'elen']\n",
      "meer ['Ġmeer']\n",
      "ochtend ['Ġochtend']\n",
      "moeras ['Ġmoeras']\n",
      "lang ['Ġlang']\n",
      "taille ['Ġtaille']\n",
      "ritme ['Ġritme']\n",
      "rand ['Ġrand']\n",
      "ramp ['Ġramp']\n",
      "wetenschapper ['wetenschapp', 'er']\n",
      "meubels ['Ġmeubel', 's']\n",
      "hart ['Ġhart']\n",
      "verhaal ['Ġverhaal']\n",
      "luisteren ['Ġluister', 'en']\n",
      "eeuw ['Ġeeuw']\n",
      "creëren ['cre', 'Ã', 'ĥ', 'Â«', 'ren']\n",
      "fabriek ['Ġfabriek']\n",
      "inkomen ['Ġinkomen']\n",
      "ontdekken ['ont', 'dekken']\n",
      "lam ['Ġlam']\n",
      "cruciaal ['cru', 'ciaal']\n",
      "held ['Ġheld']\n",
      "bocht ['Ġbocht']\n",
      "nerveus ['Ġnerveus']\n",
      "strijd ['Ġstrijd']\n",
      "zanger ['zanger']\n",
      "hoed ['Ġhoed']\n",
      "nagel ['Ġnagel']\n",
      "fantastisch ['fant', 'astisch']\n",
      "aandacht ['Ġaandacht']\n",
      "zondaar ['Ġzondaar']\n",
      "geit ['Ġgeit']\n",
      "tegenstander ['Ġtegen', 'stand', 'er']\n",
      "voldoen ['vol', 'doen']\n",
      "opvallend ['Ġopvallend']\n",
      "leeuw ['Ġleeuw']\n",
      "vlees ['Ġvlees']\n",
      "wet ['Ġwet']\n",
      "groeten ['Ġgroet', 'en']\n",
      "herzien ['her', 'zien']\n",
      "man ['Ġman']\n",
      "meedoen ['mee', 'doen']\n",
      "kogel ['Ġkogel']\n",
      "maker ['maker']\n",
      "steak ['Ġsteak']\n",
      "hoorn ['Ġhoorn']\n",
      "bloed ['Ġbloed']\n",
      "inspecteren ['inspe', 'cteren']\n",
      "kalf ['Ġkalf']\n",
      "wolk ['Ġwolk']\n",
      "ongeval ['Ġon', 'geval']\n",
      "voet ['Ġvoet']\n",
      "seizoen ['Ġseizoen']\n",
      "lawaai ['Ġlawaai']\n",
      "mand ['Ġmand']\n",
      "straat ['Ġstraat']\n",
      "vogel ['Ġvogel']\n",
      "kamer ['Ġkamer']\n",
      "schuilplaats ['Ġschuil', 'plaats']\n",
      "opdracht ['Ġopdracht']\n",
      "slaapkamer ['Ġslaap', 'kamer']\n",
      "chauffeur ['chauffeur']\n",
      "vrouw ['Ġvrouw']\n",
      "salade ['Ġsalade']\n",
      "deuropening ['Ġdeur', 'open', 'ing']\n",
      "stier ['Ġstier']\n",
      "winter ['Ġwinter']\n",
      "staaf ['Ġstaaf']\n",
      "gordijn ['Ġgordijn']\n",
      "ruw ['Ġruw']\n",
      "vlug ['Ġvlug']\n",
      "vergeven ['ver', 'geven']\n",
      "enorm ['Ġenorm']\n",
      "ongeluk ['Ġon', 'ge', 'luk']\n",
      "aandrijving ['aand', 'rijving']\n",
      "dwalen ['dw', 'alen']\n",
      "zoon ['Ġzoon']\n",
      "brug ['Ġbrug']\n",
      "groot ['Ġgroot']\n",
      "auto ['Ġauto']\n",
      "onderkant ['Ġonder', 'kant']\n",
      "motregen ['Ġmot', 'regen']\n",
      "koe ['Ġkoe']\n",
      "deken ['Ġdeken']\n",
      "borst ['Ġborst']\n",
      "burgemeester ['Ġburg', 'e', 'meester']\n",
      "saus ['Ġsaus']\n",
      "gat ['Ġgat']\n",
      "besluiten ['Ġbe', 'sluit', 'en']\n",
      "slagen ['slagen']\n",
      "roddel ['Ġroddel']\n",
      "operatie ['operatie']\n",
      "bescheiden ['Ġbescheiden']\n",
      "rechtvaardigheid ['Ġrechtvaardig', 'heid']\n",
      "formule ['Ġformule']\n",
      "omstandigheid ['Ġomstandig', 'heid']\n",
      "vliegtuig ['Ġvlieg', 'tuig']\n",
      "wafel ['Ġwafel']\n",
      "papier ['papier']\n",
      "meneer ['men', 'eer']\n",
      "drumstel ['Ġdrum', 'stel']\n",
      "verjaardag ['Ġver', 'jaar', 'dag']\n",
      "melk ['Ġmelk']\n",
      "volkslied ['Ġvolk', 's', 'lied']\n",
      "kerk ['Ġkerk']\n",
      "diepte ['Ġdiep', 'te']\n",
      "merg ['Ġmerg']\n",
      "voertuig ['Ġvoer', 'tuig']\n",
      "boot ['Ġboot']\n",
      "onderhouden ['onder', 'houden']\n",
      "evalueren ['e', 'valu', 'eren']\n",
      "wereldbol ['Ġwereld', 'bol']\n",
      "whisky ['Ġwhisky']\n",
      "geest ['Ġgeest']\n",
      "logica ['Ġlogica']\n",
      "ledemaat ['lede', 'maat']\n",
      "overwinning ['over', 'winning']\n",
      "dicht ['Ġdicht']\n",
      "elastisch ['Ġelastisch']\n",
      "vrede ['Ġvrede']\n",
      "terugtrekken ['terug', 'trekken']\n",
      "traan ['Ġtraan']\n",
      "melden ['Ġmeld', 'en']\n",
      "bang ['Ġbang']\n",
      "centimeter ['cent', 'imeter']\n",
      "eenvoudig ['Ġeenvoud', 'ig']\n",
      "rivier ['Ġrivier']\n",
      "verdrietig ['Ġverdriet', 'ig']\n",
      "vreugde ['Ġvreugde']\n",
      "brengen ['Ġbreng', 'en']\n",
      "horen ['Ġhoren']\n",
      "verzamelen ['Ġver', 'zamel', 'en']\n",
      "binnentreden ['binnen', 'treden']\n",
      "anders ['Ġanders']\n",
      "hek ['Ġhek']\n",
      "gast ['Ġgast']\n",
      "klein ['Ġklein']\n",
      "aansluiten bij ['Ġaan', 'sluit', 'en', 'Ġbij']\n",
      "orkaan ['Ġorkaan']\n",
      "gang ['Ġgang']\n",
      "oog ['Ġoog']\n",
      "luchthaven ['Ġlucht', 'haven']\n",
      "spek ['Ġspek']\n",
      "passie ['Ġpassie']\n",
      "gemakkelijk ['gemak', 'kelijk']\n",
      "weigeren ['Ġweiger', 'en']\n",
      "enkel ['Ġenkel']\n",
      "strijder ['Ġstrijd', 'er']\n",
      "tante ['Ġtante']\n",
      "auteur ['Ġauteur']\n",
      "management ['Ġmanagement']\n",
      "meisje ['Ġmeisje']\n",
      "broer ['Ġbroer']\n",
      "bubbel ['b', 'ub', 'bel']\n",
      "simpel ['Ġsimpel']\n",
      "discussiëren ['disc', 'uss', 'i', 'Ã', 'ĥ', 'Â«', 'ren']\n",
      "weekend ['Ġweek', 'end']\n",
      "ontmoeten ['ont', 'moeten']\n",
      "vrijgevig ['vrij', 'gev', 'ig']\n",
      "geven ['geven']\n",
      "bende ['Ġbende']\n",
      "referentie ['referentie']\n",
      "zee ['Ġzee']\n",
      "bezorgen ['Ġbe', 'zorg', 'en']\n",
      "falen ['falen']\n",
      "ontvangen ['ont', 'vangen']\n",
      "boon ['Ġboon']\n",
      "perceptie ['Ġperceptie']\n",
      "worden ['Ġword', 'en']\n",
      "reflectie ['Ġreflectie']\n",
      "soep ['Ġsoep']\n",
      "hals ['Ġhals']\n",
      "verdelen ['ver', 'delen']\n",
      "muziek ['Ġmuziek']\n",
      "jas ['Ġjas']\n",
      "bruid ['Ġbruid']\n",
      "buik ['Ġbuik']\n",
      "mensen ['Ġmen', 's', 'en']\n",
      "wenkbrauw ['Ġwenkbrauw']\n",
      "kil ['Ġkil']\n",
      "instrument ['Ġinstrument']\n",
      "mening ['men', 'ing']\n",
      "oordeel ['Ġoor', 'deel']\n",
      "uitleggen ['uit', 'leggen']\n",
      "voorwaarde ['Ġvoorwaarde']\n",
      "blijven ['blijven']\n",
      "ziek ['Ġziek']\n",
      "negeren ['Ġneger', 'en']\n",
      "rijkdom ['Ġrijk', 'dom']\n",
      "besmetting ['bes', 'met', 'ting']\n",
      "berg ['Ġberg']\n",
      "krimpen ['Ġkrimp', 'en']\n",
      "atoom ['Ġatoom']\n",
      "vader ['Ġvader']\n",
      "formeel ['Ġformeel']\n",
      "grens ['Ġgrens']\n",
      "raar ['Ġraar']\n",
      "maaltijd ['Ġmaal', 'tijd']\n",
      "dier ['Ġdier']\n",
      "likeur ['Ġlikeur']\n",
      "beheer ['Ġbeheer']\n",
      "samenvoegen ['Ġsamen', 'voeg', 'en']\n",
      "kerktoren ['Ġkerk', 'toren']\n",
      "textiel ['Ġtextiel']\n",
      "brood ['Ġbrood']\n",
      "afwijken ['Ġaf', 'wijk', 'en']\n",
      "doden ['do', 'den']\n",
      "aankondigen ['Ġaan', 'kond', 'ig', 'en']\n",
      "dood ['Ġdood']\n",
      "mos ['Ġmos']\n",
      "spel ['Ġspel']\n",
      "pleiten ['Ġpleit', 'en']\n",
      "woede ['Ġwoede']\n",
      "taxi's ['Ġtaxi', \"'\", 's']\n",
      "muur ['Ġmuur']\n",
      "jongen ['Ġjongen']\n",
      "vreselijk ['Ġvreselijk']\n",
      "leger ['Ġleger']\n",
      "ouder ['Ġouder']\n",
      "menigte ['Ġmenigte']\n",
      "actrice ['Ġactrice']\n",
      "feit ['Ġfeit']\n",
      "accepteren ['accepteren']\n",
      "volharding ['Ġvol', 'hard', 'ing']\n",
      "zout ['Ġzout']\n",
      "kaak ['Ġkaak']\n",
      "wagen ['Ġwagen']\n",
      "kort ['Ġkort']\n",
      "eiland ['Ġeiland']\n",
      "modern ['Ġmodern']\n",
      "school ['Ġschool']\n",
      "samenwerken ['Ġsamen', 'werk', 'en']\n",
      "os ['Ġos']\n",
      "afspraak ['Ġafspraak']\n",
      "rietje ['riet', 'je']\n",
      "bekentenis ['Ġbekentenis']\n",
      "kinderachtig ['kinder', 'achtig']\n",
      "betaling ['betaling']\n",
      "neef ['Ġneef']\n",
      "kelder ['Ġkelder']\n",
      "bruidegom ['bru', 'idegom']\n",
      "tapijt ['Ġtapijt']\n",
      "brutaal ['bru', 'taal']\n",
      "rundvlees ['Ġrund', 'vlees']\n",
      "plan ['Ġplan']\n",
      "wreed ['Ġwreed']\n",
      "code ['Ġcode']\n",
      "maan ['Ġmaan']\n",
      "instructeur ['Ġinstructeur']\n",
      "secretaresse ['secret', 'aresse']\n",
      "trots ['Ġtrots']\n",
      "pijn ['Ġpijn']\n",
      "nevel ['Ġnevel']\n",
      "manier ['Ġmanier']\n",
      "breed ['Ġbreed']\n",
      "container ['Ġcontainer']\n",
      "najagen ['na', 'jagen']\n",
      "adviseren ['advis', 'eren']\n",
      "vijandigheid ['Ġvijand', 'ig', 'heid']\n",
      "uitlenen ['uit', 'lenen']\n",
      "intelligent ['Ġintelligent']\n",
      "hoofdstuk ['Ġhoofd', 'stuk']\n",
      "nek ['Ġnek']\n",
      "dochter ['Ġdochter']\n",
      "kwaad ['Ġkwaad']\n",
      "kruid ['Ġkruid']\n",
      "atmosfeer ['Ġatmosfeer']\n",
      "gaan ['gaan']\n",
      "leveren ['Ġlever', 'en']\n",
      "leerling ['Ġleer', 'ling']\n",
      "decoratie ['decoratie']\n",
      "anker ['Ġanker']\n",
      "verkopen ['verkopen']\n",
      "gras ['Ġgras']\n",
      "gelukkig ['gelukkig']\n",
      "kalkoen ['Ġkalkoen']\n",
      "begrip ['Ġbegrip']\n",
      "ontbijt ['Ġontbijt']\n",
      "desorganiseren ['des', 'organis', 'eren']\n",
      "zelfverzekerd ['Ġzelf', 'verzekerd']\n",
      "viooltjes ['Ġviool', 'tje', 's']\n",
      "bekendheid ['Ġbekend', 'heid']\n",
      "sleutel ['Ġsleutel']\n",
      "kinderbed ['kinder', 'bed']\n",
      "parel ['Ġparel']\n",
      "betaalbaar ['Ġbetaal', 'baar']\n",
      "beschermer ['Ġbe', 'scherm', 'er']\n",
      "volwassene ['Ġvolwassene']\n",
      "brief ['Ġbrief']\n",
      "rondzwerven ['rond', 'z', 'wer', 'ven']\n",
      "zaad ['Ġzaad']\n",
      "pols ['Ġpols']\n",
      "spreken ['spreken']\n",
      "vaardigheid ['Ġvaardig', 'heid']\n",
      "thee ['Ġthee']\n",
      "dak ['Ġdak']\n",
      "geloven ['gel', 'oven']\n",
      "bekendmaken ['bekend', 'maken']\n",
      "bereiken ['Ġbe', 'reik', 'en']\n",
      "noodzakelijk ['nood', 'zakelijk']\n",
      "kom ['Ġkom']\n",
      "ontkennen ['ont', 'kennen']\n",
      "zoektocht ['z', 'oekt', 'ocht']\n",
      "verdriet ['Ġverdriet']\n",
      "logaritme ['Ġlogaritme']\n",
      "noord ['Ġnoord']\n",
      "cliff ['cli', 'ff']\n",
      "imiteren ['im', 'iteren']\n",
      "vitamine ['Ġvitamine']\n",
      "tand ['Ġtand']\n",
      "aanmoedigen ['Ġaan', 'moed', 'ig', 'en']\n",
      "balk ['Ġbalk']\n",
      "kaas ['Ġkaas']\n",
      "afwijzen ['af', 'wijzen']\n",
      "somber ['Ġsomber']\n",
      "ongelukkig ['on', 'gelukkig']\n",
      "kind ['Ġkind']\n",
      "regen ['Ġregen']\n",
      "bont ['Ġbont']\n",
      "legioen ['Ġlegioen']\n",
      "biologie ['bi', 'ologie']\n",
      "schouder ['Ġschouder']\n",
      "ziekte ['Ġziek', 'te']\n",
      "gevangeniscel ['Ġgevangenis', 'cel']\n",
      "bijvoegen ['Ġbij', 'voeg', 'en']\n",
      "kleding ['kleding']\n",
      "meel ['Ġmeel']\n",
      "koorts ['Ġkoorts']\n",
      "ravijn ['Ġravijn']\n",
      "denken ['Ġdenk', 'en']\n",
      "vlucht ['Ġvlucht']\n",
      "cd ['cd']\n",
      "tuin ['Ġtuin']\n",
      "houding ['Ġhouding']\n",
      "heilige ['Ġheilige']\n",
      "stoel ['Ġstoel']\n",
      "kolonel ['Ġkolonel']\n",
      "verklaren ['verkl', 'aren']\n",
      "nieuw ['Ġnieuw']\n",
      "mooi ['Ġmooi']\n",
      "onnodig ['Ġon', 'nodig']\n",
      "huishulp ['huis', 'hulp']\n",
      "broodje ['Ġbroodje']\n",
      "vertrekken ['ver', 'trekken']\n",
      "overtuigen ['over', 'tuigen']\n",
      "gerammel ['Ġge', 'rammel']\n",
      "krankzinnig ['k', 'rank', 'zinnig']\n",
      "vergelijken ['Ġver', 'gelijk', 'en']\n",
      "minuut ['Ġminuut']\n",
      "moeilijkheid ['Ġmoei', 'lijk', 'heid']\n",
      "maand ['Ġmaand']\n",
      "officier van justitie ['Ġofficier', 'Ġvan', 'Ġjustitie']\n",
      "schuur ['Ġschuur']\n",
      "boos ['Ġboos']\n",
      "werknemer ['werk', 'nemer']\n",
      "vos ['Ġvos']\n",
      "maken ['maken']\n",
      "aardappel ['aard', 'appel']\n",
      "akkoord gaan ['Ġakkoord', 'Ġg', 'aan']\n",
      "demon ['Ġdemon']\n",
      "waas ['Ġwaas']\n",
      "computer ['Ġcomputer']\n",
      "opbouwen ['Ġop', 'bouw', 'en']\n",
      "diner ['Ġdiner']\n",
      "suiker ['Ġsuiker']\n",
      "geweldig ['Ġgeweldig']\n",
      "vereniging ['Ġverenig', 'ing']\n",
      "huis ['Ġhuis']\n",
      "lens ['Ġlens']\n",
      "uitgebreid ['Ġuitgebreid']\n",
      "citroen ['Ġcitroen']\n",
      "duivel ['Ġduivel']\n",
      "argumenteren ['arg', 'ument', 'eren']\n",
      "weg ['Ġweg']\n",
      "fictie ['Ġfictie']\n",
      "vervuiling ['Ġver', 'vuil', 'ing']\n",
      "beslissen ['besl', 'issen']\n",
      "mond ['Ġmond']\n",
      "plaatsen ['Ġplaats', 'en']\n",
      "dollar ['Ġdollar']\n",
      "veiligheid ['Ġveilig', 'heid']\n",
      "motel ['Ġmotel']\n",
      "wieg ['Ġwieg']\n",
      "matroos ['Ġmatroos']\n",
      "gepast ['Ġgepast']\n",
      "wanhoop ['Ġwan', 'hoop']\n",
      "gesprek ['Ġgesprek']\n",
      "onrustig ['Ġon', 'rust', 'ig']\n",
      "kampioen ['Ġkampioen']\n",
      "gebied ['Ġgebied']\n",
      "ijs ['Ġijs']\n",
      "informeren ['inform', 'eren']\n",
      "zwerven ['z', 'wer', 'ven']\n",
      "geestelijke ['Ġgeestelijke']\n",
      "zeldzaam ['Ġzeldzaam']\n",
      "professor ['Ġprofessor']\n",
      "augustus ['Ġaugustus']\n",
      "constructie ['Ġconstructie']\n",
      "keuken ['Ġkeuken']\n",
      "vervangen ['ver', 'vangen']\n",
      "kandidaat ['kandid', 'aat']\n",
      "leuk ['Ġleuk']\n",
      "lezer ['lezer']\n",
      "staart ['Ġstaart']\n",
      "vermaken ['ver', 'maken']\n",
      "genieten ['genieten']\n",
      "snelweg ['Ġsnel', 'weg']\n",
      "woordenboek ['Ġwoord', 'en', 'boek']\n",
      "merrie ['Ġmerrie']\n",
      "producent ['producent']\n",
      "verdienen ['verdien', 'en']\n",
      "vinden ['Ġvind', 'en']\n",
      "weer ['Ġweer']\n",
      "champagne ['Ġchampagne']\n",
      "vallei ['vallei']\n",
      "houtskool ['Ġhout', 's', 'kool']\n",
      "ophangen ['Ġop', 'hang', 'en']\n",
      "muziekgroep ['muziek', 'groep']\n",
      "vreemd ['Ġvreemd']\n",
      "vat ['Ġvat']\n",
      "verifiëren ['ver', 'ifi', 'Ã', 'ĥ', 'Â«', 'ren']\n",
      "rat ['Ġrat']\n",
      "eigenaardig ['Ġeigen', 'aard', 'ig']\n",
      "echtgenote ['e', 'cht', 'genote']\n",
      "aardig ['Ġaardig']\n",
      "schaap ['Ġschaap']\n",
      "essentieel ['ess', 'ent', 'ieel']\n",
      "omvang ['Ġomvang']\n",
      "ziel ['Ġziel']\n",
      "houden ['Ġhoud', 'en']\n",
      "ademen ['Ġadem', 'en']\n",
      "hand ['Ġhand']\n",
      "sheriff ['Ġsheriff']\n",
      "idee ['Ġidee']\n",
      "bezitten ['be', 'zitten']\n",
      "knoop ['Ġknoop']\n",
      "modder ['Ġmodder']\n",
      "oever ['Ġoever']\n",
      "fiets ['Ġfiets']\n",
      "taxi ['Ġtaxi']\n",
      "dwaas ['Ġdwaas']\n",
      "beweging ['beweging']\n",
      "cursus ['Ġcursus']\n",
      "sprakeloos ['spra', 'kel', 'oos']\n",
      "boosheid ['Ġboos', 'heid']\n",
      "intelligentie ['Ġintelligent', 'ie']\n",
      "pijl ['Ġpijl']\n",
      "bad ['Ġbad']\n",
      "student ['student']\n",
      "ceremonie ['Ġceremonie']\n",
      "bedrijf ['Ġbedrijf']\n",
      "luchtvaart ['Ġlucht', 'vaart']\n",
      "honkbal ['Ġhonk', 'bal']\n",
      "monteur ['monteur']\n",
      "wereld ['Ġwereld']\n",
      "moeder ['Ġmoeder']\n",
      "god ['Ġgod']\n",
      "verschuldigd zijn ['Ġverschuldigd', 'Ġzijn']\n",
      "overvloed ['Ġover', 'vloed']\n",
      "inzicht ['Ġin', 'zicht']\n",
      "psalm ['Ġpsalm']\n",
      "vee ['Ġvee']\n",
      "handpalm ['Ġhand', 'palm']\n",
      "humeur ['Ġhumeur']\n",
      "storm ['Ġstorm']\n",
      "zwaar ['Ġzwaar']\n",
      "geld ['Ġgeld']\n",
      "beroep ['Ġberoep']\n",
      "cent ['Ġcent']\n",
      "schuim ['Ġschuim']\n",
      "makkelijk ['makkelijk']\n",
      "televisie ['Ġtelevisie']\n",
      "boomstam ['Ġboom', 'stam']\n",
      "tanden ['Ġtand', 'en']\n",
      "helium ['Ġhelium']\n",
      "mist ['Ġmist']\n",
      "stemming ['stemming']\n",
      "dag ['Ġdag']\n",
      "razendsnel ['Ġrazend', 'snel']\n",
      "armoede ['Ġarmoede']\n",
      "winnaar ['winnaar']\n",
      "plaatsvinden ['Ġplaats', 'vind', 'en']\n",
      "schade ['Ġschade']\n",
      "feest ['Ġfeest']\n",
      "linnen ['Ġlinnen']\n",
      "proberen ['pro', 'beren']\n",
      "eikenboom ['e', 'iken', 'boom']\n",
      "nerts ['Ġnerts']\n",
      "componist ['Ġcomponist']\n",
      "elegantie ['Ġelegant', 'ie']\n",
      "lepel ['Ġlepel']\n",
      "schuldig ['Ġschuld', 'ig']\n",
      "polyester ['Ġpoly', 'ester']\n",
      "koolstof ['Ġkool', 'stof']\n"
     ]
    }
   ],
   "source": [
    "for word in simlex_words:\n",
    "    print(word, own_50.tokenize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dingen opslaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('word_freqs_all.json', 'w') as f:\n",
    "    json.dump(word_freqs_all, f)\n",
    "\n",
    "with open('word_freqs_all_lower.json', 'w') as f:\n",
    "    json.dump(word_freqs_lower_all, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kladblok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689"
      ]
     },
     "execution_count": 1890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3803 + 10 + 11 + 13 + 32 + 30 + 25 - 2500 + 15 + 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def slow_function(n):\n",
    "    result = 0\n",
    "    for i in tqdm(range(n), desc=\"Processing\", unit=\" iterations\", leave=True):\n",
    "        time.sleep(0.1)  # Simulating a time-consuming task\n",
    "        result += i\n",
    "    return result\n",
    "\n",
    "\n",
    "def test_fun(x):\n",
    "    z = 0\n",
    "    v = 0\n",
    "    for c, i in enumerate(tqdm(range(x*999999), desc=f\"Executing function. Progress\", unit=\" iterations\", leave=True)):\n",
    "        z += i\n",
    "        v += c\n",
    "        if c == 0:\n",
    "            print('bijna')\n",
    "\n",
    "    return z, v\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing function. Progress:   8%|▊         | 751612/9999990 [00:00<00:02, 3833703.04 iterations/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bijna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing function. Progress: 100%|██████████| 9999990/9999990 [00:02<00:00, 4439866.14 iterations/s]\n"
     ]
    }
   ],
   "source": [
    "a, b = test_fun(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1807,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def number_generator():\n",
    "    for i in range(10000000):\n",
    "        yield i\n",
    "\n",
    "def fun(x):\n",
    "    s = 0\n",
    "    # Example usage with tqdm for progress bar\n",
    "    for number in tqdm(x, total=100000000, desc=\"Generating numbers\", unit=\" number\"):\n",
    "        s += number*number - number\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1808,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating numbers:  10%|█         | 10000000/100000000 [00:02<00:21, 4175792.71 number/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333333233333340000000"
      ]
     },
     "execution_count": 1808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = number_generator()\n",
    "fun(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 100/100 [00:10<00:00,  9.49 iterations/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 1714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_function(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing function. Progress: 100%|██████████| 99999900/99999900 [00:16<00:00, 5971319.45 iterations/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4999989950005050"
      ]
     },
     "execution_count": 1732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fun(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progressss: 100%|██████████| 99999900/99999900 [00:20<00:00, 4828428.92 iterations/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "989999010000"
      ]
     },
     "execution_count": 1726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fun(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {'cat': 'N', 'segments': ['be', 'houd']}\n",
    "\n",
    "'a' in b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 'N', 'segments': ['be', 'houd']}"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words['behoud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2283, 3586, 940, 6589, 2207, 8304, 1512, 5563, 363, 809, 2578]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode('dit is een test met ongberuikelijkbare woorden')\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10, 2: 20, 3: 40, 4: 50}"
      ]
     },
     "execution_count": 1389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {1: 10, 2: 20, 3: 30}\n",
    "y = {3: 40, 4: 50}\n",
    "\n",
    "x | y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 30, 4: 50, 1: 10, 2: 20}"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {1: 10, 2: 20, 3: 30}\n",
    "y = {3: 40, 4: 50}\n",
    "\n",
    "y | x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def ddd(a, b,\n",
    "                  c):\n",
    "    print(a)\n",
    "\n",
    "ddd(3, 4, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 entries in the database. Out of these:\n",
      "- 5 words have no segmentations\n",
      "        - 6 words have a single morpheme as segmentation \n",
      "        - 7 words are split up into multiple morphemes\n"
     ]
    }
   ],
   "source": [
    "print(f'''There are 3 entries in the database. Out of these:\n",
    "- 5 words have no segmentations\n",
    "        - 6 words have a single morpheme as segmentation \n",
    "        - 7 words are split up into multiple morphemes''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# this function adds the word as segmentation of itself for all words that have an empty list as segmentation\n",
    "def add_empty_segmentations(df):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for word, seg in df.items():\n",
    "        if len(seg) == 0:\n",
    "            out[word] = [word]\n",
    "        else:\n",
    "            out[word] = seg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['a'], 'b': ['r']}"
      ]
     },
     "execution_count": 1601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a': [], 'b': ['r']}\n",
    "\n",
    "b = add_empty_segmentations(a)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [], 'b': ['r'], 4: 5}"
      ]
     },
     "execution_count": 1596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a': [], 'b': ['r']}\n",
    "\n",
    "a[4] = 5\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6702288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(oscar1) as osc:\n",
    "    n = 0\n",
    "    for line in osc:\n",
    "        n+= 1\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6803845\n"
     ]
    }
   ],
   "source": [
    "oscar2 = os.path.join(data_path, 'OSCAR', 'nl_part_2.txt')\n",
    "\n",
    "\n",
    "\n",
    "with open(oscar2) as osc:\n",
    "    n = 0\n",
    "    for line in osc:\n",
    "        n+= 1\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1793,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_freqs_from_online_corpus(corpus_generator, sorted=False, progress=True, avg_size=6750000, n_files=45):\n",
    "\n",
    "    size = n_files * avg_size\n",
    "    \n",
    "    if progress:\n",
    "        print(f'The estimated size of the entire corpus is around {format_with_dots(size)} lines of text!')\n",
    "        \n",
    "        word_freqs = {}\n",
    "\n",
    "        for i in range(1):\n",
    "            if i == 0:\n",
    "                print(f'Generating the frequency dictionary ...\\n')\n",
    "\n",
    "        for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "            text = preprocess_basic(i['text'])\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    \n",
    "    return word_freqs\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this function creates a word frequency dictionary for a corpus, so that we can count faster later on\n",
    "def create_word_freqs_from_local_corpus(corpus_generator, sorted=False, progress=True, path=0):\n",
    "    \n",
    "    if progress:\n",
    "        print(f'Calculating the size of the dataset ...\\n')\n",
    "        if path == 0:\n",
    "            assert path == 1, 'Enter path to get progress bar, or set progress=False to perform the function without one'\n",
    "        else:\n",
    "            size = get_size_for_local(path)\n",
    "    \n",
    "        word_freqs = {}\n",
    "        \n",
    "\n",
    "        for i in range(1):\n",
    "            if i == 0:\n",
    "                print(f'Data size: {format_with_dots(size)} lines of text! Generating the frequency dictionary ...\\n')\n",
    "\n",
    "        for i in tqdm(corpus_generator, total=size, desc=\"Progress\", unit=\" iterations\"):     \n",
    "            text = preprocess_basic(i['text'])\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    \n",
    "    else:\n",
    "\n",
    "        print('Performing task without progress bar')\n",
    "\n",
    "        word_freqs = {}\n",
    "\n",
    "        for i in corpus_generator:     \n",
    "            text = preprocess_basic(i['text'])\n",
    "            for word in text:\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "        \n",
    "    \n",
    "    if sorted:\n",
    "        return dict(sorted(word_freqs.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "\n",
    "def get_size_for_local(path):\n",
    "    with open(path) as osc:\n",
    "        n = 0\n",
    "        for line in osc:\n",
    "            n+= 1\n",
    "        return n \n",
    "\n",
    "def format_with_dots(number):\n",
    "    return f\"{number:,}\".replace(\",\", \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1789,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_from_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wienfoiwef', 'weff', 'vervfe', 'verv', 'pp']"
      ]
     },
     "execution_count": 2164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = 'wienfoiwef weff vervfe verv PP'\n",
    "\n",
    "seq.strip().lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maak frequency dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stap 1: maak data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import os\n",
    "\n",
    "\n",
    "# function that returns a dictionary with a generator for every existing OSCAR file in this computer\n",
    "def create_local_oscar_generators(data_path, i=0, j=0):\n",
    "\n",
    "    out = {}\n",
    "    \n",
    "    if j > i:\n",
    "        n = j - i\n",
    "\n",
    "        for x in range(i, j+1):\n",
    "            full_path = os.path.join(data_path, 'OSCAR', f'nl_part_{x}.txt')\n",
    "            if os.path.isfile(full_path):\n",
    "                out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "        \n",
    "        if len(out) != n + 1:\n",
    "            print('Not all parts requested are on this computer')\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for i in range(1, 50):\n",
    "            full_path = os.path.join(data_path, 'OSCAR', f'nl_part_{i}.txt')\n",
    "            if os.path.isfile(full_path):\n",
    "                out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# function that creates one generator out of multiple generators\n",
    "def create_super_generator(generator_dict, list_input=False):\n",
    "\n",
    "    if list_input:\n",
    "        for generator in generator_dict:\n",
    "            yield from generator\n",
    "    else:\n",
    "        for generator in generator_dict.values():\n",
    "            yield from generator\n",
    "\n",
    "\n",
    "# one function to create OSCAR generator by combining n parts of the dataset, from part i to part j\n",
    "def create_super_local_oscar_generator(data_path, i=0, j=0):\n",
    "    \n",
    "    if j > i:\n",
    "        generators = create_local_oscar_generators(data_path, i=i, j=j)\n",
    "    else:\n",
    "        generators = create_local_oscar_generators(data_path)\n",
    "\n",
    "    return create_super_generator(generators)\n",
    "\n",
    "\n",
    "# function to create a dataset with text \n",
    "def create_test_set(dataset_generator, start, end):\n",
    "    it = iter(dataset_generator)\n",
    "    for _ in range(start):\n",
    "        next(it)\n",
    "    for _ in range(end - start + 1):\n",
    "        yield next(it)\n",
    "\n",
    "\n",
    "# function to turn a generator that returns a dictionary with 'text' as key into a generator of the values\n",
    "def create_text_generator(gen):\n",
    "    for i in gen:\n",
    "        yield i['text']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # set path to datasets\n",
    "# data_path = '/Users/jan/Documents/Master Information Studies/Thesis/Code/Datasets'\n",
    "\n",
    "# # create super generator from all OSCAR files on computer\n",
    "# oscar_gen_super = create_super_local_oscar_generator(data_path)\n",
    "\n",
    "# # create small dataset (uneven number of lines)\n",
    "# oscar_gen_small = create_test_set(oscar_gen_1, 0, 100007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "\n",
    "import os\n",
    "\n",
    "def get_all_file_paths(folder_path):\n",
    "    file_paths = []\n",
    "    for root, directories, files in os.walk(folder_path):\n",
    "        # Filter out directories that start with a dot\n",
    "        directories[:] = [d for d in directories if not d.startswith('.')]\n",
    "        for file in files:\n",
    "            # Filter out files that start with a dot\n",
    "            if not file.startswith('.'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                if os.path.isfile(file_path):  # Check if the path is a file\n",
    "                    file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "paths = get_all_file_paths(data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "p = '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt'\n",
    "d = load_dataset('text', data_files={\"train\": p}, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freqs_multiple_paths(paths):\n",
    "    word_freqs = {}\n",
    "    for path in paths:\n",
    "        dataset = load_dataset('text', data_files={\"train\": path}, split='train')\n",
    "        for i in dataset:\n",
    "            for word in preprocess_lower(i['text']):\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    return word_freqs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mword_freqs_multiple_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[120], line 8\u001b[0m, in \u001b[0;36mword_freqs_multiple_paths\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m preprocess_lower(i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_freqs:\n\u001b[0;32m----> 8\u001b[0m         word_freqs[word] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m         word_freqs[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_freqs_multiple_paths(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deze code is gebruikt in freqs1.job (freqs1.py)\n",
    "\n",
    "\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "path = '/home/scur2141/datasets'\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_lower(seq):\n",
    "    return [s.strip(string.punctuation) for s in seq.strip().lower().split()]\n",
    "\n",
    "\n",
    "def create_data_gen(path):\n",
    "\n",
    "    iterators = []\n",
    "\n",
    "    for i in range(1, 50):\n",
    "        full_path = os.path.join(path, f'nl_part_{i}.txt')\n",
    "        if os.path.isfile(full_path):\n",
    "            print('ja')\n",
    "            iterators.append(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "    \n",
    "    for it in iterators:\n",
    "        yield from it\n",
    "        \n",
    "    \n",
    "def create_word_freqs_from_corpus(corpus_generator, sort=False):\n",
    "    \n",
    "    word_freqs = {}\n",
    "\n",
    "    for i in corpus_generator:     \n",
    "        text = preprocess_lower(i['text'])\n",
    "        for word in text:\n",
    "            if word in word_freqs:\n",
    "                word_freqs[word] += 1\n",
    "            else:\n",
    "                word_freqs[word] = 1\n",
    "    \n",
    "    if sort:\n",
    "        word_freqs = dict(sorted(word_freqs.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "\n",
    "data_it = create_data_gen(path)\n",
    "freqs = create_word_freqs_from_corpus(data_it, sort=True)\n",
    "\n",
    "\n",
    "with open('frequencies.json', 'w') as f:\n",
    "    json.dump(freqs, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {3:4, 5: 6}\n",
    "\n",
    "with open('test_dict.json', 'w') as f:\n",
    "    json.dump(x_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2239,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_dict.json', 'r') as f:\n",
    "    my_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3': 4, '5': 6}"
      ]
     },
     "execution_count": 2240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import os\n",
    "\n",
    "\n",
    "# function that returns a dictionary with a generator for every existing OSCAR file in this computer\n",
    "def create_local_oscar_generators(path, i=0, j=0):\n",
    "\n",
    "    out = {}\n",
    "    \n",
    "    if j > i:\n",
    "        n = j - i\n",
    "\n",
    "        for x in range(i, j+1):\n",
    "            full_path = os.path.join(path, f'nl_part_{x}.txt')\n",
    "            if os.path.isfile(full_path):\n",
    "                out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "        \n",
    "        if len(out) != n + 1:\n",
    "            print('Not all parts requested are on this computer')\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for i in range(1, 50):\n",
    "            full_path = os.path.join(path, f'nl_part_{i}.txt')\n",
    "            print(full_path)\n",
    "            if os.path.isfile(full_path):\n",
    "                print('ja')\n",
    "                out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# function that creates one generator out of multiple generators\n",
    "def create_super_generator(generator_dict, list_input=False):\n",
    "\n",
    "    if list_input:\n",
    "        for generator in generator_dict:\n",
    "            yield from generator\n",
    "    else:\n",
    "        for generator in generator_dict.values():\n",
    "            yield from generator\n",
    "\n",
    "\n",
    "# one function to create OSCAR generator by combining n parts of the dataset, from part i to part j\n",
    "def create_super_local_oscar_generator(data_path, i=0, j=0):\n",
    "    \n",
    "    if j > i:\n",
    "        generators = create_local_oscar_generators(data_path, i=i, j=j)\n",
    "    else:\n",
    "        generators = create_local_oscar_generators(data_path)\n",
    "\n",
    "    return create_super_generator(generators)\n",
    "\n",
    "\n",
    "# function to create a dataset with text \n",
    "def create_test_set(dataset_generator, start, end):\n",
    "    it = iter(dataset_generator)\n",
    "    for _ in range(start):\n",
    "        next(it)\n",
    "    for _ in range(end - start + 1):\n",
    "        yield next(it)\n",
    "\n",
    "\n",
    "# function to turn a generator that returns a dictionary with 'text' as key into a generator of the values\n",
    "def create_text_generator(gen):\n",
    "    for i in gen:\n",
    "        yield i['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2242,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "\n",
    "x = create_super_generator(create_local_oscar_generators(path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2243,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(x):\n",
    "    if i < 6:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_2.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_3.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_4.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_5.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_6.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_7.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_8.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_9.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_10.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_11.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_12.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_13.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_14.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_15.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_16.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_17.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_18.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_19.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_20.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_21.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_22.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_23.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_24.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_25.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_26.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_27.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_28.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_29.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_30.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_31.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_32.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_33.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_34.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_35.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_36.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_37.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_38.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_39.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_40.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_41.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_42.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_43.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_44.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_45.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_46.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_47.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_48.txt\n",
      "Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_49.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "x = create_local_oscar_generators(path)\n",
    "\n",
    "os.path.isfile('Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 2254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2269,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "y = create_data_gen(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2270,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2270], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR'\n",
    "\n",
    "paths = []\n",
    "for x in range(25):\n",
    "    full_path = os.path.join(path, f'nl_part_{x}.txt')\n",
    "    if os.path.isfile(full_path):\n",
    "        paths.append(full_path)\n",
    "        # out[f'oscar{i}'] = create_text_generator(load_dataset('text', data_files={\"train\": full_path}, split='train', streaming=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt']\n",
      "freqs dict is gemaakt\n"
     ]
    }
   ],
   "source": [
    "# preprocess function\n",
    "def preprocess_lower(seq):\n",
    "    return [s.strip(string.punctuation) for s in seq.strip().lower().split()]\n",
    "\n",
    "# find paths\n",
    "def get_all_file_paths(folder_path):\n",
    "    file_paths = []\n",
    "    for root, directories, files in os.walk(folder_path):\n",
    "        # Filter out directories that start with a dot\n",
    "        directories[:] = [d for d in directories if not d.startswith('.')]\n",
    "        for file in files:\n",
    "            # Filter out files that start with a dot\n",
    "            if not file.startswith('.'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                if os.path.isfile(file_path):  # Check if the path is a file\n",
    "                    file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "paths = get_all_file_paths('/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short')\n",
    "\n",
    "print(paths)\n",
    "\n",
    "\n",
    "# make dict\n",
    "def word_freqs_multiple_paths(paths):\n",
    "    word_freqs = {}\n",
    "    for path in paths:\n",
    "        dataset = load_dataset('text', data_files={\"train\": path}, split='train')\n",
    "        for i in dataset:\n",
    "            for word in preprocess_lower(i['text']):\n",
    "                if word in word_freqs:\n",
    "                    word_freqs[word] += 1\n",
    "                else:\n",
    "                    word_freqs[word] = 1\n",
    "    return word_freqs\n",
    "\n",
    "word_freqs = word_freqs_multiple_paths(paths)\n",
    "\n",
    "\n",
    "print('freqs dict is gemaakt')\n",
    "\n",
    "\n",
    "# store\n",
    "with open('frequencies20.json', 'w') as f:\n",
    "    json.dump(word_freqs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('frequencies20.json', 'r') as f:\n",
    "    a = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vul': 377,\n",
       " 'het': 108245,\n",
       " 'e-mailadres': 542,\n",
       " 'in': 83947,\n",
       " 'dat': 35537,\n",
       " 'bij': 22024,\n",
       " 'uw': 11450,\n",
       " 'account': 606,\n",
       " 'hoort': 420,\n",
       " 'er': 19831,\n",
       " 'zal': 4341,\n",
       " 'een': 110514,\n",
       " 'verificatiecode': 10,\n",
       " 'naar': 16759,\n",
       " 'worden': 14045,\n",
       " 'verzonden': 252,\n",
       " 'wanneer': 2625,\n",
       " 'u': 23911,\n",
       " 'de': 219750,\n",
       " 'heeft': 12072,\n",
       " 'ontvangen': 1031,\n",
       " 'kunt': 6300,\n",
       " 'nieuw': 1513,\n",
       " 'wachtwoord': 355,\n",
       " 'kiezen': 1121,\n",
       " 'voor': 50721,\n",
       " 'gebruikersnaam': 104,\n",
       " 'dit': 15729,\n",
       " 'wijkagent': 9,\n",
       " 'michel': 52,\n",
       " 'van': 129018,\n",
       " 'kempen': 33,\n",
       " 'micheal': 1,\n",
       " 'is': 56843,\n",
       " 'nijmegen': 221,\n",
       " 'centrum': 937,\n",
       " 'geworden': 632,\n",
       " 'zijn': 34003,\n",
       " 'vorige': 542,\n",
       " 'wijken': 88,\n",
       " 'voorlopig': 129,\n",
       " 'onderverdeeld': 28,\n",
       " 'koen': 40,\n",
       " 'en': 126294,\n",
       " 'yvonne': 25,\n",
       " 'zodra': 456,\n",
       " 'nieuwe': 5391,\n",
       " 'zullen': 1714,\n",
       " 'wij': 9959,\n",
       " 'hier': 5854,\n",
       " 'kenbaar': 58,\n",
       " 'maken': 6738,\n",
       " 'wensen': 521,\n",
       " 'heel': 3699,\n",
       " 'veel': 6445,\n",
       " 'succes': 478,\n",
       " 'plezier': 518,\n",
       " 'wijk': 263,\n",
       " 'om': 29232,\n",
       " 'best': 1063,\n",
       " 'mogelijke': 457,\n",
       " 'website': 7120,\n",
       " 'toegang': 580,\n",
       " 'te': 53814,\n",
       " 'bieden': 1567,\n",
       " 'maakt': 2976,\n",
       " 'deze': 22814,\n",
       " 'site': 2424,\n",
       " 'gebruik': 5820,\n",
       " 'cookies': 6437,\n",
       " 'delete': 8,\n",
       " 'alles': 2713,\n",
       " 'begint': 766,\n",
       " 'goede': 2414,\n",
       " 'communicatie': 368,\n",
       " 'altijd': 3536,\n",
       " 'al': 8382,\n",
       " 'zo': 8230,\n",
       " 'geweest': 903,\n",
       " 'helaas': 702,\n",
       " 'wordt': 11763,\n",
       " 'rondom': 303,\n",
       " 'beveiliging': 191,\n",
       " 'vaak': 1961,\n",
       " 'niet': 25338,\n",
       " 'goed': 5979,\n",
       " 'gecommuniceerd': 11,\n",
       " 'leidt': 236,\n",
       " 'tot': 11418,\n",
       " 'frustraties': 12,\n",
       " 'onwil': 5,\n",
       " 'communicatieplan': 3,\n",
       " 'gereed': 40,\n",
       " 'dan': 17250,\n",
       " 'kunnen': 9313,\n",
       " 'we': 15232,\n",
       " 'starten': 287,\n",
       " 'met': 51676,\n",
       " 'bewustwording': 29,\n",
       " 'of': 25590,\n",
       " 'awareness': 8,\n",
       " 'middels': 167,\n",
       " 'gerichte': 88,\n",
       " 'uitingen': 30,\n",
       " 'aes': 5,\n",
       " 'verschillende': 2905,\n",
       " 'sectoren': 65,\n",
       " 'relatief': 167,\n",
       " 'portfolio': 56,\n",
       " 'maar': 16759,\n",
       " 'spectaculaire': 72,\n",
       " 'resultaten': 519,\n",
       " 'naast': 1370,\n",
       " 'bewustwordingscampagnes': 1,\n",
       " 'voeren': 447,\n",
       " 'ook': 22106,\n",
       " 'regelmatig': 684,\n",
       " 'mystery': 12,\n",
       " 'visits': 1,\n",
       " 'op': 58230,\n",
       " 'allerlei': 500,\n",
       " 'alle': 6831,\n",
       " 'organisaties': 388,\n",
       " 'kennen': 470,\n",
       " 'incidenten': 43,\n",
       " 'slechts': 1008,\n",
       " 'weinigen': 14,\n",
       " 'beheersen': 57,\n",
       " 'kunst': 551,\n",
       " 'leren': 861,\n",
       " 'ongewenste': 52,\n",
       " 'gebeurtenissen': 164,\n",
       " 'onze': 11785,\n",
       " 'applicatie': 139,\n",
       " 'bent': 2604,\n",
       " 'staat': 4148,\n",
       " 'die': 27837,\n",
       " 'periodiek': 38,\n",
       " 'informeren': 235,\n",
       " 'management': 309,\n",
       " 'over': 13160,\n",
       " 'imago': 85,\n",
       " 'afdeling': 348,\n",
       " 'professionele': 441,\n",
       " 'managementinformatie': 4,\n",
       " 'kan': 11881,\n",
       " 'men': 1227,\n",
       " 'gestructureerd': 15,\n",
       " 'kaart': 569,\n",
       " 'brengen': 1062,\n",
       " \"risico's\": 39,\n",
       " 'levert': 408,\n",
       " 'als': 22613,\n",
       " 'voordeel': 392,\n",
       " 'maatregelen': 293,\n",
       " 'synergie': 7,\n",
       " 'ontstaat': 273,\n",
       " 'veilige': 226,\n",
       " 'omgeving': 966,\n",
       " 'kostenefficiënt': 5,\n",
       " 'beveiliginsdiensten': 1,\n",
       " 'gekenmerkt': 53,\n",
       " 'door': 18490,\n",
       " 'medewerkers': 799,\n",
       " 'passief': 22,\n",
       " 'reageren': 303,\n",
       " 'gewonnen': 167,\n",
       " 'meer': 12213,\n",
       " 'kwalitatief': 111,\n",
       " 'hoogstaand': 12,\n",
       " 'uniform': 23,\n",
       " 'werken': 2414,\n",
       " 'noodzakelijk': 366,\n",
       " 'up-to-date': 55,\n",
       " 'handboek': 66,\n",
       " 'instructies': 218,\n",
       " 'werkprocessen': 14,\n",
       " 'hebben': 9889,\n",
       " 'zeker': 1999,\n",
       " 'schade': 443,\n",
       " 'beperkt': 336,\n",
       " 'grootschalig': 18,\n",
       " 'incident': 31,\n",
       " 'belang': 699,\n",
       " 'iedereen': 1650,\n",
       " 'weet': 1655,\n",
       " 'wat': 11279,\n",
       " 'hij': 8710,\n",
       " 'moet': 5219,\n",
       " 'doen': 3868,\n",
       " 'stressvolle': 10,\n",
       " 'situatie': 480,\n",
       " 'garanderen': 161,\n",
       " 'berekenen': 78,\n",
       " 'sluitplan': 2,\n",
       " 'complexe': 95,\n",
       " 'organisatie': 942,\n",
       " 'eenvoudig': 959,\n",
       " 'sleutels': 55,\n",
       " 'nadelen': 51,\n",
       " 'simpel': 168,\n",
       " 'richten': 199,\n",
       " 'standaardisatie': 1,\n",
       " 'beheer': 328,\n",
       " 'onderhoud': 500,\n",
       " 'moeten': 2349,\n",
       " 'voorzieningen': 181,\n",
       " 'afgestemd': 107,\n",
       " 'aanwezig': 620,\n",
       " \"camera's\": 26,\n",
       " 'echter': 1338,\n",
       " 'aangekocht': 15,\n",
       " 'zonder': 2967,\n",
       " 'nagedacht': 43,\n",
       " 'haalbare': 16,\n",
       " 'camera-strategie': 1,\n",
       " 'instellingen': 529,\n",
       " 'visie': 254,\n",
       " 'documenten': 230,\n",
       " 'toegangspassen': 1,\n",
       " 'bestaan': 627,\n",
       " 'technologieën': 74,\n",
       " 'belangrijk': 1154,\n",
       " 'juiste': 1394,\n",
       " 'selecteren': 219,\n",
       " 'helder': 220,\n",
       " 'welke': 2229,\n",
       " 'toepassingen': 127,\n",
       " 'aan': 26227,\n",
       " 'pas': 824,\n",
       " 'verbonden': 310,\n",
       " 'toegangsbeheer': 3,\n",
       " 'toegangsbeheerssystemen': 1,\n",
       " 'elk': 1111,\n",
       " 'hun': 5761,\n",
       " 'afhankelijk': 510,\n",
       " 'gewenste': 288,\n",
       " 'functies': 387,\n",
       " 'autorisatiestructuur': 1,\n",
       " 'past': 628,\n",
       " 'ene': 424,\n",
       " 'systeem': 710,\n",
       " 'beter': 1617,\n",
       " 'andere': 6544,\n",
       " 'verwarren': 12,\n",
       " 'security': 90,\n",
       " 'meldkamermanagement': 1,\n",
       " 'zorgt': 1098,\n",
       " 'ervoor': 1066,\n",
       " 'aanweizge': 1,\n",
       " 'beveiligingssystemen': 4,\n",
       " 'slimmer': 26,\n",
       " 'eenvoudiger': 88,\n",
       " 'gebruikt': 2774,\n",
       " 'uitermate': 118,\n",
       " 'gat': 73,\n",
       " 'vegetatie': 8,\n",
       " 'zit': 1533,\n",
       " 'ze': 12158,\n",
       " 'zitten': 1233,\n",
       " 'graag': 2271,\n",
       " 'langer': 667,\n",
       " 'gras': 106,\n",
       " 'waar': 5391,\n",
       " 'vooral': 1618,\n",
       " 'regenwormen': 2,\n",
       " 'emelten': 1,\n",
       " 'zoeken': 833,\n",
       " 'eten': 886,\n",
       " 'watersnip': 4,\n",
       " 'bedreigt': 7,\n",
       " 'vliegt': 73,\n",
       " 'laatste': 1864,\n",
       " 'moment': 1421,\n",
       " 'vliegen': 177,\n",
       " 'zigzaggend': 1,\n",
       " 'snel': 2578,\n",
       " 'omhoog': 213,\n",
       " 'trekvogels': 6,\n",
       " 'november': 1548,\n",
       " 'via': 4335,\n",
       " 'frankrijk': 577,\n",
       " 'spanje': 287,\n",
       " 'eerst': 1544,\n",
       " 'marokko': 76,\n",
       " 'daar': 3466,\n",
       " 'rusten': 65,\n",
       " 'voordat': 536,\n",
       " 'sahara': 21,\n",
       " 'oversteken': 39,\n",
       " 'wel': 7713,\n",
       " 'langs': 1048,\n",
       " 'kust': 208,\n",
       " 'gaan': 5213,\n",
       " 'italië': 340,\n",
       " 'afrika': 118,\n",
       " 'momenteel': 424,\n",
       " 'nog': 10680,\n",
       " 'ongeveer': 811,\n",
       " '46.000': 1,\n",
       " 'gruttoparen': 1,\n",
       " 'nederland': 3004,\n",
       " 'komen': 3158,\n",
       " 'broeden': 28,\n",
       " 'staan': 2400,\n",
       " 'ter': 1463,\n",
       " 'bescherming': 316,\n",
       " 'rode': 413,\n",
       " 'lijst': 640,\n",
       " 'scholeksters': 3,\n",
       " 'vind': 2225,\n",
       " 'je': 50769,\n",
       " 'weidegebieden': 2,\n",
       " 'mosselen': 18,\n",
       " 'kokkels': 1,\n",
       " 'kreeftachtigen': 1,\n",
       " 'voornamelijk': 266,\n",
       " 'wormen': 9,\n",
       " 'insecten(larven': 1,\n",
       " 'tegenwoordig': 374,\n",
       " 'maïslanden': 1,\n",
       " 'voorbeelden': 251,\n",
       " 'bekend': 1034,\n",
       " 'platte': 74,\n",
       " 'daken': 50,\n",
       " 'huizen': 188,\n",
       " 'wachtend': 5,\n",
       " 'mannetje': 49,\n",
       " 'sloot': 97,\n",
       " 'wijst': 129,\n",
       " 'broedend': 1,\n",
       " 'vrouwtje': 45,\n",
       " 'waarschuwt': 19,\n",
       " 'haar': 6969,\n",
       " 'raspend-ratelend': 1,\n",
       " 'geluid': 317,\n",
       " 'zoek': 1882,\n",
       " 'geen': 7794,\n",
       " 'nest': 50,\n",
       " 'vast': 884,\n",
       " 'broedt': 5,\n",
       " 'want': 2094,\n",
       " 'gestoord': 16,\n",
       " 'laat': 2344,\n",
       " 'steek': 107,\n",
       " 'aparte': 177,\n",
       " 'baltsvlucht': 1,\n",
       " 'waarbij': 1206,\n",
       " 'gespreide': 5,\n",
       " 'staartveren': 2,\n",
       " 'duikvlucht': 4,\n",
       " 'recht': 1182,\n",
       " 'beneden': 237,\n",
       " 'omdat': 2580,\n",
       " 'trillen': 8,\n",
       " 'veroorzaakt': 162,\n",
       " 'blatende': 1,\n",
       " 'geit': 6,\n",
       " 'slobeenden': 2,\n",
       " 'liefst': 479,\n",
       " 'tussen': 3196,\n",
       " 'dichte': 23,\n",
       " 'begroeiing': 9,\n",
       " 'oevers': 12,\n",
       " 'kleine': 1708,\n",
       " 'holte': 3,\n",
       " 'bekleed': 31,\n",
       " 'roestbruin': 3,\n",
       " 'dons': 12,\n",
       " 'donkerbruine': 9,\n",
       " 'veertjes': 11,\n",
       " 'leggen': 497,\n",
       " 'april': 1039,\n",
       " 'juni': 1152,\n",
       " '6': 1732,\n",
       " '10': 1942,\n",
       " 'vaalgele': 1,\n",
       " 'eieren': 100,\n",
       " 'soms': 1144,\n",
       " '14': 792,\n",
       " 'na': 5673,\n",
       " '23': 395,\n",
       " '26': 340,\n",
       " 'dagen': 1914,\n",
       " 'uit': 13353,\n",
       " 'rondvliegend': 2,\n",
       " 'alarmerend': 1,\n",
       " 'wakend': 2,\n",
       " 'duidt': 23,\n",
       " 'ga': 2109,\n",
       " 'slobeend': 4,\n",
       " 'verstoord': 27,\n",
       " 'verlaten': 168,\n",
       " 'tweede': 1222,\n",
       " 'keer': 1982,\n",
       " 'bevuild': 2,\n",
       " 'uitwerpselen': 8,\n",
       " 'ongeer': 1,\n",
       " '8000': 9,\n",
       " '9000': 12,\n",
       " 'paren': 27,\n",
       " 'vochtige': 31,\n",
       " 'weilanden': 16,\n",
       " 'plassen': 53,\n",
       " 'meren': 30,\n",
       " 'rivierarmen': 1,\n",
       " 'sloten': 59,\n",
       " 'klein': 935,\n",
       " 'aantal': 2418,\n",
       " 'blijft': 1256,\n",
       " 'meesten': 56,\n",
       " 'trekken': 392,\n",
       " 'winter': 343,\n",
       " 'zuiden': 143,\n",
       " 'west': 165,\n",
       " 'europa': 529,\n",
       " 'middelandse': 1,\n",
       " 'zee': 466,\n",
       " '44': 117,\n",
       " '52': 83,\n",
       " 'cm': 1013,\n",
       " 'lang': 1370,\n",
       " 'gemakkelijk': 772,\n",
       " 'herkennen': 152,\n",
       " 'brede': 277,\n",
       " 'lepelvormige': 1,\n",
       " 'snavel': 5,\n",
       " 'daarin': 340,\n",
       " 'reeks': 210,\n",
       " 'filters': 119,\n",
       " 'waarmee': 719,\n",
       " 'oppervlakte': 86,\n",
       " 'water': 1141,\n",
       " 'drijvende': 36,\n",
       " 'voedsel': 188,\n",
       " 'kroos': 1,\n",
       " 'zaadjes': 17,\n",
       " 'waterdiertjes': 1,\n",
       " 'zeven': 227,\n",
       " 'opvallend': 208,\n",
       " 'gekleurd': 54,\n",
       " 'kop': 225,\n",
       " 'glanzend': 31,\n",
       " 'groen': 496,\n",
       " 'borst': 52,\n",
       " 'wit': 475,\n",
       " 'flanken': 4,\n",
       " 'onderkant': 87,\n",
       " 'kastanjebruin': 3,\n",
       " 'onopvallend': 16,\n",
       " 'bruin': 110,\n",
       " 'achter': 1185,\n",
       " 'zomer': 453,\n",
       " 'gaat': 4685,\n",
       " 'rui': 8,\n",
       " 'lijkt': 1076,\n",
       " 'even': 2201,\n",
       " 'sterk': 518,\n",
       " 'zomertaling': 1,\n",
       " 'soort': 828,\n",
       " 'eend': 10,\n",
       " 'eind': 542,\n",
       " 'legt': 212,\n",
       " 'bruinachtig-witte': 1,\n",
       " 'verstopt': 67,\n",
       " 'ondiep': 7,\n",
       " 'kuiltje': 3,\n",
       " 'vochtig': 30,\n",
       " 'grasland': 8,\n",
       " 'dichtbegroeide': 3,\n",
       " 'oever': 32,\n",
       " 'gevoerd': 128,\n",
       " 'donkerbruin': 20,\n",
       " 'witgespikkeld': 1,\n",
       " 'witte': 474,\n",
       " 'toppen': 13,\n",
       " 'erin': 181,\n",
       " 'o.a': 475,\n",
       " 'muggen': 11,\n",
       " 'larven': 5,\n",
       " 'waterslakken': 1,\n",
       " 'kevers': 4,\n",
       " 'bijvoorbeeld': 2060,\n",
       " 'eetbare': 21,\n",
       " 'delen': 1100,\n",
       " 'waterlelie': 2,\n",
       " 'profiteert': 45,\n",
       " 'kievit': 3,\n",
       " 'geeft': 1847,\n",
       " 'tegen': 3156,\n",
       " 'predatoren': 1,\n",
       " 'dieren': 365,\n",
       " 'eieren/kuikens': 1,\n",
       " \"zo'n\": 458,\n",
       " '25': 826,\n",
       " '27': 416,\n",
       " '3': 3715,\n",
       " '4': 2727,\n",
       " 'sporen': 85,\n",
       " '39': 74,\n",
       " 'rond': 1425,\n",
       " '100.000': 37,\n",
       " 'broedparen': 3,\n",
       " 'gedeeltelijk': 110,\n",
       " 'blijven': 1423,\n",
       " 'doortrekken': 9,\n",
       " 'verborgen': 109,\n",
       " 'fijn': 425,\n",
       " 'plantenmateriaal': 1,\n",
       " 'grashalmen': 1,\n",
       " 'gebogen': 43,\n",
       " 'zodat': 1884,\n",
       " 'tentje': 17,\n",
       " 'ligt': 1362,\n",
       " 'veldleeuwerik': 3,\n",
       " 'opvallende': 114,\n",
       " 'kleuren': 877,\n",
       " 'grijsbruin': 1,\n",
       " 'gevlekt': 2,\n",
       " 'makkelijk': 655,\n",
       " 'luide': 7,\n",
       " 'heldere': 115,\n",
       " 'jubelende': 3,\n",
       " 'zang': 43,\n",
       " 'manier': 1801,\n",
       " 'zingend': 7,\n",
       " 'grote': 3542,\n",
       " 'hoogte': 1083,\n",
       " 'cirkelen': 4,\n",
       " 'weer': 4907,\n",
       " 'sluit': 343,\n",
       " 'meters': 49,\n",
       " 'vleugels': 31,\n",
       " 'vallend': 4,\n",
       " 'komt': 2868,\n",
       " 'tijdens': 2896,\n",
       " 'geregeld': 227,\n",
       " 'zie': 1484,\n",
       " 'mooi': 1525,\n",
       " 'achterrand': 1,\n",
       " 'streep': 42,\n",
       " 'boven': 908,\n",
       " 'oog': 440,\n",
       " 'doorloopt': 17,\n",
       " 'nek': 94,\n",
       " 'verder': 3266,\n",
       " 'donkere': 131,\n",
       " 'tekening': 58,\n",
       " 'bruin(gevlekt': 1,\n",
       " 'strepen': 35,\n",
       " 'hoofd': 564,\n",
       " 'lichtbruine': 6,\n",
       " 'wenkbrauwstreep': 1,\n",
       " 'daaronder': 90,\n",
       " 'oogstreep': 2,\n",
       " 'lichte': 308,\n",
       " 'kuikens': 5,\n",
       " 'ondersnavel': 1,\n",
       " 'loopt': 512,\n",
       " 'let': 544,\n",
       " 'dus': 4876,\n",
       " 'voerende': 2,\n",
       " 'ouderparen': 3,\n",
       " 'slordige': 6,\n",
       " 'ondiepe': 11,\n",
       " 'kom': 1101,\n",
       " 'open': 1311,\n",
       " 'gebieden': 177,\n",
       " 'bouwland': 2,\n",
       " 'heidevelden': 3,\n",
       " 'kwelders': 1,\n",
       " 'duinen': 68,\n",
       " 'vroeger': 313,\n",
       " 'was': 8948,\n",
       " 'meest': 1414,\n",
       " 'algemeen': 910,\n",
       " 'voorkomende': 147,\n",
       " 'broedvogels': 2,\n",
       " 'ons': 8191,\n",
       " 'land': 1124,\n",
       " 'jaren': 1810,\n",
       " 'neemt': 794,\n",
       " 'af': 2782,\n",
       " '50.000': 53,\n",
       " 'maart': 1101,\n",
       " 'twee': 3204,\n",
       " 'drie': 1462,\n",
       " 'per': 3562,\n",
       " 'jaar': 7469,\n",
       " '12-14': 3,\n",
       " 'duurt': 245,\n",
       " 'jongen': 249,\n",
       " '10-14': 2,\n",
       " 'vertrekken': 124,\n",
       " 'meeste': 881,\n",
       " 'veldleeuweriken': 1,\n",
       " 'engeland': 157,\n",
       " 'rest': 415,\n",
       " 'overwinterd': 1,\n",
       " \"grutto's\": 3,\n",
       " 'één': 2630,\n",
       " 'vanaf': 2439,\n",
       " 'meestal': 681,\n",
       " 'waarop': 813,\n",
       " '24': 717,\n",
       " 'rietland': 1,\n",
       " 'pol': 21,\n",
       " 'begroeing': 2,\n",
       " 'vlak': 419,\n",
       " 'droge': 123,\n",
       " 'grassprietjes': 2,\n",
       " 'bladeren': 78,\n",
       " 'broed': 2,\n",
       " 'juli': 1008,\n",
       " '19': 485,\n",
       " '21': 510,\n",
       " 'hele': 1691,\n",
       " 'tegenkomen': 55,\n",
       " 'kans': 854,\n",
       " 'heb': 5451,\n",
       " 'trek': 141,\n",
       " 'name': 388,\n",
       " 'najaarstrek': 1,\n",
       " 'overwinteren': 8,\n",
       " 'zuid-engeland': 1,\n",
       " 'zuidwest-europa': 1,\n",
       " 'heten': 59,\n",
       " 'deltasafe': 3,\n",
       " 'groep': 1148,\n",
       " 'harte': 196,\n",
       " 'welkom': 707,\n",
       " 'sponsor': 36,\n",
       " 'akc': 1,\n",
       " 'blauw-wit': 2,\n",
       " 'hopen': 199,\n",
       " 'duurzame': 409,\n",
       " 'samenwerking': 678,\n",
       " 'biedt': 1384,\n",
       " 'veiligheid': 534,\n",
       " 'bestaat': 1092,\n",
       " 'ruime': 370,\n",
       " 'ervaring': 1284,\n",
       " 'expertise': 126,\n",
       " 'facetten': 27,\n",
       " 'zowel': 1468,\n",
       " 'bedrijven': 1076,\n",
       " 'particulieren': 156,\n",
       " 'nu': 5754,\n",
       " 'beveiligings': 3,\n",
       " 'opleidings': 5,\n",
       " 'brand': 236,\n",
       " 'recherchewerkzaamheden': 3,\n",
       " 'adviseurs': 69,\n",
       " 'oplossing': 652,\n",
       " 'eerste': 3640,\n",
       " 'toespraak': 40,\n",
       " 'paus': 27,\n",
       " 'johannes': 59,\n",
       " 'paulus': 33,\n",
       " 'i': 753,\n",
       " 'balkon': 114,\n",
       " 'st.-pietersbasiliek': 1,\n",
       " 'augustus': 921,\n",
       " '1978': 59,\n",
       " 'lightsheer': 1,\n",
       " 'duet': 6,\n",
       " 'gouden': 212,\n",
       " 'standaard': 691,\n",
       " 'gebied': 1240,\n",
       " 'aangaande': 64,\n",
       " 'laser': 44,\n",
       " 'ontharen': 12,\n",
       " 'soprano': 1,\n",
       " 'accord': 2,\n",
       " 'bezit': 333,\n",
       " 'bijkomend': 31,\n",
       " 'getinte': 23,\n",
       " 'huidtype': 8,\n",
       " '': 28764,\n",
       " 'zongebruinde': 1,\n",
       " 'huid': 495,\n",
       " 'eerder': 761,\n",
       " 'effectiever': 29,\n",
       " 'mogen': 819,\n",
       " 'veven.regelrecht': 1,\n",
       " 'flits': 9,\n",
       " 'voelt': 364,\n",
       " 'niks': 475,\n",
       " 'verdere': 220,\n",
       " 'behandeling': 514,\n",
       " 'schaamstreek': 1,\n",
       " 'mag': 1796,\n",
       " 'hetgeen': 152,\n",
       " 'pijn': 254,\n",
       " 'geraken': 45,\n",
       " 'meemaken': 58,\n",
       " 'dorien.nl': 1,\n",
       " 'anti-ageing': 1,\n",
       " 'center': 120,\n",
       " 'beschikt': 360,\n",
       " 'anbos': 1,\n",
       " 'keurmerk': 103,\n",
       " 'wegens': 224,\n",
       " 'professionaliteit': 31,\n",
       " 'kwaliteit': 1439,\n",
       " 'vakkennis': 16,\n",
       " 'permanente': 207,\n",
       " 'ontharing': 2,\n",
       " 'hoogstaande': 21,\n",
       " 'apparatuur': 173,\n",
       " 'beschermt': 84,\n",
       " 'pigmentvlekken': 5,\n",
       " 'mogelijkheid': 617,\n",
       " 'bijwerkingen': 40,\n",
       " 'nihil': 6,\n",
       " 'specialisten': 142,\n",
       " 'iedere': 894,\n",
       " 'zorg': 1198,\n",
       " 'professionalit': 1,\n",
       " 'permanent': 49,\n",
       " 'nauwelijks': 212,\n",
       " 'last': 428,\n",
       " 'hebt': 2519,\n",
       " 'huidirritaties': 2,\n",
       " 'harsen': 12,\n",
       " 'ofwel': 179,\n",
       " 'scheren': 46,\n",
       " 'ingegroeide': 6,\n",
       " 'haartjes': 26,\n",
       " 'geïrriteerde': 14,\n",
       " 'stoppels': 2,\n",
       " 'pijnlijk': 43,\n",
       " 'lelijk': 28,\n",
       " 'laserontharing': 1,\n",
       " 'wegnemen': 21,\n",
       " 'denkt': 343,\n",
       " 'weleens': 66,\n",
       " 'feit': 440,\n",
       " 'nimmer': 41,\n",
       " 'hoeft': 672,\n",
       " 'e': 488,\n",
       " 'indien': 1501,\n",
       " 'kiest': 366,\n",
       " 'indicaties': 8,\n",
       " 'huidkliniek': 1,\n",
       " 'vliet': 13,\n",
       " 'ingeval': 45,\n",
       " 'verzekerd': 172,\n",
       " 'raakt': 148,\n",
       " 'vergoeding': 190,\n",
       " 'zorgverzekeraar': 55,\n",
       " 'bezoek': 1045,\n",
       " 'plaats': 2272,\n",
       " 'opties.indien': 1,\n",
       " 'hars': 22,\n",
       " 'afgekoeld': 5,\n",
       " 'zich': 5867,\n",
       " 'smeren': 39,\n",
       " 'bijzonder': 571,\n",
       " 'moeilijk': 442,\n",
       " 'ongemak': 41,\n",
       " 'wilt': 2392,\n",
       " 'vervolgens': 876,\n",
       " 'betreffende': 494,\n",
       " 'elos': 11,\n",
       " 'werkwijze': 93,\n",
       " 'echt': 2276,\n",
       " 'ervaart': 54,\n",
       " 'voordelen': 322,\n",
       " 'gladde': 49,\n",
       " 'hete': 204,\n",
       " 'waxen': 7,\n",
       " 'harsen.om': 1,\n",
       " 'reactie': 546,\n",
       " 'plaatsen': 1852,\n",
       " 'vragen': 2177,\n",
       " 'jouw': 3080,\n",
       " 'loggen': 154,\n",
       " 'registreren': 230,\n",
       " 'klik': 1484,\n",
       " 'verstuur': 25,\n",
       " 'k': 181,\n",
       " 'tracklist': 1,\n",
       " '01': 87,\n",
       " 'stallion': 1,\n",
       " '02': 51,\n",
       " 'make': 46,\n",
       " 'a': 1578,\n",
       " 'wish': 12,\n",
       " '03': 30,\n",
       " 'shameless': 2,\n",
       " 'shadow': 8,\n",
       " 'koningin': 76,\n",
       " 'elisabethwedstrijd': 1,\n",
       " 'internationale': 425,\n",
       " 'muziekwedstrijd': 1,\n",
       " 'belgi235': 3,\n",
       " 'opgericht': 269,\n",
       " '1937': 7,\n",
       " 'elisabeth': 29,\n",
       " 'heette': 34,\n",
       " 'wedstrijd': 393,\n",
       " 'eug232;ne': 2,\n",
       " 'ysa255;ewestrijd': 1,\n",
       " 'eerbetoon': 20,\n",
       " '1931': 11,\n",
       " 'overleden': 134,\n",
       " 'ysa255;e': 1,\n",
       " 'hoofdstuk': 305,\n",
       " '1': 5704,\n",
       " 'rivers': 5,\n",
       " 'casino': 224,\n",
       " 'nightclub': 1,\n",
       " 'krijgt': 1580,\n",
       " 'melkveehouder': 6,\n",
       " 'perrier': 1,\n",
       " 'lapadite': 1,\n",
       " 'onverwachts': 13,\n",
       " 'nno': 1,\n",
       " 'hans': 181,\n",
       " 'landa': 1,\n",
       " 'ss-standartenf252;hrer': 1,\n",
       " 'verdenking': 14,\n",
       " 'verbergen': 88,\n",
       " '…': 717,\n",
       " 'avoid': 1,\n",
       " 'coded': 1,\n",
       " 'cosmetics': 3,\n",
       " 'crush': 7,\n",
       " 'with': 466,\n",
       " 'this': 452,\n",
       " 'deluxe': 21,\n",
       " 'wood': 10,\n",
       " 'makeup': 4,\n",
       " 'box': 107,\n",
       " 'built-in': 1,\n",
       " 'mirror': 10,\n",
       " 'bezoeken': 448,\n",
       " 'akkoord': 1411,\n",
       " 'cookie': 928,\n",
       " 'beleid': 420,\n",
       " 'volg': 243,\n",
       " 'twitter': 356,\n",
       " 'copyright': 237,\n",
       " '©': 248,\n",
       " '2013': 1068,\n",
       " '2015': 1369,\n",
       " 'betekenis-voornaam.nl': 18,\n",
       " 'sitemap': 50,\n",
       " 'disclaimer': 122,\n",
       " 'script': 44,\n",
       " 'webmasters': 24,\n",
       " 'partners': 544,\n",
       " 'contact': 2152,\n",
       " 'gehele': 310,\n",
       " 'voorwerp': 39,\n",
       " 'plak': 55,\n",
       " 'html': 42,\n",
       " 'pagina': 1121,\n",
       " 'koppelen': 128,\n",
       " 'koppelingin': 2,\n",
       " 'email': 380,\n",
       " 'im': 25,\n",
       " 'document': 189,\n",
       " 'wil': 4238,\n",
       " 'design': 574,\n",
       " 'responsive': 27,\n",
       " 'refereert': 12,\n",
       " 'dikwijls': 45,\n",
       " '3e': 97,\n",
       " 'party': 76,\n",
       " 'code': 391,\n",
       " 'zoals': 4203,\n",
       " 'facebook': 643,\n",
       " 'plug-ins': 19,\n",
       " 'nogal': 218,\n",
       " 'lastig': 242,\n",
       " 'externe': 288,\n",
       " 'stu': 8,\n",
       " 'doordat': 485,\n",
       " 'steeds': 2574,\n",
       " 'projecten': 376,\n",
       " 'mijn': 7633,\n",
       " 'pad': 170,\n",
       " 'kwamen': 405,\n",
       " 'schrijven': 561,\n",
       " 'blog': 827,\n",
       " 'geleidelijk': 84,\n",
       " 'verminderd': 50,\n",
       " 'ik': 24082,\n",
       " 'ben': 4166,\n",
       " 'bijna': 1113,\n",
       " '2': 4753,\n",
       " 'geleden': 1112,\n",
       " 'boek': 1208,\n",
       " 'uitgekomen': 31,\n",
       " 'waarin': 1326,\n",
       " 'yggdrasil': 5,\n",
       " 'volgen': 785,\n",
       " 'doeken': 21,\n",
       " 'gedaan': 879,\n",
       " 'hand': 1171,\n",
       " 'verhaal': 858,\n",
       " 'koffers': 123,\n",
       " 'leg': 199,\n",
       " 'stappen': 374,\n",
       " 'zetten': 1025,\n",
       " 'succesvolle': 155,\n",
       " 'natuurlijke': 440,\n",
       " 'moestuin': 21,\n",
       " 'respons': 10,\n",
       " 'groot': 1677,\n",
       " 'verkoop': 392,\n",
       " 'sindsdien': 93,\n",
       " 'mensen': 3661,\n",
       " 'bijkomende': 87,\n",
       " 'combineren': 299,\n",
       " 'beschikbare': 194,\n",
       " 'uitgebreide': 346,\n",
       " 'uitleg': 305,\n",
       " 'vernieuwende': 39,\n",
       " 'simpele': 122,\n",
       " 'stond': 608,\n",
       " 'inleiding': 446,\n",
       " '🙂': 58,\n",
       " '2012': 867,\n",
       " 'begonnen': 344,\n",
       " 'periode': 646,\n",
       " 'ouders': 860,\n",
       " 'bedrijf': 1433,\n",
       " 'gestapt': 11,\n",
       " 'had': 3043,\n",
       " 'toen': 1750,\n",
       " 'duidelijk': 896,\n",
       " 'beeld': 803,\n",
       " 'toe': 2126,\n",
       " 'wou': 109,\n",
       " 'project': 757,\n",
       " 'wist': 430,\n",
       " 'iets': 2649,\n",
       " 'doe': 936,\n",
       " 'mee': 3598,\n",
       " 'bereiken': 413,\n",
       " 'beroeren': 2,\n",
       " 'waanzinnig': 13,\n",
       " 'geschreven': 366,\n",
       " 'nieuwsbrief': 681,\n",
       " 'papieren': 90,\n",
       " 'online': 2456,\n",
       " 'tijdschriften': 81,\n",
       " 'zou': 3203,\n",
       " 'natuurlijk': 1945,\n",
       " 'tuinieren': 17,\n",
       " 'helemaal': 1499,\n",
       " 'klaar': 1017,\n",
       " 'oorspronkelijk': 104,\n",
       " 'mulchen': 5,\n",
       " 'gedachten': 191,\n",
       " 'opvolger': 85,\n",
       " 'hierover': 233,\n",
       " 'krijg': 638,\n",
       " 'onderwerp': 580,\n",
       " 'informatie': 4216,\n",
       " 'vinden': 2600,\n",
       " 'vindt': 1677,\n",
       " 'tegenstrijdig': 8,\n",
       " 'onvolledig': 27,\n",
       " 'aandacht': 839,\n",
       " 'viel': 232,\n",
       " 'afgelopen': 1044,\n",
       " 'niets': 1115,\n",
       " 'vergelijking': 143,\n",
       " 'interesse': 291,\n",
       " 'filed': 1,\n",
       " 'under': 9,\n",
       " 'permacultuur': 6,\n",
       " 'tagged': 9,\n",
       " 'schijnbare': 14,\n",
       " 'chaos': 31,\n",
       " 'beslissing': 161,\n",
       " 'koelkast': 170,\n",
       " 'steken': 164,\n",
       " 'uitgebreid': 474,\n",
       " 'lichten': 55,\n",
       " 'valt': 636,\n",
       " 'vertellen': 396,\n",
       " 'roept': 103,\n",
       " 'direct': 1664,\n",
       " '‘schijnbare': 1,\n",
       " 'chaos’': 1,\n",
       " 'uitlegt': 12,\n",
       " 'vraagt': 389,\n",
       " 'denken': 810,\n",
       " 'kijken': 1269,\n",
       " 'tuin': 658,\n",
       " 'evident': 14,\n",
       " 'achtergrond': 227,\n",
       " 'duiding': 7,\n",
       " 'stap': 560,\n",
       " 'sneller': 344,\n",
       " ...}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt',\n",
       " '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_2.txt',\n",
       " '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_file_paths('/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_all_file_paths('/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_1.txt',\n",
       " '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/nl_part_2.txt',\n",
       " '/Users/jan/Documents/Master/Thesis/Code/Datasets/OSCAR/Short/OSCAR_short.txt']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bewaren voor de zekerheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_morpheme_set(treshold):\n",
    "    morpheme_set = set([])\n",
    "    for word, freq in word_freqs.items():\n",
    "        if freq >= treshold:\n",
    "            for morpheme in segmentations_lowercase[word]:\n",
    "                morpheme_set.add(morpheme)\n",
    "    return len(morpheme_set)\n",
    "\n",
    "results = {}\n",
    "for i in range(30):\n",
    "    results[i] = count_morpheme_set(i)\n",
    "\n",
    "# plot\n",
    "keys = list(results.keys())\n",
    "values = list(results.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(keys, values, marker='o', linestyle='-', color='b')\n",
    "plt.title('Morphemes vs Treshold')\n",
    "plt.xlabel('Treshold')\n",
    "plt.ylabel('Number of morphemes')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vocabulary size\n",
    "vocab_size = 20000\n",
    "\n",
    "# select dataset to train with\n",
    "train_set = bpe_generator(data, vocab, tokenizer)\n",
    "\n",
    "# load an existing BPE tokenizer\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# retrain the tokenizer\n",
    "tokenizer = old_tokenizer.train_new_from_iterator(train_set, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_robbert = RobertaTokenizerFast.from_pretrained(\"DTAI-KULeuven/robbert-2022-dutch-base\")\n",
    "\n",
    "t_robbert = AutoTokenizer.from_pretrained(\"DTAI-KULeuven/robbert-2022-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 204, 544, 2149, 733, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_robbert('Ik ga morgen lopen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 204, 544, 2149, 733, 4, 1903, 544, 29, 87, 733, 4, 13932, 88, 29, 9, 1083, 2203, 4, 112, 12, 9, 12960, 1049, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_robbert('Ik ga morgen lopen. Daarna ga ik weer lopen. Gisteren heb ik een fiets gekocht. Dit is een input tekst.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = t_robbert.get_vocab()\n",
    "g = {value: key for key, value in v.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ĠGisteren'"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[13932]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Met ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dik = create_segmentation_dictionary(segmentation_data, word_family_data, word_freqs_20, extra_loop=True, add_morphemes=True, \n",
    "                                   add_empty=False, add_plurals=True, replace_non_identical=False, add_verbs=True, greedy_verb=False,\n",
    "                                   add_nouns=True, greedy_noun=False, replace_verbs=True, replace_nouns=False, min_n_segments=1, \n",
    "                                   add_compounds=True, replace_compounds=False, remove_ortho=True, remove_not_in_corpus=False, meta_data=False, print_info=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = create_initial_dataframe(segmentation_data)\n",
    "\n",
    "\n",
    "# create initial segmentation dictionary\n",
    "dik = create_segmentations_from_base(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dik2 = {}\n",
    "for word, segs in dik.items():\n",
    "    if len(segs) > 0 and ''.join(segs) != word:\n",
    "        dik2[word] = segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aaien': ['aai'],\n",
       " 'aalbessengelei': ['aal', 'bes', 'en', 'gelei'],\n",
       " 'aalbessenjam': ['aal', 'bes', 'en', 'jam'],\n",
       " 'aalbessenjenever': ['aal', 'bes', 'en', 'jenever'],\n",
       " 'aalbessesap': ['aal', 'bes', 'e', 'sap'],\n",
       " 'aalbessestruik': ['aal', 'bes', 'e', 'struik'],\n",
       " 'aalmoezenier': ['aalmoes', 'enier'],\n",
       " 'aalsteker': ['aal', 'steek', 'er', 'NV'],\n",
       " 'aambeeldsbeentje': ['aambeeld', 's', 'been'],\n",
       " 'aanaarden': ['aan', 'aarde'],\n",
       " 'aanbakken': ['aan', 'bak'],\n",
       " 'aanbeeldsbeentje': ['aanbeeld', 's', 'been'],\n",
       " 'aanbenen': ['aan', 'been'],\n",
       " 'aanbehoren': ['aan', 'be', 'hoor'],\n",
       " 'aanbellen': ['aan', 'bel'],\n",
       " 'aanbelanden': ['aan', 'be', 'land'],\n",
       " 'aanbelangen': ['aan', 'belang'],\n",
       " 'aanbermen': ['aan', 'berm'],\n",
       " 'aanbesteder': ['aan', 'besteed', 'er'],\n",
       " 'aanbesteding': ['aan', 'besteed', 'ing'],\n",
       " 'aanbesteden': ['aan', 'besteed'],\n",
       " 'aanbesterven': ['aan', 'be', 'sterf'],\n",
       " 'aanbeteren': ['aan', 'beter'],\n",
       " 'aanbevelen': ['aan', 'beveel'],\n",
       " 'aanbevelenswaard': ['aan', 'beveel', 's', 'waard'],\n",
       " 'aanbevelenswaardig': ['aan', 'beveel', 's', 'waarde', 'ig'],\n",
       " 'aanbeveling': ['aan', 'beveel', 'ing'],\n",
       " 'aanbidden': ['aan', 'bid'],\n",
       " 'aanbiddelijk': ['aan', 'bid', 'elijk'],\n",
       " 'aanbiddenswaardig': ['aan', 'bid', 's', 'waarde', 'ig'],\n",
       " 'aanbidder': ['aan', 'bid', 'er'],\n",
       " 'aanbidding': ['aan', 'bid', 'ing'],\n",
       " 'aanbieden': ['aan', 'bied'],\n",
       " 'aanbijten': ['aan', 'bijt'],\n",
       " 'aanbikken': ['aan', 'bik'],\n",
       " 'aanbinden': ['aan', 'bind'],\n",
       " 'aanblazen': ['aan', 'blaas'],\n",
       " 'aanblaffen': ['aan', 'blaf'],\n",
       " 'aanblazing': ['aan', 'blaas', 'ing'],\n",
       " 'aanblijven': ['aan', 'blijf'],\n",
       " 'aanblikken': ['aan', 'blik'],\n",
       " 'aanboeken': ['aan', 'boek'],\n",
       " 'aanbonzen': ['aan', 'bons'],\n",
       " 'aanboren': ['aan', 'boor'],\n",
       " 'aanbotsen': ['aan', 'bots'],\n",
       " 'aanbouwen': ['aan', 'bouw'],\n",
       " 'aanbraden': ['aan', 'braad'],\n",
       " 'aanbranden': ['aan', 'brand'],\n",
       " 'aanbrassen': ['aan', 'bras'],\n",
       " 'aanbreken': ['aan', 'breek'],\n",
       " 'aanbreien': ['aan', 'brei'],\n",
       " 'aanbrengen': ['aan', 'breng'],\n",
       " 'aanbriesen': ['aan', 'bries'],\n",
       " 'aanbruisen': ['aan', 'bruis'],\n",
       " 'aanbrullen': ['aan', 'brul'],\n",
       " 'aanbulderen': ['aan', 'bulder'],\n",
       " 'aandachttrekkerij': ['aandacht', 'trek', 'erij', 'NV'],\n",
       " 'aandammen': ['aan', 'dam'],\n",
       " 'aandamming': ['aan', 'dam', 'ing'],\n",
       " 'aandeelhebber': ['aan', 'deel', 'heb', 'er', 'NV'],\n",
       " 'aandelenkapitaal': ['aan', 'deel', 'en', 'kapitaal'],\n",
       " 'aandelenoptie': ['aan', 'deel', 'en', 'optie'],\n",
       " 'aandelenpakket': ['aan', 'deel', 'en', 'pakket'],\n",
       " 'aandelenportefeuille': ['aan', 'deel', 'en', 'portefeuille'],\n",
       " 'aandienen': ['aan', 'dien'],\n",
       " 'aandiepen': ['aan', 'diep'],\n",
       " 'aandijken': ['aan', 'dijk'],\n",
       " 'aandikken': ['aan', 'dik'],\n",
       " 'aandoen': ['aan', 'doe'],\n",
       " 'aandoening': ['aan', 'doe', 'ing'],\n",
       " 'aandoenlijk': ['aan', 'doe', 'lijk'],\n",
       " 'aandragen': ['aan', 'draag'],\n",
       " 'aandraaien': ['aan', 'draai'],\n",
       " 'aandraven': ['aan', 'draaf'],\n",
       " 'aandrager': ['aan', 'draag', 'er'],\n",
       " 'aandrentelen': ['aan', 'drentel'],\n",
       " 'aandrijven': ['aan', 'drijf'],\n",
       " 'aandrijver': ['aan', 'drijf', 'er'],\n",
       " 'aandrijving': ['aan', 'drijf', 'ing'],\n",
       " 'aandringen': ['aan', 'dring'],\n",
       " 'aandruisen': ['aan', 'druis'],\n",
       " 'aandrukken': ['aan', 'druk'],\n",
       " 'aanduiden': ['aan', 'duid'],\n",
       " 'aandurven': ['aan', 'durf'],\n",
       " 'aanduwen': ['aan', 'duw'],\n",
       " 'aandweilen': ['aan', 'dweil'],\n",
       " 'aaneenbinden': ['aaneen', 'B', 'bind'],\n",
       " 'aaneenbrengen': ['aaneen', 'B', 'breng'],\n",
       " 'aaneendriegen': ['aaneen', 'B', 'drieg'],\n",
       " 'aaneenflansen': ['aaneen', 'B', 'flans'],\n",
       " 'aaneengrenzen': ['aaneen', 'B', 'grens'],\n",
       " 'aaneengroeien': ['aaneen', 'B', 'groei'],\n",
       " 'aaneenhaken': ['aaneen', 'B', 'haak'],\n",
       " 'aaneenhangen': ['aaneen', 'B', 'hang'],\n",
       " 'aaneenhechten': ['aaneen', 'B', 'hecht'],\n",
       " 'aaneenhouden': ['aaneen', 'B', 'houd'],\n",
       " 'aaneenketenen': ['aaneen', 'B', 'keten'],\n",
       " 'aaneenkleven': ['aaneen', 'B', 'kleef'],\n",
       " 'aaneenklinken': ['aaneen', 'B', 'klink'],\n",
       " 'aaneenkluisteren': ['aaneen', 'B', 'kluister'],\n",
       " 'aaneenknopen': ['aaneen', 'B', 'knoop'],\n",
       " 'aaneenkoeken': ['aaneen', 'B', 'koek'],\n",
       " 'aaneenkoppelen': ['aaneen', 'B', 'koppel'],\n",
       " 'aaneenlijmen': ['aaneen', 'B', 'lijm'],\n",
       " 'aaneennaaien': ['aaneen', 'B', 'naai'],\n",
       " 'aaneenpassen': ['aaneen', 'B', 'pas'],\n",
       " 'aaneenplakken': ['aaneen', 'B', 'plak'],\n",
       " 'aaneenrijgen': ['aaneen', 'B', 'rijg'],\n",
       " 'aaneenschakelen': ['aaneen', 'B', 'schakel'],\n",
       " 'aaneenschrijven': ['aaneen', 'B', 'schrijf'],\n",
       " 'aaneensluiten': ['aaneen', 'B', 'sluit'],\n",
       " 'aaneensmeden': ['aaneen', 'B', 'smeed'],\n",
       " 'aaneenspijkeren': ['aaneen', 'B', 'spijker'],\n",
       " 'aaneenvoegen': ['aaneen', 'B', 'voeg'],\n",
       " 'aaneenzetten': ['aaneen', 'B', 'zet'],\n",
       " 'aaneenzitten': ['aaneen', 'B', 'zit'],\n",
       " 'aanerven': ['aan', 'erf'],\n",
       " 'aanfietsen': ['aan', 'fiets'],\n",
       " 'aanflitsen': ['aan', 'flits'],\n",
       " 'aanfloepen': ['aan', 'floep'],\n",
       " 'aanfluiten': ['aan', 'fluit'],\n",
       " 'aanfokken': ['aan', 'fok'],\n",
       " 'aanfokking': ['aan', 'fok', 'ing'],\n",
       " 'aanfruiten': ['aan', 'fruit'],\n",
       " 'aangaan': ['aan', 'ga'],\n",
       " 'aangapen': ['aan', 'gaap'],\n",
       " 'aangeven': ['aan', 'geef'],\n",
       " 'aangespen': ['aan', 'gesp'],\n",
       " 'aangever': ['aan', 'geef', 'er'],\n",
       " 'aangeving': ['aan', 'geef', 'ing'],\n",
       " 'aangieren': ['aan', 'gier'],\n",
       " 'aangieten': ['aan', 'giet'],\n",
       " 'aanglimmen': ['aan', 'glim'],\n",
       " 'aangloeien': ['aan', 'gloei'],\n",
       " 'aangluren': ['aan', 'gluur'],\n",
       " 'aangolven': ['aan', 'golf'],\n",
       " 'aangorden': ['aan', 'gord'],\n",
       " 'aangraven': ['aan', 'graaf'],\n",
       " 'aangrauwen': ['aan', 'grauw'],\n",
       " 'aangraving': ['aan', 'graaf', 'ing'],\n",
       " 'aangrijnzen': ['aan', 'grijns'],\n",
       " 'aangrijpen': ['aan', 'grijp'],\n",
       " 'aangrimmen': ['aan', 'grim'],\n",
       " 'aangrinniken': ['aan', 'grinnik'],\n",
       " 'aangroeien': ['aan', 'groei'],\n",
       " 'aangrommen': ['aan', 'grom'],\n",
       " 'aanhaken': ['aan', 'haak'],\n",
       " 'aanhalen': ['aan', 'haal'],\n",
       " 'aanhalerig': ['aan', 'haal', 'erig'],\n",
       " 'aanhalig': ['aan', 'haal', 'ig'],\n",
       " 'aanhaling': ['aan', 'haal', 'ing'],\n",
       " 'aanhangen': ['aan', 'hang'],\n",
       " 'aanhankelijk': ['aan', 'hang', 'elijk'],\n",
       " 'aanharden': ['aan', 'hard'],\n",
       " 'aanharken': ['aan', 'hark'],\n",
       " 'aanhebben': ['aan', 'heb'],\n",
       " 'aanhechten': ['aan', 'hecht'],\n",
       " 'aanheffen': ['aan', 'hef'],\n",
       " 'aanheffer': ['aan', 'hef', 'er'],\n",
       " 'aanheffing': ['aan', 'hef', 'ing'],\n",
       " 'aanhikken': ['aan', 'hik'],\n",
       " 'aanhinken': ['aan', 'hink'],\n",
       " 'aanhitsen': ['aan', 'hits'],\n",
       " 'aanhobbelen': ['aan', 'hobbel'],\n",
       " 'aanhollen': ['aan', 'hol'],\n",
       " 'aanhopen': ['aan', 'hoop'],\n",
       " 'aanhoren': ['aan', 'hoor'],\n",
       " 'aanhoping': ['aan', 'hoop', 'ing'],\n",
       " 'aanhouden': ['aan', 'houd'],\n",
       " 'aanhuppelen': ['aan', 'huppel'],\n",
       " 'aanhuwen': ['aan', 'huw'],\n",
       " 'aanjagen': ['aan', 'jaag'],\n",
       " 'aanjager': ['aan', 'jaag', 'er'],\n",
       " 'aankaarten': ['aan', 'kaart'],\n",
       " 'aankakken': ['aan', 'kak'],\n",
       " 'aankalken': ['aan', 'kalk'],\n",
       " 'aankunnen': ['aan', 'kan'],\n",
       " 'aankanten': ['aan', 'kant'],\n",
       " 'aankappen': ['aan', 'kap'],\n",
       " 'aankeffen': ['aan', 'kef'],\n",
       " 'aankerven': ['aan', 'kerf'],\n",
       " 'aankijken': ['aan', 'kijk'],\n",
       " 'aanklagen': ['aan', 'klaag'],\n",
       " 'aanklager': ['aan', 'klaag', 'er'],\n",
       " 'aanklampen': ['aan', 'klamp'],\n",
       " 'aankleding': ['aan', 'kleed', 'ing'],\n",
       " 'aankleden': ['aan', 'kleed'],\n",
       " 'aankleven': ['aan', 'kleef'],\n",
       " 'aanklemmen': ['aan', 'klem'],\n",
       " 'aankleving': ['aan', 'kleef', 'ing'],\n",
       " 'aanklinken': ['aan', 'klink'],\n",
       " 'aankloppen': ['aan', 'klop'],\n",
       " 'aanklossen': ['aan', 'klos'],\n",
       " 'aanklotsen': ['aan', 'klots'],\n",
       " 'aanknippen': ['aan', 'knip'],\n",
       " 'aanknoeien': ['aan', 'knoei'],\n",
       " 'aanknopen': ['aan', 'knoop'],\n",
       " 'aanknoping': ['aan', 'knoop', 'ing'],\n",
       " 'aankoeken': ['aan', 'koek'],\n",
       " 'aankomen': ['aan', 'kom'],\n",
       " 'aankondigen': ['aan', 'kond', 'ig'],\n",
       " 'aankooien': ['aan', 'kooi'],\n",
       " 'aankopen': ['aan', 'koop'],\n",
       " 'aankoppelen': ['aan', 'koppel'],\n",
       " 'aankorsten': ['aan', 'korst'],\n",
       " 'aankrammen': ['aan', 'kram'],\n",
       " 'aankrijgen': ['aan', 'krijg'],\n",
       " 'aankruien': ['aan', 'krui'],\n",
       " 'aankruisen': ['aan', 'kruis'],\n",
       " 'aankweken': ['aan', 'kweek'],\n",
       " 'aankweking': ['aan', 'kweek', 'ing'],\n",
       " 'aanladen': ['aan', 'laad'],\n",
       " 'aanlachen': ['aan', 'lach'],\n",
       " 'aanlanden': ['aan', 'land'],\n",
       " 'aanlangen': ['aan', 'lang'],\n",
       " 'aanlappen': ['aan', 'lap'],\n",
       " 'aanlassen': ['aan', 'las'],\n",
       " 'aanlassing': ['aan', 'las', 'ing'],\n",
       " 'aanleren': ['aan', 'leer'],\n",
       " 'aanleggen': ['aan', 'leg'],\n",
       " 'aanlegger': ['aan', 'leg', 'er'],\n",
       " 'aanlegging': ['aan', 'leg', 'ing'],\n",
       " 'aanlengen': ['aan', 'leng'],\n",
       " 'aanleunen': ['aan', 'leun'],\n",
       " 'aanlichten': ['aan', 'licht'],\n",
       " 'aanliggen': ['aan', 'lig'],\n",
       " 'aanlijken': ['aan', 'lijk'],\n",
       " 'aanlijmen': ['aan', 'lijm'],\n",
       " 'aanlijnen': ['aan', 'lijn'],\n",
       " 'aanloeien': ['aan', 'loei'],\n",
       " 'aanloeren': ['aan', 'loer'],\n",
       " 'aanloeven': ['aan', 'loef'],\n",
       " 'aanlokken': ['aan', 'lok'],\n",
       " 'aanlokkelijk': ['aan', 'lok', 'elijk'],\n",
       " 'aanlokking': ['aan', 'lok', 'ing'],\n",
       " 'aanlonken': ['aan', 'lonk'],\n",
       " 'aanloden': ['aan', 'lood'],\n",
       " 'aanlopen': ['aan', 'loop'],\n",
       " 'aanloopkosten': ['aan', 'loop', 'kost'],\n",
       " 'aanlooptransformator': ['aan', 'loop', 'transformeer', 'ator', 'NV'],\n",
       " 'aanmaken': ['aan', 'maak'],\n",
       " 'aanmaakblokje': ['aan', 'maak', 'blok'],\n",
       " 'aanmaakkosten': ['aan', 'maak', 'kost'],\n",
       " 'aanmanen': ['aan', 'maan'],\n",
       " 'aanmaning': ['aan', 'maan', 'ing'],\n",
       " 'aanmarcheren': ['aan', 'marcheer'],\n",
       " 'aanmatigen': ['aan', 'matig'],\n",
       " 'aanmeren': ['aan', 'meer'],\n",
       " 'aanmeten': ['aan', 'meet'],\n",
       " 'aanmelden': ['aan', 'meld'],\n",
       " 'aanmengen': ['aan', 'meng'],\n",
       " 'aanmerken': ['aan', 'merk'],\n",
       " 'aanminnig': ['aan', 'min', 'ig'],\n",
       " 'aanmodderen': ['aan', 'modder'],\n",
       " 'aanmoedigen': ['aan', 'moed', 'ig', 'PN'],\n",
       " 'aanmonsteren': ['aan', 'monster'],\n",
       " 'aanmunten': ['aan', 'munt'],\n",
       " 'aannaaien': ['aan', 'naai'],\n",
       " 'aannagelen': ['aan', 'nagel'],\n",
       " 'aannemen': ['aan', 'neem'],\n",
       " 'aannemelijk': ['aan', 'neem', 'elijk'],\n",
       " 'aannemeling': ['aan', 'neem', 'eling'],\n",
       " 'aannemer': ['aan', 'neem', 'er'],\n",
       " 'aanneming': ['aan', 'neem', 'ing'],\n",
       " 'aanpakken': ['aan', 'pak'],\n",
       " 'aanpappen': ['aan', 'pap'],\n",
       " 'aanpassen': ['aan', 'pas'],\n",
       " 'aanpassing': ['aan', 'pas', 'ing'],\n",
       " 'aanpassingsmoeilijkheden': ['aan',\n",
       "  'pas',\n",
       "  'ing',\n",
       "  's',\n",
       "  'moei',\n",
       "  'lijk',\n",
       "  'heid'],\n",
       " 'aanpezen': ['aan', 'pees'],\n",
       " 'aanpersen': ['aan', 'pers'],\n",
       " 'aanpikken': ['aan', 'pik'],\n",
       " 'aanplakken': ['aan', 'plak'],\n",
       " 'aanplakker': ['aan', 'plak', 'er'],\n",
       " 'aanplakking': ['aan', 'plak', 'ing'],\n",
       " 'aanplanten': ['aan', 'plant'],\n",
       " 'aanplempen': ['aan', 'plemp'],\n",
       " 'aanploegen': ['aan', 'ploeg'],\n",
       " 'aanpoten': ['aan', 'poot'],\n",
       " 'aanporren': ['aan', 'por'],\n",
       " 'aanpoting': ['aan', 'poot', 'ing'],\n",
       " 'aanpraten': ['aan', 'praat'],\n",
       " 'aanpreken': ['aan', 'preek'],\n",
       " 'aanprijzen': ['aan', 'prijs'],\n",
       " 'aanprijzer': ['aan', 'prijs', 'er'],\n",
       " 'aanprijzing': ['aan', 'prijs', 'ing'],\n",
       " 'aanprikken': ['aan', 'prik'],\n",
       " 'aanprikkelen': ['aan', 'prikkel'],\n",
       " 'aanpunten': ['aan', 'punt'],\n",
       " 'aanraden': ['aan', 'raad'],\n",
       " 'aanraken': ['aan', 'raak'],\n",
       " 'aanrazen': ['aan', 'raas'],\n",
       " 'aanrader': ['aan', 'raad', 'er'],\n",
       " 'aanraking': ['aan', 'raak', 'ing'],\n",
       " 'aanrechten': ['aan', 'recht'],\n",
       " 'aanrechtkastje': ['aanrecht', 'kast'],\n",
       " 'aanreiken': ['aan', 'reik'],\n",
       " 'aanrekenen': ['aan', 'reken'],\n",
       " 'aanrennen': ['aan', 'ren'],\n",
       " 'aanrichten': ['aan', 'richt'],\n",
       " 'aanrijden': ['aan', 'rijd'],\n",
       " 'aanrijgen': ['aan', 'rijg'],\n",
       " 'aanrijpen': ['aan', 'rijp'],\n",
       " 'aanrissen': ['aan', 'ris'],\n",
       " 'aanristen': ['aan', 'rist'],\n",
       " 'aanroeien': ['aan', 'roei'],\n",
       " 'aanroepen': ['aan', 'roep'],\n",
       " 'aanroeren': ['aan', 'roer'],\n",
       " 'aanroesten': ['aan', 'roest'],\n",
       " 'aanrollen': ['aan', 'rol'],\n",
       " 'aanrommelen': ['aan', 'rommel'],\n",
       " 'aanroken': ['aan', 'rook'],\n",
       " 'aanruisen': ['aan', 'ruis'],\n",
       " 'aanrukken': ['aan', 'ruk'],\n",
       " 'aanschaffen': ['aan', 'schaf'],\n",
       " 'aanschaffing': ['aan', 'schaf', 'ing'],\n",
       " 'aanschakelen': ['aan', 'schakel'],\n",
       " 'aanscharrelen': ['aan', 'scharrel'],\n",
       " 'aanschellen': ['aan', 'schel'],\n",
       " 'aanscherpen': ['aan', 'scherp'],\n",
       " 'aanschieten': ['aan', 'schiet'],\n",
       " 'aanschikken': ['aan', 'schik'],\n",
       " 'aanschoffelen': ['aan', 'schoffel'],\n",
       " 'aanschoppen': ['aan', 'schop'],\n",
       " 'aanschouwen': ['aan', 'schouw'],\n",
       " 'aanschrappen': ['aan', 'schrap'],\n",
       " 'aanschrijden': ['aan', 'schrijd'],\n",
       " 'aanschrijven': ['aan', 'schrijf'],\n",
       " 'aanschrijving': ['aan', 'schrijf', 'ing'],\n",
       " 'aanschroeven': ['aan', 'schroef'],\n",
       " 'aanschuinen': ['aan', 'schuin'],\n",
       " 'aanschuiven': ['aan', 'schuif'],\n",
       " 'aansjokken': ['aan', 'sjok'],\n",
       " 'aansjorren': ['aan', 'sjor'],\n",
       " 'aansjorring': ['aan', 'sjor', 'ing'],\n",
       " 'aansjouwen': ['aan', 'sjouw'],\n",
       " 'aanslaan': ['aan', 'sla'],\n",
       " 'aanslepen': ['aan', 'sleep'],\n",
       " 'aanslenteren': ['aan', 'slenter'],\n",
       " 'aansleuren': ['aan', 'sleur'],\n",
       " 'aanslibben': ['aan', 'slib'],\n",
       " 'aanslibbing': ['aan', 'slib', 'ing'],\n",
       " 'aanslijken': ['aan', 'slijk'],\n",
       " 'aanslijmen': ['aan', 'slijm'],\n",
       " 'aanslijpen': ['aan', 'slijp'],\n",
       " 'aansloffen': ['aan', 'slof'],\n",
       " 'aansluipen': ['aan', 'sluip'],\n",
       " 'aansluiten': ['aan', 'sluit'],\n",
       " 'aansluitingskosten': ['aan', 'sluit', 'ing', 's', 'kost'],\n",
       " 'aansmeden': ['aan', 'smeed'],\n",
       " 'aansmeren': ['aan', 'smeer'],\n",
       " 'aansmering': ['aan', 'smeer', 'ing'],\n",
       " 'aansmijten': ['aan', 'smijt'],\n",
       " 'aansnauwen': ['aan', 'snauw'],\n",
       " 'aansnellen': ['aan', 'snel'],\n",
       " 'aansnijden': ['aan', 'snijd'],\n",
       " 'aansnoeren': ['aan', 'snoer'],\n",
       " 'aansnorren': ['aan', 'snor'],\n",
       " 'aanspannen': ['aan', 'span'],\n",
       " 'aanspanner': ['aan', 'span', 'er'],\n",
       " 'aanspanning': ['aan', 'span', 'ing'],\n",
       " 'aanspelen': ['aan', 'speel'],\n",
       " 'aanspeten': ['aan', 'speet'],\n",
       " 'aanspelden': ['aan', 'speld'],\n",
       " 'aanspijkeren': ['aan', 'spijker'],\n",
       " 'aanspinnen': ['aan', 'spin'],\n",
       " 'aanspoeden': ['aan', 'spoed'],\n",
       " 'aanspoelen': ['aan', 'spoel'],\n",
       " 'aansporen': ['aan', 'spoor'],\n",
       " 'aansporing': ['aan', 'spoor', 'ing'],\n",
       " 'aansprakelijk': ['aan', 'spreek', 'elijk'],\n",
       " 'aanspreken': ['aan', 'spreek'],\n",
       " 'aanspreker': ['aan', 'spreek', 'er'],\n",
       " 'aanspreking': ['aan', 'spreek', 'ing'],\n",
       " 'aanspringen': ['aan', 'spring'],\n",
       " 'aanstaan': ['aan', 'sta'],\n",
       " 'aanstaren': ['aan', 'staar'],\n",
       " 'aanstampen': ['aan', 'stamp'],\n",
       " 'aanstappen': ['aan', 'stap'],\n",
       " 'aansteken': ['aan', 'steek'],\n",
       " 'aanstekelijk': ['aan', 'steek', 'elijk'],\n",
       " 'aansteker': ['aan', 'steek', 'er'],\n",
       " 'aansteking': ['aan', 'steek', 'ing'],\n",
       " 'aanstellen': ['aan', 'stel'],\n",
       " 'aansteller': ['aan', 'stel', 'er'],\n",
       " 'aanstellerig': ['aan', 'stel', 'erig'],\n",
       " 'aanstellerij': ['aan', 'stel', 'erij'],\n",
       " 'aanstelling': ['aan', 'stel', 'ing'],\n",
       " 'aansterken': ['aan', 'sterk'],\n",
       " 'aansterven': ['aan', 'sterf'],\n",
       " 'aanstevenen': ['aan', 'steven'],\n",
       " 'aanstichten': ['aan', 'sticht'],\n",
       " 'aanstiefelen': ['aan', 'stiefel'],\n",
       " 'aanstijven': ['aan', 'stijf'],\n",
       " 'aanstikken': ['aan', 'stik'],\n",
       " 'aanstippen': ['aan', 'stip'],\n",
       " 'aanstipping': ['aan', 'stip', 'ing'],\n",
       " 'aanstoker': ['aan', 'stook', 'er'],\n",
       " 'aanstoken': ['aan', 'stook'],\n",
       " 'aanstomen': ['aan', 'stoom'],\n",
       " 'aanstoten': ['aan', 'stoot'],\n",
       " 'aanstoppen': ['aan', 'stop'],\n",
       " 'aanstormen': ['aan', 'storm'],\n",
       " 'aanstorten': ['aan', 'stort'],\n",
       " 'aanstotelijk': ['aan', 'stoot', 'elijk'],\n",
       " 'aanstoting': ['aan', 'stoot', 'ing'],\n",
       " 'aanstouwen': ['aan', 'stouw'],\n",
       " 'aanstranden': ['aan', 'strand'],\n",
       " 'aanstrepen': ['aan', 'streep'],\n",
       " 'aanstreping': ['aan', 'streep', 'ing'],\n",
       " 'aanstrijken': ['aan', 'strijk'],\n",
       " 'aanstrikken': ['aan', 'strik'],\n",
       " 'aanstrompelen': ['aan', 'strompel'],\n",
       " 'aanstromen': ['aan', 'stroom'],\n",
       " 'aanstuiven': ['aan', 'stuif'],\n",
       " 'aanstuiving': ['aan', 'stuif', 'ing'],\n",
       " 'aansturen': ['aan', 'stuur'],\n",
       " 'aanstuwen': ['aan', 'stuw'],\n",
       " 'aansukkelen': ['aan', 'sukkel'],\n",
       " 'aantakelen': ['aan', 'takel'],\n",
       " 'aantappen': ['aan', 'tap'],\n",
       " 'aantasten': ['aan', 'tast'],\n",
       " 'aantelen': ['aan', 'teel'],\n",
       " 'aantekenen': ['aan', 'teken'],\n",
       " 'aanteling': ['aan', 'teel', 'ing'],\n",
       " 'aantikken': ['aan', 'tik'],\n",
       " 'aantimmeren': ['aan', 'timmer'],\n",
       " 'aantoning': ['aan', 'toon', 'ing'],\n",
       " 'aantonen': ['aan', 'toon'],\n",
       " 'aantrappen': ['aan', 'trap'],\n",
       " 'aantreden': ['aan', 'treed'],\n",
       " 'aantreeplaats': ['aan', 'treed', 'plaats'],\n",
       " 'aantreffen': ['aan', 'tref'],\n",
       " 'aantrekken': ['aan', 'trek'],\n",
       " 'aantrekkelijk': ['aan', 'trek', 'elijk'],\n",
       " 'aantrekker': ['aan', 'trek', 'er'],\n",
       " 'aantrekking': ['aan', 'trek', 'ing'],\n",
       " 'aantrippelen': ['aan', 'trippel'],\n",
       " 'aanturen': ['aan', 'tuur'],\n",
       " 'aanvaren': ['aan', 'vaar'],\n",
       " 'aanvallen': ['aan', 'val'],\n",
       " 'aanvallenderwijs': ['aan', 'val', 'enderwijs', 'B', 'B'],\n",
       " 'aanvallenderwijze': ['aan', 'val', 'enderwijze', 'B', 'B'],\n",
       " 'aanvaller': ['aan', 'val', 'er'],\n",
       " 'aanvallig': ['aan', 'val', 'ig'],\n",
       " 'aanvangen': ['aan', 'vang'],\n",
       " 'aanvankelijk': ['aan', 'vang', 'elijk'],\n",
       " 'aanvaring': ['aan', 'vaar', 'ing'],\n",
       " 'aanvatten': ['aan', 'vat'],\n",
       " 'aanvatting': ['aan', 'vat', 'ing'],\n",
       " 'aanvechten': ['aan', 'vecht'],\n",
       " 'aanvegen': ['aan', 'veeg'],\n",
       " 'aanvetten': ['aan', 'vet'],\n",
       " 'aanvijlen': ['aan', 'vijl'],\n",
       " 'aanvijzen': ['aan', 'vijs'],\n",
       " 'aanvlammen': ['aan', 'vlam'],\n",
       " 'aanvlechten': ['aan', 'vlecht'],\n",
       " 'aanvliegen': ['aan', 'vlieg'],\n",
       " 'aanvloeien': ['aan', 'vloei'],\n",
       " 'aanvlotten': ['aan', 'vlot'],\n",
       " 'aanvoegen': ['aan', 'voeg'],\n",
       " 'aanvoelen': ['aan', 'voel'],\n",
       " 'aanvoeren': ['aan', 'voer'],\n",
       " 'aanvragen': ['aan', 'vraag'],\n",
       " 'aanvrager': ['aan', 'vraag', 'er'],\n",
       " 'aanvreten': ['aan', 'vreet'],\n",
       " 'aanvullen': ['aan', 'vul'],\n",
       " 'aanvulling': ['aan', 'vul', 'ing'],\n",
       " 'aanvullingstroepen': ['aan', 'vul', 'ing', 's', 'troep'],\n",
       " 'aanvuring': ['aan', 'vuur', 'ing'],\n",
       " 'aanvuren': ['aan', 'vuur'],\n",
       " 'aanwaaien': ['aan', 'waai'],\n",
       " 'aanwaggelen': ['aan', 'waggel'],\n",
       " 'aanwakkeren': ['aan', 'wakker'],\n",
       " 'aanwandelen': ['aan', 'wandel'],\n",
       " 'aanwassen': ['aan', 'was'],\n",
       " 'aanwassing': ['aan', 'was', 'ing'],\n",
       " 'aanweven': ['aan', 'weef'],\n",
       " 'aanwennen': ['aan', 'wen'],\n",
       " 'aanwenden': ['aan', 'wend'],\n",
       " 'aanwenning': ['aan', 'wen', 'ing'],\n",
       " 'aanwentelen': ['aan', 'wentel'],\n",
       " 'aanwerpen': ['aan', 'werp'],\n",
       " 'aanwerven': ['aan', 'werf'],\n",
       " 'aanwerver': ['aan', 'werf', 'er'],\n",
       " 'aanwerving': ['aan', 'werf', 'ing'],\n",
       " 'aanwetten': ['aan', 'wet'],\n",
       " 'aanwijzen': ['aan', 'wijs'],\n",
       " 'aanwijzer': ['aan', 'wijs', 'er'],\n",
       " 'aanwijzing': ['aan', 'wijs', 'ing'],\n",
       " 'aanwinnen': ['aan', 'win'],\n",
       " 'aanwinning': ['aan', 'win', 'ing'],\n",
       " 'aanwippen': ['aan', 'wip'],\n",
       " 'aanwoekeren': ['aan', 'woeker'],\n",
       " 'aanwrijven': ['aan', 'wrijf'],\n",
       " 'aanwrijving': ['aan', 'wrijf', 'ing'],\n",
       " 'aanzaaien': ['aan', 'zaai'],\n",
       " 'aanzakken': ['aan', 'zak'],\n",
       " 'aanzanden': ['aan', 'zand'],\n",
       " 'aanzeggen': ['aan', 'zeg'],\n",
       " 'aanzegger': ['aan', 'zeg', 'er'],\n",
       " 'aanzegging': ['aan', 'zeg', 'ing'],\n",
       " 'aanzeilen': ['aan', 'zeil'],\n",
       " 'aanzetten': ['aan', 'zet'],\n",
       " 'aanzetter': ['aan', 'zet', 'er'],\n",
       " 'aanzetting': ['aan', 'zet', 'ing'],\n",
       " 'aanzeulen': ['aan', 'zeul'],\n",
       " 'aanzitten': ['aan', 'zit'],\n",
       " 'aanzoeken': ['aan', 'zoek'],\n",
       " 'aanzoeten': ['aan', 'zoet'],\n",
       " 'aanzuigen': ['aan', 'zuig'],\n",
       " 'aanzuiveren': ['aan', 'zuiver'],\n",
       " 'aanzwaaien': ['aan', 'zwaai'],\n",
       " 'aanzwepen': ['aan', 'zweep'],\n",
       " 'aanzweven': ['aan', 'zweef'],\n",
       " 'aanzwellen': ['aan', 'zwel'],\n",
       " 'aanzwemmen': ['aan', 'zwem'],\n",
       " 'aanzwengelen': ['aan', 'zwengel'],\n",
       " 'aanzwoegen': ['aan', 'zwoeg'],\n",
       " 'aapjessnuif': ['aap', 's', 'snuif'],\n",
       " 'aapjeszeep': ['aap', 's', 'zeep'],\n",
       " 'aren': ['aar'],\n",
       " 'aarden': ['aarde', 'en'],\n",
       " 'aardamandel': ['aarde', 'amandel'],\n",
       " 'aardappel': ['aarde', 'appel'],\n",
       " 'aardappelhakker': ['aarde', 'appel', 'hak', 'er', 'NV'],\n",
       " 'aardappelmesje': ['aarde', 'appel', 'mes'],\n",
       " 'aardappelpoter': ['aarde', 'appel', 'poot', 'er', 'NV'],\n",
       " 'aardappelrooien': ['aarde', 'appel', 'rooi'],\n",
       " 'aardappelschiller': ['aarde', 'appel', 'schil', 'er', 'NV'],\n",
       " 'aardappelschilmesje': ['aarde', 'appel', 'schilmes'],\n",
       " 'aardappelvlokken': ['aarde', 'appel', 'vlok'],\n",
       " 'aardas': ['aarde', 'as'],\n",
       " 'aardatmosfeer': ['aarde', 'atmosfeer'],\n",
       " 'aardbaan': ['aarde', 'baan'],\n",
       " 'aardberging': ['aarde', 'berg', 'ing', 'NV'],\n",
       " 'aardbeving': ['aarde', 'beef', 'ing'],\n",
       " 'aardbevingsmeter': ['aarde', 'beef', 'ing', 's', 'Vx', 'meet', 'er', 'NxV'],\n",
       " 'aardbewoner': ['aarde', 'be', 'woon', 'er', 'NV'],\n",
       " 'aardbewoonster': ['aarde', 'be', 'woon', 'ster', 'NV'],\n",
       " 'aardbij': ['aarde', 'bij'],\n",
       " 'aardbodem': ['aarde', 'bodem'],\n",
       " 'aardbol': ['aarde', 'bol'],\n",
       " 'aardboog': ['aarde', 'boog'],\n",
       " 'aardboor': ['aarde', 'boor'],\n",
       " 'aardbrand': ['aarde', 'brand'],\n",
       " 'aardbuil': ['aarde', 'buil'],\n",
       " 'aardduivel': ['aarde', 'duivel'],\n",
       " 'aardgas': ['aarde', 'gas'],\n",
       " 'aardgasbaten': ['aarde', 'gas', 'baat'],\n",
       " 'aardgeest': ['aarde', 'geest'],\n",
       " 'aardgewas': ['aarde', 'ge', 'was'],\n",
       " 'aardglobe': ['aarde', 'globe'],\n",
       " 'aardgoed': ['aarde', 'goed'],\n",
       " 'aardgordel': ['aarde', 'gordel'],\n",
       " 'aardhars': ['aarde', 'hars'],\n",
       " 'aardhommel': ['aarde', 'hommel'],\n",
       " 'aardhoop': ['aarde', 'hoop'],\n",
       " 'aardkastanje': ['aarde', 'kastanje'],\n",
       " 'aardkern': ['aarde', 'kern'],\n",
       " 'aardklomp': ['aarde', 'klomp'],\n",
       " 'aardklont': ['aarde', 'klont'],\n",
       " 'aardkloot': ['aarde', 'kloot'],\n",
       " 'aardkluit': ['aarde', 'kluit'],\n",
       " 'aardkorst': ['aarde', 'korst'],\n",
       " 'aardkrekel': ['aarde', 'krekel'],\n",
       " 'aardkromming': ['aarde', 'krom', 'ing'],\n",
       " 'aardkuil': ['aarde', 'kuil'],\n",
       " 'aardkunde': ['aarde', 'kunde'],\n",
       " 'aardkundig': ['aarde', 'kunde', 'ig'],\n",
       " 'aardlaag': ['aarde', 'laag'],\n",
       " 'aardleiding': ['aarde', 'leid', 'ing'],\n",
       " 'aardlevering': ['aarde', 'lever', 'ing'],\n",
       " 'aardmagnetisme': ['aarde', 'magnetisme'],\n",
       " 'aardmannetje': ['aarde', 'man'],\n",
       " 'aardmassa': ['aarde', 'massa'],\n",
       " 'aardmeetkunde': ['aarde', 'meet', 'kunde'],\n",
       " 'aardmetalen': ['aarde', 'metaal'],\n",
       " 'aardmeting': ['aarde', 'meet', 'ing', 'NV'],\n",
       " 'aardmijt': ['aarde', 'mijt'],\n",
       " 'aardmolm': ['aarde', 'molm'],\n",
       " 'aardmuis': ['aarde', 'muis'],\n",
       " 'aardnoot': ['aarde', 'noot'],\n",
       " 'aardnotenolie': ['aarde', 'noot', 'en', 'olie'],\n",
       " 'aardolie': ['aarde', 'olie'],\n",
       " 'aardoppervlak': ['aarde', 'opper', 'vlak'],\n",
       " 'aardoppervlakte': ['aarde', 'opper', 'vlak', 'te'],\n",
       " 'aardpeer': ['aarde', 'peer'],\n",
       " 'aardpek': ['aarde', 'pek'],\n",
       " 'aardplooi': ['aarde', 'plooi'],\n",
       " 'aardpool': ['aarde', 'pool'],\n",
       " 'aardprofiel': ['aarde', 'profiel'],\n",
       " 'aardrijk': ['aarde', 'rijk'],\n",
       " 'aardrijkskundig': ['aarde', 'rijk', 's', 'kunde', 'ig'],\n",
       " 'aardrol': ['aarde', 'rol'],\n",
       " 'aardrook': ['aarde', 'rook'],\n",
       " 'aardrups': ['aarde', 'rups'],\n",
       " 'aards': ['aarde', 's'],\n",
       " 'aardschaduw': ['aarde', 'schaduw'],\n",
       " 'aardschijn': ['aarde', 'schijn'],\n",
       " 'aardschok': ['aarde', 'schok'],\n",
       " 'aardschors': ['aarde', 'schors'],\n",
       " 'aardschudding': ['aarde', 'schud', 'ing'],\n",
       " 'aardsgezind': ['aarde', 's', 'gezind'],\n",
       " 'aardslak': ['aarde', 'slak'],\n",
       " 'aardslang': ['aarde', 'slang'],\n",
       " 'aardsluiting': ['aarde', 'sluit', 'ing'],\n",
       " 'aardspin': ['aarde', 'spin'],\n",
       " 'aardster': ['aarde', 'ster'],\n",
       " 'aardstorting': ['aarde', 'stort', 'ing'],\n",
       " 'aardstraal': ['aarde', 'straal'],\n",
       " 'aardstralenkastje': ['aarde', 'straal', 'en', 'kast'],\n",
       " 'aardstraling': ['aarde', 'straal', 'ing'],\n",
       " 'aardstroom': ['aarde', 'stroom'],\n",
       " 'aardtor': ['aarde', 'tor'],\n",
       " 'aardtrilling': ['aarde', 'tril', 'ing'],\n",
       " 'aardvarken': ['aarde', 'varken'],\n",
       " 'aardvast': ['aarde', 'vast'],\n",
       " 'aardveil': ['aarde', 'veil'],\n",
       " 'aardverbinding': ['aarde', 'ver', 'bind', 'ing'],\n",
       " 'aardverschuiving': ['aarde', 'ver', 'schuif', 'ing'],\n",
       " 'aardverf': ['aarde', 'verf'],\n",
       " 'aardvlo': ['aarde', 'vlo'],\n",
       " 'aardvork': ['aarde', 'vork'],\n",
       " 'aardvrucht': ['aarde', 'vrucht'],\n",
       " 'aardwarmte': ['aarde', 'warm', 'te'],\n",
       " 'aardwas': ['aarde', 'was'],\n",
       " 'aardwerk': ['aarde', 'werk'],\n",
       " 'aardwetenschappen': ['aarde', 'weten', 'schap'],\n",
       " 'aardwinde': ['aarde', 'winde'],\n",
       " 'aardwolf': ['aarde', 'wolf'],\n",
       " 'aardworm': ['aarde', 'worm'],\n",
       " 'aartsbisschoppelijk': ['aarts', 'bisschop', 'elijk'],\n",
       " 'aarzelen': ['aarzel'],\n",
       " 'aaseter': ['aas', 'eet', 'er', 'NV'],\n",
       " 'aasjager': ['aas', 'jaag', 'er', 'NV'],\n",
       " 'aatje': ['aat'],\n",
       " 'aasje': ['aas'],\n",
       " 'azen': ['aas'],\n",
       " 'abandonneren': ['abandon', 'eer'],\n",
       " 'abandonnement': ['abandon', 'eer', 'ement'],\n",
       " 'abbatiaal': ['abt', 'aal'],\n",
       " 'abbreviatie': ['abbrevieer', 'atie'],\n",
       " 'abbreviatuur': ['abbrevieer', 'atuur'],\n",
       " 'abc-boek': ['abc', 'boek'],\n",
       " 'ABC-wapens': ['abc', 'wapen'],\n",
       " 'abdicatie': ['abdiceer', 'atie'],\n",
       " 'abdominaal': ['abdomen', 'aal'],\n",
       " 'abelenlaan': ['abeel', 'en', 'laan'],\n",
       " 'A-biljet': ['a', 'biljet'],\n",
       " 'abnormaliteit': ['abnormaal', 'iteit'],\n",
       " 'abolitie': ['aboleer', 'itie'],\n",
       " 'A-bom': ['a', 'bom'],\n",
       " 'abondance': ['abondant', 'nce'],\n",
       " 'abonnement': ['abonneer', 'ement'],\n",
       " 'aborteren': ['abortus', 'eer'],\n",
       " 'aborteur': ['abortus', 'eer', 'eur'],\n",
       " 'abortief': ['abortus', 'ief'],\n",
       " 'abricoteren': ['abrikoos', 'eer'],\n",
       " 'abrikozeboom': ['abrikoos', 'e', 'boom'],\n",
       " 'abrikozengelei': ['abrikoos', 'en', 'gelei'],\n",
       " 'abrikozentaart': ['abrikoos', 'en', 'taart'],\n",
       " 'abrikozepit': ['abrikoos', 'e', 'pit'],\n",
       " 'abrikozeschil': ['abrikoos', 'e', 'schil'],\n",
       " 'absence': ['absent', 'nce'],\n",
       " 'absenteren': ['absent', 'eer'],\n",
       " 'absolutie': ['absolveer', 'utie'],\n",
       " 'absorbaat': ['absorbeer', 'aat'],\n",
       " 'abstinent': ['abstineer', 'ent'],\n",
       " 'abstraheren': ['abstract', 'eer'],\n",
       " 'abstrahering': ['abstract', 'eer', 'ing'],\n",
       " 'abuseren': ['abuis', 'eer'],\n",
       " 'abusief': ['abuis', 'ief'],\n",
       " 'academie': ['academisch', 'ie'],\n",
       " 'acceleratie': ['accelereer', 'atie'],\n",
       " 'accelerator': ['accelereer', 'ator'],\n",
       " 'accentuatie': ['accent', 'ueer', 'atie'],\n",
       " 'accentueren': ['accent', 'ueer'],\n",
       " 'accentuering': ['accent', 'ueer', 'ing'],\n",
       " 'accentverlegging': ['accent', 'ver', 'leg', 'ing', 'NV'],\n",
       " 'acceptabel': ['accept', 'eer', 'abel'],\n",
       " 'acceptant': ['accept', 'eer', 'ant'],\n",
       " 'acceptatie': ['accept', 'eer', 'atie'],\n",
       " 'accepteren': ['accept', 'eer'],\n",
       " 'accessie': ['acces', 'ie'],\n",
       " 'accijnsrechten': ['accijns', 'recht'],\n",
       " 'acclimatisatie': ['acclimatiseer', 'atie'],\n",
       " 'acclimatisering': ['acclimatiseer', 'ing'],\n",
       " 'accommodatie': ['accommodeer', 'atie'],\n",
       " 'accompagnateur': ['accompagneer', 'ateur'],\n",
       " 'accompagnement': ['accompagneer', 'ement'],\n",
       " 'accoucheur': ['accoucheer', 'eur'],\n",
       " 'accountants-administratieconsulent': ['accountant',\n",
       "  's',\n",
       "  'NN',\n",
       "  'administreer',\n",
       "  'atie',\n",
       "  'consulent'],\n",
       " 'accumulatie': ['accumuleer', 'atie'],\n",
       " 'accumulatief': ['accumuleer', 'atie', 'ief'],\n",
       " 'accumulator': ['accumuleer', 'ator'],\n",
       " 'accuratesse': ['accuraat', 'esse'],\n",
       " 'accusatie': ['accuseer', 'atie'],\n",
       " 'accuseren': ['accuseer'],\n",
       " 'achilleshiel': ['Achilles', 'hiel'],\n",
       " 'achillespees': ['Achilles', 'pees'],\n",
       " 'a-christelijk': ['a', 'christen', 'elijk'],\n",
       " 'achten': ['acht'],\n",
       " 'achtdaags': ['acht', 'Q', 'dag', 's', 'QN'],\n",
       " 'achtenswaard': ['acht', 's', 'waard'],\n",
       " 'achtenswaardig': ['acht', 's', 'waarde', 'ig'],\n",
       " 'achteraanblijven': ['achter', 'B', 'aan', 'B', 'blijf'],\n",
       " 'achteraangaan': ['achter', 'B', 'aan', 'B', 'ga'],\n",
       " 'achteraankomen': ['achter', 'B', 'aan', 'B', 'kom'],\n",
       " 'achteraanlopen': ['achter', 'B', 'aan', 'B', 'loop'],\n",
       " 'achteraanrennen': ['achter', 'B', 'aan', 'B', 'ren'],\n",
       " 'achteraanzitten': ['achter', 'B', 'aan', 'B', 'zit'],\n",
       " 'achterblijven': ['achter', 'B', 'blijf'],\n",
       " 'achterblijver': ['achter', 'B', 'blijf', 'er'],\n",
       " 'achtergaan': ['achter', 'B', 'ga'],\n",
       " 'achtergrondinformatie': ['achter', 'B', 'grond', 'informeer', 'atie', 'NV'],\n",
       " 'achterhalen': ['achter', 'B', 'haal'],\n",
       " 'achterhaling': ['achter', 'B', 'haal', 'ing'],\n",
       " 'achterhandsbeentje': ['achter', 'B', 'hand', 's', 'been'],\n",
       " 'achterhouden': ['achter', 'B', 'houd'],\n",
       " 'achterklappen': ['achter', 'B', 'klap'],\n",
       " 'achterlaten': ['achter', 'B', 'laat'],\n",
       " 'achterlating': ['achter', 'B', 'laat', 'ing'],\n",
       " 'achterliggen': ['achter', 'B', 'lig'],\n",
       " 'achterligger': ['achter', 'B', 'lig', 'er'],\n",
       " 'achterlopen': ['achter', 'B', 'loop'],\n",
       " 'achterloper': ['achter', 'B', 'loop', 'er'],\n",
       " 'achternadoen': ['achterna', 'B', 'doe'],\n",
       " 'achternagaan': ['achterna', 'B', 'ga'],\n",
       " 'achternageven': ['achterna', 'B', 'geef'],\n",
       " 'achternalopen': ['achterna', 'B', 'loop'],\n",
       " 'achternarijden': ['achterna', 'B', 'rijd'],\n",
       " 'achternasturen': ['achterna', 'B', 'stuur'],\n",
       " 'achternazenden': ['achterna', 'B', 'zend'],\n",
       " 'achternazetten': ['achterna', 'B', 'zet'],\n",
       " 'achternazitten': ['achterna', 'B', 'zit'],\n",
       " 'achteromkijken': ['achter', 'om', 'B', 'kijk'],\n",
       " 'achteromlopen': ['achter', 'om', 'B', 'loop'],\n",
       " 'achteromzien': ['achter', 'om', 'B', 'zie'],\n",
       " 'achteropkomen': ['achter', 'op', 'B', 'kom'],\n",
       " 'achteroplopen': ['achter', 'op', 'B', 'loop'],\n",
       " 'achteropraken': ['achter', 'op', 'B', 'raak'],\n",
       " 'achteroverdrukken': ['achter', 'over', 'B', 'druk'],\n",
       " 'achteroverliggen': ['achter', 'over', 'B', 'lig'],\n",
       " 'achteroverslaan': ['achter', 'over', 'B', 'sla'],\n",
       " 'achterovervallen': ['achter', 'B', 'over', 'val'],\n",
       " 'achterstaan': ['achter', 'B', 'sta'],\n",
       " 'achterstallig': ['achter', 'B', 'stal', 'ig'],\n",
       " 'achterstellen': ['achter', 'B', 'stel'],\n",
       " 'achterstelling': ['achter', 'B', 'stel', 'ing'],\n",
       " 'achteruitboeren': ['achter', 'B', 'uit', 'B', 'B', 'boer'],\n",
       " 'achteruitdeinzen': ['achter', 'B', 'uit', 'B', 'B', 'deins'],\n",
       " 'achteruitgaan': ['achter', 'B', 'uit', 'B', 'B', 'ga'],\n",
       " 'achteruitkrabbelen': ['achter', 'B', 'uit', 'B', 'B', 'krabbel'],\n",
       " 'achteruitleren': ['achter', 'B', 'uit', 'B', 'B', 'leer'],\n",
       " 'achteruitlopen': ['achter', 'B', 'uit', 'loop'],\n",
       " 'achteruitmarcheren': ['achter', 'B', 'uit', 'B', 'B', 'marcheer'],\n",
       " 'achteruitraken': ['achter', 'B', 'uit', 'B', 'B', 'raak'],\n",
       " 'achteruitrijden': ['achter', 'B', 'uit', 'B', 'B', 'rijd'],\n",
       " 'achteruitrijlamp': ['achter', 'B', 'uit', 'B', 'B', 'rijd', 'lamp'],\n",
       " 'achteruitschoppen': ['achter', 'B', 'uit', 'B', 'B', 'schop'],\n",
       " 'achteruitschuiven': ['achter', 'B', 'uit', 'B', 'B', 'schuif'],\n",
       " 'achteruitslaan': ['achter', 'B', 'uit', 'B', 'B', 'sla'],\n",
       " 'achteruitsteken': ['achter', 'B', 'uit', 'B', 'B', 'steek'],\n",
       " 'achteruitvallen': ['achter', 'B', 'uit', 'B', 'B', 'val'],\n",
       " 'achteruitvliegen': ['achter', 'B', 'uit', 'B', 'B', 'vlieg'],\n",
       " 'achteruitwerken': ['achter', 'B', 'uit', 'B', 'B', 'werk'],\n",
       " 'achteruitwijken': ['achter', 'B', 'uit', 'B', 'B', 'wijk'],\n",
       " 'achteruitzetten': ['achter', 'B', 'uit', 'B', 'B', 'zet'],\n",
       " 'achtervoegen': ['achter', 'B', 'voeg'],\n",
       " 'achtervolgen': ['achter', 'B', 'volg'],\n",
       " 'achterwaren': ['achter', 'B', 'waar'],\n",
       " 'achterwielaandrijving': ['achter', 'B', 'wiel', 'aan', 'drijf', 'ing', 'NV'],\n",
       " 'achterzeilen': ['achter', 'B', 'zeil'],\n",
       " 'achtjarig': ['acht', 'Q', 'jaar', 'ig', 'QN'],\n",
       " 'achtpotig': ['acht', 'Q', 'poot', 'ig', 'QN'],\n",
       " 'achttiende-eeuws': ['acht',\n",
       "  'Q',\n",
       "  'tien',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'de',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'eeuw',\n",
       "  's',\n",
       "  'QN'],\n",
       " 'achttienjarig': ['acht', 'Q', 'tien', 'Q', 'Q', 'jaar', 'ig', 'QN'],\n",
       " 'achttienurig': ['acht', 'Q', 'tien', 'Q', 'Q', 'uur', 'ig', 'QN'],\n",
       " 'achturemis': ['acht', 'Q', 'uur', 'e', 'QN', 'mis'],\n",
       " 'achturendag': ['acht', 'Q', 'uur', 'en', 'QN', 'dag'],\n",
       " 'achturig': ['acht', 'Q', 'uur', 'ig', 'QN'],\n",
       " 'achtvlakkig': ['acht', 'Q', 'vlak', 'ig', 'QN'],\n",
       " 'achtzijdig': ['acht', 'Q', 'zijde', 'ig', 'QN'],\n",
       " 'acidimetrie': ['acidimeter', 'ie'],\n",
       " 'aconceptief': ['a', 'Nx', 'concept', 'ie', 'ief', 'xN'],\n",
       " 'acquisitief': ['acquisitie', 'ief'],\n",
       " 'acquitteren': ['acquit', 'eer'],\n",
       " 'acrobate': ['acrobaat', 'e'],\n",
       " 'acrobatentoer': ['acrobaat', 'en', 'toer'],\n",
       " 'acrobatie': ['acrobaat', 'isch', 'ie'],\n",
       " 'acrobatiek': ['acrobaat', 'isch', 'iek'],\n",
       " 'acrobatisch': ['acrobaat', 'isch'],\n",
       " 'acteur': ['acteer', 'eur'],\n",
       " 'actieveling': ['actie', 'ief', 'eling'],\n",
       " 'actinisch': ['actine', 'isch'],\n",
       " 'activeren': ['actief', 'eer'],\n",
       " 'activering': ['actief', 'eer', 'ing'],\n",
       " 'activiteit': ['actie', 'ief', 'iteit'],\n",
       " 'actualiseren': ['actueel', 'eer'],\n",
       " 'actualisering': ['actueel', 'eer', 'ing'],\n",
       " 'actualiteit': ['actueel', 'iteit'],\n",
       " 'actuariaat': ['actuaris', 'aat'],\n",
       " 'actuarieel': ['actuaris', 'eel'],\n",
       " 'acupuncturist': ['acupunctuur', 'ist'],\n",
       " 'adamsappel': ['Adam', 's', 'appel'],\n",
       " 'adamskostuum': ['Adam', 's', 'kostuum'],\n",
       " 'adaptatie': ['adapteer', 'atie'],\n",
       " 'adaptief': ['adapteer', 'atie', 'ief'],\n",
       " 'additie': ['addeer', 'itie'],\n",
       " 'additief': ['addeer', 'itie', 'ief'],\n",
       " 'additioneel': ['addeer', 'itie', 'ioneel'],\n",
       " 'adelen': ['adel'],\n",
       " 'ademen': ['adem'],\n",
       " 'adembeklemmend': ['adem', 'be', 'klem', 'end', 'NV'],\n",
       " 'adembenemend': ['adem', 'be', 'neem', 'end', 'NV'],\n",
       " 'ademhalen': ['adem', 'haal'],\n",
       " 'ademhaling': ['adem', 'haal', 'ing'],\n",
       " 'ademhalingswerktuigen': ['adem', 'haal', 'ing', 's', 'werk', 'tuig'],\n",
       " 'aderen': ['ader'],\n",
       " 'aderiseren': ['ader', 'iseer'],\n",
       " 'aderlaten': ['ader', 'laat'],\n",
       " 'aderlating': ['ader', 'laat', 'ing'],\n",
       " 'aderontsteking': ['ader', 'ontsteek', 'ing', 'NV'],\n",
       " 'adjectivisch': ['adjectief', 'isch'],\n",
       " 'adjudant-onderofficier': ['adjudant', 'onder', 'officier'],\n",
       " 'adjunct-administrateur': ['adjunct', 'administreer', 'ateur'],\n",
       " 'adjunct-commies': ['adjunct', 'commies'],\n",
       " 'adjunct-commissaris': ['adjunct', 'commissaris'],\n",
       " 'adjunct-directeur': ['adjunct', 'directeur'],\n",
       " 'adjunct-hoofdredacteur': ['adjunct', 'hoofd', 'redacteur'],\n",
       " 'adjunct-secretaris': ['adjunct', 'secretaris'],\n",
       " 'administrateur': ['administreer', 'ateur'],\n",
       " 'administratie': ['administreer', 'atie'],\n",
       " 'administratiekosten': ['administreer', 'atie', 'kost'],\n",
       " 'administratief': ['administreer', 'atie', 'ief'],\n",
       " 'admiraal-generaal': ['admiraal', 'generaal'],\n",
       " 'admiraalzeilen': ['admiraal', 'zeil'],\n",
       " 'admissie-examen': ['admissie', 'examen'],\n",
       " 'adnominaal': ['ad', 'Nx', 'nomen', 'aal', 'xN'],\n",
       " 'adoniseren': ['adonis', 'eer'],\n",
       " 'adoptant': ['adopteer', 'ant'],\n",
       " 'adoptiefouders': ['adoptie', 'ief', 'ouder'],\n",
       " 'adoptief': ['adoptie', 'ief'],\n",
       " 'adorabel': ['adoreer', 'abel'],\n",
       " 'adoratie': ['adoreer', 'atie'],\n",
       " 'adrenaline-injectie': ['adrenaline', 'injectie'],\n",
       " 'adressant': ['adres', 'eer', 'ant'],\n",
       " 'adresschrijver': ['adres', 'schrijf', 'er', 'NV'],\n",
       " 'adresseren': ['adres', 'eer'],\n",
       " 'adressenbank': ['adres', 'en', 'bank'],\n",
       " 'adressenlijst': ['adres', 'en', 'lijst'],\n",
       " 'adressenschrijver': ['adres', 'en', 'Vx', 'schrijf', 'er', 'NxV'],\n",
       " 'adressering': ['adres', 'eer', 'ing'],\n",
       " 'adverbiaal': ['adverbium', 'aal'],\n",
       " 'advertentie': ['adverteer', 'entie'],\n",
       " 'advertentie-exploitatie': ['adverteer', 'entie', 'exploiteer', 'atie'],\n",
       " 'advertentie-inkomst': ['adverteer', 'entie', 'in', 'kom', 'st'],\n",
       " 'advertentiekosten': ['adverteer', 'entie', 'kost'],\n",
       " 'adviseren': ['advies', 'eer'],\n",
       " 'adviseur': ['advies', 'eer', 'eur'],\n",
       " 'advocaatje': ['advocaat'],\n",
       " 'advocaat-fiscaal': ['advocaat', 'fiscaal'],\n",
       " 'advocaat-generaal': ['advocaat', 'generaal'],\n",
       " 'advocate': ['advocaat', 'e'],\n",
       " 'advocatenbureau': ['advocaat', 'en', 'bureau'],\n",
       " 'advocatencollectief': ['advocaat', 'en', 'collectief'],\n",
       " 'advocatenfirma': ['advocaat', 'en', 'firma'],\n",
       " 'advocatenkamer': ['advocaat', 'en', 'kamer'],\n",
       " 'advocatenkantoor': ['advocaat', 'en', 'kantoor'],\n",
       " 'advocatenpraktijk': ['advocaat', 'en', 'praktijk'],\n",
       " 'advocatenstreek': ['advocaat', 'en', 'streek'],\n",
       " 'advocaterij': ['advocaat', 'erij'],\n",
       " 'advocatie': ['advocaat', 'ie'],\n",
       " 'advocatuur': ['advocaat', 'uur'],\n",
       " 'aeratie': ['aereer', 'atie'],\n",
       " 'aeronautiek': ['aero', 'nautisch', 'iek'],\n",
       " 'afbaarden': ['af', 'baard'],\n",
       " 'afbakken': ['af', 'bak'],\n",
       " 'afbakenen': ['af', 'baken'],\n",
       " 'afbarsten': ['af', 'barst'],\n",
       " 'afbedelen': ['af', 'bedel'],\n",
       " 'afbeelden': ['af', 'beeld'],\n",
       " 'afbenen': ['af', 'been'],\n",
       " 'afbeitelen': ['af', 'beitel'],\n",
       " 'afbekken': ['af', 'bek'],\n",
       " 'afbellen': ['af', 'bel'],\n",
       " 'afbestellen': ['af', 'bestel'],\n",
       " 'afbestelling': ['af', 'bestel', 'ing'],\n",
       " 'afbetten': ['af', 'bet'],\n",
       " 'afbetalen': ['af', 'betaal'],\n",
       " 'afbetaling': ['af', 'betaal', 'ing'],\n",
       " 'afbeulen': ['af', 'beul'],\n",
       " 'afbidden': ['af', 'bid'],\n",
       " 'afbidding': ['af', 'bid', 'ing'],\n",
       " 'afbieden': ['af', 'bied'],\n",
       " 'afbietsen': ['af', 'biets'],\n",
       " 'afbiezen': ['af', 'bies'],\n",
       " 'afbijten': ['af', 'bijt'],\n",
       " 'afbikken': ['af', 'bik'],\n",
       " 'afbiljoenen': ['af', 'biljoen'],\n",
       " 'afbinden': ['af', 'bind'],\n",
       " 'afbladen': ['af', 'blad'],\n",
       " 'afblaren': ['af', 'blaar'],\n",
       " 'afblazen': ['af', 'blaas'],\n",
       " 'afbladderen': ['af', 'bladder'],\n",
       " 'afbladeren': ['af', 'blader'],\n",
       " 'afblaffen': ['af', 'blaf'],\n",
       " 'afblijven': ['af', 'blijf'],\n",
       " 'afbliksemen': ['af', 'bliksem'],\n",
       " 'afblokken': ['af', 'blok'],\n",
       " 'afbluffen': ['af', 'bluf'],\n",
       " 'afblussen': ['af', 'blus'],\n",
       " 'afboeken': ['af', 'boek'],\n",
       " 'afboenen': ['af', 'boen'],\n",
       " 'afboeten': ['af', 'boet'],\n",
       " 'afbollen': ['af', 'bol'],\n",
       " 'afbonken': ['af', 'bonk'],\n",
       " 'afbonzen': ['af', 'bons'],\n",
       " 'afbomen': ['af', 'boom'],\n",
       " 'afborstelen': ['af', 'borstel'],\n",
       " 'afbottelen': ['af', 'bottel'],\n",
       " 'afbouwen': ['af', 'bouw'],\n",
       " 'afbramen': ['af', 'braam'],\n",
       " 'afbranden': ['af', 'brand'],\n",
       " 'afbrassen': ['af', 'bras'],\n",
       " 'afbreken': ['af', 'breek'],\n",
       " 'afbreien': ['af', 'brei'],\n",
       " 'afbreker': ['af', 'breek', 'er'],\n",
       " 'afbreking': ['af', 'breek', 'ing'],\n",
       " 'afbrengen': ['af', 'breng'],\n",
       " 'afbrijnen': ['af', 'brijn'],\n",
       " 'afbroddelen': ['af', 'broddel'],\n",
       " 'afbrokkelen': ['af', 'brokkel'],\n",
       " 'afbuigen': ['af', 'buig'],\n",
       " 'afbuitelen': ['af', 'buitel'],\n",
       " 'afchecken': ['af', 'check'],\n",
       " 'afcommanderen': ['af', 'commandeer'],\n",
       " 'afconcluderen': ['af', 'concludeer'],\n",
       " 'afdalen': ['af', 'daal'],\n",
       " 'afdaling': ['af', 'daal', 'ing'],\n",
       " 'afdammen': ['af', 'dam'],\n",
       " 'afdamming': ['af', 'dam', 'ing'],\n",
       " 'afdanken': ['af', 'dank'],\n",
       " 'afdankertje': ['af', 'dank', 'er'],\n",
       " 'afdansen': ['af', 'dans'],\n",
       " 'afdelen': ['af', 'deel'],\n",
       " 'afdeinzen': ['af', 'deins'],\n",
       " 'afdekken': ['af', 'dek'],\n",
       " 'afdekking': ['af', 'dek', 'ing'],\n",
       " 'afdeling': ['af', 'deel', 'ing'],\n",
       " 'afdelven': ['af', 'delf'],\n",
       " 'afdichten': ['af', 'dicht'],\n",
       " 'afdienen': ['af', 'dien'],\n",
       " 'afdieven': ['af', 'dief'],\n",
       " 'afdijken': ['af', 'dijk'],\n",
       " 'afdingen': ['af', 'ding'],\n",
       " 'afdoen': ['af', 'doe'],\n",
       " 'afdoener': ['af', 'doe', 'er'],\n",
       " 'afdokken': ['af', 'dok'],\n",
       " 'afdonderen': ['af', 'donder'],\n",
       " 'afdolen': ['af', 'dool'],\n",
       " 'afdoppen': ['af', 'dop'],\n",
       " 'afdorsen': ['af', 'dors'],\n",
       " 'afdouwen': ['af', 'douw'],\n",
       " 'afdragen': ['af', 'draag'],\n",
       " 'afdraaien': ['af', 'draai'],\n",
       " 'afdraven': ['af', 'draaf'],\n",
       " 'afdrager': ['af', 'draag', 'er'],\n",
       " 'afdreggen': ['af', 'dreg'],\n",
       " 'afdreigen': ['af', 'dreig'],\n",
       " 'afdrentelen': ['af', 'drentel'],\n",
       " 'afdrijven': ['af', 'drijf'],\n",
       " 'afdrijving': ['af', 'drijf', 'ing'],\n",
       " 'afdringen': ['af', 'dring'],\n",
       " 'afdrinken': ['af', 'drink'],\n",
       " 'afdroging': ['af', 'droog', 'ing'],\n",
       " 'afdrogen': ['af', 'droog'],\n",
       " 'afdroppelen': ['af', 'droppel'],\n",
       " 'afdruipen': ['af', 'druip'],\n",
       " 'afdrukken': ['af', 'druk'],\n",
       " 'afdruppen': ['af', 'drup'],\n",
       " 'afdruppelen': ['af', 'druppel'],\n",
       " 'afduikelen': ['af', 'duikel'],\n",
       " 'afduvelen': ['af', 'duvel'],\n",
       " 'afduwen': ['af', 'duw'],\n",
       " 'afdwalen': ['af', 'dwaal'],\n",
       " 'afdwaling': ['af', 'dwaal', 'ing'],\n",
       " 'afdweilen': ['af', 'dweil'],\n",
       " 'afdwingen': ['af', 'dwing'],\n",
       " 'afeten': ['af', 'eet'],\n",
       " 'afeisen': ['af', 'eis'],\n",
       " 'af-fabriekprijs': ['af', 'fabriek', 'prijs'],\n",
       " 'affakkelen': ['af', 'fakkel'],\n",
       " 'affectatie': ['affecteer', 'atie'],\n",
       " 'affectief': ['affect', 'ie', 'ief'],\n",
       " 'affichering': ['afficheer', 'ing'],\n",
       " 'affietsen': ['af', 'fiets'],\n",
       " 'affiliatie': ['affilieer', 'atie'],\n",
       " 'affineren': ['affineer'],\n",
       " ...}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dik2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_verbs(base):\n",
    "\n",
    "    verbs = {}\n",
    "    rest = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for word, dic in base.items():\n",
    "        \n",
    "        seg = dic['segments1']\n",
    "        split1 = seg.split('+')\n",
    "        split2 = dic['segments2']\n",
    "\n",
    "        concat1 = ''.join(split1)\n",
    "        concat2 = ''.join(split2)\n",
    "\n",
    "        if concat2 != word and len(seg) > 0:\n",
    "\n",
    "\n",
    "            if dic['cat'] == 'V':\n",
    "\n",
    "                verbs[word] = split2\n",
    "            \n",
    "            else:\n",
    "\n",
    "                rest[word] = split2\n",
    "\n",
    "\n",
    "    return verbs, rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, n = split_verbs(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, segs in v.items():\n",
    "    if segs[-1] == 'en':\n",
    "        print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aalbessengelei': ['aal', 'bes', 'en', 'gelei'],\n",
       " 'aalbessenjam': ['aal', 'bes', 'en', 'jam'],\n",
       " 'aalbessenjenever': ['aal', 'bes', 'en', 'jenever'],\n",
       " 'aalbessesap': ['aal', 'bes', 'e', 'sap'],\n",
       " 'aalbessestruik': ['aal', 'bes', 'e', 'struik'],\n",
       " 'aalmoezenier': ['aalmoes', 'enier'],\n",
       " 'aalmoezenierskamer': ['aalmoes', 'enier', 's', 'kamer'],\n",
       " 'aalsteker': ['aal', 'steek', 'er', 'NV'],\n",
       " 'aalvormig': ['aal', 'vorm', 'ig', 'NN'],\n",
       " 'aambeeldsbeentje': ['aambeeld', 's', 'been'],\n",
       " 'aamborstig': ['aam', 'borst', 'ig', 'NN'],\n",
       " 'aamborstigheid': ['aam', 'borst', 'ig', 'NN', 'heid'],\n",
       " 'aanaarding': ['aan', 'aarde', 'ing'],\n",
       " 'aanaardploeg': ['aan', 'aarde', 'ploeg'],\n",
       " 'aanbeeldsbeentje': ['aanbeeld', 's', 'been'],\n",
       " 'aanbesteder': ['aan', 'besteed', 'er'],\n",
       " 'aanbesteding': ['aan', 'besteed', 'ing'],\n",
       " 'aanbetaling': ['aan', 'betaal', 'ing'],\n",
       " 'aanbevelenswaard': ['aan', 'beveel', 's', 'waard'],\n",
       " 'aanbevelenswaardig': ['aan', 'beveel', 's', 'waarde', 'ig'],\n",
       " 'aanbeveling': ['aan', 'beveel', 'ing'],\n",
       " 'aanbevelingsbrief': ['aan', 'beveel', 'ing', 's', 'brief'],\n",
       " 'aanbiddelijk': ['aan', 'bid', 'elijk'],\n",
       " 'aanbiddenswaardig': ['aan', 'bid', 's', 'waarde', 'ig'],\n",
       " 'aanbidder': ['aan', 'bid', 'er'],\n",
       " 'aanbidding': ['aan', 'bid', 'ing'],\n",
       " 'aanblazing': ['aan', 'blaas', 'ing'],\n",
       " 'aandachtsconcentratie': ['aandacht', 's', 'concentreer', 'atie'],\n",
       " 'aandachttrekkerij': ['aandacht', 'trek', 'erij', 'NV'],\n",
       " 'aandamming': ['aan', 'dam', 'ing'],\n",
       " 'aandeelhebber': ['aan', 'deel', 'heb', 'er', 'NV'],\n",
       " 'aandeelhouder': ['aan', 'deel', 'houd', 'er', 'NV'],\n",
       " 'aandeelhoudersvergadering': ['aan',\n",
       "  'deel',\n",
       "  'houd',\n",
       "  'er',\n",
       "  'NV',\n",
       "  's',\n",
       "  'vergader',\n",
       "  'ing'],\n",
       " 'aandelenkapitaal': ['aan', 'deel', 'en', 'kapitaal'],\n",
       " 'aandelenoptie': ['aan', 'deel', 'en', 'optie'],\n",
       " 'aandelenpakket': ['aan', 'deel', 'en', 'pakket'],\n",
       " 'aandelenportefeuille': ['aan', 'deel', 'en', 'portefeuille'],\n",
       " 'aandoening': ['aan', 'doe', 'ing'],\n",
       " 'aandoenlijk': ['aan', 'doe', 'lijk'],\n",
       " 'aandoenlijkheid': ['aan', 'doe', 'lijk', 'heid'],\n",
       " 'aandrager': ['aan', 'draag', 'er'],\n",
       " 'aandrijver': ['aan', 'drijf', 'er'],\n",
       " 'aandrijving': ['aan', 'drijf', 'ing'],\n",
       " 'aaneengeboren': ['aaneen', 'B', 'geboren'],\n",
       " 'aaneengroeiing': ['aaneen', 'B', 'groei', 'ing'],\n",
       " 'aaneenkoppeling': ['aaneen', 'B', 'koppel', 'ing'],\n",
       " 'aaneenrijging': ['aaneen', 'B', 'rijg', 'ing'],\n",
       " 'aaneenschakeling': ['aaneen', 'B', 'schakel', 'ing'],\n",
       " 'aaneensluiting': ['aaneen', 'B', 'sluit', 'ing'],\n",
       " 'aaneenvoeging': ['aaneen', 'B', 'voeg', 'ing'],\n",
       " 'aanfokking': ['aan', 'fok', 'ing'],\n",
       " 'aangever': ['aan', 'geef', 'er'],\n",
       " 'aangeving': ['aan', 'geef', 'ing'],\n",
       " 'aangezichtsligging': ['aan', 'ge', 'zicht', 's', 'lig', 'ing'],\n",
       " 'aangraving': ['aan', 'graaf', 'ing'],\n",
       " 'aanhalerig': ['aan', 'haal', 'erig'],\n",
       " 'aanhalerigheid': ['aan', 'haal', 'erig', 'heid'],\n",
       " 'aanhalig': ['aan', 'haal', 'ig'],\n",
       " 'aanhaligheid': ['aan', 'haal', 'ig', 'heid'],\n",
       " 'aanhaling': ['aan', 'haal', 'ing'],\n",
       " 'aanhalingsteken': ['aan', 'haal', 'ing', 's', 'teken'],\n",
       " 'aanhankelijk': ['aan', 'hang', 'elijk'],\n",
       " 'aanhankelijkheid': ['aan', 'hang', 'elijk', 'heid'],\n",
       " 'aanheffer': ['aan', 'hef', 'er'],\n",
       " 'aanheffing': ['aan', 'hef', 'ing'],\n",
       " 'aanhoping': ['aan', 'hoop', 'ing'],\n",
       " 'aanjager': ['aan', 'jaag', 'er'],\n",
       " 'aanklager': ['aan', 'klaag', 'er'],\n",
       " 'aankleding': ['aan', 'kleed', 'ing'],\n",
       " 'aankleving': ['aan', 'kleef', 'ing'],\n",
       " 'aanknoping': ['aan', 'knoop', 'ing'],\n",
       " 'aanknopingspunt': ['aan', 'knoop', 'ing', 's', 'punt'],\n",
       " 'aankweking': ['aan', 'kweek', 'ing'],\n",
       " 'aanlassing': ['aan', 'las', 'ing'],\n",
       " 'aanlegger': ['aan', 'leg', 'er'],\n",
       " 'aanlegging': ['aan', 'leg', 'ing'],\n",
       " 'aanlokkelijk': ['aan', 'lok', 'elijk'],\n",
       " 'aanlokkelijkheid': ['aan', 'lok', 'elijk', 'heid'],\n",
       " 'aanlokking': ['aan', 'lok', 'ing'],\n",
       " 'aanloopkosten': ['aan', 'loop', 'kost'],\n",
       " 'aanlooppeiler': ['aan', 'loop', 'peil', 'er', 'NV'],\n",
       " 'aanlooptransformator': ['aan', 'loop', 'transformeer', 'ator', 'NV'],\n",
       " 'aanmaakblokje': ['aan', 'maak', 'blok'],\n",
       " 'aanmaakkosten': ['aan', 'maak', 'kost'],\n",
       " 'aanmaning': ['aan', 'maan', 'ing'],\n",
       " 'aanminnig': ['aan', 'min', 'ig'],\n",
       " 'aanminnigheid': ['aan', 'min', 'ig', 'heid'],\n",
       " 'aanmoediging': ['aan', 'moed', 'ig', 'PN', 'ing'],\n",
       " 'aanmoedigingsprijs': ['aan', 'moed', 'ig', 'PN', 'ing', 's', 'prijs'],\n",
       " 'aanmonding': ['aan', 'mond', 'ing', 'PN'],\n",
       " 'aannemelijk': ['aan', 'neem', 'elijk'],\n",
       " 'aannemelijkheid': ['aan', 'neem', 'elijk', 'heid'],\n",
       " 'aannemeling': ['aan', 'neem', 'eling'],\n",
       " 'aannemelinge': ['aan', 'neem', 'eling', 'e'],\n",
       " 'aannemer': ['aan', 'neem', 'er'],\n",
       " 'aannemersfirma': ['aan', 'neem', 'er', 's', 'firma'],\n",
       " 'aanneming': ['aan', 'neem', 'ing'],\n",
       " 'aannemingsbeleid': ['aan', 'neem', 'ing', 's', 'beleid'],\n",
       " 'aannemingsbiljet': ['aan', 'neem', 'ing', 's', 'biljet'],\n",
       " 'aannemingsmaatschappij': ['aan', 'neem', 'ing', 's', 'maatschappij'],\n",
       " 'aannemingssom': ['aan', 'neem', 'ing', 's', 'som'],\n",
       " 'aanpassing': ['aan', 'pas', 'ing'],\n",
       " 'aanpassingsbeleid': ['aan', 'pas', 'ing', 's', 'beleid'],\n",
       " 'aanpassingsgedrag': ['aan', 'pas', 'ing', 's', 'gedrag'],\n",
       " 'aanpassingsmanoeuvre': ['aan', 'pas', 'ing', 's', 'manoeuvre'],\n",
       " 'aanpassingsmechanisme': ['aan', 'pas', 'ing', 's', 'mechanisme'],\n",
       " 'aanpassingsmoeilijkheden': ['aan',\n",
       "  'pas',\n",
       "  'ing',\n",
       "  's',\n",
       "  'moei',\n",
       "  'lijk',\n",
       "  'heid'],\n",
       " 'aanpassingsmogelijkheid': ['aan', 'pas', 'ing', 's', 'mogelijk', 'heid'],\n",
       " 'aanpassingsperiode': ['aan', 'pas', 'ing', 's', 'periode'],\n",
       " 'aanpassingsprobleem': ['aan', 'pas', 'ing', 's', 'probleem'],\n",
       " 'aanpassingsproces': ['aan', 'pas', 'ing', 's', 'proces'],\n",
       " 'aanpassingsstoornis': ['aan', 'pas', 'ing', 's', 'stoor', 'nis'],\n",
       " 'aanpassingsstrategie': ['aan', 'pas', 'ing', 's', 'strategisch', 'ie'],\n",
       " 'aanpassingsvermogen': ['aan', 'pas', 'ing', 's', 'vermogen'],\n",
       " 'aanplakker': ['aan', 'plak', 'er'],\n",
       " 'aanplakking': ['aan', 'plak', 'ing'],\n",
       " 'aanpoting': ['aan', 'poot', 'ing'],\n",
       " 'aanprijzer': ['aan', 'prijs', 'er'],\n",
       " 'aanprijzing': ['aan', 'prijs', 'ing'],\n",
       " 'aanrader': ['aan', 'raad', 'er'],\n",
       " 'aanraking': ['aan', 'raak', 'ing'],\n",
       " 'aanrakingsangst': ['aan', 'raak', 'ing', 's', 'angst'],\n",
       " 'aanrakingspunt': ['aan', 'raak', 'ing', 's', 'punt'],\n",
       " 'aanrechtkastje': ['aanrecht', 'kast'],\n",
       " 'aanschaffing': ['aan', 'schaf', 'ing'],\n",
       " 'aanschrijving': ['aan', 'schrijf', 'ing'],\n",
       " 'aanschrijvingsbiljet': ['aan', 'schrijf', 'ing', 's', 'biljet'],\n",
       " 'aansjorring': ['aan', 'sjor', 'ing'],\n",
       " 'aanslibbing': ['aan', 'slib', 'ing'],\n",
       " 'aansluitingskosten': ['aan', 'sluit', 'ing', 's', 'kost'],\n",
       " 'aansmering': ['aan', 'smeer', 'ing'],\n",
       " 'aanspanner': ['aan', 'span', 'er'],\n",
       " 'aanspanning': ['aan', 'span', 'ing'],\n",
       " 'aansporing': ['aan', 'spoor', 'ing'],\n",
       " 'aansprakelijk': ['aan', 'spreek', 'elijk'],\n",
       " 'aansprakelijkheid': ['aan', 'spreek', 'elijk', 'heid'],\n",
       " 'aansprakelijkheidsverzekering': ['aan',\n",
       "  'spreek',\n",
       "  'elijk',\n",
       "  'heid',\n",
       "  's',\n",
       "  'ver',\n",
       "  'zeker',\n",
       "  'ing'],\n",
       " 'aanspreker': ['aan', 'spreek', 'er'],\n",
       " 'aanspreking': ['aan', 'spreek', 'ing'],\n",
       " 'aanstekelijk': ['aan', 'steek', 'elijk'],\n",
       " 'aanstekelijkheid': ['aan', 'steek', 'elijk', 'heid'],\n",
       " 'aansteker': ['aan', 'steek', 'er'],\n",
       " 'aansteking': ['aan', 'steek', 'ing'],\n",
       " 'aansteller': ['aan', 'stel', 'er'],\n",
       " 'aanstellerig': ['aan', 'stel', 'erig'],\n",
       " 'aanstellerigheid': ['aan', 'stel', 'erig', 'heid'],\n",
       " 'aanstellerij': ['aan', 'stel', 'erij'],\n",
       " 'aanstelling': ['aan', 'stel', 'ing'],\n",
       " 'aanstellingsbeleid': ['aan', 'stel', 'ing', 's', 'beleid'],\n",
       " 'aanstellingsbrief': ['aan', 'stel', 'ing', 's', 'brief'],\n",
       " 'aanstipping': ['aan', 'stip', 'ing'],\n",
       " 'aanstoker': ['aan', 'stook', 'er'],\n",
       " 'aanstotelijk': ['aan', 'stoot', 'elijk'],\n",
       " 'aanstotelijkheid': ['aan', 'stoot', 'elijk', 'heid'],\n",
       " 'aanstoting': ['aan', 'stoot', 'ing'],\n",
       " 'aanstreping': ['aan', 'streep', 'ing'],\n",
       " 'aanstuiving': ['aan', 'stuif', 'ing'],\n",
       " 'aanteling': ['aan', 'teel', 'ing'],\n",
       " 'aantoning': ['aan', 'toon', 'ing'],\n",
       " 'aantreeplaats': ['aan', 'treed', 'plaats'],\n",
       " 'aantrekkelijk': ['aan', 'trek', 'elijk'],\n",
       " 'aantrekkelijkheid': ['aan', 'trek', 'elijk', 'heid'],\n",
       " 'aantrekker': ['aan', 'trek', 'er'],\n",
       " 'aantrekking': ['aan', 'trek', 'ing'],\n",
       " 'aantrekkingskracht': ['aan', 'trek', 'ing', 's', 'kracht'],\n",
       " 'aantrekkingsvermogen': ['aan', 'trek', 'ing', 's', 'vermogen'],\n",
       " 'aanvallenderwijs': ['aan', 'val', 'enderwijs', 'B', 'B'],\n",
       " 'aanvallenderwijze': ['aan', 'val', 'enderwijze', 'B', 'B'],\n",
       " 'aanvaller': ['aan', 'val', 'er'],\n",
       " 'aanvallig': ['aan', 'val', 'ig'],\n",
       " 'aanvalligheid': ['aan', 'val', 'ig', 'heid'],\n",
       " 'aanvalspositie': ['aanval', 's', 'pose', 'eer', 'itie'],\n",
       " 'aanvalstactiek': ['aanval', 's', 'tact', 'isch', 'iek'],\n",
       " 'aanvangssituatie': ['aanvang', 's', 'situeer', 'atie'],\n",
       " 'aanvankelijk': ['aan', 'vang', 'elijk'],\n",
       " 'aanvaring': ['aan', 'vaar', 'ing'],\n",
       " 'aanvaringsschot': ['aan', 'vaar', 'ing', 's', 'schot'],\n",
       " 'aanvatting': ['aan', 'vat', 'ing'],\n",
       " 'aanvrager': ['aan', 'vraag', 'er'],\n",
       " 'aanvulling': ['aan', 'vul', 'ing'],\n",
       " 'aanvullingsbegroting': ['aan', 'vul', 'ing', 's', 'be', 'groot', 'ing'],\n",
       " 'aanvullingsexamen': ['aan', 'vul', 'ing', 's', 'examen'],\n",
       " 'aanvullingskohier': ['aan', 'vul', 'ing', 's', 'kohier'],\n",
       " 'aanvullingstroepen': ['aan', 'vul', 'ing', 's', 'troep'],\n",
       " 'aanvuring': ['aan', 'vuur', 'ing'],\n",
       " 'aanwassing': ['aan', 'was', 'ing'],\n",
       " 'aanwenning': ['aan', 'wen', 'ing'],\n",
       " 'aanwerver': ['aan', 'werf', 'er'],\n",
       " 'aanwerving': ['aan', 'werf', 'ing'],\n",
       " 'aanwijzer': ['aan', 'wijs', 'er'],\n",
       " 'aanwijzing': ['aan', 'wijs', 'ing'],\n",
       " 'aanwijzingsbevoegdheid': ['aan', 'wijs', 'ing', 's', 'bevoegd', 'heid'],\n",
       " 'aanwijzingsbord': ['aan', 'wijs', 'ing', 's', 'bord'],\n",
       " 'aanwinning': ['aan', 'win', 'ing'],\n",
       " 'aanwrijving': ['aan', 'wrijf', 'ing'],\n",
       " 'aanzegger': ['aan', 'zeg', 'er'],\n",
       " 'aanzegging': ['aan', 'zeg', 'ing'],\n",
       " 'aanzetter': ['aan', 'zet', 'er'],\n",
       " 'aanzetting': ['aan', 'zet', 'ing'],\n",
       " 'aapjessnuif': ['aap', 's', 'snuif'],\n",
       " 'aapjeszeep': ['aap', 's', 'zeep'],\n",
       " 'aarden': ['aarde', 'en'],\n",
       " 'aardamandel': ['aarde', 'amandel'],\n",
       " 'aardappel': ['aarde', 'appel'],\n",
       " 'aardappelakker': ['aarde', 'appel', 'akker'],\n",
       " 'aardappelbak': ['aarde', 'appel', 'bak'],\n",
       " 'aardappelboer': ['aarde', 'appel', 'boer'],\n",
       " 'aardappelbovist': ['aarde', 'appel', 'bovist'],\n",
       " 'aardappelbuik': ['aarde', 'appel', 'buik'],\n",
       " 'aardappelcampagne': ['aarde', 'appel', 'campagne'],\n",
       " 'aardappelcroquet': ['aarde', 'appel', 'croquet'],\n",
       " 'aardappeldeeg': ['aarde', 'appel', 'deeg'],\n",
       " 'aardappelhakker': ['aarde', 'appel', 'hak', 'er', 'NV'],\n",
       " 'aardappelkelder': ['aarde', 'appel', 'kelder'],\n",
       " 'aardappelkever': ['aarde', 'appel', 'kever'],\n",
       " 'aardappelknol': ['aarde', 'appel', 'knol'],\n",
       " 'aardappelkriel': ['aarde', 'appel', 'kriel'],\n",
       " 'aardappelmeel': ['aarde', 'appel', 'meel'],\n",
       " 'aardappelmesje': ['aarde', 'appel', 'mes'],\n",
       " 'aardappelmoeheid': ['aarde', 'appel', 'moe', 'heid'],\n",
       " 'aardappelpan': ['aarde', 'appel', 'pan'],\n",
       " 'aardappelplant': ['aarde', 'appel', 'plant'],\n",
       " 'aardappelpoter': ['aarde', 'appel', 'poot', 'er', 'NV'],\n",
       " 'aardappelpuree': ['aarde', 'appel', 'puree'],\n",
       " 'aardappelrooier': ['aarde', 'appel', 'rooi', 'er'],\n",
       " 'aardappelsalade': ['aarde', 'appel', 'salade'],\n",
       " 'aardappelschijf': ['aarde', 'appel', 'schijf'],\n",
       " 'aardappelschiller': ['aarde', 'appel', 'schil', 'er', 'NV'],\n",
       " 'aardappelschilmesje': ['aarde', 'appel', 'schilmes'],\n",
       " 'aardappelsoep': ['aarde', 'appel', 'soep'],\n",
       " 'aardappelstijfsel': ['aarde', 'appel', 'stijf', 'sel'],\n",
       " 'aardappelstroop': ['aarde', 'appel', 'stroop'],\n",
       " 'aardappelveld': ['aarde', 'appel', 'veld'],\n",
       " 'aardappelvlokken': ['aarde', 'appel', 'vlok'],\n",
       " 'aardappelziekte': ['aarde', 'appel', 'ziek', 'te'],\n",
       " 'aardas': ['aarde', 'as'],\n",
       " 'aardatmosfeer': ['aarde', 'atmosfeer'],\n",
       " 'aardbaan': ['aarde', 'baan'],\n",
       " 'aardberging': ['aarde', 'berg', 'ing', 'NV'],\n",
       " 'aardbeving': ['aarde', 'beef', 'ing'],\n",
       " 'aardbevingsgebied': ['aarde', 'beef', 'ing', 's', 'gebied'],\n",
       " 'aardbevingsgolf': ['aarde', 'beef', 'ing', 's', 'golf'],\n",
       " 'aardbevingsgordel': ['aarde', 'beef', 'ing', 's', 'gordel'],\n",
       " 'aardbevingshaard': ['aarde', 'beef', 'ing', 's', 'haard'],\n",
       " 'aardbevingsmeter': ['aarde', 'beef', 'ing', 's', 'Vx', 'meet', 'er', 'NxV'],\n",
       " 'aardbewoner': ['aarde', 'be', 'woon', 'er', 'NV'],\n",
       " 'aardbewoonster': ['aarde', 'be', 'woon', 'ster', 'NV'],\n",
       " 'aardbij': ['aarde', 'bij'],\n",
       " 'aardbodem': ['aarde', 'bodem'],\n",
       " 'aardbol': ['aarde', 'bol'],\n",
       " 'aardboog': ['aarde', 'boog'],\n",
       " 'aardboor': ['aarde', 'boor'],\n",
       " 'aardbrand': ['aarde', 'brand'],\n",
       " 'aardbuil': ['aarde', 'buil'],\n",
       " 'aardduivel': ['aarde', 'duivel'],\n",
       " 'aardgas': ['aarde', 'gas'],\n",
       " 'aardgasbaten': ['aarde', 'gas', 'baat'],\n",
       " 'aardgasbel': ['aarde', 'gas', 'bel'],\n",
       " 'aardgasnet': ['aarde', 'gas', 'net'],\n",
       " 'aardgasopbrengst': ['aarde', 'gas', 'op', 'breng', 'st'],\n",
       " 'aardgastanker': ['aarde', 'gas', 'tank', 'er'],\n",
       " 'aardgasterminal': ['aarde', 'gas', 'terminal'],\n",
       " 'aardgeest': ['aarde', 'geest'],\n",
       " 'aardgewas': ['aarde', 'ge', 'was'],\n",
       " 'aardglobe': ['aarde', 'globe'],\n",
       " 'aardgoed': ['aarde', 'goed'],\n",
       " 'aardgordel': ['aarde', 'gordel'],\n",
       " 'aardhars': ['aarde', 'hars'],\n",
       " 'aardhommel': ['aarde', 'hommel'],\n",
       " 'aardhoop': ['aarde', 'hoop'],\n",
       " 'aardigjes': ['aardig', 'jes', 'B', 'B'],\n",
       " 'aardkastanje': ['aarde', 'kastanje'],\n",
       " 'aardkern': ['aarde', 'kern'],\n",
       " 'aardklomp': ['aarde', 'klomp'],\n",
       " 'aardklont': ['aarde', 'klont'],\n",
       " 'aardkloot': ['aarde', 'kloot'],\n",
       " 'aardkluit': ['aarde', 'kluit'],\n",
       " 'aardkorst': ['aarde', 'korst'],\n",
       " 'aardkrekel': ['aarde', 'krekel'],\n",
       " 'aardkromming': ['aarde', 'krom', 'ing'],\n",
       " 'aardkuil': ['aarde', 'kuil'],\n",
       " 'aardkunde': ['aarde', 'kunde'],\n",
       " 'aardkundig': ['aarde', 'kunde', 'ig'],\n",
       " 'aardlaag': ['aarde', 'laag'],\n",
       " 'aardleiding': ['aarde', 'leid', 'ing'],\n",
       " 'aardlevering': ['aarde', 'lever', 'ing'],\n",
       " 'aardmagnetisme': ['aarde', 'magnetisme'],\n",
       " 'aardmannetje': ['aarde', 'man'],\n",
       " 'aardmassa': ['aarde', 'massa'],\n",
       " 'aardmeetkunde': ['aarde', 'meet', 'kunde'],\n",
       " 'aardmetalen': ['aarde', 'metaal'],\n",
       " 'aardmeting': ['aarde', 'meet', 'ing', 'NV'],\n",
       " 'aardmijt': ['aarde', 'mijt'],\n",
       " 'aardmolm': ['aarde', 'molm'],\n",
       " 'aardmuis': ['aarde', 'muis'],\n",
       " 'aardnoot': ['aarde', 'noot'],\n",
       " 'aardnotenolie': ['aarde', 'noot', 'en', 'olie'],\n",
       " 'aardolie': ['aarde', 'olie'],\n",
       " 'aardolieprodukt': ['aarde', 'olie', 'produkt'],\n",
       " 'aardoppervlak': ['aarde', 'opper', 'vlak'],\n",
       " 'aardoppervlakte': ['aarde', 'opper', 'vlak', 'te'],\n",
       " 'aardpeer': ['aarde', 'peer'],\n",
       " 'aardpek': ['aarde', 'pek'],\n",
       " 'aardplooi': ['aarde', 'plooi'],\n",
       " 'aardpool': ['aarde', 'pool'],\n",
       " 'aardprofiel': ['aarde', 'profiel'],\n",
       " 'aardrijk': ['aarde', 'rijk'],\n",
       " 'aardrijkskunde': ['aarde', 'rijk', 's', 'kunde'],\n",
       " 'aardrijkskundeboek': ['aarde', 'rijk', 's', 'kunde', 'boek'],\n",
       " 'aardrijkskundig': ['aarde', 'rijk', 's', 'kunde', 'ig'],\n",
       " 'aardrol': ['aarde', 'rol'],\n",
       " 'aardrook': ['aarde', 'rook'],\n",
       " 'aardrups': ['aarde', 'rups'],\n",
       " 'aards': ['aarde', 's'],\n",
       " 'aardschaduw': ['aarde', 'schaduw'],\n",
       " 'aardschijn': ['aarde', 'schijn'],\n",
       " 'aardschok': ['aarde', 'schok'],\n",
       " 'aardschors': ['aarde', 'schors'],\n",
       " 'aardschudding': ['aarde', 'schud', 'ing'],\n",
       " 'aardsgezind': ['aarde', 's', 'gezind'],\n",
       " 'aardsgezindheid': ['aarde', 's', 'gezind', 'heid'],\n",
       " 'aardsheid': ['aarde', 's', 'heid'],\n",
       " 'aardslak': ['aarde', 'slak'],\n",
       " 'aardslang': ['aarde', 'slang'],\n",
       " 'aardsluiting': ['aarde', 'sluit', 'ing'],\n",
       " 'aardspin': ['aarde', 'spin'],\n",
       " 'aardster': ['aarde', 'ster'],\n",
       " 'aardstorting': ['aarde', 'stort', 'ing'],\n",
       " 'aardstraal': ['aarde', 'straal'],\n",
       " 'aardstralenkastje': ['aarde', 'straal', 'en', 'kast'],\n",
       " 'aardstraling': ['aarde', 'straal', 'ing'],\n",
       " 'aardstroom': ['aarde', 'stroom'],\n",
       " 'aardtor': ['aarde', 'tor'],\n",
       " 'aardtrilling': ['aarde', 'tril', 'ing'],\n",
       " 'aardvarken': ['aarde', 'varken'],\n",
       " 'aardvast': ['aarde', 'vast'],\n",
       " 'aardveil': ['aarde', 'veil'],\n",
       " 'aardverbinding': ['aarde', 'ver', 'bind', 'ing'],\n",
       " 'aardverschuiving': ['aarde', 'ver', 'schuif', 'ing'],\n",
       " 'aardverf': ['aarde', 'verf'],\n",
       " 'aardvlo': ['aarde', 'vlo'],\n",
       " 'aardvork': ['aarde', 'vork'],\n",
       " 'aardvrucht': ['aarde', 'vrucht'],\n",
       " 'aardwarmte': ['aarde', 'warm', 'te'],\n",
       " 'aardwas': ['aarde', 'was'],\n",
       " 'aardwerk': ['aarde', 'werk'],\n",
       " 'aardwerker': ['aarde', 'werk', 'er'],\n",
       " 'aardwetenschappen': ['aarde', 'weten', 'schap'],\n",
       " 'aardwinde': ['aarde', 'winde'],\n",
       " 'aardwolf': ['aarde', 'wolf'],\n",
       " 'aardworm': ['aarde', 'worm'],\n",
       " 'aartsbisschoppelijk': ['aarts', 'bisschop', 'elijk'],\n",
       " 'aartsconservatief': ['aarts', 'conserveer', 'atie', 'ief'],\n",
       " 'aartsdeugniet': ['aarts', 'deug', 'niet', 'B'],\n",
       " 'aartsliefhebber': ['aarts', 'lief', 'heb', 'er'],\n",
       " 'aartsverrader': ['aarts', 'verraad', 'er'],\n",
       " 'aarvormig': ['aar', 'vorm', 'ig', 'NN'],\n",
       " 'aaseter': ['aas', 'eet', 'er', 'NV'],\n",
       " 'aasjager': ['aas', 'jaag', 'er', 'NV'],\n",
       " 'aatje': ['aat'],\n",
       " 'aasje': ['aas'],\n",
       " 'abandonnement': ['abandon', 'eer', 'ement'],\n",
       " 'abbatiaal': ['abt', 'aal'],\n",
       " 'abbreviatie': ['abbrevieer', 'atie'],\n",
       " 'abbreviatuur': ['abbrevieer', 'atuur'],\n",
       " 'abc-boek': ['abc', 'boek'],\n",
       " 'ABC-wapens': ['abc', 'wapen'],\n",
       " 'abdicatie': ['abdiceer', 'atie'],\n",
       " 'abdominaal': ['abdomen', 'aal'],\n",
       " 'abelenlaan': ['abeel', 'en', 'laan'],\n",
       " 'A-biljet': ['a', 'biljet'],\n",
       " 'abnormaliteit': ['abnormaal', 'iteit'],\n",
       " 'abolitie': ['aboleer', 'itie'],\n",
       " 'A-bom': ['a', 'bom'],\n",
       " 'abondance': ['abondant', 'nce'],\n",
       " 'abonnement': ['abonneer', 'ement'],\n",
       " 'abonnementhouder': ['abonneer', 'ement', 'houd', 'er', 'NV'],\n",
       " 'abonnementhoudster': ['abonneer', 'ement', 'houd', 'ster', 'NV'],\n",
       " 'abonnementsconcert': ['abonneer', 'ement', 's', 'concert'],\n",
       " 'abonnementshonorarium': ['abonneer', 'ement', 's', 'honorarium'],\n",
       " 'abonnementskaart': ['abonneer', 'ement', 's', 'kaart'],\n",
       " 'abonnementsprijsverhoging': ['abonneer',\n",
       "  'ement',\n",
       "  's',\n",
       "  'prijs',\n",
       "  'ver',\n",
       "  'hoog',\n",
       "  'ing',\n",
       "  'NV'],\n",
       " 'abonnementstarief': ['abonneer', 'ement', 's', 'tarief'],\n",
       " 'abonnementsvoorstelling': ['abonneer',\n",
       "  'ement',\n",
       "  's',\n",
       "  'voor',\n",
       "  'B',\n",
       "  'stel',\n",
       "  'ing'],\n",
       " 'aborteur': ['abortus', 'eer', 'eur'],\n",
       " 'abortief': ['abortus', 'ief'],\n",
       " 'abortuskliniek': ['abortus', 'klinisch', 'iek'],\n",
       " 'abrikozeboom': ['abrikoos', 'e', 'boom'],\n",
       " 'abrikozengelei': ['abrikoos', 'en', 'gelei'],\n",
       " 'abrikozentaart': ['abrikoos', 'en', 'taart'],\n",
       " 'abrikozepit': ['abrikoos', 'e', 'pit'],\n",
       " 'abrikozeschil': ['abrikoos', 'e', 'schil'],\n",
       " 'absence': ['absent', 'nce'],\n",
       " 'absolutie': ['absolveer', 'utie'],\n",
       " 'absorbaat': ['absorbeer', 'aat'],\n",
       " 'abstinent': ['abstineer', 'ent'],\n",
       " 'abstinentie': ['abstineer', 'ent', 'ie'],\n",
       " 'abstinentiedag': ['abstineer', 'ent', 'ie', 'dag'],\n",
       " 'abstinentiesyndroom': ['abstineer', 'ent', 'ie', 'syndroom'],\n",
       " 'abstinentieverschijnsel': ['abstineer', 'ent', 'ie', 'verschijn', 'sel'],\n",
       " 'abstrahering': ['abstract', 'eer', 'ing'],\n",
       " 'abusief': ['abuis', 'ief'],\n",
       " 'academie': ['academisch', 'ie'],\n",
       " 'academiedag': ['academisch', 'ie', 'dag'],\n",
       " 'academiegebouw': ['academisch', 'ie', 'ge', 'bouw'],\n",
       " 'academiejaar': ['academisch', 'ie', 'jaar'],\n",
       " 'academiestad': ['academisch', 'ie', 'stad'],\n",
       " 'academievergadering': ['academisch', 'ie', 'vergader', 'ing'],\n",
       " 'academievriend': ['academisch', 'ie', 'vriend'],\n",
       " 'acceleratie': ['accelereer', 'atie'],\n",
       " 'acceleratiepomp': ['accelereer', 'atie', 'pomp'],\n",
       " 'acceleratieproef': ['accelereer', 'atie', 'proef'],\n",
       " 'acceleratievermogen': ['accelereer', 'atie', 'vermogen'],\n",
       " 'accelerator': ['accelereer', 'ator'],\n",
       " 'accentuatie': ['accent', 'ueer', 'atie'],\n",
       " 'accentuering': ['accent', 'ueer', 'ing'],\n",
       " 'accentverlegging': ['accent', 'ver', 'leg', 'ing', 'NV'],\n",
       " 'accentverschuiving': ['accent', 'ver', 'schuif', 'ing'],\n",
       " 'acceptabel': ['accept', 'eer', 'abel'],\n",
       " 'acceptant': ['accept', 'eer', 'ant'],\n",
       " 'acceptatie': ['accept', 'eer', 'atie'],\n",
       " 'acceptatiegraad': ['accept', 'eer', 'atie', 'graad'],\n",
       " 'accessie': ['acces', 'ie'],\n",
       " 'accijnsrechten': ['accijns', 'recht'],\n",
       " 'acclimatisatie': ['acclimatiseer', 'atie'],\n",
       " 'acclimatisatieproces': ['acclimatiseer', 'atie', 'proces'],\n",
       " 'acclimatisatiestation': ['acclimatiseer', 'atie', 'station'],\n",
       " 'acclimatisatietuin': ['acclimatiseer', 'atie', 'tuin'],\n",
       " 'acclimatisering': ['acclimatiseer', 'ing'],\n",
       " 'accommodatie': ['accommodeer', 'atie'],\n",
       " 'accommodatiebeleid': ['accommodeer', 'atie', 'beleid'],\n",
       " 'accommodatieflat': ['accommodeer', 'atie', 'flat'],\n",
       " 'accommodatieplatform': ['accommodeer', 'atie', 'platform'],\n",
       " 'accommodatievermogen': ['accommodeer', 'atie', 'vermogen'],\n",
       " 'accompagnateur': ['accompagneer', 'ateur'],\n",
       " 'accompagnement': ['accompagneer', 'ement'],\n",
       " 'accoucheur': ['accoucheer', 'eur'],\n",
       " 'accountants-administratieconsulent': ['accountant',\n",
       "  's',\n",
       "  'NN',\n",
       "  'administreer',\n",
       "  'atie',\n",
       "  'consulent'],\n",
       " 'accumulatie': ['accumuleer', 'atie'],\n",
       " 'accumulatietheorie': ['accumuleer', 'atie', 'theorie'],\n",
       " 'accumulatief': ['accumuleer', 'atie', 'ief'],\n",
       " 'accumulator': ['accumuleer', 'ator'],\n",
       " 'accumulatorcentrale': ['accumuleer', 'ator', 'centrum', 'aal', 'e'],\n",
       " 'accumulatorenbatterij': ['accumuleer', 'ator', 'en', 'batterij'],\n",
       " 'accuratesse': ['accuraat', 'esse'],\n",
       " 'accusatie': ['accuseer', 'atie'],\n",
       " 'achilleshiel': ['Achilles', 'hiel'],\n",
       " 'achillespees': ['Achilles', 'pees'],\n",
       " 'a-christelijk': ['a', 'christen', 'elijk'],\n",
       " 'achtarm': ['acht', 'Q', 'arm'],\n",
       " 'achtarmig': ['acht', 'Q', 'arm', 'ig', 'QN'],\n",
       " 'achtdaags': ['acht', 'Q', 'dag', 's', 'QN'],\n",
       " 'achtdubbel': ['acht', 'Q', 'dubbel'],\n",
       " 'achtduizend': ['acht', 'Q', 'duizend', 'Q', 'Q'],\n",
       " 'achtduizendste': ['acht', 'Q', 'duizend', 'Q', 'Q', 'ste', 'Q', 'Q', 'Q'],\n",
       " 'achtender': ['acht', 'Q', 'end', 'er', 'QN'],\n",
       " 'achtendertig': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'drie',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtendertigste': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'drie',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtenswaard': ['acht', 's', 'waard'],\n",
       " 'achtenswaardig': ['acht', 's', 'waarde', 'ig'],\n",
       " 'achtenswaardigheid': ['acht', 's', 'waarde', 'ig', 'heid'],\n",
       " 'achtentwintig': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'twee',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtentwintigduizend': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'twee',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'duizend',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtentwintigduizendste': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'twee',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'duizend',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achtentwintigste': ['acht',\n",
       "  'Q',\n",
       "  'en',\n",
       "  'C',\n",
       "  'twee',\n",
       "  'Q',\n",
       "  'tig',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achteraan': ['achter', 'B', 'aan', 'B'],\n",
       " 'achteraandrijving': ['achter', 'B', 'aan', 'drijf', 'ing'],\n",
       " 'achteraanzicht': ['achter', 'B', 'aanzicht'],\n",
       " 'achteraf': ['achter', 'af', 'B'],\n",
       " 'achterafbuurt': ['achter', 'af', 'B', 'buurt'],\n",
       " 'achterafje': ['achter', 'af', 'B', 'je', 'B'],\n",
       " 'achterafstraat': ['achter', 'af', 'B', 'straat'],\n",
       " 'achteras': ['achter', 'B', 'as'],\n",
       " 'achterbak': ['achter', 'B', 'bak'],\n",
       " 'achterbalk': ['achter', 'B', 'balk'],\n",
       " 'achterbalkon': ['achter', 'B', 'balkon'],\n",
       " 'achterban': ['achter', 'B', 'ban'],\n",
       " 'achterband': ['achter', 'B', 'band'],\n",
       " 'achterbank': ['achter', 'B', 'bank'],\n",
       " 'achterbeen': ['achter', 'B', 'been'],\n",
       " 'achterbil': ['achter', 'B', 'bil'],\n",
       " 'achterblijfster': ['achter', 'B', 'blijf', 'ster'],\n",
       " 'achterblijver': ['achter', 'B', 'blijf', 'er'],\n",
       " 'achterboom': ['achter', 'B', 'boom'],\n",
       " 'achterbout': ['achter', 'B', 'bout'],\n",
       " 'achterbuur': ['achter', 'B', 'buur'],\n",
       " 'achterbuurman': ['achter', 'B', 'buur', 'man'],\n",
       " 'achterbuurt': ['achter', 'B', 'buurt'],\n",
       " 'achterbuurttaal': ['achter', 'B', 'buurt', 'taal'],\n",
       " 'achterbuurvrouw': ['achter', 'B', 'buur', 'vrouw'],\n",
       " 'achterdak': ['achter', 'B', 'dak'],\n",
       " 'achterdeel': ['achter', 'B', 'deel'],\n",
       " 'achterdek': ['achter', 'B', 'dek'],\n",
       " 'achterdeur': ['achter', 'B', 'deur'],\n",
       " 'achterdijks': ['achter', 'dijk', 's', 'PN'],\n",
       " 'achterdoek': ['achter', 'B', 'doek'],\n",
       " 'achtereenvolgend': ['achtereen', 'B', 'volgend'],\n",
       " 'achtereind': ['achter', 'B', 'eind'],\n",
       " 'achtereinde': ['achter', 'B', 'einde'],\n",
       " 'achterelkaar': ['achter', 'B', 'elkaar', 'O', 'B'],\n",
       " 'achterelkander': ['achter', 'B', 'elkander', 'O', 'B'],\n",
       " 'achtererf': ['achter', 'B', 'erf'],\n",
       " 'achterflap': ['achter', 'B', 'flap'],\n",
       " 'achtergalerij': ['achter', 'B', 'galerij'],\n",
       " 'achtergang': ['achter', 'B', 'gang'],\n",
       " 'achtergebouw': ['achter', 'B', 'ge', 'bouw'],\n",
       " 'achtergedeelte': ['achter', 'B', 'ge', 'Nx', 'deel', 'te', 'xN'],\n",
       " 'achtergevel': ['achter', 'B', 'gevel'],\n",
       " 'achtergracht': ['achter', 'B', 'gracht'],\n",
       " 'achtergrond': ['achter', 'B', 'grond'],\n",
       " 'achtergrondartikel': ['achter', 'B', 'grond', 'artikel'],\n",
       " 'achtergronddecor': ['achter', 'B', 'grond', 'decor'],\n",
       " 'achtergrondfiguur': ['achter', 'B', 'grond', 'figuur'],\n",
       " 'achtergrondgegeven': ['achter', 'B', 'grond', 'gegeven'],\n",
       " 'achtergrondgeheugen': ['achter', 'B', 'grond', 'geheugen'],\n",
       " 'achtergrondgeluid': ['achter', 'B', 'grond', 'ge', 'luid'],\n",
       " 'achtergrondgesprek': ['achter', 'B', 'grond', 'gesprek'],\n",
       " 'achtergrondinformatie': ['achter', 'B', 'grond', 'informeer', 'atie', 'NV'],\n",
       " 'achtergrondkoor': ['achter', 'B', 'grond', 'koor'],\n",
       " 'achtergrondmateriaal': ['achter', 'B', 'grond', 'materie', 'aal'],\n",
       " 'achtergrondmotief': ['achter', 'B', 'grond', 'motief'],\n",
       " 'achtergrondmuziek': ['achter', 'B', 'grond', 'muziek'],\n",
       " 'achtergrondstraling': ['achter', 'B', 'grond', 'straal', 'ing'],\n",
       " 'achtergrondstudie': ['achter', 'B', 'grond', 'studie'],\n",
       " 'achterhaalbaar': ['achter', 'B', 'haal', 'baar'],\n",
       " 'achterhaling': ['achter', 'B', 'haal', 'ing'],\n",
       " 'achterham': ['achter', 'B', 'ham'],\n",
       " 'achterhand': ['achter', 'B', 'hand'],\n",
       " 'achterhandsbeentje': ['achter', 'B', 'hand', 's', 'been'],\n",
       " 'achterheen': ['achter', 'B', 'heen', 'B', 'B'],\n",
       " 'achterhesp': ['achter', 'B', 'hesp'],\n",
       " 'achterhoede': ['achter', 'B', 'hoede'],\n",
       " 'achterhoedegevecht': ['achter', 'B', 'hoede', 'ge', 'vecht'],\n",
       " 'achterhoedespeelster': ['achter', 'B', 'hoede', 'speel', 'ster'],\n",
       " 'achterhoedespeler': ['achter', 'B', 'hoede', 'speel', 'er'],\n",
       " 'achterhoek': ['achter', 'B', 'hoek'],\n",
       " 'achterhoofd': ['achter', 'B', 'hoofd'],\n",
       " 'achterhoofdsbeen': ['achter', 'B', 'hoofd', 's', 'been'],\n",
       " 'achterhoofdsknobbel': ['achter', 'B', 'hoofd', 's', 'knobbel'],\n",
       " 'achterhoofdsligging': ['achter', 'B', 'hoofd', 's', 'lig', 'ing'],\n",
       " 'achterhouding': ['achter', 'B', 'houd', 'ing'],\n",
       " 'achterhout': ['achter', 'B', 'hout'],\n",
       " 'achterhuis': ['achter', 'B', 'huis'],\n",
       " 'achterin': ['achter', 'in', 'B'],\n",
       " 'achteringang': ['achter', 'B', 'ingang'],\n",
       " 'achterkamer': ['achter', 'B', 'kamer'],\n",
       " 'achterkant': ['achter', 'B', 'kant'],\n",
       " 'achterkasteel': ['achter', 'B', 'kasteel'],\n",
       " 'achterkeuken': ['achter', 'B', 'keuken'],\n",
       " 'achterkleindochter': ['achter', 'B', 'kleindochter'],\n",
       " 'achterkleinkind': ['achter', 'B', 'kleinkind'],\n",
       " 'achterkleinzoon': ['achter', 'B', 'kleinzoon'],\n",
       " 'achterklep': ['achter', 'B', 'klep'],\n",
       " 'achterklinker': ['achter', 'B', 'klink', 'er'],\n",
       " 'achterkwab': ['achter', 'B', 'kwab'],\n",
       " 'achterkwartier': ['achter', 'B', 'kwart', 'ier'],\n",
       " 'achterlader': ['achter', 'B', 'laad', 'er'],\n",
       " 'achterland': ['achter', 'B', 'land'],\n",
       " 'achterlap': ['achter', 'B', 'lap'],\n",
       " 'achterlast': ['achter', 'B', 'last'],\n",
       " 'achterlastig': ['achter', 'B', 'last', 'ig'],\n",
       " 'achterlating': ['achter', 'B', 'laat', 'ing'],\n",
       " 'achterleen': ['achter', 'B', 'leen'],\n",
       " 'achterleenheer': ['achter', 'B', 'leen', 'heer'],\n",
       " 'achterleenman': ['achter', 'B', 'leen', 'man'],\n",
       " 'achterlichaam': ['achter', 'B', 'lichaam'],\n",
       " 'achterlicht': ['achter', 'B', 'licht'],\n",
       " 'achterligger': ['achter', 'B', 'lig', 'er'],\n",
       " 'achterlijfssegment': ['achter', 'B', 'lijf', 's', 'segment'],\n",
       " 'achterlijk': ['achter', 'B', 'lijk', 'B'],\n",
       " 'achterlijkheid': ['achter', 'B', 'lijk', 'B', 'heid'],\n",
       " 'achterlijf': ['achter', 'B', 'lijf'],\n",
       " 'achterloper': ['achter', 'B', 'loop', 'er'],\n",
       " 'achterluik': ['achter', 'B', 'luik'],\n",
       " 'achterman': ['achter', 'B', 'man'],\n",
       " 'achtermiddag': ['achter', 'B', 'middag'],\n",
       " 'achternaad': ['achter', 'B', 'naad'],\n",
       " 'achternaam': ['achter', 'B', 'naam'],\n",
       " 'achternageloop': ['achterna', 'B', 'ge', 'loop'],\n",
       " 'achternamiddag': ['achter', 'B', 'na', 'middag'],\n",
       " 'achterneef': ['achter', 'B', 'neef'],\n",
       " 'achternicht': ['achter', 'B', 'nicht'],\n",
       " 'achteronder': ['achter', 'B', 'onder', 'B'],\n",
       " 'achterop': ['achter', 'op', 'B'],\n",
       " 'achteros': ['achter', 'B', 'os'],\n",
       " 'achterover': ['achter', 'over', 'B'],\n",
       " 'achterpaard': ['achter', 'B', 'paard'],\n",
       " 'achterpad': ['achter', 'B', 'pad'],\n",
       " 'achterpagina': ['achter', 'B', 'pagina'],\n",
       " 'achterpand': ['achter', 'B', 'pand'],\n",
       " 'achterplaats': ['achter', 'B', 'plaats'],\n",
       " 'achterplan': ['achter', 'B', 'plan'],\n",
       " 'achterplecht': ['achter', 'B', 'plecht'],\n",
       " 'achterpoort': ['achter', 'B', 'poort'],\n",
       " 'achterpoot': ['achter', 'B', 'poot'],\n",
       " 'achterruit': ['achter', 'B', 'ruit'],\n",
       " 'achterruitverwarming': ['achter', 'B', 'ruit', 'ver', 'warm', 'ing', 'NV'],\n",
       " 'achterschip': ['achter', 'B', 'schip'],\n",
       " 'achterspatbord': ['achter', 'B', 'spat', 'bord'],\n",
       " 'achterspeler': ['achter', 'B', 'speel', 'er'],\n",
       " 'achterspoiler': ['achter', 'B', 'spoiler'],\n",
       " 'achterstal': ['achter', 'B', 'stal'],\n",
       " 'achterstallig': ['achter', 'B', 'stal', 'ig'],\n",
       " 'achterstalligheid': ['achter', 'B', 'stal', 'ig', 'heid'],\n",
       " 'achterstand': ['achter', 'B', 'stand'],\n",
       " 'achterstandsbeleid': ['achter', 'B', 'stand', 's', 'beleid'],\n",
       " 'achterstandsituatie': ['achter', 'B', 'stand', 'situeer', 'atie'],\n",
       " 'achterstandspositie': ['achter', 'B', 'stand', 's', 'pose', 'eer', 'itie'],\n",
       " 'achterstandssituatie': ['achter', 'B', 'stand', 's', 'situeer', 'atie'],\n",
       " 'achtersteek': ['achter', 'B', 'steek'],\n",
       " 'achterstel': ['achter', 'B', 'stel'],\n",
       " 'achterstelling': ['achter', 'B', 'stel', 'ing'],\n",
       " 'achtersteven': ['achter', 'B', 'steven'],\n",
       " 'achterstevoren': ['achterste', 'voren', 'B', 'B'],\n",
       " 'achterstraat': ['achter', 'B', 'straat'],\n",
       " 'achterstreng': ['achter', 'B', 'streng'],\n",
       " 'achterstuk': ['achter', 'B', 'stuk'],\n",
       " 'achtertalie': ['achter', 'B', 'talie'],\n",
       " 'achtertuin': ['achter', 'B', 'tuin'],\n",
       " 'achteruitgang': ['achter', 'B', 'uit', 'gang'],\n",
       " 'achteruitkijkspiegel': ['achter', 'B', 'uit', 'B', 'B', 'kijk', 'spiegel'],\n",
       " 'achteruitrijlamp': ['achter', 'B', 'uit', 'B', 'B', 'rijd', 'lamp'],\n",
       " 'achtervanger': ['achter', 'B', 'vang', 'er'],\n",
       " 'achtervertrek': ['achter', 'B', 'vertrek'],\n",
       " 'achtervoeging': ['achter', 'B', 'voeg', 'ing'],\n",
       " 'achtervoegsel': ['achter', 'B', 'voeg', 'sel'],\n",
       " 'achtervoet': ['achter', 'B', 'voet'],\n",
       " 'achtervolger': ['achter', 'B', 'volg', 'er'],\n",
       " 'achtervolging': ['achter', 'B', 'volg', 'ing'],\n",
       " 'achtervolgingswaanzin': ['achter', 'B', 'volg', 'ing', 's', 'waan', 'zin'],\n",
       " 'achtervolgingswedstrijd': ['achter',\n",
       "  'B',\n",
       "  'volg',\n",
       "  'ing',\n",
       "  's',\n",
       "  'wed',\n",
       "  'strijd'],\n",
       " 'achtervolgster': ['achter', 'B', 'volg', 'ster'],\n",
       " 'achterwaarster': ['achter', 'B', 'waar', 'ster'],\n",
       " 'achterwaarts': ['achter', 'B', 'waarts', 'B'],\n",
       " 'achterwacht': ['achter', 'B', 'wacht'],\n",
       " 'achterwagen': ['achter', 'B', 'wagen'],\n",
       " 'achterweg': ['achter', 'B', 'weg'],\n",
       " 'achterwiel': ['achter', 'B', 'wiel'],\n",
       " 'achterwielaandrijving': ['achter', 'B', 'wiel', 'aan', 'drijf', 'ing', 'NV'],\n",
       " 'achterzak': ['achter', 'B', 'zak'],\n",
       " 'achterzij': ['achter', 'B', 'zij'],\n",
       " 'achterzijde': ['achter', 'B', 'zijde'],\n",
       " 'achterzolder': ['achter', 'B', 'zolder'],\n",
       " 'achthoek': ['acht', 'Q', 'hoek'],\n",
       " 'achthoekig': ['acht', 'Q', 'hoek', 'ig', 'QN'],\n",
       " 'achthonderd': ['acht', 'Q', 'honderd', 'Q', 'Q'],\n",
       " 'achthonderdduizend': ['acht', 'Q', 'honderd', 'Q', 'Q', 'duizend', 'Q', 'Q'],\n",
       " 'achthonderdduizendste': ['acht',\n",
       "  'Q',\n",
       "  'honderd',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'duizend',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achthonderdste': ['acht', 'Q', 'honderd', 'Q', 'Q', 'ste', 'Q', 'Q', 'Q'],\n",
       " 'achtjarig': ['acht', 'Q', 'jaar', 'ig', 'QN'],\n",
       " 'achtkant': ['acht', 'Q', 'kant'],\n",
       " 'achtkantig': ['acht', 'Q', 'kant', 'ig', 'QN'],\n",
       " 'achtmaal': ['acht', 'Q', 'maal', 'B'],\n",
       " 'achtmaands': ['acht', 'Q', 'maand', 's', 'QN'],\n",
       " 'achtpotig': ['acht', 'Q', 'poot', 'ig', 'QN'],\n",
       " 'achtregelig': ['acht', 'Q', 'regel', 'ig', 'QN'],\n",
       " 'achtspan': ['acht', 'Q', 'span'],\n",
       " 'achttal': ['acht', 'Q', 'tal'],\n",
       " 'achttien': ['acht', 'Q', 'tien', 'Q', 'Q'],\n",
       " 'achttiende': ['acht', 'Q', 'tien', 'Q', 'Q', 'de', 'Q', 'Q', 'Q'],\n",
       " 'achttiende-eeuws': ['acht',\n",
       "  'Q',\n",
       "  'tien',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'de',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'eeuw',\n",
       "  's',\n",
       "  'QN'],\n",
       " 'achttienduizend': ['acht', 'Q', 'tien', 'Q', 'Q', 'duizend', 'Q', 'Q'],\n",
       " 'achttienduizendste': ['acht',\n",
       "  'Q',\n",
       "  'tien',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'duizend',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achttienhonderd': ['acht', 'Q', 'tien', 'Q', 'Q', 'honderd', 'Q', 'Q'],\n",
       " 'achttienhonderdste': ['acht',\n",
       "  'Q',\n",
       "  'tien',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'honderd',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'ste',\n",
       "  'Q',\n",
       "  'Q',\n",
       "  'Q'],\n",
       " 'achttienjarig': ['acht', 'Q', 'tien', 'Q', 'Q', 'jaar', 'ig', 'QN'],\n",
       " 'achttienmaander': ['acht', 'Q', 'tien', 'Q', 'Q', 'maand', 'er', 'QN'],\n",
       " 'achttienurig': ['acht', 'Q', 'tien', 'Q', 'Q', 'uur', 'ig', 'QN'],\n",
       " 'achturemis': ['acht', 'Q', 'uur', 'e', 'QN', 'mis'],\n",
       " 'achturendag': ['acht', 'Q', 'uur', 'en', 'QN', 'dag'],\n",
       " 'achturig': ['acht', 'Q', 'uur', 'ig', 'QN'],\n",
       " 'achtvlak': ['acht', 'Q', 'vlak'],\n",
       " 'achtvlakkig': ['acht', 'Q', 'vlak', 'ig', 'QN'],\n",
       " 'achtvoetig': ['acht', 'Q', 'voet', 'ig', 'QN'],\n",
       " 'achtzijdig': ['acht', 'Q', 'zijde', 'ig', 'QN'],\n",
       " 'acidimetrie': ['acidimeter', 'ie'],\n",
       " 'aconceptief': ['a', 'Nx', 'concept', 'ie', 'ief', 'xN'],\n",
       " 'acquisitief': ['acquisitie', 'ief'],\n",
       " 'acrobate': ['acrobaat', 'e'],\n",
       " 'acrobatentoer': ['acrobaat', 'en', 'toer'],\n",
       " 'acrobatie': ['acrobaat', 'isch', 'ie'],\n",
       " 'acrobatiek': ['acrobaat', 'isch', 'iek'],\n",
       " 'acrobatisch': ['acrobaat', 'isch'],\n",
       " 'acteur': ['acteer', 'eur'],\n",
       " 'acteursfilm': ['acteer', 'eur', 's', 'film'],\n",
       " 'acteurskwaliteit': ['acteer', 'eur', 's', 'kwaliteit'],\n",
       " 'acteursloopbaan': ['acteer', 'eur', 's', 'loop', 'baan'],\n",
       " 'acteursprestatie': ['acteer', 'eur', 's', 'presteer', 'atie'],\n",
       " 'actieveling': ['actie', 'ief', 'eling'],\n",
       " 'actievoerster': ['actie', 'voer', 'ster', 'NV'],\n",
       " 'actinisch': ['actine', 'isch'],\n",
       " 'activering': ['actief', 'eer', 'ing'],\n",
       " 'activeringsschool': ['actief', 'eer', 'ing', 's', 'school'],\n",
       " 'activiteit': ['actie', 'ief', 'iteit'],\n",
       " 'activiteitenanalyse': ['actie', 'ief', 'iteit', 'en', 'analyse'],\n",
       " 'activiteitencentrum': ['actie', 'ief', 'iteit', 'en', 'centrum'],\n",
       " 'activiteitenpakket': ['actie', 'ief', 'iteit', 'en', 'pakket'],\n",
       " 'activiteitenprogramma': ['actie', 'ief', 'iteit', 'en', 'programma'],\n",
       " 'activiteitsniveau': ['actie', 'ief', 'iteit', 's', 'niveau'],\n",
       " 'actualisering': ['actueel', 'eer', 'ing'],\n",
       " 'actualiteit': ['actueel', 'iteit'],\n",
       " 'actualiteitenprogramma': ['actueel', 'iteit', 'en', 'programma'],\n",
       " 'actualiteitenrubriek': ['actueel', 'iteit', 'en', 'rubriek'],\n",
       " 'actualiteitskarakter': ['actueel', 'iteit', 's', 'karakter'],\n",
       " 'actuariaat': ['actuaris', 'aat'],\n",
       " 'actuarieel': ['actuaris', 'eel'],\n",
       " 'acultureel': ['a', 'cultuur', 'eel'],\n",
       " 'acupuncturist': ['acupunctuur', 'ist'],\n",
       " 'adamsappel': ['Adam', 's', 'appel'],\n",
       " 'adamskostuum': ['Adam', 's', 'kostuum'],\n",
       " 'adaptatie': ['adapteer', 'atie'],\n",
       " 'adaptief': ['adapteer', 'atie', 'ief'],\n",
       " 'additie': ['addeer', 'itie'],\n",
       " 'additief': ['addeer', 'itie', 'ief'],\n",
       " 'additioneel': ['addeer', 'itie', 'ioneel'],\n",
       " 'adembeklemmend': ['adem', 'be', 'klem', 'end', 'NV'],\n",
       " 'adembenemend': ['adem', 'be', 'neem', 'end', 'NV'],\n",
       " 'ademhaling': ['adem', 'haal', 'ing'],\n",
       " 'ademhalingsapparaat': ['adem', 'haal', 'ing', 's', 'apparaat'],\n",
       " 'ademhalingscentrum': ['adem', 'haal', 'ing', 's', 'centrum'],\n",
       " 'ademhalingsdepressie': ['adem', 'haal', 'ing', 's', 'depressie'],\n",
       " 'ademhalingsfrequentie': ['adem', 'haal', 'ing', 's', 'frequent', 'ie'],\n",
       " 'ademhalingsfunctie': ['adem', 'haal', 'ing', 's', 'functie'],\n",
       " 'ademhalingsgymnastiek': ['adem', 'haal', 'ing', 's', 'gymnastisch', 'iek'],\n",
       " 'ademhalingsinsufficientie': ['adem',\n",
       "  'haal',\n",
       "  'ing',\n",
       "  's',\n",
       "  'in',\n",
       "  'sufficient',\n",
       "  'ie'],\n",
       " 'ademhalingsklacht': ['adem', 'haal', 'ing', 's', 'klacht'],\n",
       " 'ademhalingsmoeilijkheid': ['adem',\n",
       "  'haal',\n",
       "  'ing',\n",
       "  's',\n",
       "  'moei',\n",
       "  'lijk',\n",
       "  'heid'],\n",
       " 'ademhalingsoefening': ['adem', 'haal', 'ing', 's', 'oefen', 'ing'],\n",
       " 'ademhalingsorgaan': ['adem', 'haal', 'ing', 's', 'orgaan'],\n",
       " 'ademhalingsprobleem': ['adem', 'haal', 'ing', 's', 'probleem'],\n",
       " 'ademhalingsritme': ['adem', 'haal', 'ing', 's', 'ritme'],\n",
       " 'ademhalingsstoornis': ['adem', 'haal', 'ing', 's', 'stoor', 'nis'],\n",
       " 'ademhalingssysteem': ['adem', 'haal', 'ing', 's', 'systeem'],\n",
       " 'ademhalingstechniek': ['adem', 'haal', 'ing', 's', 'technisch', 'iek'],\n",
       " 'ademhalingstherapie': ['adem', 'haal', 'ing', 's', 'therapie'],\n",
       " 'ademhalingswerktuigen': ['adem', 'haal', 'ing', 's', 'werk', 'tuig'],\n",
       " 'aderlating': ['ader', 'laat', 'ing'],\n",
       " 'aderontsteking': ['ader', 'ontsteek', 'ing', 'NV'],\n",
       " 'aderverkalking': ['ader', 'ver', 'kalk', 'ing', 'NV'],\n",
       " 'adhesiebetuiging': ['adhesie', 'be', 'tuig', 'ing', 'NV'],\n",
       " 'adjectivisch': ['adjectief', 'isch'],\n",
       " 'adjudant-onderofficier': ['adjudant', 'onder', 'officier'],\n",
       " 'adjunct-administrateur': ['adjunct', 'administreer', 'ateur'],\n",
       " 'adjunct-commies': ['adjunct', 'commies'],\n",
       " 'adjunct-commissaris': ['adjunct', 'commissaris'],\n",
       " 'adjunct-directeur': ['adjunct', 'directeur'],\n",
       " 'adjunct-hoofdredacteur': ['adjunct', 'hoofd', 'redacteur'],\n",
       " 'adjunct-secretaris': ['adjunct', 'secretaris'],\n",
       " 'administrateur': ['administreer', 'ateur'],\n",
       " 'administratie': ['administreer', 'atie'],\n",
       " 'administratiefrechtelijk': ['administreer', 'atie', 'ief', 'recht', 'elijk'],\n",
       " 'administratiegebouw': ['administreer', 'atie', 'ge', 'bouw'],\n",
       " 'administratiekantoor': ['administreer', 'atie', 'kantoor'],\n",
       " 'administratiekosten': ['administreer', 'atie', 'kost'],\n",
       " 'administratief': ['administreer', 'atie', 'ief'],\n",
       " 'admiraal-generaal': ['admiraal', 'generaal'],\n",
       " 'admissie-examen': ['admissie', 'examen'],\n",
       " 'adnominaal': ['ad', 'Nx', 'nomen', 'aal', 'xN'],\n",
       " 'adolescentiepsychologie': ['adolescent', 'ie', 'psychologisch', 'ie'],\n",
       " 'adoptant': ['adopteer', 'ant'],\n",
       " 'adoptiefkind': ['adoptie', 'ief', 'kind'],\n",
       " 'adoptiefouders': ['adoptie', 'ief', 'ouder'],\n",
       " 'adoptiefzoon': ['adoptie', 'ief', 'zoon'],\n",
       " 'adoptief': ['adoptie', 'ief'],\n",
       " 'adorabel': ['adoreer', 'abel'],\n",
       " 'adoratie': ['adoreer', 'atie'],\n",
       " 'adrenaline-injectie': ['adrenaline', 'injectie'],\n",
       " 'adressant': ['adres', 'eer', 'ant'],\n",
       " 'adressante': ['adres', 'eer', 'ant', 'e'],\n",
       " 'adresschrijver': ['adres', 'schrijf', 'er', 'NV'],\n",
       " 'adresseermachine': ['adres', 'eer', 'machine'],\n",
       " 'adressenbank': ['adres', 'en', 'bank'],\n",
       " 'adressenlijst': ['adres', 'en', 'lijst'],\n",
       " 'adressenschrijver': ['adres', 'en', 'Vx', 'schrijf', 'er', 'NxV'],\n",
       " 'adressering': ['adres', 'eer', 'ing'],\n",
       " 'adreswijziging': ['adres', 'wijzig', 'ing', 'NV'],\n",
       " 'adverbiaal': ['adverbium', 'aal'],\n",
       " 'advertentie': ['adverteer', 'entie'],\n",
       " 'advertentieacquisiteur': ['adverteer', 'entie', 'acquisiteur'],\n",
       " 'advertentieacquisitie': ['adverteer', 'entie', 'acquisitie'],\n",
       " 'advertentiebeleid': ['adverteer', 'entie', 'beleid'],\n",
       " 'advertentiebezetting': ['adverteer', 'entie', 'be', 'zet', 'ing'],\n",
       " 'advertentieblad': ['adverteer', 'entie', 'blad'],\n",
       " 'advertentiebureau': ['adverteer', 'entie', 'bureau'],\n",
       " 'advertentiecampagne': ['adverteer', 'entie', 'campagne'],\n",
       " 'advertentie-exploitatie': ['adverteer', 'entie', 'exploiteer', 'atie'],\n",
       " 'advertentie-inkomst': ['adverteer', 'entie', 'in', 'kom', 'st'],\n",
       " 'advertentiekolom': ['adverteer', 'entie', 'kolom'],\n",
       " 'advertentiekosten': ['adverteer', 'entie', 'kost'],\n",
       " 'advertentiepagina': ['adverteer', 'entie', 'pagina'],\n",
       " 'advertentieruimte': ['adverteer', 'entie', 'ruim', 'te'],\n",
       " 'advertentietarief': ['adverteer', 'entie', 'tarief'],\n",
       " 'advertentietekst': ['adverteer', 'entie', 'tekst'],\n",
       " 'advertentievolume': ['adverteer', 'entie', 'volume'],\n",
       " 'adviescommissie': ['advies', 'con', 'missie'],\n",
       " 'adviseur': ['advies', 'eer', 'eur'],\n",
       " 'advocaatje': ['advocaat'],\n",
       " 'advocaat-fiscaal': ['advocaat', 'fiscaal'],\n",
       " 'advocaat-generaal': ['advocaat', 'generaal'],\n",
       " 'advocate': ['advocaat', 'e'],\n",
       " 'advocatenbureau': ['advocaat', 'en', 'bureau'],\n",
       " 'advocatencollectief': ['advocaat', 'en', 'collectief'],\n",
       " 'advocatenfirma': ['advocaat', 'en', 'firma'],\n",
       " 'advocatenkamer': ['advocaat', 'en', 'kamer'],\n",
       " 'advocatenkantoor': ['advocaat', 'en', 'kantoor'],\n",
       " 'advocatenpraktijk': ['advocaat', 'en', 'praktijk'],\n",
       " 'advocatenstreek': ['advocaat', 'en', 'streek'],\n",
       " 'advocaterij': ['advocaat', 'erij'],\n",
       " 'advocatie': ['advocaat', 'ie'],\n",
       " 'advocatuur': ['advocaat', 'uur'],\n",
       " 'aeratie': ['aereer', 'atie'],\n",
       " 'aerofobie': ['aero', 'fobisch', 'ie'],\n",
       " 'aerometer': ['aero', 'meet', 'er'],\n",
       " 'aeronautiek': ['aero', 'nautisch', 'iek'],\n",
       " 'aerosolverpakking': ['aero', 'sol', 'ver', 'pak', 'ing'],\n",
       " 'afbestelling': ['af', 'bestel', 'ing'],\n",
       " 'afbetaling': ['af', 'betaal', 'ing'],\n",
       " 'afbetalingscontract': ['af', 'betaal', 'ing', 's', 'contract'],\n",
       " 'afbetalingsstelsel': ['af', 'betaal', 'ing', 's', 'stel', 'sel'],\n",
       " 'afbetalingssysteem': ['af', 'betaal', 'ing', 's', 'systeem'],\n",
       " 'afbetalingstermijn': ['af', 'betaal', 'ing', 's', 'termijn'],\n",
       " 'afbidding': ['af', 'bid', 'ing'],\n",
       " 'afbraakmateriaal': ['af', 'braak', 'materie', 'aal'],\n",
       " 'afbreker': ['af', 'breek', 'er'],\n",
       " 'afbreking': ['af', 'breek', 'ing'],\n",
       " 'afbrekingsteken': ['af', 'breek', 'ing', 's', 'teken'],\n",
       " 'afdaling': ['af', 'daal', 'ing'],\n",
       " 'afdalingsproces': ['af', 'daal', 'ing', 's', 'proces'],\n",
       " 'afdamming': ['af', 'dam', 'ing'],\n",
       " 'afdankertje': ['af', 'dank', 'er'],\n",
       " 'afdekking': ['af', 'dek', 'ing'],\n",
       " 'afdeling': ['af', 'deel', 'ing'],\n",
       " 'afdelingsarts': ['af', 'deel', 'ing', 's', 'arts'],\n",
       " 'afdelingsbestuur': ['af', 'deel', 'ing', 's', 'bestuur'],\n",
       " 'afdelingsbibliotheek': ['af', 'deel', 'ing', 's', 'bibliotheek'],\n",
       " 'afdelingsbijeenkomst': ['af',\n",
       "  'deel',\n",
       "  'ing',\n",
       "  's',\n",
       "  'bijeen',\n",
       "  'B',\n",
       "  'kom',\n",
       "  'st'],\n",
       " 'afdelingschef': ['af', 'deel', 'ing', 's', 'chef'],\n",
       " 'afdelingshoofd': ['af', 'deel', 'ing', 's', 'hoofd'],\n",
       " 'afdelingsniveau': ['af', 'deel', 'ing', 's', 'niveau'],\n",
       " 'afdelingsonderzoek': ['af', 'deel', 'ing', 's', 'onderzoek'],\n",
       " 'afdelingsorganisatie': ['af', 'deel', 'ing', 's', 'orgaan', 'iseer', 'atie'],\n",
       " 'afdelingsvergadering': ['af', 'deel', 'ing', 's', 'vergader', 'ing'],\n",
       " 'afdoener': ['af', 'doe', 'er'],\n",
       " 'afdrager': ['af', 'draag', 'er'],\n",
       " 'afdrijving': ['af', 'drijf', 'ing'],\n",
       " 'afdroging': ['af', 'droog', 'ing'],\n",
       " 'afdrukpapier': ['af', 'druk', 'paap', 'ier'],\n",
       " 'afdwaling': ['af', 'dwaal', 'ing'],\n",
       " 'af-fabriekprijs': ['af', 'fabriek', 'prijs'],\n",
       " 'affectatie': ['affecteer', 'atie'],\n",
       " 'affectief': ['affect', 'ie', 'ief'],\n",
       " 'affichering': ['afficheer', 'ing'],\n",
       " 'affiliatie': ['affilieer', 'atie'],\n",
       " 'affirmatie': ['affirmeer', 'atie'],\n",
       " 'affirmatief': ['affirmeer', 'atie', 'ief'],\n",
       " 'afgeving': ['af', 'geef', 'ing'],\n",
       " 'afgietseldiertje': ['af', 'giet', 'sel', 'dier'],\n",
       " 'afgodendienares': ['afgod', 'en', 'dien', 'aar', 'es'],\n",
       " 'afgraving': ['af', 'graaf', 'ing'],\n",
       " 'afgrijselijk': ['afgrijzen', 'elijk'],\n",
       " 'afgrijselijkheid': ['afgrijzen', 'elijk', 'heid'],\n",
       " 'afgrijslijk': ['afgrijzen', 'lijk'],\n",
       " 'afgrijslijkheid': ['afgrijzen', 'lijk', 'heid'],\n",
       " 'afgrijzenwekkend': ['afgrijzen', 'wek', 'end', 'NV'],\n",
       " 'afhaalrestaurant': ['af', 'haal', 'restaureer', 'ant'],\n",
       " 'afhaker': ['af', 'haak', 'er'],\n",
       " 'afhaler': ['af', 'haal', 'er'],\n",
       " 'afhaling': ['af', 'haal', 'ing'],\n",
       " 'afhandig': ['af', 'hand', 'ig', 'PN'],\n",
       " 'afhankelijk': ['af', 'hang', 'elijk'],\n",
       " 'afhankelijkheid': ['af', 'hang', 'elijk', 'heid'],\n",
       " 'afhankelijkheidsbehoefte': ['af', 'hang', 'elijk', 'heid', 's', 'behoefte'],\n",
       " 'afhankelijkheidspositie': ['af',\n",
       "  'hang',\n",
       "  'elijk',\n",
       "  'heid',\n",
       "  's',\n",
       "  'pose',\n",
       "  'eer',\n",
       "  'itie'],\n",
       " 'afhankelijkheidsrelatie': ['af', 'hang', 'elijk', 'heid', 's', 'relatie'],\n",
       " 'afhelling': ['af', 'hel', 'ing'],\n",
       " 'afhuring': ['af', 'huur', 'ing'],\n",
       " 'afkading': ['af', 'kade', 'ing'],\n",
       " 'afkalving': ['af', 'kalf', 'ing'],\n",
       " 'afkamming': ['af', 'kam', 'ing'],\n",
       " 'afkapping': ['af', 'kap', 'ing'],\n",
       " 'afkappingsteken': ['af', 'kap', 'ing', 's', 'teken'],\n",
       " 'afkerig': ['afkeer', 'ig'],\n",
       " 'afkerigheid': ['afkeer', 'ig', 'heid'],\n",
       " 'afkering': ['af', 'keer', 'ing'],\n",
       " 'afkeurenswaard': ['af', 'keur', 's', 'waard'],\n",
       " 'afkeurenswaardig': ['af', 'keur', 's', 'waarde', 'ig'],\n",
       " 'afklemming': ['af', 'klem', 'ing'],\n",
       " 'afklopper': ['af', 'klop', 'er'],\n",
       " 'afklopping': ['af', 'klop', 'ing'],\n",
       " 'afknaging': ['af', 'knaag', 'ing'],\n",
       " 'afknapper': ['af', 'knap', 'er'],\n",
       " 'afknelling': ['af', 'knel', 'ing'],\n",
       " 'afknotting': ['af', 'knot', 'ing'],\n",
       " 'afkoker': ['af', 'kook', 'er'],\n",
       " 'afkoopbaarstelling': ['af', 'koop', 'baar', 'stel', 'ing'],\n",
       " 'afkoping': ['af', 'koop', 'ing'],\n",
       " 'afkrabber': ['af', 'krab', 'er'],\n",
       " 'aflader': ['af', 'laad', 'er'],\n",
       " 'aflading': ['af', 'laad', 'ing'],\n",
       " 'aflandig': ['af', 'land', 'ig', 'PN'],\n",
       " 'aflating': ['af', 'laat', 'ing'],\n",
       " 'aflegger': ['af', 'leg', 'er'],\n",
       " 'aflegging': ['af', 'leg', 'ing'],\n",
       " 'afleidkundig': ['af', 'leid', 'kunde', 'ig'],\n",
       " 'aflezer': ['af', 'lees', 'er'],\n",
       " 'aflezing': ['af', 'lees', 'ing'],\n",
       " 'aflokking': ['af', 'lok', 'ing'],\n",
       " 'aflosser': ['af', 'los', 'er'],\n",
       " 'aflossing': ['af', 'los', 'ing'],\n",
       " 'aflossingsploeg': ['af', 'los', 'ing', 's', 'ploeg'],\n",
       " 'aflossingstermijn': ['af', 'los', 'ing', 's', 'termijn'],\n",
       " 'aflossingswedstrijd': ['af', 'los', 'ing', 's', 'wed', 'strijd'],\n",
       " 'afluisterapparatuur': ['af', 'luister', 'apparaat', 'uur'],\n",
       " 'afluisterpraktijken': ['af', 'luister', 'praktijk'],\n",
       " 'afmaker': ['af', 'maak', 'er'],\n",
       " 'afmaking': ['af', 'maak', 'ing'],\n",
       " 'afmatting': ['af', 'mat', 'ing'],\n",
       " 'afmeting': ['af', 'meet', 'ing'],\n",
       " 'afmuring': ['af', 'muur', 'ing'],\n",
       " 'afname': ['af', 'neem'],\n",
       " 'afnemer': ['af', 'neem', 'er'],\n",
       " 'afnemerskrediet': ['af', 'neem', 'er', 's', 'krediet'],\n",
       " 'afneming': ['af', 'neem', 'ing'],\n",
       " 'afonie': ['afoon', 'ie'],\n",
       " 'afpakking': ['af', 'pak', 'ing'],\n",
       " 'afpaling': ['af', 'paal', 'ing'],\n",
       " 'afpassing': ['af', 'pas', 'ing'],\n",
       " 'afplatting': ['af', 'plat', 'ing'],\n",
       " 'afpluizing': ['af', 'pluis', 'ing'],\n",
       " 'afreding': ['af', 'reed', 'ing'],\n",
       " 'afreehekel': ['af', 'reed', 'hekel'],\n",
       " 'afrikanisering': ['Afrikaan', 'iseer', 'ing'],\n",
       " 'afrodisie': ['afrodisiacum', 'ie'],\n",
       " 'afromer': ['af', 'room', 'er'],\n",
       " 'afroming': ['af', 'room', 'ing'],\n",
       " 'afrossing': ['af', 'ros', 'ing'],\n",
       " 'afrotting': ['af', 'rot', 'ing'],\n",
       " 'afroving': ['af', 'roof', 'ing'],\n",
       " 'afrukking': ['af', 'ruk', 'ing'],\n",
       " 'afschaffer': ['af', 'schaf', 'er'],\n",
       " 'afschaffergenootschap': ['af', 'schaf', 'er', 'genoot', 'schap'],\n",
       " 'afschaffing': ['af', 'schaf', 'ing'],\n",
       " 'afschaveling': ['afschaveel', 'ing'],\n",
       " 'afscheidsvoorstelling': ['afscheid', 's', 'voor', 'B', 'stel', 'ing'],\n",
       " 'afscheper': ['af', 'scheep', 'er'],\n",
       " 'afscheping': ['af', 'scheep', 'ing'],\n",
       " 'afschering': ['af', 'scheer', 'ing'],\n",
       " 'afscherving': ['af', 'scherf', 'ing'],\n",
       " 'afschrabber': ['af', 'schrab', 'er'],\n",
       " 'afschraper': ['af', 'schraap', 'er'],\n",
       " 'afschrijver': ['af', 'schrijf', 'er'],\n",
       " 'afschrijving': ['af', 'schrijf', 'ing'],\n",
       " 'afschrijvingsbank': ['af', 'schrijf', 'ing', 's', 'bank'],\n",
       " 'afschrijvingsperiode': ['af', 'schrijf', 'ing', 's', 'periode'],\n",
       " 'afschrikking': ['af', 'schrik', 'ing'],\n",
       " 'afschrikwekkend': ['af', 'schrik', 'wek', 'end', 'NV'],\n",
       " 'afschuiving': ['af', 'schuif', 'ing'],\n",
       " 'afschuring': ['af', 'schuur', 'ing'],\n",
       " 'afschutting': ['af', 'schut', 'ing'],\n",
       " 'afschuwwekkend': ['afschuw', 'wek', 'end', 'NV'],\n",
       " 'afsleping': ['af', 'sleep', 'ing'],\n",
       " 'afsloting': ['af', 'sloot', 'ing'],\n",
       " 'afsloving': ['af', 'sloof', 'ing'],\n",
       " 'afsmeking': ['af', 'smeek', 'ing'],\n",
       " 'afsnijschaar': ['af', 'snijd', 'schaar'],\n",
       " 'afsnijsel': ['af', 'snijd', 'sel'],\n",
       " 'afspanning': ['af', 'span', 'ing'],\n",
       " 'afspatting': ['af', 'spat', 'ing'],\n",
       " 'afspeelapparatuur': ['af', 'speel', 'apparaat', 'uur'],\n",
       " 'afstammeling': ['af', 'stam', 'eling'],\n",
       " 'afstammelinge': ['af', 'stam', 'eling', 'e'],\n",
       " 'afstamming': ['af', 'stam', 'ing'],\n",
       " 'afstammingsleer': ['af', 'stam', 'ing', 's', 'leer'],\n",
       " 'afstammingstheorie': ['af', 'stam', 'ing', 's', 'theorie'],\n",
       " 'afstandmeter': ['afstand', 'meet', 'er', 'NV'],\n",
       " 'afstandmeting': ['afstand', 'meet', 'ing', 'NV'],\n",
       " 'afstandsbepaling': ['afstand', 's', 'Vx', 'be', 'paal', 'ing', 'NxV'],\n",
       " 'afstandsbesturing': ['afstand', 's', 'be', 'stuur', 'ing'],\n",
       " 'afstandswijzer': ['afstand', 's', 'Vx', 'wijs', 'er', 'NxV'],\n",
       " 'afsteker': ['af', 'steek', 'er'],\n",
       " 'afsteking': ['af', 'steek', 'ing'],\n",
       " 'afstelling': ['af', 'stel', 'ing'],\n",
       " 'afstemmer': ['af', 'stem', 'er'],\n",
       " 'afstemming': ['af', 'stem', 'ing'],\n",
       " 'afstemmingsprobleem': ['af', 'stem', 'ing', 's', 'probleem'],\n",
       " 'afsterving': ['af', 'sterf', 'ing'],\n",
       " 'afstervingsproces': ['af', 'sterf', 'ing', 's', 'proces'],\n",
       " 'afstotelijk': ['af', 'stoot', 'elijk'],\n",
       " 'afstoting': ['af', 'stoot', 'ing'],\n",
       " 'afstotingskracht': ['af', 'stoot', 'ing', 's', 'kracht'],\n",
       " 'afstotingsreactie': ['af', 'stoot', 'ing', 's', 're', 'actie'],\n",
       " 'afstraffing': ['af', 'straf', 'ing'],\n",
       " 'afstraling': ['af', 'straal', 'ing'],\n",
       " 'afstroming': ['af', 'stroom', 'ing'],\n",
       " 'afstuiving': ['af', 'stuif', 'ing'],\n",
       " 'aftakking': ['af', 'tak', 'ing'],\n",
       " 'aftapper': ['af', 'tap', 'er'],\n",
       " 'aftapping': ['af', 'tap', 'ing'],\n",
       " 'aftelliedje': ['af', 'tel', 'lied'],\n",
       " 'aftelling': ['af', 'tel', 'ing'],\n",
       " ...}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_en(df):\n",
    "\n",
    "    out = {}\n",
    "    same = {}\n",
    "\n",
    "    for word, segs in df.items():\n",
    "        # if word[-2:] == 'en':\n",
    "        #     out[word] = segs + ['en']\n",
    "        # else:\n",
    "        #     same[word] = segs\n",
    "        \n",
    "        out[word] = segs + ['en']\n",
    "    \n",
    "\n",
    "    \n",
    "    return out, same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2, same = add_en(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['a'],\n",
       " 'Aafje': [''],\n",
       " 'Aafke': [''],\n",
       " 'Aagje': [''],\n",
       " 'aagt': ['aagt'],\n",
       " 'aagtappel': ['aagt', 'appel'],\n",
       " 'aai': ['aai'],\n",
       " 'aaiing': ['aai', 'ing'],\n",
       " 'aak': ['aak'],\n",
       " 'aal': ['aal'],\n",
       " 'aaltje': [''],\n",
       " 'aaltjes': [''],\n",
       " 'aalbes': ['aal', 'bes'],\n",
       " 'aalbessengelei': ['aalbes', 'en', 'gelei'],\n",
       " 'aalbessenjam': ['aalbes', 'en', 'jam'],\n",
       " 'aalbessenjenever': ['aalbes', 'en', 'jenever'],\n",
       " 'aalbessesap': ['aalbes', 'e', 'sap'],\n",
       " 'aalbessestruik': ['aalbes', 'e', 'struik'],\n",
       " 'Aalders': [''],\n",
       " 'aalelger': ['aal', 'elger'],\n",
       " 'aalfuik': ['aal', 'fuik'],\n",
       " 'aalgeer': [''],\n",
       " 'aalglad': ['aal', 'glad'],\n",
       " 'aalkaar': ['aal', 'kaar'],\n",
       " 'aalkast': ['aal', 'kast'],\n",
       " 'aalkorf': ['aal', 'korf'],\n",
       " 'aalkuip': ['aal', 'kuip'],\n",
       " 'aalkwab': ['aal', 'kwab'],\n",
       " 'aalkwabbe': [''],\n",
       " 'aalmoes': [''],\n",
       " 'aalmoezenier': ['aalmoes', 'enier'],\n",
       " 'aalmoezenierskamer': ['aalmoezenier', 's', 'kamer'],\n",
       " 'aalpomp': ['aal', 'pomp'],\n",
       " 'aalput': ['aal', 'put'],\n",
       " 'aalreep': ['aal', 'reep'],\n",
       " 'aalreiger': ['aal', 'reiger'],\n",
       " 'aalschaar': ['aal', 'schaar'],\n",
       " 'aalscholver': ['aal', 'scholver'],\n",
       " 'aalshuid': ['aal', 's', 'huid'],\n",
       " 'aalskruik': ['aal', 's', 'kruik'],\n",
       " 'Aalsmeer': [''],\n",
       " 'aalspeer': ['aal', 'speer'],\n",
       " 'Aalst': [''],\n",
       " 'aalstal': ['aal', 'stal'],\n",
       " 'aalsteek': ['aal', 'steek'],\n",
       " 'aalsteker': ['aal', 'steek', 'er'],\n",
       " 'aalsvel': ['aal', 's', 'vel'],\n",
       " 'aalt': ['aalt'],\n",
       " 'a-al-tolletje': [''],\n",
       " 'aalvork': ['aal', 'vork'],\n",
       " 'aalvormig': ['aal', 'vorm', 'ig'],\n",
       " 'aam': ['aam'],\n",
       " 'aambeeld': [''],\n",
       " 'aambeeldsbeentje': ['aambeeld', 's', 'been'],\n",
       " 'aambeeldsblok': ['aambeeld', 's', 'blok'],\n",
       " 'aambei': [''],\n",
       " 'aambeienkruid': ['aambei', 'en', 'kruid'],\n",
       " 'aamborstig': ['aam', 'borst', 'ig'],\n",
       " 'aamborstigheid': ['aamborstig', 'heid'],\n",
       " 'aamt': ['aamt'],\n",
       " 'aan': ['aan'],\n",
       " 'aanaarding': ['aanaard', 'ing'],\n",
       " 'aanaardploeg': ['aanaard', 'ploeg'],\n",
       " 'aanademing': [''],\n",
       " 'aanbaksel': ['aanbak', 'sel'],\n",
       " 'aanbeeld': [''],\n",
       " 'aanbeeldsbeentje': ['aanbeeld', 's', 'been'],\n",
       " 'aanbeeldsblok': ['aanbeeld', 's', 'blok'],\n",
       " 'aanbelang': ['aan', 'belang'],\n",
       " 'aanberming': ['aanberm', 'ing'],\n",
       " 'aanbesteder': ['aanbesteed', 'er'],\n",
       " 'aanbesteding': ['aanbesteed', 'ing'],\n",
       " 'aanbetaling': ['aan', 'betaling'],\n",
       " 'aanbevelenswaard': ['aanbeveel', 's', 'waard'],\n",
       " 'aanbevelenswaardig': ['aanbeveel', 's', 'waardig'],\n",
       " 'aanbeveling': ['aanbeveel', 'ing'],\n",
       " 'aanbevelingsbrief': ['aanbeveling', 's', 'brief'],\n",
       " 'aanbiddelijk': ['aanbid', 'elijk'],\n",
       " 'aanbiddenswaardig': ['aanbid', 's', 'waardig'],\n",
       " 'aanbidder': ['aanbid', 'er'],\n",
       " 'aanbidding': ['aanbid', 'ing'],\n",
       " 'aanbidster': ['aanbid', 'ster'],\n",
       " 'aanbieding': ['aanbied', 'ing'],\n",
       " 'aanbiedingsbrief': ['aanbieding', 's', 'brief'],\n",
       " 'aanblazing': ['aanblaas', 'ing'],\n",
       " 'aanblik': ['aan', 'blik'],\n",
       " 'aanbod': [''],\n",
       " 'aanbodcurve': ['aanbod', 'curve'],\n",
       " 'aanbodstructuur': ['aanbod', 'structuur'],\n",
       " 'aanbouw': [''],\n",
       " 'aanbouwing': ['aanbouw', 'ing'],\n",
       " 'aanbouwsel': ['aanbouw', 'sel'],\n",
       " 'aanbreisel': ['aanbrei', 'sel'],\n",
       " 'aanbreng': [''],\n",
       " 'aanbrenger': ['aanbreng', 'er'],\n",
       " 'aanbrenging': ['aanbreng', 'ing'],\n",
       " 'aanbrengpremie': ['aanbreng', 'premie'],\n",
       " 'aanbrengst': ['aanbreng', 'st'],\n",
       " 'aanbrug': ['aan', 'brug'],\n",
       " 'aandacht': [''],\n",
       " 'aandachtig': [''],\n",
       " 'aandachtigheid': ['aandachtig', 'heid'],\n",
       " 'aandachtsconcentratie': ['aandacht', 's', 'concentratie'],\n",
       " 'aandachtseenheid': ['aandacht', 's', 'eenheid'],\n",
       " 'aandachtsproces': ['aandacht', 's', 'proces'],\n",
       " 'aandachtsstreep': ['aandacht', 's', 'streep'],\n",
       " 'aandachtsteken': ['aandacht', 's', 'teken'],\n",
       " 'aandachtsveld': ['aandacht', 's', 'veld'],\n",
       " 'aandachttrekkerij': ['aandacht', 'trek', 'erij'],\n",
       " 'aandak': ['aan', 'dak'],\n",
       " 'aandamming': ['aandam', 'ing'],\n",
       " 'aandeel': ['aan', 'deel'],\n",
       " 'aandeelbewijs': ['aandeel', 'bewijs'],\n",
       " 'aandeelhebber': ['aandeel', 'heb', 'er'],\n",
       " 'aandeelhouder': ['aandeel', 'houd', 'er'],\n",
       " 'aandeelhoudersvergadering': ['aandeelhouder', 's', 'vergadering'],\n",
       " 'aandelenkapitaal': ['aandeel', 'en', 'kapitaal'],\n",
       " 'aandelenoptie': ['aandeel', 'en', 'optie'],\n",
       " 'aandelenpakket': ['aandeel', 'en', 'pakket'],\n",
       " 'aandelenportefeuille': ['aandeel', 'en', 'portefeuille'],\n",
       " 'aandenken': ['aan', 'denken'],\n",
       " 'aandijking': ['aandijk', 'ing'],\n",
       " 'aandoening': ['aandoe', 'ing'],\n",
       " 'aandoenlijk': ['aandoe', 'lijk'],\n",
       " 'aandoenlijkheid': ['aandoenlijk', 'heid'],\n",
       " 'aandrager': ['aandraag', 'er'],\n",
       " 'aandrang': [''],\n",
       " 'aandrift': ['aan', 'drift'],\n",
       " 'aandrijfas': ['aandrijf', 'as'],\n",
       " 'aandrijfketting': ['aandrijf', 'ketting'],\n",
       " 'aandrijfkracht': ['aandrijf', 'kracht'],\n",
       " 'aandrijfsysteem': ['aandrijf', 'systeem'],\n",
       " 'aandrijver': ['aandrijf', 'er'],\n",
       " 'aandrijving': ['aandrijf', 'ing'],\n",
       " 'aanduiding': ['aanduid', 'ing'],\n",
       " 'aaneen': [''],\n",
       " 'aaneengeboren': ['aaneen', 'geboren'],\n",
       " 'aaneengeschakeld': [''],\n",
       " 'aaneengesloten': [''],\n",
       " 'aaneengroeiing': ['aaneengroei', 'ing'],\n",
       " 'aaneenkoppeling': ['aaneenkoppel', 'ing'],\n",
       " 'aaneenrijging': ['aaneenrijg', 'ing'],\n",
       " 'aaneenschakelend': [''],\n",
       " 'aaneenschakeling': ['aaneenschakel', 'ing'],\n",
       " 'aaneensluiting': ['aaneensluit', 'ing'],\n",
       " 'aaneenvoeging': ['aaneenvoeg', 'ing'],\n",
       " 'aanfluiting': ['aanfluit', 'ing'],\n",
       " 'aanfok': [''],\n",
       " 'aanfokking': ['aanfok', 'ing'],\n",
       " 'aangaande': [''],\n",
       " 'aangebedene': [''],\n",
       " 'aangeblazen': [''],\n",
       " 'aangebonden': [''],\n",
       " 'aangeboren': ['aan', 'geboren'],\n",
       " 'aangeborenheid': ['aangeboren', 'heid'],\n",
       " 'aangebrand': [''],\n",
       " 'aangedaan': [''],\n",
       " 'aangeefster': ['aangeef', 'ster'],\n",
       " 'aangeerfd': [''],\n",
       " 'aangehuwd': [''],\n",
       " 'aangeklaagde': [''],\n",
       " 'aangekleed': [''],\n",
       " 'aangelande': ['aangeland', 'e'],\n",
       " 'aangeleerd': [''],\n",
       " 'aangelegd': [''],\n",
       " 'aangelegen': [''],\n",
       " 'aangelegenheid': ['aangelegen', 'heid'],\n",
       " 'aangeleund': [''],\n",
       " 'aangenaam': [''],\n",
       " 'aangenaamheid': ['aangenaam', 'heid'],\n",
       " 'aangenomen': [''],\n",
       " 'aangepast': [''],\n",
       " 'aangeschoten': [''],\n",
       " 'aangeschreven': [''],\n",
       " 'aangeslagen': [''],\n",
       " 'aangestoken': [''],\n",
       " 'aangetekend': [''],\n",
       " 'aangetogen': [''],\n",
       " 'aangetrouwd': [''],\n",
       " 'aangever': ['aangeef', 'er'],\n",
       " 'aangeving': ['aangeef', 'ing'],\n",
       " 'aangewezen': [''],\n",
       " 'aangezicht': ['aan', 'gezicht'],\n",
       " 'aangezichtsligging': ['aangezicht', 's', 'ligging'],\n",
       " 'aangezichtspijn': ['aangezicht', 's', 'pijn'],\n",
       " 'aangezien': [''],\n",
       " 'aangietkleur': ['aangiet', 'kleur'],\n",
       " 'aangifte': [''],\n",
       " 'aangiftebereidheid': ['aangifte', 'bereidheid'],\n",
       " 'aangiftebiljet': ['aangifte', 'biljet'],\n",
       " 'aangifteformulier': ['aangifte', 'formulier'],\n",
       " 'aangifteplicht': ['aangifte', 'plicht'],\n",
       " 'aangraving': ['aangraaf', 'ing'],\n",
       " 'aangrenzend': ['aan', 'grenzend'],\n",
       " 'aangrijpend': [''],\n",
       " 'aangrijping': ['aangrijp', 'ing'],\n",
       " 'aangrijpingspunt': ['aangrijping', 's', 'punt'],\n",
       " 'aangroei': [''],\n",
       " 'aangroeiing': ['aangroei', 'ing'],\n",
       " 'aanhalerig': ['aanhaal', 'erig'],\n",
       " 'aanhalerigheid': ['aanhalerig', 'heid'],\n",
       " 'aanhalig': ['aanhaal', 'ig'],\n",
       " 'aanhaligheid': ['aanhalig', 'heid'],\n",
       " 'aanhaling': ['aanhaal', 'ing'],\n",
       " 'aanhalingsteken': ['aanhaling', 's', 'teken'],\n",
       " 'aanhang': [''],\n",
       " 'aanhangeling': ['aanhang', 'eling'],\n",
       " 'aanhangelinge': ['aanhangeling', 'e'],\n",
       " 'aanhanger': ['aanhang', 'er'],\n",
       " 'aanhangig': ['aanhang', 'ig'],\n",
       " 'aanhangsel': ['aanhang', 'sel'],\n",
       " 'aanhangster': ['aanhang', 'ster'],\n",
       " 'aanhangwagen': ['aanhang', 'wagen'],\n",
       " 'aanhankelijk': ['aanhang', 'elijk'],\n",
       " 'aanhankelijkheid': ['aanhankelijk', 'heid'],\n",
       " 'aanharding': ['aanhard', 'ing'],\n",
       " 'aanhechting': ['aanhecht', 'ing'],\n",
       " 'aanhechtingspunt': ['aanhechting', 's', 'punt'],\n",
       " 'aanhechtsel': ['aanhecht', 'sel'],\n",
       " 'aanhef': [''],\n",
       " 'aanheffer': ['aanhef', 'er'],\n",
       " 'aanheffing': ['aanhef', 'ing'],\n",
       " 'aanhitser': ['aanhits', 'er'],\n",
       " 'aanhitsing': ['aanhits', 'ing'],\n",
       " 'aanhoorder': ['aanhoor', 'der'],\n",
       " 'aanhoorster': ['aanhoor', 'ster'],\n",
       " 'aanhoping': ['aanhoop', 'ing'],\n",
       " 'aanhorig': [''],\n",
       " 'aanhorigheid': ['aanhorig', 'heid'],\n",
       " 'aanhoudend': [''],\n",
       " 'aanhoudendheid': ['aanhoudend', 'heid'],\n",
       " 'aanhouder': ['aanhoud', 'er'],\n",
       " 'aanhouderij': ['aanhoud', 'erij'],\n",
       " 'aanhouding': ['aanhoud', 'ing'],\n",
       " 'aanhoudingsbevel': ['aanhouding', 's', 'bevel'],\n",
       " 'aanhoudingspremie': ['aanhouding', 's', 'premie'],\n",
       " 'aanhoudster': ['aanhoud', 'ster'],\n",
       " 'aanhuwing': ['aanhuw', 'ing'],\n",
       " 'aanjager': ['aanjaag', 'er'],\n",
       " 'aankap': [''],\n",
       " 'aanklaagster': ['aanklaag', 'ster'],\n",
       " 'aanklacht': [''],\n",
       " 'aanklager': ['aanklaag', 'er'],\n",
       " 'aanklamping': ['aanklamp', 'ing'],\n",
       " 'aankleding': ['aankleed', 'ing'],\n",
       " 'aankleef': [''],\n",
       " 'aankleve': [''],\n",
       " 'aankleving': ['aankleef', 'ing'],\n",
       " 'aanknoping': ['aanknoop', 'ing'],\n",
       " 'aanknopingspunt': ['aanknoping', 's', 'punt'],\n",
       " 'aankomeling': ['aankom', 'eling'],\n",
       " 'aankomelinge': ['aankomeling', 'e'],\n",
       " 'aankomelingschap': ['aankomeling', 'schap'],\n",
       " 'aankomend': [''],\n",
       " 'aankomst': ['aankom', 'st'],\n",
       " 'aankomstdatum': ['aankomst', 'datum'],\n",
       " 'aankomsthal': ['aankomst', 'hal'],\n",
       " 'aankomsttijd': ['aankomst', 'tijd'],\n",
       " 'aankondiger': ['aankondig', 'er'],\n",
       " 'aankondiging': ['aankondig', 'ing'],\n",
       " 'aankondigster': ['aankondig', 'ster'],\n",
       " 'aankoop': ['aan', 'koop'],\n",
       " 'aankoopsom': ['aankoop', 'som'],\n",
       " 'aankoppeling': ['aankoppel', 'ing'],\n",
       " 'aankorsting': ['aankorst', 'ing'],\n",
       " 'aankruiing': ['aankrui', 'ing'],\n",
       " 'aankweek': [''],\n",
       " 'aankweking': ['aankweek', 'ing'],\n",
       " 'aanlandig': ['aanland', 'ig'],\n",
       " 'aanlanding': ['aanland', 'ing'],\n",
       " 'aanlassing': ['aanlas', 'ing'],\n",
       " 'aanleg': [''],\n",
       " 'aanlegger': ['aanleg', 'er'],\n",
       " 'aanlegging': ['aanleg', 'ing'],\n",
       " 'aanleghaven': ['aanleg', 'haven'],\n",
       " 'aanlegplaats': ['aanleg', 'plaats'],\n",
       " 'aanlegsteiger': ['aanleg', 'steiger'],\n",
       " 'aanlegster': ['aanleg', 'ster'],\n",
       " 'aanleiden': [''],\n",
       " 'aanleidend': [''],\n",
       " 'aanleiding': ['aan', 'leid', 'ing'],\n",
       " 'aanleuning': ['aanleun', 'ing'],\n",
       " 'aanleuningspunt': ['aanleuning', 's', 'punt'],\n",
       " 'aanliggend': [''],\n",
       " 'aanlokkelijk': ['aanlok', 'elijk'],\n",
       " 'aanlokkelijkheid': ['aanlokkelijk', 'heid'],\n",
       " 'aanlokking': ['aanlok', 'ing'],\n",
       " 'aanloksel': ['aanlok', 'sel'],\n",
       " 'aanloop': ['aan', 'loop'],\n",
       " 'aanloophaven': ['aanloop', 'haven'],\n",
       " 'aanloopkleur': ['aanloop', 'kleur'],\n",
       " 'aanloopkosten': ['aanloop', 'kost'],\n",
       " 'aanlooppeiler': ['aanloop', 'peil', 'er'],\n",
       " 'aanloopperiode': ['aanloop', 'periode'],\n",
       " 'aanloopspreekuur': ['aanloop', 'spreekuur'],\n",
       " 'aanlooptijd': ['aanloop', 'tijd'],\n",
       " 'aanlooptransformator': ['aanloop', 'transformeer', 'ator'],\n",
       " 'aanmaak': [''],\n",
       " 'aanmaakblokje': ['aanmaak', 'blok'],\n",
       " 'aanmaakhout': ['aanmaak', 'hout'],\n",
       " 'aanmaakhoutje': [''],\n",
       " 'aanmaakkosten': ['aanmaak', 'kost'],\n",
       " 'aanmaning': ['aanmaan', 'ing'],\n",
       " 'aanmatigend': [''],\n",
       " 'aanmatiging': ['aanmatig', 'ing'],\n",
       " 'aanmelding': ['aanmeld', 'ing'],\n",
       " 'aanmeldingsformulier': ['aanmelding', 's', 'formulier'],\n",
       " 'aanmenging': ['aanmeng', 'ing'],\n",
       " 'aanmerkelijk': ['aanmerk', 'elijk'],\n",
       " 'aanmerking': ['aanmerk', 'ing'],\n",
       " 'aanminnig': ['aan', 'min', 'ig'],\n",
       " 'aanminnigheid': ['aanminnig', 'heid'],\n",
       " 'aanmoediging': ['aanmoedig', 'ing'],\n",
       " 'aanmoedigingsprijs': ['aanmoediging', 's', 'prijs'],\n",
       " 'aanmonding': ['aan', 'mond', 'ing'],\n",
       " 'aanmonstering': ['aanmonster', 'ing'],\n",
       " 'aanmunting': ['aanmunt', 'ing'],\n",
       " 'aanname': [''],\n",
       " 'aannamebeleid': ['aanname', 'beleid'],\n",
       " 'aanneembaar': ['aanneem', 'baar'],\n",
       " 'aanneemsom': ['aanneem', 'som'],\n",
       " 'aanneemster': ['aanneem', 'ster'],\n",
       " 'aannemelijk': ['aanneem', 'elijk'],\n",
       " 'aannemelijkheid': ['aannemelijk', 'heid'],\n",
       " 'aannemeling': ['aanneem', 'eling'],\n",
       " 'aannemelinge': ['aannemeling', 'e'],\n",
       " 'aannemer': ['aanneem', 'er'],\n",
       " 'aannemersfirma': ['aannemer', 's', 'firma'],\n",
       " 'aanneming': ['aanneem', 'ing'],\n",
       " 'aannemingsbeleid': ['aanneming', 's', 'beleid'],\n",
       " 'aannemingsbiljet': ['aanneming', 's', 'biljet'],\n",
       " 'aannemingsmaatschappij': ['aanneming', 's', 'maatschappij'],\n",
       " 'aannemingssom': ['aanneming', 's', 'som'],\n",
       " 'aanpak': [''],\n",
       " 'aanpalend': ['aan', 'palend'],\n",
       " 'aanpassing': ['aanpas', 'ing'],\n",
       " 'aanpassingsbeleid': ['aanpassing', 's', 'beleid'],\n",
       " 'aanpassingsgedrag': ['aanpassing', 's', 'gedrag'],\n",
       " 'aanpassingsmanoeuvre': ['aanpassing', 's', 'manoeuvre'],\n",
       " 'aanpassingsmechanisme': ['aanpassing', 's', 'mechanisme'],\n",
       " 'aanpassingsmoeilijkheden': ['aanpassing', 's', 'moeilijkheid'],\n",
       " 'aanpassingsmogelijkheid': ['aanpassing', 's', 'mogelijkheid'],\n",
       " 'aanpassingsperiode': ['aanpassing', 's', 'periode'],\n",
       " 'aanpassingsprobleem': ['aanpassing', 's', 'probleem'],\n",
       " 'aanpassingsproces': ['aanpassing', 's', 'proces'],\n",
       " 'aanpassingsstoornis': ['aanpassing', 's', 'stoornis'],\n",
       " 'aanpassingsstrategie': ['aanpassing', 's', 'strategie'],\n",
       " 'aanpassingsvermogen': ['aanpassing', 's', 'vermogen'],\n",
       " 'aanpeil': [''],\n",
       " 'aanpersing': ['aanpers', 'ing'],\n",
       " 'aanplakbiljet': ['aanplak', 'biljet'],\n",
       " 'aanplakbord': ['aanplak', 'bord'],\n",
       " 'aanplakbrief': ['aanplak', 'brief'],\n",
       " 'aanplakker': ['aanplak', 'er'],\n",
       " 'aanplakking': ['aanplak', 'ing'],\n",
       " 'aanplakzuil': ['aanplak', 'zuil'],\n",
       " 'aanplant': [''],\n",
       " 'aanplanting': ['aanplant', 'ing'],\n",
       " 'aanplemping': ['aanplemp', 'ing'],\n",
       " 'aanpoting': ['aanpoot', 'ing'],\n",
       " 'aanprijzer': ['aanprijs', 'er'],\n",
       " 'aanprijzing': ['aanprijs', 'ing'],\n",
       " 'aanprikkeling': ['aanprikkel', 'ing'],\n",
       " 'aanpunter': ['aanpunt', 'er'],\n",
       " 'aanpunting': ['aanpunt', 'ing'],\n",
       " 'aanrader': ['aanraad', 'er'],\n",
       " 'aanraking': ['aanraak', 'ing'],\n",
       " 'aanrakingsangst': ['aanraking', 's', 'angst'],\n",
       " 'aanrakingspunt': ['aanraking', 's', 'punt'],\n",
       " 'aanranden': [''],\n",
       " 'aanrander': ['aanrand', 'er'],\n",
       " 'aanranding': ['aanrand', 'ing'],\n",
       " 'aanrandster': ['aanrand', 'ster'],\n",
       " 'aanrazeren': [''],\n",
       " 'aanrecht': [''],\n",
       " 'aanrechtbank': ['aanrecht', 'bank'],\n",
       " 'aanrechtblad': ['aanrecht', 'blad'],\n",
       " 'aanrechting': ['aanrecht', 'ing'],\n",
       " 'aanrechtkastje': ['aanrecht', 'kast'],\n",
       " 'aanrechtkeuken': ['aanrecht', 'keuken'],\n",
       " 'aanrechttafel': ['aanrecht', 'tafel'],\n",
       " 'aanrijding': ['aanrijd', 'ing'],\n",
       " 'aanroep': ['aan', 'roep'],\n",
       " 'aanroeping': ['aanroep', 'ing'],\n",
       " 'aanschaf': [''],\n",
       " 'aanschaffing': ['aanschaf', 'ing'],\n",
       " 'aanscherping': ['aanscherp', 'ing'],\n",
       " 'aanschijn': [''],\n",
       " 'aanschouwelijk': ['aanschouw', 'elijk'],\n",
       " 'aanschouwelijkheid': ['aanschouwelijk', 'heid'],\n",
       " 'aanschouwing': ['aanschouw', 'ing'],\n",
       " 'aanschouwingsonderwijs': ['aanschouwing', 's', 'onderwijs'],\n",
       " 'aanschouwingsvermogen': ['aanschouwing', 's', 'vermogen'],\n",
       " 'aanschrijving': ['aanschrijf', 'ing'],\n",
       " 'aanschrijvingsbiljet': ['aanschrijving', 's', 'biljet'],\n",
       " 'aansjorring': ['aansjor', 'ing'],\n",
       " 'aanslaander': [''],\n",
       " 'aanslag': [''],\n",
       " 'aanslagbeitel': ['aanslag', 'beitel'],\n",
       " 'aanslagbiljet': ['aanslag', 'biljet'],\n",
       " 'aanslaghouding': ['aanslag', 'houding'],\n",
       " 'aanslagsteen': [''],\n",
       " 'aanslibbing': ['aanslib', 'ing'],\n",
       " 'aanslibsel': ['aanslib', 'sel'],\n",
       " 'aanslijking': ['aanslijk', 'ing'],\n",
       " 'aansluiting': ['aansluit', 'ing'],\n",
       " 'aansluitingskosten': ['aansluiting', 's', 'kost'],\n",
       " 'aansluitingsmoeilijkheid': ['aansluiting', 's', 'moeilijkheid'],\n",
       " 'aansluitingsmogelijkheid': ['aansluiting', 's', 'mogelijkheid'],\n",
       " 'aansluitingsplaats': ['aansluiting', 's', 'plaats'],\n",
       " 'aansluitingsprobleem': ['aansluiting', 's', 'probleem'],\n",
       " 'aansluitingspunt': ['aansluiting', 's', 'punt'],\n",
       " 'aansmering': ['aansmeer', 'ing'],\n",
       " 'aansnede': ['aan', 'snede'],\n",
       " 'aansnee': ['aan', 'snee'],\n",
       " 'aansnijding': ['aansnijd', 'ing'],\n",
       " 'aanspanner': ['aanspan', 'er'],\n",
       " 'aanspanning': ['aanspan', 'ing'],\n",
       " 'aanspoeling': ['aanspoel', 'ing'],\n",
       " 'aanspoelsel': ['aanspoel', 'sel'],\n",
       " 'aanspoorder': ['aanspoor', 'der'],\n",
       " 'aansporing': ['aanspoor', 'ing'],\n",
       " 'aanspraak': ['aan', 'spraak'],\n",
       " 'aansprakelijk': ['aanspreek', 'elijk'],\n",
       " 'aansprakelijkheid': ['aansprakelijk', 'heid'],\n",
       " 'aansprakelijkheidsverzekering': ['aansprakelijkheid', 's', 'verzekering'],\n",
       " 'aanspreekbaar': ['aanspreek', 'baar'],\n",
       " 'aanspreekbaarheid': ['aanspreekbaar', 'heid'],\n",
       " 'aanspreekster': ['aanspreek', 'ster'],\n",
       " 'aanspreektitel': ['aanspreek', 'titel'],\n",
       " 'aanspreekvorm': ['aanspreek', 'vorm'],\n",
       " 'aanspreker': ['aanspreek', 'er'],\n",
       " 'aanspreking': ['aanspreek', 'ing'],\n",
       " 'aanstaand': [''],\n",
       " 'aanstaande': [''],\n",
       " 'aanstalten': [''],\n",
       " 'aanstamper': ['aanstamp', 'er'],\n",
       " 'aanstamping': ['aanstamp', 'ing'],\n",
       " 'aansteekvlam': ['aansteek', 'vlam'],\n",
       " 'aanstekelijk': ['aansteek', 'elijk'],\n",
       " 'aanstekelijkheid': ['aanstekelijk', 'heid'],\n",
       " 'aansteker': ['aansteek', 'er'],\n",
       " 'aansteking': ['aansteek', 'ing'],\n",
       " 'aansteller': ['aanstel', 'er'],\n",
       " 'aanstellerig': ['aanstel', 'erig'],\n",
       " 'aanstellerigheid': ['aanstellerig', 'heid'],\n",
       " 'aanstellerij': ['aanstel', 'erij'],\n",
       " 'aanstelleritis': [''],\n",
       " 'aanstelling': ['aanstel', 'ing'],\n",
       " 'aanstellingsbeleid': ['aanstelling', 's', 'beleid'],\n",
       " 'aanstellingsbrief': ['aanstelling', 's', 'brief'],\n",
       " 'aanstelster': ['aanstel', 'ster'],\n",
       " 'aanstichter': ['aansticht', 'er'],\n",
       " 'aanstichting': ['aansticht', 'ing'],\n",
       " 'aanstichtster': ['aansticht', 'ster'],\n",
       " 'aanstipping': ['aanstip', 'ing'],\n",
       " 'aanstoker': ['aanstook', 'er'],\n",
       " 'aanstonds': [''],\n",
       " 'aanstookster': ['aanstook', 'ster'],\n",
       " 'aanstoot': ['aan', 'stoot'],\n",
       " 'aanstorting': ['aanstort', 'ing'],\n",
       " 'aanstotelijk': ['aanstoot', 'elijk'],\n",
       " 'aanstotelijkheid': ['aanstotelijk', 'heid'],\n",
       " 'aanstotend': [''],\n",
       " 'aanstoting': ['aanstoot', 'ing'],\n",
       " 'aanstreping': ['aanstreep', 'ing'],\n",
       " 'aanstuiving': ['aanstuif', 'ing'],\n",
       " 'aantal': ['aan', 'tal'],\n",
       " 'aantasting': ['aantast', 'ing'],\n",
       " 'aanteelt': [''],\n",
       " 'aantekenaar': ['aanteken', 'aar'],\n",
       " 'aantekenboek': ['aanteken', 'boek'],\n",
       " 'aantekengeld': ['aanteken', 'geld'],\n",
       " 'aantekening': ['aanteken', 'ing'],\n",
       " 'aantekeningspartij': ['aantekening', 's', 'partij'],\n",
       " 'aantekenkantoor': ['aanteken', 'kantoor'],\n",
       " 'aantekenpartij': ['aanteken', 'partij'],\n",
       " 'aantekenrecht': ['aanteken', 'recht'],\n",
       " 'aantekenschrift': ['aanteken', 'schrift'],\n",
       " 'aanteling': ['aanteel', 'ing'],\n",
       " 'aantijgen': [''],\n",
       " 'aantijger': ['aantijg', 'er'],\n",
       " 'aantijging': ['aantijg', 'ing'],\n",
       " 'Aantjes': [''],\n",
       " 'aantocht': [''],\n",
       " 'aantonend': [''],\n",
       " 'aantoning': ['aantoon', 'ing'],\n",
       " 'aantoonbaar': ['aantoon', 'baar'],\n",
       " 'aantoonbaarheid': ['aantoonbaar', 'heid'],\n",
       " 'aantrede': [''],\n",
       " 'aantree': [''],\n",
       " 'aantreeplaats': ['aantreed', 'plaats'],\n",
       " 'aantrek': [''],\n",
       " 'aantrekkelijk': ['aantrek', 'elijk'],\n",
       " 'aantrekkelijkheid': ['aantrekkelijk', 'heid'],\n",
       " 'aantrekker': ['aantrek', 'er'],\n",
       " 'aantrekking': ['aantrek', 'ing'],\n",
       " 'aantrekkingskracht': ['aantrekking', 's', 'kracht'],\n",
       " 'aantrekkingsvermogen': ['aantrekking', 's', 'vermogen'],\n",
       " 'aantrouwing': ['aan', 'trouw', 'ing'],\n",
       " 'aanvaarden': [''],\n",
       " 'aanvaardbaar': ['aanvaard', 'baar'],\n",
       " 'aanvaardbaarheid': ['aanvaardbaar', 'heid'],\n",
       " 'aanvaarding': ['aanvaard', 'ing'],\n",
       " 'aanvaardingsproces': ['aanvaarding', 's', 'proces'],\n",
       " 'aanvaarpaal': ['aanvaar', 'paal'],\n",
       " 'aanvaart': ['aan', 'vaart'],\n",
       " 'aanval': [''],\n",
       " 'aanvallend': [''],\n",
       " 'aanvallenderwijs': ['aanval', 'enderwijs'],\n",
       " 'aanvallenderwijze': ['aanval', 'enderwijze'],\n",
       " 'aanvaller': ['aanval', 'er'],\n",
       " 'aanvallig': ['aanval', 'ig'],\n",
       " 'aanvalligheid': ['aanvallig', 'heid'],\n",
       " 'aanvalsactie': ['aanval', 's', 'actie'],\n",
       " 'aanvalsbasis': ['aanval', 's', 'basis'],\n",
       " 'aanvalsbevel': ['aanval', 's', 'bevel'],\n",
       " 'aanvalscolonne': ['aanval', 's', 'colonne'],\n",
       " 'aanvalsdrift': ['aanval', 's', 'drift'],\n",
       " 'aanvalsfront': ['aanval', 's', 'front'],\n",
       " 'aanvalskracht': ['aanval', 's', 'kracht'],\n",
       " 'aanvalskreet': ['aanval', 's', 'kreet'],\n",
       " 'aanvalslinie': ['aanval', 's', 'linie'],\n",
       " 'aanvalsoorlog': ['aanval', 's', 'oorlog'],\n",
       " 'aanvalsplan': ['aanval', 's', 'plan'],\n",
       " 'aanvalspositie': ['aanval', 's', 'positie'],\n",
       " 'aanvalssein': ['aanval', 's', 'sein'],\n",
       " 'aanvalstactiek': ['aanval', 's', 'tactiek'],\n",
       " 'aanvalsteken': ['aanval', 's', 'teken'],\n",
       " 'aanvalster': ['aanval', 'ster'],\n",
       " 'aanvalswapen': ['aanval', 's', 'wapen'],\n",
       " 'aanvalswijs': ['aanval', 's', 'wijs'],\n",
       " 'aanvalswijze': ['aanval', 's', 'wijze'],\n",
       " 'aanvang': [''],\n",
       " 'aanvanger': ['aanvang', 'er'],\n",
       " 'aanvangsdatum': ['aanvang', 's', 'datum'],\n",
       " 'aanvangsjaar': ['aanvang', 's', 'jaar'],\n",
       " 'aanvangsklas': ['aanvang', 's', 'klas'],\n",
       " 'aanvangsklasse': ['aanvang', 's', 'klasse'],\n",
       " 'aanvangsperiode': ['aanvang', 's', 'periode'],\n",
       " 'aanvangspunt': ['aanvang', 's', 'punt'],\n",
       " 'aanvangssalaris': ['aanvang', 's', 'salaris'],\n",
       " 'aanvangssituatie': ['aanvang', 's', 'situatie'],\n",
       " 'aanvangssnelheid': ['aanvang', 's', 'snelheid'],\n",
       " 'aanvangsstadium': ['aanvang', 's', 'stadium'],\n",
       " 'aanvangstijd': ['aanvang', 's', 'tijd'],\n",
       " 'aanvangstijdstip': ['aanvang', 's', 'tijdstip'],\n",
       " 'aanvangsuur': ['aanvang', 's', 'uur'],\n",
       " 'aanvankelijk': ['aanvang', 'elijk'],\n",
       " 'aanvaring': ['aanvaar', 'ing'],\n",
       " 'aanvaringsschot': ['aanvaring', 's', 'schot'],\n",
       " 'aanvatting': ['aanvat', 'ing'],\n",
       " 'aanvechtbaar': ['aanvecht', 'baar'],\n",
       " 'aanvechting': ['aanvecht', 'ing'],\n",
       " 'aanverstorven': ['aan', 'verstorven'],\n",
       " 'aanverwant': ['aan', 'verwant'],\n",
       " 'aanverwante': ['aanverwant', 'e'],\n",
       " 'aanverwantschap': ['aanverwant', 'schap'],\n",
       " 'aanvijl': ['aan', 'vijl'],\n",
       " 'aanvijlsblok': ['aanvijl', 's', 'blok'],\n",
       " 'aanvlieging': ['aanvlieg', 'ing'],\n",
       " 'aanvliegroute': ['aanvlieg', 'route'],\n",
       " 'aanvoegend': [''],\n",
       " 'aanvoeging': ['aanvoeg', 'ing'],\n",
       " 'aanvoegsel': ['aanvoeg', 'sel'],\n",
       " 'aanvoeling': ['aanvoel', 'ing'],\n",
       " 'aanvoelingsvermogen': ['aanvoeling', 's', 'vermogen'],\n",
       " 'aanvoer': [''],\n",
       " 'aanvoerbuis': ['aanvoer', 'buis'],\n",
       " 'aanvoerder': ['aanvoer', 'der'],\n",
       " 'aanvoerhaven': ['aanvoer', 'haven'],\n",
       " 'aanvoering': ['aanvoer', 'ing'],\n",
       " 'aanvoerpijp': ['aanvoer', 'pijp'],\n",
       " 'aanvoerrol': ['aanvoer', 'rol'],\n",
       " 'aanvoerster': ['aanvoer', 'ster'],\n",
       " 'aanvraag': ['aan', 'vraag'],\n",
       " 'aanvraagprocedure': ['aanvraag', 'procedure'],\n",
       " 'aanvraagster': ['aanvraag', 'ster'],\n",
       " 'aanvrage': [''],\n",
       " 'aanvrager': ['aanvraag', 'er'],\n",
       " 'aanvullend': [''],\n",
       " 'aanvulling': ['aanvul', 'ing'],\n",
       " 'aanvullingsbegroting': ['aanvulling', 's', 'begroting'],\n",
       " 'aanvullingsexamen': ['aanvulling', 's', 'examen'],\n",
       " 'aanvullingskohier': ['aanvulling', 's', 'kohier'],\n",
       " 'aanvullingstroepen': ['aanvulling', 's', 'troep'],\n",
       " 'aanvulsel': ['aanvul', 'sel'],\n",
       " 'aanvuring': ['aanvuur', 'ing'],\n",
       " 'aanwas': [''],\n",
       " 'aanwassing': ['aanwas', 'ing'],\n",
       " 'aanwendbaar': ['aanwend', 'baar'],\n",
       " 'aanwendbaarheid': ['aanwendbaar', 'heid'],\n",
       " 'aanwending': ['aanwend', 'ing'],\n",
       " 'aanwendingsmogelijkheid': ['aanwending', 's', 'mogelijkheid'],\n",
       " 'aanwenning': ['aanwen', 'ing'],\n",
       " 'aanwensel': ['aanwen', 'sel'],\n",
       " 'aanwerver': ['aanwerf', 'er'],\n",
       " 'aanwerving': ['aanwerf', 'ing'],\n",
       " 'aanwezend': [''],\n",
       " 'aanwezig': [''],\n",
       " 'aanwezige': [''],\n",
       " 'aanwezigheid': ['aanwezig', 'heid'],\n",
       " 'aanwezigheidslijst': ['aanwezigheid', 's', 'lijst'],\n",
       " 'aanwijsbaar': ['aanwijs', 'baar'],\n",
       " 'aanwijsstok': ['aanwijs', 'stok'],\n",
       " 'aanwijzend': [''],\n",
       " 'aanwijzer': ['aanwijs', 'er'],\n",
       " 'aanwijzing': ['aanwijs', 'ing'],\n",
       " 'aanwijzingsbevoegdheid': ['aanwijzing', 's', 'bevoegdheid'],\n",
       " 'aanwijzingsbord': ['aanwijzing', 's', 'bord'],\n",
       " 'aanwinning': ['aanwin', 'ing'],\n",
       " 'aanwinst': ['aanwin', 'st'],\n",
       " 'aanwonenden': [''],\n",
       " 'aanwrijving': ['aanwrijf', 'ing'],\n",
       " 'aanzeg': [''],\n",
       " 'aanzegger': ['aanzeg', 'er'],\n",
       " 'aanzegging': ['aanzeg', 'ing'],\n",
       " 'aanzeiling': ['aanzeil', 'ing'],\n",
       " 'aanzet': ['aan', 'zet'],\n",
       " 'aanzethamer': ['aanzet', 'hamer'],\n",
       " 'aanzetriem': ['aanzet', 'riem'],\n",
       " 'aanzetschroef': ['aanzet', 'schroef'],\n",
       " 'aanzetsel': ['aanzet', 'sel'],\n",
       " 'aanzetslinger': ['aanzet', 'slinger'],\n",
       " 'aanzetstaal': ['aanzet', 'staal'],\n",
       " 'aanzetsteen': ['aanzet', 'steen'],\n",
       " 'aanzetster': ['aanzet', 'ster'],\n",
       " 'aanzetstok': ['aanzet', 'stok'],\n",
       " 'aanzetstuk': ['aanzet', 'stuk'],\n",
       " 'aanzetter': ['aanzet', 'er'],\n",
       " 'aanzetting': ['aanzet', 'ing'],\n",
       " 'aanzetvijl': ['aanzet', 'vijl'],\n",
       " 'aanzicht': [''],\n",
       " 'aanzien': [''],\n",
       " 'aanziend': [''],\n",
       " 'aanzienlijk': ['aanzien', 'lijk'],\n",
       " 'aanzienlijkheid': ['aanzienlijk', 'heid'],\n",
       " 'aanzijn': ['aan', 'zijn'],\n",
       " 'aanzoek': [''],\n",
       " 'aanzoeker': ['aanzoek', 'er'],\n",
       " 'aanzuiging': ['aanzuig', 'ing'],\n",
       " 'aanzuivering': ['aanzuiver', 'ing'],\n",
       " 'aanzwellend': [''],\n",
       " 'aap': ['aap'],\n",
       " 'aapje': [''],\n",
       " 'aapachtig': ['aap', 'achtig'],\n",
       " 'aapjessnuif': ['aap', 's', 'snuif'],\n",
       " 'aapjeszeep': ['aap', 's', 'zeep'],\n",
       " 'aapmens': ['aap', 'mens'],\n",
       " 'aar': ['aar'],\n",
       " 'aarbussel': ['aar', 'bussel'],\n",
       " 'aard': ['aard'],\n",
       " 'aarden': ['aarde', 'en'],\n",
       " 'aardachtig': ['aard', 'achtig'],\n",
       " 'aardaker': ['aard', 'aker'],\n",
       " 'aardalkalimetalen': [''],\n",
       " 'aardamandel': ['aarde', 'amandel'],\n",
       " 'aardappel': ['aarde', 'appel'],\n",
       " 'aardappelakker': ['aardappel', 'akker'],\n",
       " 'aardappelbak': ['aardappel', 'bak'],\n",
       " 'aardappelboer': ['aardappel', 'boer'],\n",
       " 'aardappelbovist': ['aardappel', 'bovist'],\n",
       " 'aardappelbuik': ['aardappel', 'buik'],\n",
       " 'aardappelcampagne': ['aardappel', 'campagne'],\n",
       " 'aardappelcroquet': ['aardappel', 'croquet'],\n",
       " 'aardappeldeeg': ['aardappel', 'deeg'],\n",
       " 'aardappelhakker': ['aardappel', 'hak', 'er'],\n",
       " 'aardappelkelder': ['aardappel', 'kelder'],\n",
       " 'aardappelkever': ['aardappel', 'kever'],\n",
       " 'aardappelknol': ['aardappel', 'knol'],\n",
       " 'aardappelkriel': ['aardappel', 'kriel'],\n",
       " 'aardappelmeel': ['aardappel', 'meel'],\n",
       " 'aardappelmesje': ['aardappel', 'mes'],\n",
       " 'aardappelmoeheid': ['aardappel', 'moeheid'],\n",
       " 'aardappelpan': ['aardappel', 'pan'],\n",
       " 'aardappelplant': ['aardappel', 'plant'],\n",
       " 'aardappelpoter': ['aardappel', 'poot', 'er'],\n",
       " 'aardappelpuree': ['aardappel', 'puree'],\n",
       " 'aardappelrooier': ['aardappelrooi', 'er'],\n",
       " 'aardappelsalade': ['aardappel', 'salade'],\n",
       " 'aardappelschijf': ['aardappel', 'schijf'],\n",
       " 'aardappelschiller': ['aardappel', 'schil', 'er'],\n",
       " 'aardappelschillertje': [''],\n",
       " 'aardappelschilmesje': ['aardappel', 'schilmes'],\n",
       " 'aardappelsoep': ['aardappel', 'soep'],\n",
       " 'aardappelstijfsel': ['aardappel', 'stijfsel'],\n",
       " 'aardappelstroop': ['aardappel', 'stroop'],\n",
       " 'aardappelveld': ['aardappel', 'veld'],\n",
       " 'aardappelvlokken': ['aardappel', 'vlok'],\n",
       " 'aardappelziekte': ['aardappel', 'ziekte'],\n",
       " 'aardas': ['aarde', 'as'],\n",
       " 'aardatmosfeer': ['aarde', 'atmosfeer'],\n",
       " 'aardbaan': ['aarde', 'baan'],\n",
       " 'aardbei': [''],\n",
       " 'aardbeiboom': ['aardbei', 'boom'],\n",
       " 'aardbeienbed': ['aardbei', 'en', 'bed'],\n",
       " 'aardbeiengelei': ['aardbei', 'en', 'gelei'],\n",
       " 'aardbeienijs': ['aardbei', 'en', 'ijs'],\n",
       " 'aardbeienjam': ['aardbei', 'en', 'jam'],\n",
       " 'aardbeienneus': ['aardbei', 'en', 'neus'],\n",
       " 'aardbeiensorbet': ['aardbei', 'en', 'sorbet'],\n",
       " 'aardbeientaart': ['aardbei', 'en', 'taart'],\n",
       " 'aardbeienteelt': ['aardbei', 'en', 'teelt'],\n",
       " 'aardbeientijd': ['aardbei', 'en', 'tijd'],\n",
       " 'aardbeiklaver': ['aardbei', 'klaver'],\n",
       " 'aardbeiloof': ['aardbei', 'loof'],\n",
       " 'aardbeiplant': ['aardbei', 'plant'],\n",
       " 'aardbeistruik': ['aardbei', 'struik'],\n",
       " 'aardberging': ['aarde', 'berg', 'ing'],\n",
       " 'aardbeving': ['aarde', 'beving'],\n",
       " 'aardbevingsgebied': ['aardbeving', 's', 'gebied'],\n",
       " 'aardbevingsgolf': ['aardbeving', 's', 'golf'],\n",
       " 'aardbevingsgordel': ['aardbeving', 's', 'gordel'],\n",
       " 'aardbevingshaard': ['aardbeving', 's', 'haard'],\n",
       " 'aardbevingsmeter': ['aardbeving', 's', 'meet', 'er'],\n",
       " 'aardbewoner': ['aarde', 'bewoon', 'er'],\n",
       " 'aardbewoonster': ['aarde', 'bewoon', 'ster'],\n",
       " 'aardbij': ['aarde', 'bij'],\n",
       " 'aardbodem': ['aarde', 'bodem'],\n",
       " 'aardbol': ['aarde', 'bol'],\n",
       " 'aardboog': ['aarde', 'boog'],\n",
       " 'aardboor': ['aarde', 'boor'],\n",
       " 'aardbrand': ['aarde', 'brand'],\n",
       " 'aardbuil': ['aarde', 'buil'],\n",
       " 'aarddraad': ['aard', 'draad'],\n",
       " 'aardduivel': ['aarde', 'duivel'],\n",
       " 'aarde': ['aarde'],\n",
       " 'aardebaan': ['aarde', 'baan'],\n",
       " 'aardedonker': ['aarde', 'donker'],\n",
       " 'aardegoed': ['aarde', 'goed'],\n",
       " 'aardelektrode': ['aard', 'elektrode'],\n",
       " 'Aardenne': [''],\n",
       " 'aardeteken': ['aarde', 'teken'],\n",
       " 'aardeweg': ['aarde', 'weg'],\n",
       " 'aardewerk': [''],\n",
       " 'aardewerken': ['aardewerk', 'en'],\n",
       " 'aardewerker': ['aardewerk', 'er'],\n",
       " 'aardewerkfabriek': ['aardewerk', 'fabriek'],\n",
       " 'aardewerkschuit': ['aardewerk', 'schuit'],\n",
       " 'aardewerkwinkel': ['aarde', 'werkwinkel'],\n",
       " 'aardewind': [''],\n",
       " 'aardfout': ['aard', 'fout'],\n",
       " 'aardgas': ['aarde', 'gas'],\n",
       " 'aardgasbaten': ['aardgas', 'baat'],\n",
       " 'aardgasbel': ['aardgas', 'bel'],\n",
       " 'aardgasnet': ['aardgas', 'net'],\n",
       " 'aardgasopbrengst': ['aardgas', 'opbrengst'],\n",
       " 'aardgastanker': ['aardgas', 'tanker'],\n",
       " 'aardgasterminal': ['aardgas', 'terminal'],\n",
       " 'aardgeest': ['aarde', 'geest'],\n",
       " 'aardgewas': ['aarde', 'gewas'],\n",
       " 'aardglobe': ['aarde', 'globe'],\n",
       " 'aardgoed': ['aarde', 'goed'],\n",
       " 'aardgordel': ['aarde', 'gordel'],\n",
       " 'aardhars': ['aarde', 'hars'],\n",
       " 'aardhommel': ['aarde', 'hommel'],\n",
       " 'aardhoop': ['aarde', 'hoop'],\n",
       " 'aardig': [''],\n",
       " 'aardigheid': ['aardig', 'heid'],\n",
       " 'aardigjes': ['aardig', 'jes'],\n",
       " 'aarding': ['aard', 'ing'],\n",
       " 'aardkastanje': ['aarde', 'kastanje'],\n",
       " 'aardkern': ['aarde', 'kern'],\n",
       " 'aardklem': ['aard', 'klem'],\n",
       " 'aardklomp': ['aarde', 'klomp'],\n",
       " 'aardklont': ['aarde', 'klont'],\n",
       " 'aardkloot': ['aarde', 'kloot'],\n",
       " 'aardkluit': ['aarde', 'kluit'],\n",
       " 'aardkorst': ['aarde', 'korst'],\n",
       " 'aardkrekel': ['aarde', 'krekel'],\n",
       " 'aardkromming': ['aarde', 'kromming'],\n",
       " 'aardkuil': ['aarde', 'kuil'],\n",
       " 'aardkunde': ['aarde', 'kunde'],\n",
       " 'aardkundig': ['aardkunde', 'ig'],\n",
       " 'aardkundige': [''],\n",
       " 'aardlaag': ['aarde', 'laag'],\n",
       " 'aardleiding': ['aarde', 'leiding'],\n",
       " 'aardlevering': ['aarde', 'levering'],\n",
       " 'aardmagnetisch': [''],\n",
       " 'aardmagnetisme': ['aarde', 'magnetisme'],\n",
       " 'aardmannetje': ['aarde', 'man'],\n",
       " 'aardmassa': ['aarde', 'massa'],\n",
       " 'aardmeetkunde': ['aarde', 'meetkunde'],\n",
       " 'aardmeetkunst': [''],\n",
       " 'aardmetalen': ['aarde', 'metaal'],\n",
       " 'aardmeting': ['aarde', 'meet', 'ing'],\n",
       " 'aardmijt': ['aarde', 'mijt'],\n",
       " 'aardmolm': ['aarde', 'molm'],\n",
       " 'aardmuis': ['aarde', 'muis'],\n",
       " 'aardnoot': ['aarde', 'noot'],\n",
       " 'aardnotenolie': ['aardnoot', 'en', 'olie'],\n",
       " 'aardolie': ['aarde', 'olie'],\n",
       " 'aardolieprodukt': ['aardolie', 'produkt'],\n",
       " 'aardoppervlak': ['aarde', 'oppervlak'],\n",
       " 'aardoppervlakte': ['aarde', 'oppervlakte'],\n",
       " 'aardpeer': ['aarde', 'peer'],\n",
       " 'aardpek': ['aarde', 'pek'],\n",
       " 'aardpijler': [''],\n",
       " 'aardplooi': ['aarde', 'plooi'],\n",
       " 'aardpool': ['aarde', 'pool'],\n",
       " 'aardprofiel': ['aarde', 'profiel'],\n",
       " 'aardrijk': ['aarde', 'rijk'],\n",
       " 'aardrijkskunde': ['aardrijk', 's', 'kunde'],\n",
       " 'aardrijkskundeboek': ['aardrijkskunde', 'boek'],\n",
       " 'aardrijkskundig': ['aardrijkskunde', 'ig'],\n",
       " 'aardrijkskundige': [''],\n",
       " 'aardrol': ['aarde', 'rol'],\n",
       " 'aardrook': ['aarde', 'rook'],\n",
       " 'aardrups': ['aarde', 'rups'],\n",
       " 'aards': ['aarde', 's'],\n",
       " 'aardschaduw': ['aarde', 'schaduw'],\n",
       " 'aardschijn': ['aarde', 'schijn'],\n",
       " 'aardschok': ['aarde', 'schok'],\n",
       " 'aardschors': ['aarde', 'schors'],\n",
       " 'aardschudding': ['aarde', 'schudding'],\n",
       " 'aardsgezind': ['aarde', 's', 'gezind'],\n",
       " 'aardsgezindheid': ['aardsgezind', 'heid'],\n",
       " 'aardsheid': ['aards', 'heid'],\n",
       " 'aardslak': ['aarde', 'slak'],\n",
       " 'aardslang': ['aarde', 'slang'],\n",
       " 'aardsluiting': ['aarde', 'sluiting'],\n",
       " 'aardspin': ['aarde', 'spin'],\n",
       " 'aardster': ['aarde', 'ster'],\n",
       " 'aardstorting': ['aarde', 'storting'],\n",
       " 'aardstraal': ['aarde', 'straal'],\n",
       " 'aardstralenkastje': ['aardstraal', 'en', 'kast'],\n",
       " 'aardstraling': ['aarde', 'straling'],\n",
       " 'aardstroom': ['aarde', 'stroom'],\n",
       " 'aardtor': ['aarde', 'tor'],\n",
       " 'aardtrilling': ['aarde', 'trilling'],\n",
       " 'aardvarken': ['aarde', 'varken'],\n",
       " 'aardvast': ['aarde', 'vast'],\n",
       " 'aardveil': ['aarde', 'veil'],\n",
       " 'aardverbinding': ['aarde', 'verbinding'],\n",
       " 'aardverschuiving': ['aarde', 'verschuiving'],\n",
       " 'aardverf': ['aarde', 'verf'],\n",
       " 'aardvlo': ['aarde', 'vlo'],\n",
       " 'aardvork': ['aarde', 'vork'],\n",
       " 'aardvrucht': ['aarde', 'vrucht'],\n",
       " 'aardwarmte': ['aarde', 'warmte'],\n",
       " 'aardwas': ['aarde', 'was'],\n",
       " 'aardwerk': ['aarde', 'werk'],\n",
       " 'aardwerker': ['aardwerk', 'er'],\n",
       " 'aardwetenschappen': ['aarde', 'wetenschap'],\n",
       " 'aardwind': [''],\n",
       " 'aardwinde': ['aarde', 'winde'],\n",
       " 'aardwolf': ['aarde', 'wolf'],\n",
       " 'aardworm': ['aarde', 'worm'],\n",
       " 'Aargau': [''],\n",
       " 'Aarlen': [''],\n",
       " 'aarling': [''],\n",
       " 'Aaron': [''],\n",
       " 'Aarschot': [''],\n",
       " 'aarsdarm': ['aars', 'darm'],\n",
       " 'aarsgat': ['aars', 'gat'],\n",
       " 'aarskramp': ['aars', 'kramp'],\n",
       " 'aarsmade': ['aars', 'made'],\n",
       " 'aarsopening': ['aars', 'opening'],\n",
       " 'aarsvin': ['aars', 'vin'],\n",
       " 'Aart': [''],\n",
       " 'aartsbedrieger': ['aarts', 'bedrieger'],\n",
       " 'aartsbedriegster': ['aarts', 'bedriegster'],\n",
       " 'aartsbisdom': ['aarts', 'bisdom'],\n",
       " 'aartsbisschop': ['aarts', 'bisschop'],\n",
       " 'aartsbisschoppelijk': ['aartsbisschop', 'elijk'],\n",
       " 'aartsbooswicht': ['aarts', 'booswicht'],\n",
       " 'aartsbroederschap': ['aarts', 'broederschap'],\n",
       " 'aartsconservatief': ['aarts', 'conservatief'],\n",
       " 'aartsdeugniet': ['aarts', 'deugniet'],\n",
       " 'aartsdiaken': ['aarts', 'diaken'],\n",
       " 'aartsdiakenschap': ['aartsdiaken', 'schap'],\n",
       " 'aartsdiocees': ['aarts', 'diocees'],\n",
       " 'aartsdom': ['aarts', 'dom'],\n",
       " 'aartsdomkop': ['aarts', 'domkop'],\n",
       " 'aartsengel': ['aarts', 'engel'],\n",
       " 'aartshertog': ['aarts', 'hertog'],\n",
       " 'aartshertogdom': ['aartshertog', 'dom'],\n",
       " 'aartshertogelijk': ['aarts', 'hertogelijk'],\n",
       " 'aartshertogin': ['aarts', 'hertogin'],\n",
       " 'aartshuichelaar': ['aarts', 'huichelaar'],\n",
       " 'aartskanselier': ['aarts', 'kanselier'],\n",
       " 'aartsketter': ['aarts', 'ketter'],\n",
       " 'aartslelijk': ['aarts', 'lelijk'],\n",
       " 'aartsleugenaar': ['aarts', 'leugenaar'],\n",
       " 'aartsliefhebber': ['aarts', 'liefhebber'],\n",
       " 'aartslui': ['aarts', 'lui'],\n",
       " 'aartsluiaard': ['aartslui', 'aard'],\n",
       " 'aartsmoeilijk': ['aarts', 'moeilijk'],\n",
       " 'aartspriester': ['aarts', 'priester'],\n",
       " 'aartspriesterschap': ['aartspriester', 'schap'],\n",
       " 'aartsrivaal': ['aarts', 'rivaal'],\n",
       " 'aartsschelm': ['aarts', 'schelm'],\n",
       " 'aartstwijfelaar': ['aarts', 'twijfelaar'],\n",
       " 'aartsvader': ['aarts', 'vader'],\n",
       " 'aartsvaderlijk': ['aartsvader', 'lijk'],\n",
       " 'aartsverrader': ['aarts', 'verrader'],\n",
       " 'aartsvijand': ['aarts', 'vijand'],\n",
       " 'aarvormig': ['aar', 'vorm', 'ig'],\n",
       " 'aars': ['aars'],\n",
       " 'aarzeling': ['aarzel', 'ing'],\n",
       " 'aasbloem': ['aas', 'bloem'],\n",
       " 'aasdier': ['aas', 'dier'],\n",
       " 'aaseter': ['aas', 'eet', 'er'],\n",
       " 'aasgier': ['aas', 'gier'],\n",
       " 'aasjager': ['aas', 'jaag', 'er'],\n",
       " 'aaskever': ['aas', 'kever'],\n",
       " 'aastor': ['aas', 'tor'],\n",
       " 'aasvlieg': ['aas', 'vlieg'],\n",
       " 'aasvogel': ['aas', 'vogel'],\n",
       " 'aaszak': ['aas', 'zak'],\n",
       " 'aatje': ['aat'],\n",
       " 'aas': ['aas'],\n",
       " 'aasje': ['aas'],\n",
       " 'Ab': [''],\n",
       " 'abactis': [''],\n",
       " 'abacus': [''],\n",
       " 'abandon': [''],\n",
       " 'abandonnement': ['abandonneer', 'ement'],\n",
       " 'abat-jour': [''],\n",
       " 'abattoir': [''],\n",
       " 'abbatiaal': ['abt', 'aal'],\n",
       " 'abbe': ['abbe'],\n",
       " 'abberdaan': [''],\n",
       " 'Abbeville': [''],\n",
       " 'abbreviatie': ['abbrevieer', 'atie'],\n",
       " 'abbreviatuur': ['abbrevieer', 'atuur'],\n",
       " 'abbrevieren': [''],\n",
       " 'abc': [''],\n",
       " 'abc-boek': ['abc', 'boek'],\n",
       " 'abces': [''],\n",
       " 'Abcoude': [''],\n",
       " 'ABC-wapens': ['abc', 'wapen'],\n",
       " 'Abdallah': [''],\n",
       " 'abdicatie': ['abdiceer', 'atie'],\n",
       " 'abdiceren': [''],\n",
       " 'abdij': [''],\n",
       " 'abdijkerk': ['abdij', 'kerk'],\n",
       " 'abdijschool': ['abdij', 'school'],\n",
       " 'abdijsiroop': ['abdij', 'siroop'],\n",
       " 'abdiqueren': [''],\n",
       " 'abdis': [''],\n",
       " 'abdomen': [''],\n",
       " 'abdominaal': ['abdomen', 'aal'],\n",
       " 'abductie': [''],\n",
       " 'Abe': [''],\n",
       " 'abecedarium': [''],\n",
       " 'abeel': ['abeel'],\n",
       " 'abeelboom': ['abeel', 'boom'],\n",
       " 'abel': [''],\n",
       " 'abelenlaan': ['abeel', 'en', 'laan'],\n",
       " 'Abeltje': [''],\n",
       " 'Aberdeen': [''],\n",
       " 'aberratie': [''],\n",
       " 'Abidjan': [''],\n",
       " 'Abilene': [''],\n",
       " 'A-biljet': ['a', 'biljet'],\n",
       " 'abiturient': [''],\n",
       " 'abituriente': ['abiturient', 'e'],\n",
       " 'abject': [''],\n",
       " 'ablatie': [''],\n",
       " 'ablatief': [''],\n",
       " 'ablativus': [''],\n",
       " 'ablaut': [''],\n",
       " 'ablutie': [''],\n",
       " 'Abma': [''],\n",
       " 'abnormaal': [''],\n",
       " 'abnormaliteit': ['abnormaal', 'iteit'],\n",
       " 'aboleren': [''],\n",
       " 'abolitie': ['aboleer', 'itie'],\n",
       " 'abolitionist': [''],\n",
       " 'abolitionistisch': ['abolitionist', 'isch'],\n",
       " 'A-bom': ['a', 'bom'],\n",
       " 'abominabel': [''],\n",
       " 'abondance': ['abondant', 'nce'],\n",
       " 'abondant': [''],\n",
       " 'abonnee': [''],\n",
       " 'abonneren': [''],\n",
       " 'abonneetelevisie': ['abonnee', 'televisie'],\n",
       " 'abonnement': ['abonneer', 'ement'],\n",
       " 'abonnementhouder': ['abonnement', 'houd', 'er'],\n",
       " 'abonnementhoudster': ['abonnement', 'houd', 'ster'],\n",
       " 'abonnementsconcert': ['abonnement', 's', 'concert'],\n",
       " 'abonnementshonorarium': ['abonnement', 's', 'honorarium'],\n",
       " 'abonnementskaart': ['abonnement', 's', 'kaart'],\n",
       " 'abonnementsprijsverhoging': ['abonnement', 's', 'prijsverhoging'],\n",
       " 'abonnementstarief': ['abonnement', 's', 'tarief'],\n",
       " 'abonnementsvoorstelling': ['abonnement', 's', 'voorstelling'],\n",
       " 'aborigines': [''],\n",
       " 'aborteur': ['aborteer', 'eur'],\n",
       " 'aborteuse': [''],\n",
       " 'abortief': ['abortus', 'ief'],\n",
       " 'abortoir': [''],\n",
       " 'abortus': [''],\n",
       " 'abortuskliniek': ['abortus', 'kliniek'],\n",
       " 'abortuskwestie': ['abortus', 'kwestie'],\n",
       " 'abortuspraktijk': ['abortus', 'praktijk'],\n",
       " 'abortusregeling': ['abortus', 'regeling'],\n",
       " 'abortusvraagstuk': ['abortus', 'vraagstuk'],\n",
       " 'abortuswet': ['abortus', 'wet'],\n",
       " 'abracadabra': [''],\n",
       " ...}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = {}\n",
    "for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d88b4992e5b06b322ead3277a6c0c22aea73de159b15016e3d5eb1aecc84f355"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
